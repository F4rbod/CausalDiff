# @package _global_
dataset:
  _target_: src.data.SyntheticCancerDatasetCollection   # Will be dynamically instantiated
  name: tumor_generator
  coeff: 4                                            # Confounding coefficient (gamma)
  chemo_coeff: ${dataset.coeff}                       # Confounding coefficient of chemotherapy
  radio_coeff: ${dataset.coeff}                       # Confounding coefficient of radiotherapy
  seed: ${exp.seed}
  num_patients:
    train: 10000
    val: 1000
    test: 100
  window_size: 15                                     # Used for biased treatment assignment
  lag: 0                                              # Lag for treatment assignment window
  max_seq_length: 60                                  # Max length of time series
  projection_horizon: 5                               # Range of tau-step-ahead prediction (tau = projection_horizon + 1)
  cf_seq_mode: sliding_treatment                      # sliding_treatment / random_trajectories
  val_batch_size: 4096                                # Batch size for evaluation
  treatment_mode: multiclass                          # multiclass / multilabel -- for RMSN
  holdout_ratio: 0.1

model:
  name: G-Net
  g_net:
    _target_: src.models.gnet.GNet

    # Representation network
    seq_hidden_units: 24                              # Replaced with provided value
    num_layer: 1                                      # Replaced with provided value
    r_size: 18                                        # Replaced with provided value

    # Conditional networks
    fc_hidden_units: 72                               # Replaced with provided value
    num_comp: 1
    mc_samples: 50
    fit_vitals: True
    comp_sizes: []                                    # (Fill in if needed)

    # Other parameters
    batch_size: 256                                   # Replaced with provided value
    dropout_rate: 0.1                                 # Replaced with provided value
    optimizer:
      optimizer_cls: adam
      learning_rate: 0.01                             # Replaced with provided value
      weight_decay: 0.0
      lr_scheduler: False

    tune_hparams: False
    tune_range: 50
    hparams_grid:
    resources_per_trial:

exp:
  update_alpha: False
  unscale_rmse: True
  percentage_rmse: True
  seed: 100
  weights_ema: True
  gpus: [0]                                         # Number/indices of GPUs to use
  logging: True                                     # Enable MLFlow logging
  mlflow_uri: http://127.0.0.1:8081                   # MLFlow server URI
  alpha: 0.01
  beta: 0.99 
  max_epochs: 150
  alpha_rate: exp
  bce_weight: False