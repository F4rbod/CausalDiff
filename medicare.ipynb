{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import zipfile\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from einops import rearrange, reduce, repeat\n",
    "from einops.layers.torch import Rearrange, Reduce\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0.dev20230502+cu118\n",
      "11.8\n",
      "Python 3.11.3\n"
     ]
    }
   ],
   "source": [
    "# show pytorch version and cuda version\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "\n",
    "# show python version\n",
    "!python -V"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moded Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class moded_TimesSeriesAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    A module that computes multi-head attention given query, key, and value tensors for time series data of shape (b, t, f, e)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim: int, num_heads: int):\n",
    "        \"\"\"\n",
    "        Constructor.\n",
    "        \n",
    "        Inputs:\n",
    "        - input_dim: Dimension of the input query, key, and value. We assume they all have\n",
    "          the same dimensions. This is basically the dimension of the embedding.\n",
    "        - num_heads: Number of attention heads\n",
    "        \"\"\"\n",
    "        super(moded_TimesSeriesAttention, self).__init__()\n",
    "\n",
    "        assert embed_dim % num_heads == 0\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dim_per_head = embed_dim // num_heads\n",
    "\n",
    "\n",
    "        self.linear_query = nn.Linear(embed_dim, embed_dim)\n",
    "        self.linear_key = nn.Linear(embed_dim, embed_dim)\n",
    "        self.linear_value = nn.Linear(embed_dim, embed_dim)#(self.num_heads * self.dim_per_head * self.dim_per_head))\n",
    "        self.output_linear = nn.Linear(embed_dim, embed_dim)\n",
    "        self.softmax = nn.Softmax2d()\n",
    "\n",
    "\n",
    "    def forward(self, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor, mask: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        Compute the attended feature representations.\n",
    "        \n",
    "        Inputs:\n",
    "        - query: Tensor of the shape BxTxFXE, where B is the batch size, T is the time dimension, F is the feature dimension, \n",
    "        and E is the embedding dimension\n",
    "        - key: Tensor of the shape BxTxFXE\n",
    "        - value: Tensor of the shape BxTxFXE\n",
    "        - mask: Tensor indicating where the attention should *not* be performed\n",
    "        \"\"\"\n",
    "        b = query.shape[0]\n",
    "        t = query.shape[1]\n",
    "        f = query.shape[2]\n",
    "        e = query.shape[3]\n",
    "        d = self.dim_per_head\n",
    "        h = self.num_heads\n",
    "\n",
    "\n",
    "        query_linear = self.linear_query(query)\n",
    "        key_linear = self.linear_key(key)\n",
    "        value_linear = self.linear_value(value)\n",
    "\n",
    "        query_reshaped = query_linear.reshape(b, t, f, self.num_heads, self.dim_per_head)\n",
    "        key_reshaped = key_linear.reshape(b, t, f, self.num_heads, self.dim_per_head)\n",
    "        value_reshaped = value_linear.reshape(b, t, f, self.num_heads, self.dim_per_head)#, self.dim_per_head)\n",
    "\n",
    "        query_reshaped = query_reshaped.permute(0, 3, 1, 2, 4) # BxHxTxFxD\n",
    "        key_reshaped = key_reshaped.permute(0, 3, 1, 2, 4) # BxHxTxFxD\n",
    "        value_reshaped = value_reshaped.permute(0, 3, 1, 2, 4)#, 5) # BxHxTxFxDxD\n",
    "\n",
    "\n",
    "        kq = torch.einsum(\"bhtfd,bhxyd->bhtfxy\", key_reshaped, query_reshaped)\n",
    "\n",
    "        dot_prod_scores = kq/math.sqrt(self.dim_per_head)\n",
    "\n",
    "\n",
    "        #softmax across last 2 features (use softmax2d)\n",
    "        dot_prod_scores = dot_prod_scores.reshape(b*h, t*f, t, f)\n",
    "        dot_prod_scores = self.softmax(dot_prod_scores)\n",
    "        dot_prod_scores = dot_prod_scores.reshape(b, h, t, f, t, f)\n",
    "\n",
    "        out = torch.einsum(\"bhtfxy,bhtfd->bhtfd\",\n",
    "                           dot_prod_scores, value_reshaped)\n",
    "        out = out.permute(0, 2, 3, 1, 4).reshape(b, t, f, e)\n",
    "        out = self.output_linear(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class moded_TransformerEncoderCell(nn.Module):\n",
    "    \"\"\"\n",
    "    A single cell (unit) for the Transformer encoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim: int, num_heads: int, ff_dim: int, dropout: float):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - embed_dim: embedding dimension for each element in the time series data\n",
    "        - num_heads: Number of attention heads in a multi-head attention module\n",
    "        - ff_dim: The hidden dimension for a feedforward network\n",
    "        - dropout: Dropout ratio for the output of the multi-head attention and feedforward\n",
    "          modules.\n",
    "        \"\"\"\n",
    "        super(moded_TransformerEncoderCell, self).__init__()\n",
    "\n",
    "        self.time_series_attention = moded_TimesSeriesAttention(embed_dim, num_heads)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(embed_dim, ff_dim)\n",
    "        self.linear2 = nn.Linear(ff_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - x: Tensor of the shape BxTxFXE, where B is the batch size, T is the time dimension, F is the feature dimension,\n",
    "        and E is the embedding dimension\n",
    "        - mask: Tensor for multi-head attention\n",
    "        \"\"\"\n",
    "\n",
    "        attention2 = self.time_series_attention(x, x, x, mask)\n",
    "        attention = x + self.dropout1(attention2)\n",
    "        attention = self.layer_norm(attention)\n",
    "\n",
    "        attention2 = self.linear2(self.dropout(\n",
    "            self.activation(self.linear1(attention))))\n",
    "        attention = attention + self.dropout2(attention2)\n",
    "        attention = self.layer_norm(attention)\n",
    "\n",
    "        return attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class moded_TransformerEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A full encoder consisting of a set of TransformerEncoderCell.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim: int, num_heads: int, ff_dim: int, num_cells: int, dropout: float = 0.1):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - embed_dim: embedding dimension for each element in the time series data\n",
    "        - num_heads: Number of attention heads in a multi-head attention module\n",
    "        - ff_dim: The hidden dimension for a feedforward network\n",
    "        - num_cells: Number of time series attention cells in the encoder\n",
    "        - dropout: Dropout ratio for the output of the multi-head attention and feedforward\n",
    "          modules.\n",
    "        \"\"\"\n",
    "        super(moded_TransformerEncoder, self).__init__()\n",
    "\n",
    "        self.norm = None\n",
    "\n",
    "        self.encoder_modules = nn.ModuleList(moded_TransformerEncoderCell(\n",
    "            embed_dim, num_heads, ff_dim, dropout) for _ in range(num_cells))\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - x: Tensor of the shape BxTxFXE, where B is the batch size, T is the time dimension, F is the feature dimension,\n",
    "        and E is the embedding dimension\n",
    "        - mask: Tensor for multi-head attention\n",
    "        \n",
    "        Return:\n",
    "        - y: Tensor of the shape BxTxFXE\n",
    "        \"\"\"\n",
    "\n",
    "        #run encoder modules and add residual connections\n",
    "        for encoder_module in self.encoder_modules:\n",
    "            x = encoder_module(x, mask)\n",
    "\n",
    "        y = x\n",
    "\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimesSeriesAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_in,\n",
    "        d_out,\n",
    "        nh=8,\n",
    "        dk=0,\n",
    "        dv=0,\n",
    "        dd=0,\n",
    "        kernel_size=(3, 7),\n",
    "        stride=(1,1,1),\n",
    "        kernel_type='VplusR',  # ['V', 'R', 'VplusR']\n",
    "        feat_type='VplusR',  # ['V', 'R', 'VplusR']\n",
    "    ):\n",
    "        super(TimesSeriesAttention, self).__init__()\n",
    "\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.nh = nh\n",
    "        self.dv = dv = d_out // nh if dv == 0 else dv\n",
    "        self.dk = dk = dv if dk == 0 else dk\n",
    "        self.dd = dd = dk if dd == 0 else dd\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.kernel_type = kernel_type\n",
    "        self.feat_type = feat_type\n",
    "\n",
    "        assert self.kernel_type in [\n",
    "            'V', 'R', 'VplusR'], \"Not implemented involution type: {}\".format(self.kernel_type)\n",
    "        assert self.feat_type in [\n",
    "            'V', 'R', 'VplusR'], \"Not implemented feature type: {}\".format(self.feat_type)\n",
    "\n",
    "        # print(\"d_in: {}, d_out: {}, nh: {}, dk: {}, dv: {}, dd:{}, kernel_size: {}, kernel_type: {}, feat_type: {}\"\n",
    "        #       .format(d_in, d_out, nh, dk, dv, self.dd, kernel_size, kernel_type, feat_type))\n",
    "\n",
    "        self.ksize = ksize = kernel_size[0] * kernel_size[1]\n",
    "        self.pad = pad = tuple(k//2 for k in kernel_size)\n",
    "\n",
    "        # hidden dimension\n",
    "        d_hid = nh * dk + dv if self.kernel_type == 'V' else nh * dk + dk + dv\n",
    "\n",
    "        # Linear projection\n",
    "        #self.projection = nn.Conv2d(d_in, d_hid, 1, bias=False)\n",
    "        self.projection_linear = nn.Sequential(\n",
    "            nn.Linear(d_in, d_hid, bias=False),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Linear(d_hid, d_hid, bias=False)\n",
    "        )\n",
    "\n",
    "        # Intervolution Kernel\n",
    "        if self.kernel_type == 'V':\n",
    "            self.H2 = nn.Conv2d(1, dd, kernel_size,\n",
    "                                padding=self.pad, bias=False)\n",
    "        elif self.kernel_type == 'R':\n",
    "            self.H1 = nn.Conv2d(dk, dk*dd, kernel_size,\n",
    "                                padding=self.pad, groups=dk, bias=False)\n",
    "            self.H2 = nn.Conv2d(1, dd, kernel_size,\n",
    "                                padding=self.pad, bias=False)\n",
    "        elif self.kernel_type == 'VplusR':\n",
    "            self.P1 = nn.Parameter(torch.randn(dk, dd).unsqueeze(\n",
    "                0)*np.sqrt(1/(ksize*dd)), requires_grad=True)\n",
    "            self.H1 = nn.Conv2d(dk, dk*dd, kernel_size,\n",
    "                                padding=self.pad, groups=dk, bias=False)\n",
    "            self.H2 = nn.Conv2d(1, dd, kernel_size,\n",
    "                                padding=self.pad, bias=False)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # Feature embedding layer\n",
    "        if self.feat_type == 'V':\n",
    "            pass\n",
    "        elif self.feat_type == 'R':\n",
    "            self.G = nn.Conv2d(1, dv, kernel_size,\n",
    "                               padding=self.pad, bias=False)\n",
    "        elif self.feat_type == 'VplusR':\n",
    "            self.G = nn.Conv2d(1, dv, kernel_size,\n",
    "                               padding=self.pad, bias=False)\n",
    "            self.I = nn.Parameter(torch.eye(dk).unsqueeze(0), requires_grad=True)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # Downsampling layer\n",
    "        if max(self.stride) > 1:\n",
    "            self.avgpool = nn.AvgPool2d(kernel_size=(\n",
    "                1, 3), stride=(1, 2), padding=(0, 1))\n",
    "\n",
    "    def L2norm(self, x, d=1):\n",
    "        eps = 1e-6\n",
    "        norm = x ** 2\n",
    "        norm = norm.sum(dim=d, keepdim=True) + eps\n",
    "        norm = norm ** (0.5)\n",
    "        return (x / norm)\n",
    "\n",
    "    def forward(self, x):\n",
    "                \n",
    "        #print(x.shape)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        N, C, T, H= x.shape\n",
    "\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        \n",
    "        '''Linear projection'''\n",
    "        #x_proj = self.projection(x)\n",
    "        x_proj = self.projection_linear(x)\n",
    "        x_proj = x_proj.permute(0, 3, 1, 2)\n",
    "        #print(x_proj.shape)\n",
    "\n",
    "        if self.kernel_type != 'V':\n",
    "            q, k, v = torch.split(\n",
    "                x_proj, [self.nh * self.dk, self.dk, self.dv], dim=1)\n",
    "        else:\n",
    "            q, v = torch.split(x_proj, [self.nh * self.dk, self.dv], dim=1)\n",
    "\n",
    "        '''Normalization'''\n",
    "        q = rearrange(q, 'b (nh k) t h -> b nh k t h', k=self.dk)\n",
    "        q = self.L2norm(q, d=2)\n",
    "        q = rearrange(q, 'b nh k t h -> (b t h) nh k')\n",
    "\n",
    "        v = self.L2norm(v, d=1)\n",
    "\n",
    "        if self.kernel_type != 'V':\n",
    "            k = self.L2norm(k, d=1)\n",
    "\n",
    "        '''\n",
    "        q = (b t h) nh k\n",
    "        k = b k t h\n",
    "        v = b v t h\n",
    "        '''\n",
    "\n",
    "        #Intervolution generation\n",
    "        # Basic kernel\n",
    "        if self.kernel_type == 'V':\n",
    "            kernel = q\n",
    "        # Relational kernel\n",
    "        else:\n",
    "            K_H1 = self.H1(k)\n",
    "            K_H1 = rearrange(K_H1, 'b (k d) t h-> (b t h) k d', k=self.dk)\n",
    "\n",
    "            if self.kernel_type == 'VplusR':\n",
    "                K_H1 = K_H1 + self.P1\n",
    "\n",
    "            kernel = torch.einsum(\n",
    "                'abc,abd->acd', q.transpose(1, 2), K_H1)  # (bth, nh, d)\n",
    "\n",
    "        #feature generation\n",
    "        # Appearance feature\n",
    "        v = rearrange(v, 'b (v 1) t h-> (b v) 1 t h')\n",
    "\n",
    "        V = self.H2(v)  # (bv, d, t, h)\n",
    "        feature = rearrange(V, '(b v) d t h -> (b t h) v d', v=self.dv)\n",
    "\n",
    "        # Relational feature\n",
    "        if self.feat_type in ['R', 'VplusR']:\n",
    "            V_G = self.G(v)  # (bv, v2, t, h)\n",
    "            V_G = rearrange(V_G, '(b v) v2 t h -> (b t h) v v2', v=self.dv)\n",
    "\n",
    "            if self.feat_type == 'VplusR':\n",
    "                V_G = V_G + self.I\n",
    "\n",
    "            feature = torch.einsum('abc,abd->acd', V_G, feature)  # (bth, v2, d)\n",
    "\n",
    "        #kernel * feat\n",
    "        out = torch.einsum('abc,adc->adb', kernel, feature)  # (bth, nh, v2)\n",
    "\n",
    "        out = rearrange(out, '(b t h) nh v -> b (nh v) t h', t=T, h=H)\n",
    "\n",
    "        if max(self.stride) > 1:\n",
    "            out = self.avgpool(out)\n",
    "\n",
    "        out = out.permute(0, 2, 3, 1)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderCell(nn.Module):\n",
    "    \"\"\"\n",
    "    A single cell (unit) for the Transformer encoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim: int, num_heads: int, kernel_size, ff_dim: int, dropout: float):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - embed_dim: embedding dimension for each element in the time series data\n",
    "        - num_heads: Number of attention heads in a multi-head attention module\n",
    "        - ff_dim: The hidden dimension for a feedforward network\n",
    "        - dropout: Dropout ratio for the output of the multi-head attention and feedforward\n",
    "          modules.\n",
    "        \"\"\"\n",
    "        super(TransformerEncoderCell, self).__init__()\n",
    "\n",
    "        self.time_series_attention = TimesSeriesAttention(embed_dim, embed_dim, nh = num_heads, kernel_size=kernel_size)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(embed_dim, ff_dim)\n",
    "        self.linear2 = nn.Linear(ff_dim, embed_dim)\n",
    "\n",
    "\n",
    "    def forward(self, data: torch.Tensor,embeddings, mask: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - x: Tensor of the shape BxTxFXE, where B is the batch size, T is the time dimension, F is the feature dimension,\n",
    "        and E is the embedding dimension\n",
    "        - mask: Tensor for multi-head attention\n",
    "        \"\"\"\n",
    "\n",
    "        #attention2 = self.time_series_attention(x, x, x, mask)\n",
    "        attention2 = self.time_series_attention(data)\n",
    "        attention = data + self.dropout1(attention2)\n",
    "        attention = self.layer_norm(attention)\n",
    "\n",
    "        attention2 = self.linear2(self.dropout(self.activation(self.linear1(attention))))\n",
    "        attention = attention + self.dropout2(attention2)\n",
    "        attention = self.layer_norm(attention)\n",
    "\n",
    "        return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A full encoder consisting of a set of TransformerEncoderCell.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim: int, num_heads: int, kernel_size, ff_dim: int, num_cells: int, dropout: float=0.1):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - embed_dim: embedding dimension for each element in the time series data\n",
    "        - num_heads: Number of attention heads in a multi-head attention module\n",
    "        - ff_dim: The hidden dimension for a feedforward network\n",
    "        - num_cells: Number of time series attention cells in the encoder\n",
    "        - dropout: Dropout ratio for the output of the multi-head attention and feedforward\n",
    "          modules.\n",
    "        \"\"\"\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        \n",
    "        self.norm = None\n",
    "\n",
    "        self.encoder_modules = nn.ModuleList(TransformerEncoderCell(embed_dim, num_heads, kernel_size, ff_dim, dropout) for _ in range(num_cells))\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor=None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - x: Tensor of the shape BxTxFXE, where B is the batch size, T is the time dimension, F is the feature dimension,\n",
    "        and E is the embedding dimension\n",
    "        - mask: Tensor for multi-head attention\n",
    "        \n",
    "        Return:\n",
    "        - y: Tensor of the shape BxTxFXE\n",
    "        \"\"\"\n",
    "\n",
    "        #run encoder modules and add residual connections\n",
    "        for encoder_module in self.encoder_modules:\n",
    "            x = encoder_module(x, mask)\n",
    "\n",
    "        y = x\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSDI transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_torch_trans(num_heads=8, num_cells=1, embed_dim=128, ff_dim=512, dropout=0.1):\n",
    "    encoder_layer = nn.TransformerEncoderLayer(\n",
    "        d_model=embed_dim, nhead=num_heads, dim_feedforward=ff_dim, activation=\"gelu\", dropout=dropout\n",
    "    )\n",
    "    return nn.TransformerEncoder(encoder_layer, num_layers=num_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionEmbedding(nn.Module):\n",
    "    def __init__(self, num_steps, embedding_dim, projection_dim=None):\n",
    "        super(DiffusionEmbedding, self).__init__()\n",
    "        if projection_dim is None:\n",
    "            projection_dim = embedding_dim\n",
    "        self.register_buffer(\n",
    "            \"embedding\",\n",
    "            self._build_embedding(num_steps, embedding_dim / 2),\n",
    "            persistent=False,\n",
    "        )\n",
    "        self.projection1 = nn.Linear(embedding_dim, projection_dim)\n",
    "        self.projection2 = nn.Linear(projection_dim, embedding_dim)        \n",
    "\n",
    "    def forward(self, diffusion_step, data, device=\"cpu\"):\n",
    "        x = self.embedding[diffusion_step]\n",
    "        x = self.projection1(x)\n",
    "        x = F.silu(x)\n",
    "        x = self.projection2(x)\n",
    "        x = F.silu(x)\n",
    "        x = torch.zeros(data.shape).to(device) + x.unsqueeze(1).unsqueeze(1)\n",
    "        return x\n",
    "\n",
    "    def _build_embedding(self, num_steps, dim=64):\n",
    "        steps = torch.arange(num_steps).unsqueeze(1)  # (T,1)\n",
    "        frequencies = 10.0 ** (torch.arange(dim) / (dim - 1) * 4.0).unsqueeze(0)  # (1,dim)\n",
    "        table = steps * frequencies  # (T,dim)\n",
    "        table = torch.cat([torch.sin(table), torch.cos(table)], dim=1)  # (T,dim*2)\n",
    "        return table\n",
    "    \n",
    "\n",
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim, max_len=10000.0):\n",
    "        super(TimeEmbedding, self).__init__()\n",
    "        self.max_len = max_len\n",
    "        self.learnable = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, data, device=\"cpu\"):\n",
    "\n",
    "        b, l, f, e = data.shape\n",
    "        pe = None\n",
    "        pe_row = torch.arange(l)\n",
    "\n",
    "        pe = pe_row.unsqueeze(0)\n",
    "        pe = pe.unsqueeze(2)\n",
    "\n",
    "        pe = pe.repeat((b,1,e))\n",
    "        pe = pe.float()\n",
    "\n",
    "        pe[:, :, 0::2] = torch.sin(pe[:, :, 0::2]/(self.max_len**(torch.arange(0, e, 2)/e)))\n",
    "        pe[:, :, 1::2] = torch.cos(pe[:, :, 1::2]/(self.max_len**(torch.arange(0, e, 2)/e)))\n",
    "\n",
    "        pe = pe.to(device).unsqueeze(2).repeat((1,1,f,1))\n",
    "\n",
    "        # pe = torch.arange(l).unsqueeze(0).unsqueeze(-1).unsqueeze(-1).to(device)\n",
    "        # pe = torch.zeros(data.shape).to(device) + pe\n",
    "        \n",
    "        # div_term = 1 / torch.pow(\n",
    "        #     self.max_len, torch.arange(0, f, 2) / f\n",
    "        # ).unsqueeze(-1).to(device)\n",
    "\n",
    "        # pe[:, :, 0::2] = torch.sin(pe[:, :, 0::2] * div_term)\n",
    "        # pe[:, :, 1::2] = torch.cos(pe[:, :, 1::2] * div_term)\n",
    "\n",
    "        return self.learnable(pe) \n",
    "    \n",
    "class FeatureEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim, max_len=10000.0):\n",
    "        super(FeatureEmbedding, self).__init__()\n",
    "        self.max_len = max_len\n",
    "        self.learnable = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, data, device=\"cpu\"):\n",
    "        b, l, f, e = data.shape\n",
    "\n",
    "        pe = None\n",
    "        pe_row = torch.arange(f)\n",
    "\n",
    "        pe = pe_row.unsqueeze(0)\n",
    "        pe = pe.unsqueeze(2)\n",
    "\n",
    "        pe = pe.repeat((b,1,e))\n",
    "        pe = pe.float()\n",
    "\n",
    "        pe[:, :, 0::2] = torch.sin(pe[:, :, 0::2]/(self.max_len**(torch.arange(0, e, 2)/e)))\n",
    "        pe[:, :, 1::2] = torch.cos(pe[:, :, 1::2]/(self.max_len**(torch.arange(0, e, 2)/e)))\n",
    "\n",
    "        pe = pe.to(device).unsqueeze(1).repeat((1,l,1,1))\n",
    "\n",
    "        # pe = torch.arange(f).unsqueeze(0).unsqueeze(0).unsqueeze(-1).to(device)\n",
    "        # pe = torch.zeros(data.shape).to(device) + pe\n",
    "\n",
    "        # div_term = 1 / torch.pow(\n",
    "        #     self.max_len, torch.arange(0, e, 2) / e\n",
    "        # ).to(device)\n",
    "\n",
    "        # pe[:, :, :, 0::2] = torch.sin(pe[:, :, :, 0::2] * div_term)\n",
    "        # pe[:, :, :, 1::2] = torch.cos(pe[:, :, :, 1::2] * div_term)\n",
    "\n",
    "        return self.learnable(pe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv1d_with_init(in_channels, out_channels, kernel_size):\n",
    "    layer = nn.Conv1d(in_channels, out_channels, kernel_size)\n",
    "    nn.init.kaiming_normal_(layer.weight)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, num_heads=8, num_cells=1, kernel_size=(3, 7), embed_dim=128, ff_dim=512, dropout=0.1, method = \"rsa\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.method = method\n",
    "\n",
    "        self.embedding_add = nn.Sequential(\n",
    "            nn.Linear(embed_dim*4, embed_dim*4),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embed_dim*4, embed_dim*2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embed_dim*2, embed_dim)\n",
    "        )\n",
    "        \n",
    "\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        self.mid_projection = Conv1d_with_init(embed_dim, 2 * embed_dim, 1)\n",
    "        #nn.Linear(embed_dim, embed_dim*2)\n",
    "        self.output_projection = Conv1d_with_init(embed_dim, 2 * embed_dim, 1)\n",
    "        #self.output_projection = nn.Linear(embed_dim, embed_dim*2)\n",
    "\n",
    "        if method == \"rsa\":\n",
    "            self.feature_and_time_transformer = TransformerEncoder(embed_dim = embed_dim,\n",
    "                                              num_heads = num_heads,\n",
    "                                              kernel_size=kernel_size,\n",
    "                                              ff_dim = ff_dim,\n",
    "                                              num_cells = num_cells,\n",
    "                                              dropout = dropout)\n",
    "            self.linear_time_and_feature = nn.Linear(embed_dim, embed_dim)\n",
    "            \n",
    "        elif method == \"csdi\":\n",
    "            self.time_layer = get_torch_trans(num_heads=num_heads, num_cells=num_cells, embed_dim=embed_dim, ff_dim=ff_dim, dropout=dropout)\n",
    "            self.feature_layer = get_torch_trans(num_heads=num_heads, num_cells=num_cells, embed_dim=embed_dim, ff_dim=ff_dim, dropout=dropout)\n",
    "            self.linear_time = nn.Linear(embed_dim, embed_dim)\n",
    "            self.linear_feature = nn.Linear(embed_dim, embed_dim)\n",
    "        \n",
    "        elif method == \"csdi_moded_transformer\":\n",
    "            self.time_layer = get_torch_trans(num_heads=num_heads, num_cells=num_cells, embed_dim=embed_dim, ff_dim=ff_dim, dropout=dropout)\n",
    "            self.feature_layer = get_torch_trans(num_heads=num_heads, num_cells=num_cells, embed_dim=embed_dim, ff_dim=ff_dim, dropout=dropout)\n",
    "            self.linear_time = nn.Linear(embed_dim, embed_dim)\n",
    "            self.linear_feature = nn.Linear(embed_dim, embed_dim)\n",
    "            self.feature_and_time_transformer = moded_TransformerEncoder(embed_dim=embed_dim,\n",
    "                                                                   num_heads=num_heads,\n",
    "                                                                   ff_dim=ff_dim,\n",
    "                                                                   num_cells=num_cells,\n",
    "                                                                   dropout=dropout)\n",
    "            self.linear_time_and_feature = nn.Linear(embed_dim, embed_dim)\n",
    "        \n",
    "        elif method == \"rsa_csdi\":\n",
    "            self.time_layer = get_torch_trans(\n",
    "                num_heads=num_heads, num_cells=num_cells, embed_dim=embed_dim, ff_dim=ff_dim, dropout=dropout)\n",
    "            self.feature_layer = get_torch_trans(\n",
    "                num_heads=num_heads, num_cells=num_cells, embed_dim=embed_dim, ff_dim=ff_dim, dropout=dropout)\n",
    "            self.linear_time = nn.Linear(embed_dim, embed_dim)\n",
    "            self.linear_feature = nn.Linear(embed_dim, embed_dim)\n",
    "            self.feature_and_time_transformer = TransformerEncoder(embed_dim = embed_dim,\n",
    "                                              num_heads = num_heads,\n",
    "                                              kernel_size=kernel_size,\n",
    "                                              ff_dim = ff_dim,\n",
    "                                              num_cells = num_cells,\n",
    "                                              dropout = dropout)\n",
    "            self.linear_time_and_feature = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "        \n",
    "        elif method == \"rsa_moded_transformer\":\n",
    "            self.feature_and_time_transformer = TransformerEncoder(embed_dim = embed_dim,\n",
    "                                              num_heads = num_heads,\n",
    "                                              kernel_size=kernel_size,\n",
    "                                              ff_dim = ff_dim,\n",
    "                                              num_cells = num_cells,\n",
    "                                              dropout = dropout)\n",
    "            self.linear_time_and_feature = nn.Linear(embed_dim, embed_dim)\n",
    "            self.moded_feature_and_time_transformer = moded_TransformerEncoder(embed_dim=embed_dim,\n",
    "                                                                   num_heads=num_heads,\n",
    "                                                                   ff_dim=ff_dim,\n",
    "                                                                   num_cells=num_cells,\n",
    "                                                                   dropout=dropout)\n",
    "            self.moded_linear_time_and_feature = nn.Linear(embed_dim, embed_dim)\n",
    "        \n",
    "        elif method == \"moded_transformer_alone\":\n",
    "            self.moded_feature_and_time_transformer = moded_TransformerEncoder(embed_dim=embed_dim,\n",
    "                                                                   num_heads=num_heads,\n",
    "                                                                   ff_dim=ff_dim,\n",
    "                                                                   num_cells=num_cells,\n",
    "                                                                   dropout=dropout)\n",
    "            self.moded_linear_time_and_feature = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "        elif method == \"rsa_csdi_moded_transformer\":\n",
    "            self.time_layer = get_torch_trans(\n",
    "                num_heads=num_heads, num_cells=num_cells, embed_dim=embed_dim, ff_dim=ff_dim, dropout=dropout)\n",
    "            self.feature_layer = get_torch_trans(\n",
    "                num_heads=num_heads, num_cells=num_cells, embed_dim=embed_dim, ff_dim=ff_dim, dropout=dropout)\n",
    "            self.linear_time = nn.Linear(embed_dim, embed_dim)\n",
    "            self.linear_feature = nn.Linear(embed_dim, embed_dim)\n",
    "            self.feature_and_time_transformer = TransformerEncoder(embed_dim = embed_dim,\n",
    "                                              num_heads = num_heads,\n",
    "                                              kernel_size=kernel_size,\n",
    "                                              ff_dim = ff_dim,\n",
    "                                              num_cells = num_cells,\n",
    "                                              dropout = dropout)\n",
    "            self.linear_time_and_feature = nn.Linear(embed_dim, embed_dim)\n",
    "            self.moded_feature_and_time_transformer = moded_TransformerEncoder(embed_dim=embed_dim,\n",
    "                                                                               num_heads=num_heads,\n",
    "                                                                               ff_dim=ff_dim,\n",
    "                                                                               num_cells=num_cells,\n",
    "                                                                               dropout=dropout)\n",
    "            self.moded_linear_time_and_feature = nn.Linear(\n",
    "                embed_dim, embed_dim)\n",
    "\n",
    "        \n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward_time(self, y, base_shape):\n",
    "        b, t, f, e = base_shape\n",
    "        y = y.permute(0, 2, 1, 3).reshape(b * f, t, e)\n",
    "        y = self.time_layer(y.permute(1, 0, 2)).permute(1, 0, 2)\n",
    "        y = y.reshape(b, f, t, e).permute(0, 2, 1, 3)\n",
    "        return y\n",
    "\n",
    "    def forward_feature(self, y, base_shape):\n",
    "        b, t, f, e = base_shape\n",
    "        y = y.reshape(b * t, f, e)\n",
    "        y = self.feature_layer(y.permute(1, 0, 2)).permute(1, 0, 2)\n",
    "        y = y.reshape(b, t, f, e)\n",
    "        return y        \n",
    "\n",
    "\n",
    "    def forward(self, noised_data, diffusion_emb, time_emb, feature_emb):\n",
    "\n",
    "        b, t, f, e = noised_data.shape\n",
    "        base_shape = noised_data.shape\n",
    "        \n",
    "        y = torch.stack((noised_data, diffusion_emb, time_emb, feature_emb), dim = -1)\n",
    "        y = y.reshape(b, t, f, -1)\n",
    "        y = self.embedding_add(y)\n",
    "        y_resid = y\n",
    "\n",
    "        if self.method == \"rsa\":\n",
    "            y = self.feature_and_time_transformer(y)\n",
    "            y = y.squeeze(-1)\n",
    "            y = self.linear_time_and_feature(y)\n",
    "        \n",
    "        elif self.method == \"csdi\":\n",
    "            y = self.forward_time(y, base_shape)\n",
    "            y = self.linear_time(y)\n",
    "            y = (y + y_resid) / math.sqrt(2.0)\n",
    "            y = self.layer_norm(y)\n",
    "            y = self.forward_feature(y, base_shape) \n",
    "            y = self.linear_feature(y)\n",
    "        \n",
    "        elif self.method == \"csdi_moded_transformer\":\n",
    "            y = self.forward_time(y, base_shape)\n",
    "            y = self.linear_time(y)\n",
    "            y = (y + y_resid) / math.sqrt(2.0)\n",
    "            y = self.layer_norm(y)\n",
    "            y = self.forward_feature(y, base_shape) \n",
    "            y = self.linear_feature(y)\n",
    "            y = (y + y_resid) / math.sqrt(2.0)\n",
    "            y_resid = y\n",
    "            y = self.layer_norm(y)\n",
    "            y = self.feature_and_time_transformer(y)\n",
    "            y = self.linear_time_and_feature(y)\n",
    "        \n",
    "        elif self.method == \"rsa_csdi\":\n",
    "            y = self.forward_time(y, base_shape)\n",
    "            y = self.linear_time(y)\n",
    "            y = (y + y_resid) / math.sqrt(2.0)\n",
    "            y = self.layer_norm(y)\n",
    "            y = self.forward_feature(y, base_shape) \n",
    "            y = self.linear_feature(y)\n",
    "            y = (y + y_resid) / math.sqrt(2.0)\n",
    "            y_resid = y\n",
    "            y = self.layer_norm(y)\n",
    "            y = self.feature_and_time_transformer(y)\n",
    "            y = y.squeeze(-1)\n",
    "            y = self.linear_time_and_feature(y)\n",
    "        \n",
    "        elif self.method == \"rsa_moded_transformer\":\n",
    "            y = self.feature_and_time_transformer(y)\n",
    "            y = y.squeeze(-1)\n",
    "            y = self.linear_time_and_feature(y)\n",
    "            y = (y + y_resid) / math.sqrt(2.0)\n",
    "            y = self.layer_norm(y)\n",
    "            y = self.moded_feature_and_time_transformer(y)\n",
    "            y = self.moded_linear_time_and_feature(y)\n",
    "        \n",
    "        elif self.method == \"moded_transformer_alone\":\n",
    "            y = self.moded_feature_and_time_transformer(y)\n",
    "            y = self.moded_linear_time_and_feature(y)\n",
    "        \n",
    "        elif self.method == \"rsa_csdi_moded_transformer\":\n",
    "            y = self.forward_time(y, base_shape)\n",
    "            y = self.linear_time(y)\n",
    "            y = (y + y_resid) / math.sqrt(2.0)\n",
    "            y = self.layer_norm(y)\n",
    "            y = self.forward_feature(y, base_shape) \n",
    "            y = self.linear_feature(y)\n",
    "            y = (y + y_resid) / math.sqrt(2.0)\n",
    "            y_resid = y\n",
    "            y = self.layer_norm(y)\n",
    "            y = self.feature_and_time_transformer(y)\n",
    "            y = y.squeeze(-1)\n",
    "            y = self.linear_time_and_feature(y)\n",
    "            y = (y + y_resid) / math.sqrt(2.0)\n",
    "            y_resid = y\n",
    "            y = self.layer_norm(y)\n",
    "            y = self.moded_feature_and_time_transformer(y)\n",
    "            y = self.moded_linear_time_and_feature(y)\n",
    "\n",
    "\n",
    "        \n",
    "        y = (y + y_resid) / math.sqrt(2.0)\n",
    "        y = self.layer_norm(y)\n",
    "        y = y.permute(0, 3, 1, 2).reshape(b, e, t*f)\n",
    "        y = self.mid_projection(y)\n",
    "        #y = y.permute(0, 3, 2, 1).reshape(b, 2*e, t*f)\n",
    "\n",
    "        gate, filter = torch.chunk(y, 2, dim=1)\n",
    "        y = torch.sigmoid(gate) * torch.tanh(filter)  # (b,e,f*t)\n",
    "        #y = y.permute(0, 2, 1)\n",
    "        y = self.output_projection(y)\n",
    "        #y = y.permute(0, 2, 1)\n",
    "\n",
    "        residual, skip = torch.chunk(y, 2, dim=1)\n",
    "        residual = residual.permute(0, 2, 1)\n",
    "        skip = skip.permute(0, 2, 1)\n",
    "        residual = residual.reshape(base_shape)\n",
    "        skip = skip.reshape(base_shape)\n",
    "        return (noised_data + residual) / math.sqrt(2.0), skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelLoop(nn.Module):\n",
    "    def __init__(self, embed_dim=128, diffusion_steps = 1000, num_heads=8, kernel_size=(3, 7),num_cells=1, num_residual_layers = 4, ff_dim=512, dropout=0.1, method = \"rsa\", device = \"cpu\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.emb_dim = embed_dim\n",
    "\n",
    "        # self.data_embedding_linear = nn.Sequential(\n",
    "        #     nn.Linear(1, self.emb_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.emb_dim, self.emb_dim)\n",
    "        # ) \n",
    "        # self.x_embedding = nn.Sequential(\n",
    "        #     nn.Linear(1, self.emb_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.emb_dim, self.emb_dim)\n",
    "        # ) \n",
    "\n",
    "        self.data_embedding_linear = Conv1d_with_init(1, self.emb_dim, 1)\n",
    "        self.x_embedding = Conv1d_with_init(2, self.emb_dim, 1)\n",
    "        \n",
    "        self.output = Conv1d_with_init(self.emb_dim, 1, 1)\n",
    "        self.output_final = Conv1d_with_init(self.emb_dim, 1, 1)\n",
    "        \n",
    "        # self.x_add = nn.Sequential(\n",
    "        #     nn.Linear(embed_dim*num_residual_layers, embed_dim*num_residual_layers),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(embed_dim*num_residual_layers, embed_dim)\n",
    "        # )\n",
    "\n",
    "        \n",
    "        self.diffusion_embedding = DiffusionEmbedding(diffusion_steps, embed_dim)\n",
    "        self.time_embedding = TimeEmbedding(embed_dim)\n",
    "        self.feature_embedding = FeatureEmbedding(embed_dim)\n",
    "\n",
    "        self.residual_layers = nn.ModuleList(\n",
    "                ResidualBlock(\n",
    "                    num_heads=num_heads,\n",
    "                    num_cells=num_cells,\n",
    "                    kernel_size=kernel_size,\n",
    "                    embed_dim=embed_dim,\n",
    "                    ff_dim=ff_dim,\n",
    "                    dropout=dropout,\n",
    "                    method = method\n",
    "                ) for _ in range(num_residual_layers)\n",
    "        )\n",
    "    \n",
    "        # self.output = nn.Sequential(\n",
    "        #     nn.Linear(self.emb_dim, self.emb_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.emb_dim, 1)\n",
    "        # )\n",
    "\n",
    "        # self.output_final = nn.Sequential(\n",
    "        #     nn.Linear(self.emb_dim, self.emb_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.emb_dim, 1)\n",
    "        # )\n",
    "\n",
    "\n",
    "    def forward(self, noised_data, noise_mask, diffusion_t):\n",
    "\n",
    "        b, t, f, a = noised_data.shape\n",
    "        \n",
    "        noised_data_reshaped = noised_data.permute(0, 3, 1, 2).reshape(b, 1, t*f)\n",
    "        noised_data_embedded = self.data_embedding_linear(noised_data_reshaped).permute(0, 2, 1).reshape(b, t, f, self.emb_dim)\n",
    "        diffusion_embedding = self.diffusion_embedding(diffusion_t, noised_data_embedded, device = self.device)\n",
    "        time_embedding = self.time_embedding(noised_data_embedded, device = self.device)\n",
    "        feature_embedding = self.feature_embedding(noised_data_embedded, device = self.device)\n",
    "\n",
    "        x = noised_data_embedded\n",
    "        skip = []\n",
    "        for layer in self.residual_layers:\n",
    "            x, skip_connection = layer(x, diffusion_embedding, time_embedding, feature_embedding)\n",
    "            skip.append(skip_connection)\n",
    "            x = x.permute(0, 3, 1, 2).reshape(b, self.emb_dim, t*f)\n",
    "            x = self.output(x).permute(0, 2, 1).reshape(b, t, f)\n",
    "            x = torch.stack((x, noised_data.squeeze(-1)), dim = -1)\n",
    "            #x = x * noise_mask + noised_data * (1 - noise_mask)\n",
    "            x = x.permute(0, 3, 1, 2).reshape(b, 2, t*f)\n",
    "            x = self.x_embedding(x).permute(0, 2, 1).reshape(b, t, f, self.emb_dim)\n",
    "\n",
    "        x = torch.sum(torch.stack(skip, dim = -1), dim=-1)/ math.sqrt(len(self.residual_layers))\n",
    "        # x = torch.stack(skip, dim = -1).reshape(b, t, f, -1)\n",
    "        #x = self.x_add(x)\n",
    "        x = x.permute(0, 3, 1, 2).reshape(b, self.emb_dim, t*f)\n",
    "        x = self.output_final(x).permute(0, 2, 1).reshape(b, t, f, 1).squeeze(-1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_named_beta_schedule(schedule_name, num_diffusion_timesteps):\n",
    "    \"\"\"\n",
    "    Get a pre-defined beta schedule for the given name.\n",
    "\n",
    "    The beta schedule library consists of beta schedules which remain similar\n",
    "    in the limit of num_diffusion_timesteps.\n",
    "    Beta schedules may be added, but should not be removed or changed once\n",
    "    they are committed to maintain backwards compatibility.\n",
    "    \"\"\"\n",
    "    if schedule_name == \"linear\":\n",
    "        # Linear schedule from Ho et al, extended to work for any number of\n",
    "        # diffusion steps.\n",
    "        scale = 1000 / num_diffusion_timesteps\n",
    "        beta_start = scale * 0.0001\n",
    "        beta_end = scale * 0.02\n",
    "        return torch.linspace(\n",
    "            beta_start, beta_end, num_diffusion_timesteps\n",
    "        )\n",
    "    elif schedule_name == \"cosine\":\n",
    "        return betas_for_alpha_bar(\n",
    "            num_diffusion_timesteps,\n",
    "            lambda t: math.cos((t + 0.008) / 1.008 * math.pi / 2) ** 2,\n",
    "        )\n",
    "    elif schedule_name == \"quadratic\":\n",
    "        scale = 50 / num_diffusion_timesteps\n",
    "        beta_start = scale * 0.0001\n",
    "        beta_end = scale * 0.5\n",
    "        return torch.linspace(\n",
    "            beta_start ** 0.5, beta_end ** 0.5, num_diffusion_timesteps\n",
    "        ) ** 2\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(f\"unknown beta schedule: {schedule_name}\")\n",
    "\n",
    "def betas_for_alpha_bar(num_diffusion_timesteps, alpha_bar, max_beta=0.999):\n",
    "    \"\"\"\n",
    "    Create a beta schedule that discretizes the given alpha_t_bar function,\n",
    "    which defines the cumulative product of (1-beta) over time from t = [0,1].\n",
    "\n",
    "    :param num_diffusion_timesteps: the number of betas to produce.\n",
    "    :param alpha_bar: a lambda that takes an argument t from 0 to 1 and\n",
    "                      produces the cumulative product of (1-beta) up to that\n",
    "                      part of the diffusion process.\n",
    "    :param max_beta: the maximum beta to use; use values lower than 1 to\n",
    "                     prevent singularities.\n",
    "    \"\"\"\n",
    "    betas = []\n",
    "    for i in range(num_diffusion_timesteps):\n",
    "        t1 = i / num_diffusion_timesteps\n",
    "        t2 = (i + 1) / num_diffusion_timesteps\n",
    "        betas.append(min(1 - alpha_bar(t2) / alpha_bar(t1), max_beta))\n",
    "    return torch.tensor(betas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class diffusion_imputation(nn.Module):\n",
    "    def __init__(self, emb_dim,\n",
    "                #vocab_size,\n",
    "                #pad_idx= None,\n",
    "                strategy = \"random\",\n",
    "                num_residual_layers = 4,\n",
    "                features_to_impute = None,\n",
    "                last_n_time = 1,\n",
    "                missing_prp = 0.1,\n",
    "                diffusion_steps = 1000,\n",
    "                diffusion_beta_schedule = \"quadratic\",\n",
    "                num_heads = 8,\n",
    "                kernel_size=(3, 7),\n",
    "                ff_dim = 512,\n",
    "                num_cells = 2,\n",
    "                dropout = 0.1,\n",
    "                method = \"rsa\",\n",
    "                device = \"cpu\"):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "    \n",
    "        self.device = device\n",
    "        self.emb_dim = emb_dim\n",
    "        self.strategy = strategy\n",
    "        self.features_to_impute = features_to_impute\n",
    "        self.missing_prp = missing_prp\n",
    "        self.diffusion_steps = diffusion_steps\n",
    "        self.last_n_time = last_n_time\n",
    "\n",
    "        #set device to cuda if available\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = \"cuda\"\n",
    "\n",
    "        \n",
    "        self.model_loop = ModelLoop(embed_dim = self.emb_dim,\n",
    "                                    diffusion_steps = diffusion_steps,\n",
    "                                    num_heads = num_heads,\n",
    "                                    kernel_size = kernel_size,\n",
    "                                    ff_dim = ff_dim,\n",
    "                                    num_cells = num_cells,\n",
    "                                    dropout = dropout,\n",
    "                                    num_residual_layers = num_residual_layers,\n",
    "                                    method = method,\n",
    "                                    device = self.device)\n",
    "        \n",
    "        self.beta = get_named_beta_schedule(diffusion_beta_schedule, \n",
    "                                            diffusion_steps)\n",
    "        \n",
    "        #self.beta = torch.linspace(0.0001, 0.5, diffusion_steps)\n",
    "\n",
    "        # self.beta = torch.linspace(\n",
    "        #         0.0001 ** 0.5, 0.5 ** 0.5, diffusion_steps\n",
    "        #     ) ** 2\n",
    "        \n",
    "        self.alpha_hat = 1 - self.beta \n",
    "        self.alpha = torch.cumprod(self.alpha_hat, dim=0)\n",
    "        self.alpha_torch = torch.tensor(self.alpha).float()\n",
    "\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "\n",
    "    def get_mask(self, data, strategy = \"random\", last_n_time = None, missing_prp = None):\n",
    "        \n",
    "        if last_n_time is not None:\n",
    "            self.last_n_time = last_n_time\n",
    "        \n",
    "        if missing_prp is not None:\n",
    "            self.missing_prp = missing_prp\n",
    "        \n",
    "        b = data.shape[0]\n",
    "        t = data.shape[1]\n",
    "        f = data.shape[2]\n",
    "\n",
    "        if strategy == \"forecasting\":\n",
    "            forecasted_time = torch.randint(2, t, (b, 1, 1))\n",
    "            mask = torch.zeros_like(data)\n",
    "            for i in range(b):\n",
    "                mask[i, forecasted_time[i]:, :] = 1\n",
    "\n",
    "        if strategy == \"forecasting_last_n_time\":\n",
    "            mask = torch.zeros_like(data)\n",
    "            mask[:, -self.last_n_time:, :] = 1\n",
    "\n",
    "        if strategy == \"death_prediction\":\n",
    "            mask = torch.zeros_like(data)\n",
    "            #death is the last 7 columns of the data\n",
    "            mask[:,:, -1] = 1\n",
    "        \n",
    "        if strategy == \"random_features\":\n",
    "            selected_features = torch.randint(0, f, (b, 1, 1))\n",
    "            mask = torch.zeros_like(data)\n",
    "            mask[:, :, selected_features] = 1\n",
    "        \n",
    "        if strategy == \"selected_features\":\n",
    "            mask = torch.zeros_like(data)\n",
    "            mask[:, :, self.features_to_impute] = 1\n",
    "        \n",
    "        if strategy == \"selected_features_after_time\":\n",
    "            selected_time = torch.randint(1, t, (b, 1, 1))\n",
    "            mask = torch.zeros_like(data)\n",
    "            mask[:, selected_time:, self.features_to_impute] = 1\n",
    "\n",
    "        if strategy == \"selected_features_last_n_time\":\n",
    "            mask = torch.zeros_like(data)\n",
    "            mask[:, -self.last_n_time:, self.features_to_impute] = 1\n",
    "        \n",
    "        if strategy == \"random\":\n",
    "            mask = torch.rand(size=(b, t, f))\n",
    "            mask = mask < self.missing_prp\n",
    "            mask = mask.float()\n",
    "            \n",
    "        return mask\n",
    "    \n",
    "    def loss_func(self, predicted_noise, noise, noise_mask):\n",
    "\n",
    "        residual = noise - predicted_noise\n",
    "        num_obs = torch.sum(noise_mask)\n",
    "        loss = (residual**2).sum() / num_obs\n",
    "        return(loss)\n",
    "    \n",
    "    def forward(self, data, observed_mask):\n",
    "         \n",
    "        b, t, f = data.shape\n",
    "\n",
    "        noise_mask = self.get_mask(data, self.strategy).to(self.device)*(observed_mask)\n",
    "        noise = torch.randn((b, t, f)).to(self.device)\n",
    "        noise = (noise_mask * noise)\n",
    "\n",
    "        diffusion_t = torch.randint(0, self.diffusion_steps, (b,1)).squeeze(1)\n",
    "        alpha = self.alpha_torch[diffusion_t].unsqueeze(1).unsqueeze(2).to(self.device)\n",
    "\n",
    "        noised_data = data * noise_mask\n",
    "        noised_data = noised_data * (alpha**0.5) + noise * ((1 - alpha)**0.5)\n",
    "        conditional_data = data * (1 - noise_mask)\n",
    "        noised_data = noised_data + conditional_data\n",
    "        noised_data = noised_data.float()\n",
    "\n",
    "        predicted_noise = self.model_loop(noised_data.unsqueeze(3), noise_mask.unsqueeze(3), diffusion_t)\n",
    "        predicted_noise = predicted_noise * noise_mask\n",
    "\n",
    "        return (predicted_noise, noise, noise_mask)\n",
    "    \n",
    "    def eval(self, data, imputation_mask, scale=1 , verbose = True, strategy = None, last_n_time = None):\n",
    "        \n",
    "        conditional_data = data * (1 - imputation_mask)\n",
    "        random_noise = torch.randn_like(data)* imputation_mask *scale\n",
    "        data_2 = (conditional_data + random_noise).unsqueeze(3)\n",
    "\n",
    "        b, ti, f, e = data_2.shape\n",
    "        imputed_samples = torch.zeros((b, ti, f)).to(self.device)\n",
    "        x = (conditional_data + random_noise)\n",
    "\n",
    "        #   #implementing an autoregressive imputer for forecasting\n",
    "        # if strategy == \"forecasting_last_n_time\":\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for t in range(self.diffusion_steps - 1, -1, -1):\n",
    "\n",
    "                x = x.unsqueeze(3).float()\n",
    "                predicted_noise = self.model_loop(x, imputation_mask.unsqueeze(3), torch.tensor([t]).to(self.device))\n",
    "                predicted_noise = predicted_noise * imputation_mask\n",
    "                \n",
    "                coeff1 = 1 / self.alpha_hat[t] ** 0.5\n",
    "                coeff2 = (1 - self.alpha_hat[t]) / (1 - self.alpha[t]) ** 0.5\n",
    "                \n",
    "                x = x.squeeze(3)\n",
    "                x = coeff1 * (x - coeff2 * predicted_noise)\n",
    "                \n",
    "                if t > 0:\n",
    "                    noise = torch.randn_like(x)\n",
    "                    sigma = (\n",
    "                        (1.0 - self.alpha[t - 1]) / (1.0 - self.alpha[t]) * self.beta[t]\n",
    "                    ) ** 0.5\n",
    "                    x += sigma * noise\n",
    "                \n",
    "                x = data_2.squeeze(3) * (1 - imputation_mask) + x * imputation_mask\n",
    "            \n",
    "\n",
    "            imputed_samples = x.detach()\n",
    "        \n",
    "        mae = torch.mean(torch.abs(data[imputation_mask !=0] - imputed_samples[imputation_mask !=0])).item()\n",
    "        if verbose == True:\n",
    "            print(\"mae = \", mae)\n",
    "        # data_to_print = data[imputation_mask !=0]\n",
    "        # imputed_samples_to_print = imputed_samples[imputation_mask !=0]\n",
    "        # print(\"data:\", data_to_print)\n",
    "        # print(\"imputed:\", imputed_samples_to_print)\n",
    "        # print(\"absolute difference in the first 100 : \", torch.abs(data_to_print - imputed_samples_to_print)[:100])\n",
    "        # print(\"mae = \", torch.mean(torch.abs(data_to_print - imputed_samples_to_print)).item())\n",
    "\n",
    "        return(imputed_samples, data, imputation_mask, mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medicare data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DESY_SORT_KEY</th>\n",
       "      <th>CLM_THRU_DT</th>\n",
       "      <th>GNDR_CD</th>\n",
       "      <th>BENE_RACE_CD</th>\n",
       "      <th>CLM_PMT_AMT</th>\n",
       "      <th>ICD_DGNS_CD1</th>\n",
       "      <th>ICD_DGNS_CD2</th>\n",
       "      <th>ICD_DGNS_CD3</th>\n",
       "      <th>ICD_DGNS_CD4</th>\n",
       "      <th>ICD_DGNS_CD5</th>\n",
       "      <th>...</th>\n",
       "      <th>ICD_DGNS_CD10</th>\n",
       "      <th>ICD_PRCDR_CD1</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>died_2016</th>\n",
       "      <th>died_2017</th>\n",
       "      <th>died_2018</th>\n",
       "      <th>died_2019</th>\n",
       "      <th>died_2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000203</td>\n",
       "      <td>20160403</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6110.17</td>\n",
       "      <td>J189</td>\n",
       "      <td>E871</td>\n",
       "      <td>I509</td>\n",
       "      <td>F329</td>\n",
       "      <td>F419</td>\n",
       "      <td>...</td>\n",
       "      <td>K449</td>\n",
       "      <td>BB241ZZ</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100000421</td>\n",
       "      <td>20160617</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>26010.55</td>\n",
       "      <td>T84020A</td>\n",
       "      <td>T84090A</td>\n",
       "      <td>F952</td>\n",
       "      <td>E559</td>\n",
       "      <td>I071</td>\n",
       "      <td>...</td>\n",
       "      <td>M1990</td>\n",
       "      <td>0SR901Z</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000905</td>\n",
       "      <td>20160920</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4354.34</td>\n",
       "      <td>N132</td>\n",
       "      <td>K760</td>\n",
       "      <td>E119</td>\n",
       "      <td>N3000</td>\n",
       "      <td>B9620</td>\n",
       "      <td>...</td>\n",
       "      <td>R9431</td>\n",
       "      <td>0T768DZ</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100000905</td>\n",
       "      <td>20161015</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7344.59</td>\n",
       "      <td>J189</td>\n",
       "      <td>J90</td>\n",
       "      <td>E119</td>\n",
       "      <td>R630</td>\n",
       "      <td>Z936</td>\n",
       "      <td>...</td>\n",
       "      <td>J45909</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100000945</td>\n",
       "      <td>20160226</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25869.46</td>\n",
       "      <td>N132</td>\n",
       "      <td>G912</td>\n",
       "      <td>N179</td>\n",
       "      <td>I739</td>\n",
       "      <td>N3281</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0TC78ZZ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DESY_SORT_KEY  CLM_THRU_DT  GNDR_CD  BENE_RACE_CD  CLM_PMT_AMT   \n",
       "0      100000203     20160403        2             1      6110.17  \\\n",
       "1      100000421     20160617        2             1     26010.55   \n",
       "2      100000905     20160920        2             1      4354.34   \n",
       "3      100000905     20161015        2             1      7344.59   \n",
       "4      100000945     20160226        1             1     25869.46   \n",
       "\n",
       "  ICD_DGNS_CD1 ICD_DGNS_CD2 ICD_DGNS_CD3 ICD_DGNS_CD4 ICD_DGNS_CD5  ...   \n",
       "0         J189         E871         I509         F329         F419  ...  \\\n",
       "1      T84020A      T84090A         F952         E559         I071  ...   \n",
       "2         N132         K760         E119        N3000        B9620  ...   \n",
       "3         J189          J90         E119         R630         Z936  ...   \n",
       "4         N132         G912         N179         I739        N3281  ...   \n",
       "\n",
       "  ICD_DGNS_CD10 ICD_PRCDR_CD1 sex race age died_2016  died_2017  died_2018   \n",
       "0          K449       BB241ZZ   2    1  68     False      False      False  \\\n",
       "1         M1990       0SR901Z   2    1  45     False      False      False   \n",
       "2         R9431       0T768DZ   2    1  79     False      False      False   \n",
       "3        J45909             0   2    1  79     False      False      False   \n",
       "4             0       0TC78ZZ   1    1  80     False      False      False   \n",
       "\n",
       "   died_2019  died_2020  \n",
       "0      False      False  \n",
       "1      False      False  \n",
       "2      False      False  \n",
       "3      False      False  \n",
       "4      False      False  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data csv\n",
    "data = pd.read_csv(\"/work/postresearch/Shared/Projects/Farbod/clustering_physicians/sample_for_imputation.csv\")\n",
    "data = data.drop(columns = [\"Unnamed: 0\", \"county\", \"state\", \"BENE_STATE_CD\"])\n",
    "#see the first 5 rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(564276, 24)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DESY_SORT_KEY', 'CLM_THRU_DT', 'GNDR_CD', 'BENE_RACE_CD',\n",
       "       'CLM_PMT_AMT', 'ICD_DGNS_CD1', 'ICD_DGNS_CD2', 'ICD_DGNS_CD3',\n",
       "       'ICD_DGNS_CD4', 'ICD_DGNS_CD5', 'ICD_DGNS_CD6', 'ICD_DGNS_CD7',\n",
       "       'ICD_DGNS_CD8', 'ICD_DGNS_CD9', 'ICD_DGNS_CD10', 'ICD_PRCDR_CD1', 'sex',\n",
       "       'race', 'age', 'died_2016', 'died_2017', 'died_2018', 'died_2019',\n",
       "       'died_2020'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print column names\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set GNDR_CD, BENE_RACE_CD, BENE_STATE_CD, state, county, sex, race as object\n",
    "\n",
    "data[\"GNDR_CD\"] = data[\"GNDR_CD\"].astype(object)\n",
    "data[\"BENE_RACE_CD\"] = data[\"BENE_RACE_CD\"].astype(object)\n",
    "#data[\"BENE_STATE_CD\"] = data[\"BENE_STATE_CD\"].astype(object)\n",
    "# data[\"state\"] = data[\"state\"].astype(object)\n",
    "# data[\"county\"] = data[\"county\"].astype(object)\n",
    "data[\"sex\"] = data[\"sex\"].astype(object)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GNDR_CD', 'BENE_RACE_CD', 'ICD_DGNS_CD1', 'ICD_DGNS_CD2', 'ICD_DGNS_CD3', 'ICD_DGNS_CD4', 'ICD_DGNS_CD5', 'ICD_DGNS_CD6', 'ICD_DGNS_CD7', 'ICD_DGNS_CD8', 'ICD_DGNS_CD9', 'ICD_DGNS_CD10', 'ICD_PRCDR_CD1', 'sex']\n"
     ]
    }
   ],
   "source": [
    "#find the categorical columns\n",
    "categorical_columns = []\n",
    "for column in data.columns:\n",
    "    if data[column].dtype == object:\n",
    "        categorical_columns.append(column)\n",
    "print(categorical_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the date column as datetime, it's formatted like this 20160403\n",
    "data[\"date\"] = pd.to_datetime(data[\"CLM_THRU_DT\"], format = \"%Y%m%d\")\n",
    "#create a variable for the month\n",
    "data[\"month\"] = data[\"date\"].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GNDR_CD': array([2, 1], dtype=object), 'BENE_RACE_CD': array([1, 4, 2, 5, 0, 3, 6], dtype=object), 'ICD_DGNS_CD1': array(['J189', 'T84020A', 'N132', ..., 'S0281XD', 'Q620', 'I409'],\n",
      "      dtype=object), 'ICD_DGNS_CD2': array(['E871', 'T84090A', 'K760', ..., 'H53459', 'S34101S', 'H53122'],\n",
      "      dtype=object), 'ICD_DGNS_CD3': array(['I509', 'F952', 'E119', ..., 'T461X1A', 'I401', 'N343'],\n",
      "      dtype=object), 'ICD_DGNS_CD4': array(['F329', 'E559', 'N3000', ..., 'S60032A', 'F13129', 'H5350'],\n",
      "      dtype=object), 'ICD_DGNS_CD5': array(['F419', 'I071', 'B9620', ..., 'T433X5D', 'I401', 'S06820A'],\n",
      "      dtype=object), 'ICD_DGNS_CD6': array(['E785', 'M419', 'E039', ..., 'O99284', 'S06319D', 'B1009'],\n",
      "      dtype=object), 'ICD_DGNS_CD7': array(['K219', 'Z96642', 'N8320', ..., 'S41011A', 'S12030D', 'T85848A'],\n",
      "      dtype=object), 'ICD_DGNS_CD8': array(['I10', 'E780', 'R600', ..., 'S4981XA', 'S22019D', 'S22019A'],\n",
      "      dtype=object), 'ICD_DGNS_CD9': array(['A084', 'J45909', 'R0789', ..., 'T8459XD', 'I688', 'T17898A'],\n",
      "      dtype=object), 'ICD_DGNS_CD10': array(['K449', 'M1990', 'R9431', ..., 'N50811', 'S0240CD', 'S52609A'],\n",
      "      dtype=object), 'ICD_PRCDR_CD1': array(['BB241ZZ', '0SR901Z', '0T768DZ', ..., 'D0109YZ', '07T00ZZ',\n",
      "       'B31GY10'], dtype=object), 'sex': array([2, 1], dtype=object)}\n",
      "GNDR_CD is done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39m# replace the categorical columns with their indices\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m column \u001b[39min\u001b[39;00m categorical_columns:\n\u001b[0;32m----> 9\u001b[0m     data[column] \u001b[39m=\u001b[39m data[column]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: np\u001b[39m.\u001b[39;49mwhere(categorical_vocab[column] \u001b[39m==\u001b[39;49m x)[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m])\n\u001b[1;32m     10\u001b[0m     \u001b[39mprint\u001b[39m(column \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m is done\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_311/lib/python3.11/site-packages/pandas/core/series.py:4626\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4516\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4517\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4518\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4521\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4522\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4523\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4524\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4525\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4624\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4625\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4626\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_311/lib/python3.11/site-packages/pandas/core/apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1024\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_311/lib/python3.11/site-packages/pandas/core/apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1075\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1076\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1077\u001b[0m             values,\n\u001b[1;32m   1078\u001b[0m             f,\n\u001b[1;32m   1079\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1080\u001b[0m         )\n\u001b[1;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#create a vocabulary for the categorical columns\n",
    "categorical_vocab = {}\n",
    "for column in categorical_columns:\n",
    "    categorical_vocab[column] = data[column].unique()\n",
    "print(categorical_vocab)\n",
    "\n",
    "# replace the categorical columns with their indices\n",
    "for column in categorical_columns:\n",
    "    data[column] = data[column].apply(lambda x: np.where(categorical_vocab[column] == x)[0][0])\n",
    "    print(column + \" is done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the categorical vocab\n",
    "with open(\"/work/postresearch/Shared/Projects/Farbod/clustering_physicians/categorical_vocab.pickle\", \"wb\") as f:\n",
    "    pickle.dump(categorical_vocab, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#save the data\n",
    "data.to_csv(\"/work/postresearch/Shared/Projects/Farbod/clustering_physicians/data_for_imputation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/work/postresearch/Shared/Projects/Farbod/clustering_physicians/data_for_imputation.csv\")\n",
    "data = data.drop(columns = [\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn all the columns into floats (dropping the date column and CLM_THRU_DT)\n",
    "data = data.drop(columns = [\"date\", \"CLM_THRU_DT\"])\n",
    "data = data.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DESY_SORT_KEY</th>\n",
       "      <th>GNDR_CD</th>\n",
       "      <th>BENE_RACE_CD</th>\n",
       "      <th>CLM_PMT_AMT</th>\n",
       "      <th>ICD_DGNS_CD1</th>\n",
       "      <th>ICD_DGNS_CD2</th>\n",
       "      <th>ICD_DGNS_CD3</th>\n",
       "      <th>ICD_DGNS_CD4</th>\n",
       "      <th>ICD_DGNS_CD5</th>\n",
       "      <th>ICD_DGNS_CD6</th>\n",
       "      <th>...</th>\n",
       "      <th>ICD_PRCDR_CD1</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>died_2016</th>\n",
       "      <th>died_2017</th>\n",
       "      <th>died_2018</th>\n",
       "      <th>died_2019</th>\n",
       "      <th>died_2020</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000203.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6110.17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100000421.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26010.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000905.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4354.34</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100000905.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7344.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100000945.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25869.46</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DESY_SORT_KEY  GNDR_CD  BENE_RACE_CD  CLM_PMT_AMT  ICD_DGNS_CD1  \\\n",
       "0    100000203.0      0.0           0.0      6110.17           0.0   \n",
       "1    100000421.0      0.0           0.0     26010.55           1.0   \n",
       "2    100000905.0      0.0           0.0      4354.34           2.0   \n",
       "3    100000905.0      0.0           0.0      7344.59           0.0   \n",
       "4    100000945.0      1.0           0.0     25869.46           2.0   \n",
       "\n",
       "   ICD_DGNS_CD2  ICD_DGNS_CD3  ICD_DGNS_CD4  ICD_DGNS_CD5  ICD_DGNS_CD6  ...  \\\n",
       "0           0.0           0.0           0.0           0.0           0.0  ...   \n",
       "1           1.0           1.0           1.0           1.0           1.0  ...   \n",
       "2           2.0           2.0           2.0           2.0           2.0  ...   \n",
       "3           3.0           2.0           3.0           3.0           3.0  ...   \n",
       "4           4.0           3.0           4.0           4.0           4.0  ...   \n",
       "\n",
       "   ICD_PRCDR_CD1  sex  race   age  died_2016  died_2017  died_2018  died_2019  \\\n",
       "0            0.0  0.0   1.0  68.0        0.0        0.0        0.0        0.0   \n",
       "1            1.0  0.0   1.0  45.0        0.0        0.0        0.0        0.0   \n",
       "2            2.0  0.0   1.0  79.0        0.0        0.0        0.0        0.0   \n",
       "3            3.0  0.0   1.0  79.0        0.0        0.0        0.0        0.0   \n",
       "4            4.0  1.0   1.0  80.0        0.0        0.0        0.0        0.0   \n",
       "\n",
       "   died_2020  month  \n",
       "0        0.0    4.0  \n",
       "1        0.0    6.0  \n",
       "2        0.0    9.0  \n",
       "3        0.0   10.0  \n",
       "4        0.0    2.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_for_imputation = data.copy()\n",
    "data_for_imputation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DESY_SORT_KEY</th>\n",
       "      <th>month</th>\n",
       "      <th>GNDR_CD</th>\n",
       "      <th>BENE_RACE_CD</th>\n",
       "      <th>CLM_PMT_AMT</th>\n",
       "      <th>ICD_DGNS_CD1</th>\n",
       "      <th>ICD_DGNS_CD2</th>\n",
       "      <th>ICD_DGNS_CD3</th>\n",
       "      <th>ICD_DGNS_CD4</th>\n",
       "      <th>ICD_DGNS_CD5</th>\n",
       "      <th>ICD_DGNS_CD6</th>\n",
       "      <th>ICD_DGNS_CD7</th>\n",
       "      <th>ICD_DGNS_CD8</th>\n",
       "      <th>ICD_DGNS_CD9</th>\n",
       "      <th>ICD_DGNS_CD10</th>\n",
       "      <th>ICD_PRCDR_CD1</th>\n",
       "      <th>sex</th>\n",
       "      <th>race</th>\n",
       "      <th>age</th>\n",
       "      <th>died_overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100041295.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100041295.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17827.84</td>\n",
       "      <td>186.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100041295.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100041295.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7122.15</td>\n",
       "      <td>186.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100041295.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18458.00</td>\n",
       "      <td>79.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DESY_SORT_KEY  month  GNDR_CD  BENE_RACE_CD  CLM_PMT_AMT  ICD_DGNS_CD1  \\\n",
       "0    100041295.0    1.0      0.0           0.0         0.00           0.0   \n",
       "1    100041295.0    2.0      0.0           0.0     17827.84         186.0   \n",
       "2    100041295.0    3.0      0.0           0.0         0.00           0.0   \n",
       "3    100041295.0    4.0      0.0           0.0      7122.15         186.0   \n",
       "4    100041295.0    5.0      0.0           0.0     18458.00          79.0   \n",
       "\n",
       "   ICD_DGNS_CD2  ICD_DGNS_CD3  ICD_DGNS_CD4  ICD_DGNS_CD5  ICD_DGNS_CD6  \\\n",
       "0           0.0           0.0           0.0           0.0           0.0   \n",
       "1         143.0         166.0          67.0          36.0         146.0   \n",
       "2           0.0           0.0           0.0           0.0           0.0   \n",
       "3         144.0         167.0           5.0         167.0           3.0   \n",
       "4          54.0         168.0          28.0          33.0         147.0   \n",
       "\n",
       "   ICD_DGNS_CD7  ICD_DGNS_CD8  ICD_DGNS_CD9  ICD_DGNS_CD10  ICD_PRCDR_CD1  \\\n",
       "0           0.0           0.0           0.0            0.0            0.0   \n",
       "1         149.0         152.0          23.0           26.0          118.0   \n",
       "2           0.0           0.0           0.0            0.0            0.0   \n",
       "3          37.0          15.0          51.0           96.0            3.0   \n",
       "4          37.0           0.0          19.0           20.0          105.0   \n",
       "\n",
       "   sex  race   age  died_overall  \n",
       "0  0.0   0.0   0.0             1  \n",
       "1  0.0   1.0  80.0             1  \n",
       "2  0.0   0.0   0.0             1  \n",
       "3  0.0   1.0  80.0             1  \n",
       "4  0.0   1.0  80.0             1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sort by DESY_SORT_KEY and month\n",
    "data_for_imputation = data_for_imputation.sort_values(by = [\"DESY_SORT_KEY\", \"month\"])\n",
    "#keep only one observation per DESY_SORT_KEY and month\n",
    "data_for_imputation = data_for_imputation.drop_duplicates(subset = [\"DESY_SORT_KEY\", \"month\"])\n",
    "#only keep people with at least 6 months of data\n",
    "data_for_imputation = data_for_imputation.groupby(\"DESY_SORT_KEY\").filter(lambda x: len(x) >= 6)\n",
    "data_for_imputation[\"died_overall\"] = data_for_imputation[\"died_2016\"] + data_for_imputation[\"died_2017\"] + data_for_imputation[\"died_2018\"] + data_for_imputation[\"died_2019\"] + data_for_imputation[\"died_2020\"]\n",
    "data_for_imputation[\"died_2016_2017\"] = data_for_imputation[\"died_2016\"] + data_for_imputation[\"died_2017\"]\n",
    "data_for_imputation[\"died_overall\"] = data_for_imputation[\"died_overall\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "data_for_imputation[\"died_2016_2017\"] = data_for_imputation[\"died_2016_2017\"].apply(lambda x: 1 if x > 0 else 0)\n",
    "#create columns of all zeros for months that a DESY_SORT_KEY is not present\n",
    "death_data = data_for_imputation[[\"DESY_SORT_KEY\", \"died_overall\"]]#, \"died_2016_2017\"]]\n",
    "#choose only unique rows in death_data\n",
    "death_data = death_data.drop_duplicates(subset = [\"DESY_SORT_KEY\"])\n",
    "data_for_imputation = data_for_imputation.drop(columns = [\"died_overall\", \"died_2016_2017\", \"died_2016\", \"died_2017\", \"died_2018\", \"died_2019\", \"died_2020\"])\n",
    "data_for_imputation = data_for_imputation.set_index([\"DESY_SORT_KEY\", \"month\"]).unstack(fill_value = 0).stack().reset_index()\n",
    "#merge the death data back in and if unavailable, fill with 0\n",
    "data_for_imputation = data_for_imputation.merge(death_data, how = \"left\", on = [\"DESY_SORT_KEY\"])\n",
    "data_for_imputation[\"died_overall\"] = data_for_imputation[\"died_overall\"].fillna(0)\n",
    "#data_for_imputation[\"died_2016_2017\"] = data_for_imputation[\"died_2016_2017\"].fillna(0)\n",
    "#sort by DESY_SORT_KEY again\n",
    "data_for_imputation = data_for_imputation.sort_values(by = [\"DESY_SORT_KEY\", \"month\"])\n",
    "#add a column for died overall based on the last 5 columns\n",
    "\n",
    "data_for_imputation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38976, 20)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_for_imputation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3248"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#number of unique DESY_SORT_KEYs\n",
    "len(data_for_imputation[\"DESY_SORT_KEY\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#number of columns\n",
    "len(data_for_imputation.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nomrlaize the data\n",
    "data_for_imputation = data_for_imputation.drop(columns = [\"DESY_SORT_KEY\", \"month\"])\n",
    "#save the mean and std\n",
    "train_mean = data_for_imputation.mean()\n",
    "train_std = data_for_imputation.std()\n",
    "\n",
    "#normalize the data\n",
    "# data_for_imputation = (data_for_imputation - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3248, 12, 18])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([    1.0000,     0.0000, 13537.2200,   486.0000,    22.0000,   434.0000,\n",
       "          432.0000,   457.0000,   326.0000,    62.0000,   396.0000,    55.0000,\n",
       "          358.0000,   326.0000,     1.0000,     1.0000,    43.0000,     1.0000],\n",
       "       dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create tensor\n",
    "data_for_imputation_tensor = torch.tensor(data_for_imputation.values).reshape(3248, 12, -1)\n",
    "print(data_for_imputation_tensor.shape)\n",
    "#turn of pytorch scientific notation\n",
    "torch.set_printoptions(profile=\"full\", sci_mode=False)\n",
    "#see the first 5 rows\n",
    "data_for_imputation_tensor[6, 0, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the tensor\n",
    "torch.save(data_for_imputation_tensor, \"/work/postresearch/Shared/Projects/Farbod/clustering_physicians/data_for_imputation_tensor.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_imputation_tensor = torch.load(\"/work/postresearch/Shared/Projects/Farbod/clustering_physicians/data_for_imputation_tensor.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Subset' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 14\u001b[0m\n\u001b[1;32m      2\u001b[0m train_data_observed, val_data_observed, test_data_observed \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mrandom_split(\n\u001b[1;32m      3\u001b[0m     data_for_imputation[\u001b[39m\"\u001b[39m\u001b[39mobserved_data\u001b[39m\u001b[39m\"\u001b[39m], \n\u001b[1;32m      4\u001b[0m [\u001b[39mint\u001b[39m(\u001b[39m0.8\u001b[39m \u001b[39m*\u001b[39m data_for_imputation_tensor\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]), \n\u001b[1;32m      5\u001b[0m \u001b[39mint\u001b[39m(\u001b[39m0.1\u001b[39m \u001b[39m*\u001b[39m data_for_imputation_tensor\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, \n\u001b[1;32m      6\u001b[0m \u001b[39mint\u001b[39m(\u001b[39m0.1\u001b[39m \u001b[39m*\u001b[39m data_for_imputation_tensor\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m      8\u001b[0m train_data_observed_mask, val_data_observed_mask, test_data_observed_mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mrandom_split(\n\u001b[1;32m      9\u001b[0m     data_for_imputation[\u001b[39m\"\u001b[39m\u001b[39mobserved_mask\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m     10\u001b[0m [\u001b[39mint\u001b[39m(\u001b[39m0.8\u001b[39m \u001b[39m*\u001b[39m data_for_imputation_tensor\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]),\n\u001b[1;32m     11\u001b[0m \u001b[39mint\u001b[39m(\u001b[39m0.1\u001b[39m \u001b[39m*\u001b[39m data_for_imputation_tensor\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     12\u001b[0m \u001b[39mint\u001b[39m(\u001b[39m0.1\u001b[39m \u001b[39m*\u001b[39m data_for_imputation_tensor\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m---> 14\u001b[0m train_data \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mobserved_data\u001b[39m\u001b[39m\"\u001b[39m: train_data_observed\u001b[39m.\u001b[39;49mtolist(),\n\u001b[1;32m     15\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mobserved_mask\u001b[39m\u001b[39m\"\u001b[39m: train_data_observed_mask\u001b[39m.\u001b[39mtolist()}\n\u001b[1;32m     17\u001b[0m val_data \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mobserved_data\u001b[39m\u001b[39m\"\u001b[39m: val_data_observed\u001b[39m.\u001b[39mtolist(),\n\u001b[1;32m     18\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mobserved_mask\u001b[39m\u001b[39m\"\u001b[39m: val_data_observed_mask\u001b[39m.\u001b[39mtolist()}\n\u001b[1;32m     20\u001b[0m test_data \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mobserved_data\u001b[39m\u001b[39m\"\u001b[39m: test_data_observed\u001b[39m.\u001b[39mtolist(),\n\u001b[1;32m     21\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mobserved_mask\u001b[39m\u001b[39m\"\u001b[39m: test_data_observed_mask\u001b[39m.\u001b[39mtolist()}\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Subset' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "#train val test split using the first dimension\n",
    "class medicare_dataset(data_for_imputation):\n",
    "    def __init__(self, data_for_imputation):\n",
    "        #create the observed_data and observed_mask within the data\n",
    "        data_for_imputation = {\"observed_data\": data_for_imputation_tensor,\n",
    "                              \"observed_mask\": data_for_imputation_tensor == 0}\n",
    "        \n",
    "    def \n",
    "train_data_observed, val_data_observed, test_data_observed = torch.utils.data.random_split(\n",
    "    data_for_imputation[\"observed_data\"], \n",
    "[int(0.8 * data_for_imputation_tensor.shape[0]), \n",
    "int(0.1 * data_for_imputation_tensor.shape[0])+1, \n",
    "int(0.1 * data_for_imputation_tensor.shape[0])+1])\n",
    "\n",
    "train_data_observed_mask, val_data_observed_mask, test_data_observed_mask = torch.utils.data.random_split(\n",
    "    data_for_imputation[\"observed_mask\"],\n",
    "[int(0.8 * data_for_imputation_tensor.shape[0]),\n",
    "int(0.1 * data_for_imputation_tensor.shape[0])+1,\n",
    "int(0.1 * data_for_imputation_tensor.shape[0])+1])\n",
    "\n",
    "train_data = {\"observed_data\": train_data_observed,\n",
    "                \"observed_mask\": train_data_observed_mask}\n",
    "\n",
    "val_data = {\"observed_data\": val_data_observed,\n",
    "                \"observed_mask\": val_data_observed_mask}\n",
    "\n",
    "test_data = {\"observed_data\": test_data_observed,\n",
    "                \"observed_mask\": test_data_observed_mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 2.0000e+00, 7.3748e+03, 4.2400e+02, 5.4000e+01, 5.4400e+02,\n",
       "         2.3000e+01, 4.0300e+02, 5.8000e+02, 3.6000e+01, 4.0000e+00, 2.7000e+01,\n",
       "         1.0500e+02, 4.1000e+01, 1.0000e+00, 2.0000e+00, 6.5000e+01, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 2.0000e+00, 2.2286e+04, 1.1600e+02, 5.0000e+00, 2.6000e+01,\n",
       "         7.1000e+01, 4.5000e+01, 1.9300e+02, 5.4800e+02, 2.1300e+02, 1.3800e+02,\n",
       "         8.2000e+01, 1.3380e+03, 1.0000e+00, 2.0000e+00, 6.5000e+01, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 2.0000e+00, 1.2403e+04, 2.5600e+02, 1.5400e+02, 7.2000e+01,\n",
       "         1.1100e+02, 1.6000e+01, 3.1000e+01, 2.1500e+02, 2.8900e+02, 4.8600e+02,\n",
       "         1.2100e+02, 4.1000e+01, 1.0000e+00, 2.0000e+00, 6.5000e+01, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 2.0000e+00, 3.6576e+04, 3.1200e+02, 1.4000e+01, 1.6000e+01,\n",
       "         4.9900e+02, 5.5300e+02, 3.1000e+01, 8.9700e+02, 3.2990e+03, 1.9100e+02,\n",
       "         1.6600e+02, 1.6000e+01, 1.0000e+00, 2.0000e+00, 6.5000e+01, 0.0000e+00],\n",
       "        [1.0000e+00, 2.0000e+00, 0.0000e+00, 1.5030e+03, 7.0000e+00, 2.1700e+02,\n",
       "         2.3000e+01, 2.6800e+02, 2.6000e+02, 8.7000e+01, 4.5600e+03, 5.4620e+03,\n",
       "         1.6600e+02, 1.6000e+01, 1.0000e+00, 2.0000e+00, 6.5000e+01, 0.0000e+00],\n",
       "        [1.0000e+00, 2.0000e+00, 1.6828e+04, 1.7300e+02, 1.4000e+01, 1.6900e+02,\n",
       "         5.5700e+02, 3.1400e+02, 3.1000e+01, 5.4200e+02, 2.2000e+01, 7.1600e+02,\n",
       "         5.0000e+00, 7.2000e+01, 1.0000e+00, 2.0000e+00, 6.5000e+01, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [1.0000e+00, 2.0000e+00, 1.4137e+04, 1.3500e+02, 3.7000e+01, 2.2000e+01,\n",
       "         2.3000e+01, 2.2000e+01, 3.1000e+01, 1.8900e+02, 3.5400e+02, 2.0000e+01,\n",
       "         4.2000e+01, 3.0000e+00, 1.0000e+00, 2.0000e+00, 6.5000e+01, 0.0000e+00]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[\"observed_data\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#create data loader for train, val, and test \n",
    "train_loader = DataLoader(train_data, batch_size=50, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=25, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=25, shuffle=True)\n",
    "\n",
    "#check the size of the train, val, and test sets\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))\n",
    "print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2b85d762db10>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m i, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m      2\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m      3\u001b[0m         \u001b[39mprint\u001b[39m(batch)\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_311/lib/python3.11/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_311/lib/python3.11/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_311/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_311/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_loader):\n",
    "    if i == 0:\n",
    "        print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a train function that also shows a dynamic loss plot. It should also be batched. \n",
    "#the plot should be dynamic and show the loss for each epoch.\n",
    "%matplotlib inline\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "def train(model, data_loader, data_loader_validation, epochs, lr, loss_func, device = \"cuda\", verbose = True, validation_frequency = 1, validation_prp = 10, strategy = \"random\"):\n",
    "\n",
    "    model = model.to(device)\n",
    "    #annealing for the learning rate\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "    loss_list = []\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    epoch_loss = 0\n",
    "    epoch_loss_list = []\n",
    "    mae = 0\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        #annealing for the learning rate (if the loss has not decreased in the last 2 epochs, divide the learning rate by 2)\n",
    "        if epoch > 5:\n",
    "            if epoch_loss >= np.mean(epoch_loss_list[-5:]):\n",
    "                for g in optimizer.param_groups:\n",
    "                    g['lr'] = g['lr'] / 2\n",
    "\n",
    "        start = time.time()\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            optimizer.zero_grad()\n",
    "            predicted_noise, noise, noise_mask = model(batch[\"observed_data\"].to(device), batch[\"observed_mask\"].to(device))\n",
    "            loss = loss_func(predicted_noise, noise, noise_mask)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_list.append(loss.item())\n",
    "            if i % 2 == 0:       \n",
    "                ax.clear()\n",
    "                ax.set_ylim(0, 1)\n",
    "                ax.plot(loss_list)\n",
    "                #ax.text(len(loss_list) - 1, loss_list[-1], str(round(loss_list[-1], 3)))\n",
    "                #add a smooth line to the plot every 100 steps\n",
    "                if len(loss_list) > 100:\n",
    "                    ax.plot(np.convolve(loss_list, np.ones((100,))/100, mode='valid'))\n",
    "                    #show the last loss value on the plot\n",
    "                    ax.text(len(loss_list) - 1, np.convolve(loss_list, np.ones((100,))/100, mode='valid')[-1],\n",
    "                             str(round(np.convolve(loss_list, np.ones((100,))/100, mode='valid')[-1], 3)))\n",
    "                ax.text(0.1, 0.9, \"Epoch: \" + str(epoch) + \" Loss: \" + str(round(epoch_loss, 3)))\n",
    "                ax.text(0.1, 0.8, \"Learning rate: \" + str(round(optimizer.param_groups[0]['lr'], 9)))\n",
    "                ax.text(0.1, 0.7, \"Validation mae: \" + str(round(mae, 3)))\n",
    "                display(fig)\n",
    "                clear_output(wait=True)\n",
    "            #print(\"Epoch: \", epoch, \"Loss: \", loss.item())\n",
    "        end = time.time()    \n",
    "        \n",
    "        if verbose:\n",
    "            #add the epoch average loss to the plot\n",
    "            #find the number of batches in the epoch\n",
    "            num_batches = len(data_loader)\n",
    "            #find the average loss for the epoch\n",
    "            epoch_loss = sum(loss_list[-num_batches:]) / num_batches\n",
    "            epoch_loss_list.append(epoch_loss)\n",
    "        \n",
    "        #validation at the end of each n epoch\n",
    "\n",
    "        if epoch % validation_frequency == 0:\n",
    "            imputed_samples = torch.tensor([]).to(\"cuda\")\n",
    "            data = torch.tensor([]).to(\"cuda\")\n",
    "            imputation_mask = torch.tensor([]).to(\"cuda\")\n",
    "            mae_list = []\n",
    "            \n",
    "            for i, batch in enumerate(data_loader_validation):\n",
    "                if i % validation_prp == 0:\n",
    "                    test_data = batch[\"observed_data\"].to(\"cuda\")\n",
    "                    imputation_mask = diffusion_imputation.get_mask(model, test_data, model.strategy).to(\"cuda\")*batch[\"observed_mask\"].to(\"cuda\")\n",
    "                    imputed_step, data_step, imputation_mask_step, mae_step = diffusion_imputation.eval(model, test_data, imputation_mask, verbose=False)\n",
    "                    imputed_samples = torch.cat((imputed_samples, imputed_step), dim = 0)\n",
    "                    data = torch.cat((data, data_step), dim = 0)\n",
    "                    imputation_mask = torch.cat((imputation_mask, imputation_mask_step), dim = 0)\n",
    "                    mae_list.append(mae_step)\n",
    "            mae = np.mean(mae_list)\n",
    "\n",
    "\n",
    "    return(model, loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'observed_data': array([[-0.        , -0.        , -0.        , ..., -0.        ,\n",
      "        -0.        , -0.        ],\n",
      "       [-0.        , -0.        , -0.        , ..., -0.        ,\n",
      "        -0.        , -0.        ],\n",
      "       [-0.        , -0.        , -0.        , ..., -0.        ,\n",
      "        -0.        , -0.        ],\n",
      "       ...,\n",
      "       [ 0.41346119,  0.53711331,  0.26384671, ...,  2.4418168 ,\n",
      "         1.53607472,  0.90641488],\n",
      "       [ 0.51382443,  0.84540919,  0.2380207 , ...,  2.82506697,\n",
      "         2.66970738,  0.42094893],\n",
      "       [ 0.6894601 ,  0.87221753,  0.2380207 , ...,  3.79327793,\n",
      "         2.32961758,  0.4838797 ]]), 'observed_mask': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 1, 1, 1],\n",
      "       [1, 1, 1, ..., 1, 1, 1],\n",
      "       [1, 1, 1, ..., 1, 1, 1]]), 'gt_mask': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 1, 1, 1],\n",
      "       [1, 1, 1, ..., 1, 1, 1],\n",
      "       [1, 1, 1, ..., 1, 1, 1]]), 'hist_mask': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 1, 1, 1],\n",
      "       [1, 1, 1, ..., 1, 1, 1],\n",
      "       [1, 1, 1, ..., 1, 1, 1]]), 'timepoints': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
      "       34, 35]), 'cut_length': 0}\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(train_set):\n",
    "    if i == 0:\n",
    "        print(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_239287/3246490296.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.alpha_torch = torch.tensor(self.alpha).float()\n"
     ]
    }
   ],
   "source": [
    "diffusion_imputer = diffusion_imputation(emb_dim = 128,\n",
    "                                         strategy='random',\n",
    "                                         #last_n_time = 1,\n",
    "                                         num_residual_layers=1,\n",
    "                                         missing_prp= 0.3,\n",
    "                                         diffusion_steps= 50,\n",
    "                                         diffusion_beta_schedule= \"quadratic\",\n",
    "                                         num_heads=4,\n",
    "                                         kernel_size=(3, 3),\n",
    "                                         ff_dim=512,\n",
    "                                         num_cells = 1,\n",
    "                                         dropout=0.0,\n",
    "                                         method=\"rsa_csdi\",  # csdi, csdi_moded_transformer, rsa, rsa_moded_transformer, moded_transformer_alone, rsa_csdi, rsa_csdi_moded_transformer\n",
    "                                         device=\"cuda\")\n",
    "\n",
    "# data = torch.ones((10,10,10)).to(\"cuda\")\n",
    "# diffusion_imputer(data, strategy='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n",
      "\u001b[0;32m----> 1\u001b[0m train(\n",
      "\u001b[1;32m      2\u001b[0m     diffusion_imputer, \n",
      "\u001b[1;32m      3\u001b[0m     data_loader_model, \n",
      "\u001b[1;32m      4\u001b[0m     data_loader_validation,\n",
      "\u001b[1;32m      5\u001b[0m     epochs \u001b[39m=\u001b[39;49m \u001b[39m30\u001b[39;49m, \n",
      "\u001b[1;32m      6\u001b[0m     lr \u001b[39m=\u001b[39;49m \u001b[39m0.0001\u001b[39;49m, \n",
      "\u001b[1;32m      7\u001b[0m     loss_func \u001b[39m=\u001b[39;49m diffusion_imputer\u001b[39m.\u001b[39;49mloss_func,\n",
      "\u001b[1;32m      8\u001b[0m     validation_frequency\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m,\n",
      "\u001b[1;32m      9\u001b[0m     validation_prp\u001b[39m=\u001b[39;49m\u001b[39m14\u001b[39;49m)\n",
      "\n",
      "Cell \u001b[0;32mIn[21], line 34\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, data_loader_validation, epochs, lr, loss_func, device, verbose, validation_frequency, validation_prp, strategy)\u001b[0m\n",
      "\u001b[1;32m     32\u001b[0m loss \u001b[39m=\u001b[39m loss_func(predicted_noise, noise, noise_mask)\n",
      "\u001b[1;32m     33\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "\u001b[0;32m---> 34\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n",
      "\u001b[1;32m     35\u001b[0m loss_list\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "\u001b[1;32m     36\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m2\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:       \n",
      "\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_311/lib/python3.11/site-packages/torch/optim/optimizer.py:269\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    267\u001b[0m \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m_ \u001b[39m=\u001b[39m args\n",
      "\u001b[1;32m    268\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n",
      "\u001b[0;32m--> 269\u001b[0m \u001b[39mwith\u001b[39;49;00m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39;49mrecord_function(profile_name):\n",
      "\u001b[1;32m    270\u001b[0m     \u001b[39m# call optimizer step pre hooks\u001b[39;49;00m\n",
      "\u001b[1;32m    271\u001b[0m     \u001b[39mfor\u001b[39;49;00m pre_hook \u001b[39min\u001b[39;49;00m chain(_global_optimizer_pre_hooks\u001b[39m.\u001b[39;49mvalues(), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer_step_pre_hooks\u001b[39m.\u001b[39;49mvalues()):\n",
      "\u001b[1;32m    272\u001b[0m         result \u001b[39m=\u001b[39;49m pre_hook(\u001b[39mself\u001b[39;49m, args, kwargs)\n",
      "\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_311/lib/python3.11/site-packages/torch/autograd/profiler.py:519\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[1;32m    518\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__enter__\u001b[39m(\u001b[39mself\u001b[39m):\n",
      "\u001b[0;32m--> 519\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrecord \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39;49m_record_function_enter_new(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs)\n",
      "\u001b[1;32m    520\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Alinezhad/Miniconda/envs/pytorch_311/lib/python3.11/site-packages/torch/_ops.py:641\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m    638\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n",
      "\u001b[1;32m    639\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39miter\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dir)\n",
      "\u001b[0;32m--> 641\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n",
      "\u001b[1;32m    642\u001b[0m     \u001b[39m# overloading __call__ to ensure torch.ops.foo.bar()\u001b[39;00m\n",
      "\u001b[1;32m    643\u001b[0m     \u001b[39m# is still callable from JIT\u001b[39;00m\n",
      "\u001b[1;32m    644\u001b[0m     \u001b[39m# We save the function ptr as the `op` attribute on\u001b[39;00m\n",
      "\u001b[1;32m    645\u001b[0m     \u001b[39m# OpOverloadPacket to access it here.\u001b[39;00m\n",
      "\u001b[1;32m    646\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_op(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs \u001b[39mor\u001b[39;00m {})\n",
      "\u001b[1;32m    648\u001b[0m \u001b[39m# TODO: use this to make a __dir__\u001b[39;00m\n",
      "\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(\n",
    "    diffusion_imputer, \n",
    "    data_loader_model, \n",
    "    data_loader_validation,\n",
    "    epochs = 30, \n",
    "    lr = 0.0001, \n",
    "    loss_func = diffusion_imputer.loss_func,\n",
    "    validation_frequency=4,\n",
    "    validation_prp=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the entire model for further training\n",
    "#torch.save(diffusion_imputer, \"/work/postresearch/Shared/Projects/Farbod/diffusion_imputer_forecast_last_4.pt\")\n",
    "#torch.save(diffusion_imputer, \"/work/postresearch/Shared/Projects/Farbod/diffusion_imputer_27.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
