{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/postresearch/Shared/Researchers/Farbod/cancer/code\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# set wd to cancer\n",
    "os.chdir(\"/work/postresearch/Shared/Researchers/Farbod/cancer/code/\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import copy\n",
    "import logging\n",
    "import requests\n",
    "import zipfile\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from itertools import chain\n",
    "from typing import Union\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier, MultiOutputRegressor\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from omegaconf.errors import MissingMandatoryValue\n",
    "\n",
    "import ray\n",
    "from ray import tune, ray_constants\n",
    "\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "from einops import rearrange, reduce, repeat\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "from src.data import RealDatasetCollection, SyntheticDatasetCollection\n",
    "from src.models import TimeVaryingCausalModel\n",
    "from src.models.utils import (\n",
    "    grad_reverse,\n",
    "    BRTreatmentOutcomeHead,\n",
    "    AlphaRise,\n",
    "    clip_normalize_stabilized_weights,\n",
    ")\n",
    "from src.models.utils_lstm import VariationalLSTM\n",
    "from copy import deepcopy\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "11.8\n",
      "Number of available GPUs: 1\n",
      "GPU 0: NVIDIA A100 80GB PCIe\n"
     ]
    }
   ],
   "source": [
    "# show pytorch version and cuda version\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of available GPUs: {num_gpus}\")\n",
    "    for i in range(num_gpus):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        print(f\"GPU {i}: {gpu_name}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. No GPUs detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import LightningModule\n",
    "from omegaconf import DictConfig\n",
    "from omegaconf.errors import MissingMandatoryValue\n",
    "import torch\n",
    "import math\n",
    "from typing import Union\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import logging\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from pytorch_lightning import Trainer\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray import ray_constants\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier, MultiOutputRegressor\n",
    "\n",
    "from src.data import RealDatasetCollection, SyntheticDatasetCollection\n",
    "from src.models import TimeVaryingCausalModel\n",
    "from src.models.utils import grad_reverse, BRTreatmentOutcomeHead, AlphaRise, clip_normalize_stabilized_weights\n",
    "from src.models.utils_lstm import VariationalLSTM\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class MSM(TimeVaryingCausalModel):\n",
    "    \"\"\"\n",
    "    Pytorch-Lightning implementation of Marginal Structural Models (MSMs) (https://pubmed.ncbi.nlm.nih.gov/10955408/)\n",
    "    \"\"\"\n",
    "\n",
    "    model_type = None  # Will be defined in subclasses\n",
    "    possible_model_types = {'msm_regressor',\n",
    "                            'propensity_treatment', 'propensity_history'}\n",
    "    tuning_criterion = None\n",
    "\n",
    "    def __init__(self,\n",
    "                 args: DictConfig,\n",
    "                 dataset_collection: Union[RealDatasetCollection,\n",
    "                                           SyntheticDatasetCollection] = None,\n",
    "                 autoregressive: bool = None,\n",
    "                 has_vitals: bool = None,\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            args: DictConfig of model hyperparameters\n",
    "            dataset_collection: Dataset collection\n",
    "            autoregressive: Flag of including previous outcomes to modelling\n",
    "            has_vitals: Flag of vitals in dataset\n",
    "            **kwargs: Other arguments\n",
    "        \"\"\"\n",
    "        super().__init__(args, dataset_collection, autoregressive, has_vitals)\n",
    "        self.lag_features = args.model.lag_features\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        if self.dataset_collection is not None and not self.dataset_collection.processed_data_multi:\n",
    "            # Only binary multilabel regime possible\n",
    "            assert self.hparams.dataset.treatment_mode == 'multilabel'\n",
    "            self.dataset_collection.process_data_multi()\n",
    "\n",
    "    def get_exploded_dataset(self, dataset: Dataset, min_length: int, only_active_entries=True, max_length=None) -> Dataset:\n",
    "        exploded_dataset = deepcopy(dataset)\n",
    "        if max_length is None:\n",
    "            max_length = max(exploded_dataset.data['sequence_lengths'][:])\n",
    "        if not only_active_entries:\n",
    "            exploded_dataset.data['active_entries'][:, :, :] = 1.0\n",
    "            exploded_dataset.data['sequence_lengths'][:] = max_length\n",
    "        exploded_dataset.explode_trajectories(min_length)\n",
    "        return exploded_dataset\n",
    "\n",
    "    def get_propensity_scores(self, dataset: Dataset) -> np.array:\n",
    "        logger.info(f'Propensity scores for {dataset.subset_name}.')\n",
    "        exploded_dataset = self.get_exploded_dataset(\n",
    "            dataset, min_length=self.lag_features, only_active_entries=False)\n",
    "\n",
    "        inputs = self.get_inputs(exploded_dataset)\n",
    "        classifier = getattr(self, self.model_type)\n",
    "\n",
    "        propensity_scores = np.stack(\n",
    "            classifier.predict_proba(inputs), 1)[:, :, 1]\n",
    "        propensity_scores = propensity_scores.reshape(dataset.data['active_entries'].shape[0],\n",
    "                                                      dataset.data['active_entries'].shape[1] -\n",
    "                                                      self.lag_features,\n",
    "                                                      self.dim_treatments)\n",
    "        propensity_scores = np.concatenate([0.5 * np.ones((propensity_scores.shape[0], self.lag_features, self.dim_treatments)),\n",
    "                                            propensity_scores], axis=1)\n",
    "        return propensity_scores\n",
    "\n",
    "\n",
    "class MSMPropensityTreatment(MSM):\n",
    "\n",
    "    model_type = 'propensity_treatment'\n",
    "\n",
    "    def __init__(self,\n",
    "                 args: DictConfig,\n",
    "                 dataset_collection: Union[RealDatasetCollection,\n",
    "                                           SyntheticDatasetCollection] = None,\n",
    "                 autoregressive: bool = None, has_vitals: bool = None, **kwargs):\n",
    "        super().__init__(args, dataset_collection, autoregressive, has_vitals)\n",
    "\n",
    "        self.input_size = self.dim_treatments\n",
    "        logger.info(f'Input size of {self.model_type}: {self.input_size}')\n",
    "        self.output_size = self.dim_treatments\n",
    "\n",
    "        self.propensity_treatment = MultiOutputClassifier(\n",
    "            LogisticRegression(penalty=None, max_iter=args.exp.max_epochs))\n",
    "        self.save_hyperparameters(args)\n",
    "\n",
    "    def get_inputs(self, dataset: Dataset) -> np.array:\n",
    "        active_entries = dataset.data['active_entries']\n",
    "        prev_treatments = dataset.data['prev_treatments']\n",
    "        inputs = (prev_treatments * active_entries).sum(1)\n",
    "        return inputs\n",
    "\n",
    "    def fit(self):\n",
    "        self.prepare_data()\n",
    "        train_f = self.get_exploded_dataset(\n",
    "            self.dataset_collection.train_f, min_length=self.lag_features)\n",
    "        active_entries = train_f.data['active_entries']\n",
    "        last_entries = active_entries - \\\n",
    "            np.concatenate([active_entries[:, 1:, :], np.zeros(\n",
    "                (active_entries.shape[0], 1, 1))], axis=1)\n",
    "\n",
    "        # Inputs\n",
    "        inputs = self.get_inputs(train_f)\n",
    "\n",
    "        # Outputs\n",
    "        current_treatments = train_f.data['current_treatments']\n",
    "        outputs = (current_treatments * last_entries).sum(1)\n",
    "\n",
    "        self.propensity_treatment.fit(inputs, outputs)\n",
    "\n",
    "\n",
    "class MSMPropensityHistory(MSM):\n",
    "\n",
    "    model_type = 'propensity_history'\n",
    "\n",
    "    def __init__(self,\n",
    "                 args: DictConfig,\n",
    "                 dataset_collection: Union[RealDatasetCollection,\n",
    "                                           SyntheticDatasetCollection] = None,\n",
    "                 autoregressive: bool = None, has_vitals: bool = None, **kwargs):\n",
    "        super().__init__(args, dataset_collection, autoregressive, has_vitals)\n",
    "\n",
    "        self.input_size = self.dim_treatments + self.dim_static_features\n",
    "        self.input_size += self.dim_vitals if self.has_vitals else 0\n",
    "        self.input_size += self.dim_outcome if self.autoregressive else 0\n",
    "\n",
    "        logger.info(f'Input size of {self.model_type}: {self.input_size}')\n",
    "        self.output_size = self.dim_treatments\n",
    "\n",
    "        self.propensity_history = MultiOutputClassifier(\n",
    "            LogisticRegression(penalty=None, max_iter=args.exp.max_epochs))\n",
    "        self.save_hyperparameters(args)\n",
    "\n",
    "    def get_inputs(self, dataset: Dataset, projection_horizon=0) -> np.array:\n",
    "        active_entries = dataset.data['active_entries']\n",
    "        lagged_entries = active_entries - \\\n",
    "            np.concatenate([active_entries[:, self.lag_features + 1:, :],\n",
    "                            np.zeros((active_entries.shape[0], self.lag_features + 1, 1))], axis=1)\n",
    "        if projection_horizon > 0:\n",
    "            lagged_entries = np.concatenate([lagged_entries[:, projection_horizon:, :],\n",
    "                                             np.zeros((active_entries.shape[0], projection_horizon, 1))], axis=1)\n",
    "\n",
    "        active_entries_before_proection = np.concatenate([active_entries[:, projection_horizon:, :],\n",
    "                                                          np.zeros((active_entries.shape[0], projection_horizon, 1))], axis=1)\n",
    "\n",
    "        prev_treatments = dataset.data['prev_treatments']\n",
    "        inputs = [(prev_treatments * active_entries_before_proection).sum(1)]\n",
    "        if self.has_vitals:\n",
    "            vitals = dataset.data['vitals']\n",
    "            inputs.append(vitals[np.repeat(lagged_entries, self.dim_vitals, 2) == 1.0].reshape(vitals.shape[0],\n",
    "                                                                                               (self.lag_features + 1) *\n",
    "                                                                                               self.dim_vitals))\n",
    "        if self.autoregressive:\n",
    "            prev_outputs = dataset.data['prev_outputs']\n",
    "            inputs.append(prev_outputs[np.repeat(lagged_entries, self.dim_outcome, 2) == 1.0].reshape(prev_outputs.shape[0],\n",
    "                                                                                                      (self.lag_features + 1) *\n",
    "                                                                                                      self.dim_outcome))\n",
    "        static_features = dataset.data['static_features']\n",
    "        inputs.append(static_features)\n",
    "        return np.concatenate(inputs, axis=1)\n",
    "\n",
    "    def fit(self):\n",
    "        self.prepare_data()\n",
    "        train_f = self.get_exploded_dataset(\n",
    "            self.dataset_collection.train_f, min_length=self.lag_features)\n",
    "        active_entries = train_f.data['active_entries']\n",
    "        last_entries = active_entries - \\\n",
    "            np.concatenate([active_entries[:, 1:, :], np.zeros(\n",
    "                (active_entries.shape[0], 1, 1))], axis=1)\n",
    "\n",
    "        # Inputs\n",
    "        inputs = self.get_inputs(train_f)\n",
    "\n",
    "        # Outputs\n",
    "        current_treatments = train_f.data['current_treatments']\n",
    "        outputs = (current_treatments * last_entries).sum(1)\n",
    "\n",
    "        self.propensity_history.fit(inputs, outputs)\n",
    "\n",
    "\n",
    "class MSMRegressor(MSM):\n",
    "\n",
    "    model_type = 'msm_regressor'\n",
    "\n",
    "    def __init__(self,\n",
    "                 args: DictConfig,\n",
    "                 propensity_treatment: MSMPropensityTreatment = None,\n",
    "                 propensity_history: MSMPropensityHistory = None,\n",
    "                 dataset_collection: Union[RealDatasetCollection,\n",
    "                                           SyntheticDatasetCollection] = None,\n",
    "                 autoregressive: bool = None, has_vitals: bool = None, **kwargs):\n",
    "        super().__init__(args, dataset_collection, autoregressive, has_vitals)\n",
    "\n",
    "        self.input_size = self.dim_treatments + self.dim_static_features\n",
    "        self.input_size += self.dim_vitals if self.has_vitals else 0\n",
    "        self.input_size += self.dim_outcome if self.autoregressive else 0\n",
    "\n",
    "        logger.info(f'Input size of {self.model_type}: {self.input_size}')\n",
    "        self.output_size = self.dim_outcome\n",
    "\n",
    "        self.propensity_treatment = propensity_treatment\n",
    "        self.propensity_history = propensity_history\n",
    "\n",
    "        self.msm_regressor = \\\n",
    "            [MultiOutputRegressor(LinearRegression()) for _ in range(\n",
    "                self.dataset_collection.projection_horizon + 1)]\n",
    "        self.save_hyperparameters(args)\n",
    "\n",
    "    def get_inputs(self, dataset: Dataset, projection_horizon=0, tau=0) -> np.array:\n",
    "        active_entries = dataset.data['active_entries']\n",
    "        lagged_entries = active_entries - np.concatenate([active_entries[:, self.lag_features + 1:, :],\n",
    "                                                          np.zeros((active_entries.shape[0], self.lag_features + 1, 1))], axis=1)\n",
    "        if projection_horizon > 0:\n",
    "            lagged_entries = np.concatenate([lagged_entries[:, projection_horizon:, :],\n",
    "                                             np.zeros((active_entries.shape[0], projection_horizon, 1))], axis=1)\n",
    "\n",
    "        active_entries_before_proection = np.concatenate([active_entries[:, projection_horizon:, :],\n",
    "                                                          np.zeros((active_entries.shape[0], projection_horizon, 1))], axis=1)\n",
    "\n",
    "        prev_treatments = dataset.data['prev_treatments']\n",
    "        inputs = [(prev_treatments * active_entries_before_proection).sum(1)]\n",
    "        if self.has_vitals:\n",
    "            vitals = dataset.data['vitals']\n",
    "            inputs.append(vitals[np.repeat(lagged_entries, self.dim_vitals, 2) == 1.0].reshape(vitals.shape[0],\n",
    "                                                                                               (self.lag_features + 1) *\n",
    "                                                                                               self.dim_vitals))\n",
    "        if self.autoregressive:\n",
    "            prev_outputs = dataset.data['prev_outputs']\n",
    "            inputs.append(\n",
    "                prev_outputs[np.repeat(lagged_entries, self.dim_outcome, 2) == 1.0].reshape(prev_outputs.shape[0],\n",
    "                                                                                            (self.lag_features + 1) *\n",
    "                                                                                            self.dim_outcome))\n",
    "        static_features = dataset.data['static_features']\n",
    "        inputs.append(static_features)\n",
    "\n",
    "        # Adding current actions\n",
    "        current_treatments = dataset.data['current_treatments']\n",
    "        prediction_entries = active_entries - np.concatenate(\n",
    "            [active_entries[:, tau + 1:, :], np.zeros((active_entries.shape[0], tau + 1, 1))], axis=1)\n",
    "        prediction_entries = np.concatenate([prediction_entries[:, projection_horizon - tau:, :],\n",
    "                                             np.zeros((prediction_entries.shape[0], projection_horizon - tau, 1))], axis=1)\n",
    "        inputs.append((current_treatments * prediction_entries).sum(1))\n",
    "\n",
    "        return np.concatenate(inputs, axis=1)\n",
    "\n",
    "    def get_sample_weights(self, dataset: Dataset, tau=0) -> np.array:\n",
    "        active_entries = dataset.data['active_entries']\n",
    "        stabilized_weights = dataset.data['stabilized_weights']\n",
    "\n",
    "        prediction_entries = active_entries - np.concatenate(\n",
    "            [active_entries[:, tau + 1:, :],\n",
    "                np.zeros((active_entries.shape[0], tau + 1, 1))],\n",
    "            axis=1)\n",
    "        stabilized_weights = stabilized_weights[np.squeeze(prediction_entries) == 1.0].reshape(stabilized_weights.shape[0],\n",
    "                                                                                               tau + 1)\n",
    "        sw = np.prod(stabilized_weights, axis=1)\n",
    "        sw_tilde = np.clip(sw, np.nanquantile(\n",
    "            sw, 0.01), np.nanquantile(sw, 0.99))\n",
    "        return sw_tilde\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        if self.dataset_collection is not None and not self.dataset_collection.processed_data_multi:\n",
    "            self.dataset_collection.process_data_multi()\n",
    "        if self.dataset_collection is not None and 'stabilized_weights' not in self.dataset_collection.train_f.data:\n",
    "            self.dataset_collection.process_propensity_train_f(\n",
    "                self.propensity_treatment, self.propensity_history)\n",
    "\n",
    "    def fit(self):\n",
    "        self.prepare_data()\n",
    "        for tau in range(self.dataset_collection.projection_horizon + 1):\n",
    "\n",
    "            train_f = self.get_exploded_dataset(\n",
    "                self.dataset_collection.train_f, min_length=self.lag_features + tau)\n",
    "            active_entries = train_f.data['active_entries']\n",
    "            last_entries = active_entries - \\\n",
    "                np.concatenate([active_entries[:, 1:, :], np.zeros(\n",
    "                    (active_entries.shape[0], 1, 1))], axis=1)\n",
    "\n",
    "            # Inputs\n",
    "            inputs = self.get_inputs(train_f, projection_horizon=tau, tau=tau)\n",
    "\n",
    "            # Stabilized weights\n",
    "            sw = self.get_sample_weights(train_f, tau=tau)\n",
    "\n",
    "            # Outputs\n",
    "            outputs = train_f.data['outputs']\n",
    "            outputs = (outputs * last_entries).sum(1)\n",
    "\n",
    "            self.msm_regressor[tau].fit(inputs, outputs, sample_weight=sw)\n",
    "\n",
    "    def get_predictions(self, dataset: Dataset) -> np.array:\n",
    "        logger.info(f'Predictions for {dataset.subset_name}.')\n",
    "        batch_size = 10000\n",
    "        outcome_pred = np.zeros_like(dataset.data['outputs'])\n",
    "        for batch in range(len(dataset) // batch_size + 1):\n",
    "            subset = deepcopy(dataset)\n",
    "            for (k, v) in subset.data.items():\n",
    "                subset.data[k] = v[batch * batch_size:(batch + 1) * batch_size]\n",
    "\n",
    "            exploded_dataset = self.get_exploded_dataset(subset, min_length=self.lag_features, only_active_entries=False,\n",
    "                                                         max_length=max(dataset.data['sequence_lengths'][:]))\n",
    "            inputs = self.get_inputs(\n",
    "                exploded_dataset, projection_horizon=0, tau=0)\n",
    "            outcome_pred_batch = self.msm_regressor[0].predict(inputs)\n",
    "\n",
    "            outcome_pred_batch = outcome_pred_batch.reshape(subset.data['active_entries'].shape[0],\n",
    "                                                            subset.data['active_entries'].shape[1] - 1,\n",
    "                                                            self.dim_outcome)\n",
    "            # First time-step requires two previous outcomes -> duplicating the next prediction\n",
    "            outcome_pred_batch = np.concatenate(\n",
    "                [outcome_pred_batch[:, :1, :], outcome_pred_batch], axis=1)\n",
    "            outcome_pred[batch *\n",
    "                         batch_size:(batch + 1) * batch_size] = outcome_pred_batch\n",
    "        return outcome_pred\n",
    "\n",
    "    def get_autoregressive_predictions(self, dataset: Dataset) -> np.array:\n",
    "        logger.info(f'Autoregressive Prediction for {dataset.subset_name}.')\n",
    "        predicted_outputs = np.zeros(\n",
    "            (len(dataset), self.hparams.dataset.projection_horizon, self.dim_outcome))\n",
    "\n",
    "        for t in range(1, self.dataset_collection.projection_horizon + 1):\n",
    "            inputs = self.get_inputs(\n",
    "                dataset, projection_horizon=self.dataset_collection.projection_horizon - 1, tau=t - 1)\n",
    "            outcome_pred = self.msm_regressor[t].predict(inputs)\n",
    "            predicted_outputs[:, t - 1] = outcome_pred\n",
    "\n",
    "        return predicted_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:\n",
      "dataset:\n",
      "  _target_: src.data.SyntheticCancerDatasetCollection\n",
      "  name: tumor_generator\n",
      "  coeff: 4\n",
      "  chemo_coeff: 4\n",
      "  radio_coeff: 4\n",
      "  seed: 100\n",
      "  num_patients:\n",
      "    train: 10000\n",
      "    val: 1000\n",
      "    test: 1000\n",
      "  window_size: 15\n",
      "  lag: 0\n",
      "  max_seq_length: 60\n",
      "  projection_horizon: 5\n",
      "  cf_seq_mode: sliding_treatment\n",
      "  val_batch_size: 512\n",
      "  treatment_mode: multilabel\n",
      "model:\n",
      "  dim_treatments: 4\n",
      "  dim_vitals: 0\n",
      "  dim_static_features: 1\n",
      "  dim_outcomes: 1\n",
      "  min_length: 1\n",
      "  lag_features: 1\n",
      "  name: MSM\n",
      "  propensity_treatment:\n",
      "    _target_: src.models.msm.MSMPropensityTreatment\n",
      "  propensity_history:\n",
      "    _target_: src.models.msm.MSMPropensityHistory\n",
      "  msm_regressor:\n",
      "    _target_: src.models.msm.MSMRegressor\n",
      "exp:\n",
      "  unscale_rmse: true\n",
      "  percentage_rmse: true\n",
      "  seed: 100\n",
      "  max_epochs: 100\n",
      "  gpus:\n",
      "  - 0\n",
      "  logging: true\n",
      "  mlflow_uri: http://127.0.0.1:8081\n",
      "  alpha: 1.0\n",
      "  update_alpha: false\n",
      "  alpha_rate: exp\n",
      "  balancing: null\n",
      "  bce_weight: false\n",
      "  weights_ema: null\n",
      "  beta: 0.99\n",
      "\n",
      "Global seed set to 100\n",
      "INFO:root:Simulating initial volumes for stage I  with norm params: mu=1.72, sigma=4.7, lb=-0.6221218732608373, ub=-0.023523848418276528\n",
      "INFO:root:Simulating initial volumes for stage II  with norm params: mu=1.96, sigma=1.63, lb=-1.9410876100159118, ub=0.3711345751297772\n",
      "INFO:root:Simulating initial volumes for stage IIIA  with norm params: mu=1.91, sigma=9.4, lb=-0.33127370258786554, ub=0.06967546355973796\n",
      "INFO:root:Simulating initial volumes for stage IIIB  with norm params: mu=2.76, sigma=6.87, lb=-0.5769974969906748, ub=-0.02839165102452155\n",
      "INFO:root:Simulating initial volumes for stage IV  with norm params: mu=3.86, sigma=8.82, lb=-0.5741465764541877, ub=-0.14683113860980307\n",
      "INFO:root:Got correlated params for 4597 patients\n",
      "INFO:root:Got correlated params for 9177 patients\n",
      "INFO:root:Got correlated params for 13793 patients\n",
      "INFO:root:Simulating beta_c parameters\n",
      "INFO:root:Randomising outputs\n",
      "  0%|          | 0/10000 [00:00<?, ?it/s]/work/postresearch/Shared/Researchers/Farbod/cancer/code/src/data/cancer_sim/cancer_simulation.py:346: RuntimeWarning: overflow encountered in exp\n",
      "  if recovery_rvs[i, t] < np.exp(-cancer_volume[i, t] * TUMOUR_CELL_DENSITY):\n",
      "100%|██████████| 10000/10000 [00:11<00:00, 887.33it/s]\n",
      "INFO:root:Simulating initial volumes for stage I  with norm params: mu=1.72, sigma=4.7, lb=-0.6221218732608373, ub=-0.023523848418276528\n",
      "INFO:root:Simulating initial volumes for stage II  with norm params: mu=1.96, sigma=1.63, lb=-1.9410876100159118, ub=0.3711345751297772\n",
      "INFO:root:Simulating initial volumes for stage IIIA  with norm params: mu=1.91, sigma=9.4, lb=-0.33127370258786554, ub=0.06967546355973796\n",
      "INFO:root:Simulating initial volumes for stage IIIB  with norm params: mu=2.76, sigma=6.87, lb=-0.5769974969906748, ub=-0.02839165102452155\n",
      "INFO:root:Simulating initial volumes for stage IV  with norm params: mu=3.86, sigma=8.82, lb=-0.5741465764541877, ub=-0.14683113860980307\n",
      "INFO:root:Got correlated params for 444 patients\n",
      "INFO:root:Got correlated params for 922 patients\n",
      "INFO:root:Got correlated params for 1372 patients\n",
      "INFO:root:Simulating beta_c parameters\n",
      "INFO:root:Randomising outputs\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 901.81it/s]\n",
      "INFO:root:Simulating initial volumes for stage I  with norm params: mu=1.72, sigma=4.7, lb=-0.6221218732608373, ub=-0.023523848418276528\n",
      "INFO:root:Simulating initial volumes for stage II  with norm params: mu=1.96, sigma=1.63, lb=-1.9410876100159118, ub=0.3711345751297772\n",
      "INFO:root:Simulating initial volumes for stage IIIA  with norm params: mu=1.91, sigma=9.4, lb=-0.33127370258786554, ub=0.06967546355973796\n",
      "INFO:root:Simulating initial volumes for stage IIIB  with norm params: mu=2.76, sigma=6.87, lb=-0.5769974969906748, ub=-0.02839165102452155\n",
      "INFO:root:Simulating initial volumes for stage IV  with norm params: mu=3.86, sigma=8.82, lb=-0.5741465764541877, ub=-0.14683113860980307\n",
      "INFO:root:Got correlated params for 466 patients\n",
      "INFO:root:Got correlated params for 911 patients\n",
      "INFO:root:Got correlated params for 1403 patients\n",
      "INFO:root:Simulating beta_c parameters\n",
      "INFO:root:Randomising outputs\n",
      "100%|██████████| 1000/1000 [00:04<00:00, 239.25it/s]\n",
      "INFO:root:Simulating initial volumes for stage I  with norm params: mu=1.72, sigma=4.7, lb=-0.6221218732608373, ub=-0.023523848418276528\n",
      "INFO:root:Simulating initial volumes for stage II  with norm params: mu=1.96, sigma=1.63, lb=-1.9410876100159118, ub=0.3711345751297772\n",
      "INFO:root:Simulating initial volumes for stage IIIA  with norm params: mu=1.91, sigma=9.4, lb=-0.33127370258786554, ub=0.06967546355973796\n",
      "INFO:root:Simulating initial volumes for stage IIIB  with norm params: mu=2.76, sigma=6.87, lb=-0.5769974969906748, ub=-0.02839165102452155\n",
      "INFO:root:Simulating initial volumes for stage IV  with norm params: mu=3.86, sigma=8.82, lb=-0.5741465764541877, ub=-0.14683113860980307\n",
      "INFO:root:Got correlated params for 447 patients\n",
      "INFO:root:Got correlated params for 915 patients\n",
      "INFO:root:Got correlated params for 1414 patients\n",
      "INFO:root:Simulating beta_c parameters\n",
      "INFO:root:Randomising outputs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call to simulate counterfactuals data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 124/1000 [00:02<00:17, 49.97it/s]/work/postresearch/Shared/Researchers/Farbod/cancer/code/src/data/cancer_sim/cancer_simulation.py:734: RuntimeWarning: invalid value encountered in log\n",
      "  (1 + rho * np.log(K / (counterfactual_cancer_volume[current_t] + 1e-07) + 1e-07) -\n",
      "100%|██████████| 1000/1000 [00:19<00:00, 50.24it/s]\n",
      "INFO:src.data.cancer_sim.dataset:Processing train dataset before training\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed train data: {'cancer_volume': (10000, 60), 'chemo_dosage': (10000, 60), 'radio_dosage': (10000, 60), 'chemo_application': (10000, 60), 'radio_application': (10000, 60), 'chemo_probabilities': (10000, 60), 'radio_probabilities': (10000, 60), 'sequence_lengths': (10000,), 'death_flags': (10000, 60), 'recovery_flags': (10000, 60), 'patient_types': (10000,), 'prev_treatments': (10000, 59, 2), 'current_treatments': (10000, 59, 2), 'current_covariates': (10000, 59, 2), 'outputs': (10000, 59, 1), 'active_entries': (10000, 59, 1), 'unscaled_outputs': (10000, 59, 1), 'prev_outputs': (10000, 59, 1), 'static_features': (10000, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Processing val dataset before training\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed val data: {'cancer_volume': (1000, 60), 'chemo_dosage': (1000, 60), 'radio_dosage': (1000, 60), 'chemo_application': (1000, 60), 'radio_application': (1000, 60), 'chemo_probabilities': (1000, 60), 'radio_probabilities': (1000, 60), 'sequence_lengths': (1000,), 'death_flags': (1000, 60), 'recovery_flags': (1000, 60), 'patient_types': (1000,), 'prev_treatments': (1000, 59, 2), 'current_treatments': (1000, 59, 2), 'current_covariates': (1000, 59, 2), 'outputs': (1000, 59, 1), 'active_entries': (1000, 59, 1), 'unscaled_outputs': (1000, 59, 1), 'prev_outputs': (1000, 59, 1), 'static_features': (1000, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Processing test dataset before training\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'cancer_volume': (227200, 60), 'chemo_application': (227200, 60), 'radio_application': (227200, 60), 'sequence_lengths': (227200,), 'patient_types': (227200,), 'prev_treatments': (227200, 59, 2), 'current_treatments': (227200, 59, 2), 'current_covariates': (227200, 59, 2), 'outputs': (227200, 59, 1), 'active_entries': (227200, 59, 1), 'unscaled_outputs': (227200, 59, 1), 'prev_outputs': (227200, 59, 1), 'static_features': (227200, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Processing test dataset before training\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'cancer_volume': (575074, 65), 'chemo_application': (575074, 65), 'radio_application': (575074, 65), 'sequence_lengths': (575074,), 'patient_types': (575074,), 'patient_ids_all_trajectories': (575074,), 'patient_current_t': (575074,), 'prev_treatments': (575074, 64, 2), 'current_treatments': (575074, 64, 2), 'current_covariates': (575074, 64, 2), 'outputs': (575074, 64, 1), 'active_entries': (575074, 64, 1), 'unscaled_outputs': (575074, 64, 1), 'prev_outputs': (575074, 64, 1), 'static_features': (575074, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Processing test dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'active_encoder_r': (575074, 59), 'prev_treatments': (575074, 5, 2), 'current_treatments': (575074, 5, 2), 'current_covariates': (575074, 5, 2), 'prev_outputs': (575074, 5, 1), 'static_features': (575074, 1), 'outputs': (575074, 5, 1), 'sequence_lengths': (575074,), 'active_entries': (575074, 5, 1), 'unscaled_outputs': (575074, 5, 1), 'patient_types': (575074,), 'patient_ids_all_trajectories': (575074,), 'patient_current_t': (575074,)}\n",
      "INFO:src.models.msm:Input size of propensity_treatment: 2\n",
      "WARNING:urllib3.connectionpool:Retrying (JitteredRetry(total=6, connect=6, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa3d2304390>: Failed to establish a new connection: [Errno 111] Connection refused')': /api/2.0/mlflow/experiments/get-by-name?experiment_name=MSM%2Ftumor_generator\n",
      "WARNING:urllib3.connectionpool:Retrying (JitteredRetry(total=5, connect=5, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa51791ea10>: Failed to establish a new connection: [Errno 111] Connection refused')': /api/2.0/mlflow/experiments/get-by-name?experiment_name=MSM%2Ftumor_generator\n",
      "WARNING:urllib3.connectionpool:Retrying (JitteredRetry(total=4, connect=4, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa517960190>: Failed to establish a new connection: [Errno 111] Connection refused')': /api/2.0/mlflow/experiments/get-by-name?experiment_name=MSM%2Ftumor_generator\n",
      "WARNING:urllib3.connectionpool:Retrying (JitteredRetry(total=3, connect=3, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa517960c10>: Failed to establish a new connection: [Errno 111] Connection refused')': /api/2.0/mlflow/experiments/get-by-name?experiment_name=MSM%2Ftumor_generator\n",
      "WARNING:urllib3.connectionpool:Retrying (JitteredRetry(total=2, connect=2, read=7, redirect=7, status=7)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fa517961a50>: Failed to establish a new connection: [Errno 111] Connection refused')': /api/2.0/mlflow/experiments/get-by-name?experiment_name=MSM%2Ftumor_generator\n",
      "INFO:src.data.cancer_sim.dataset:Exploding train dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed train data: {'prev_treatments': (561403, 59, 2), 'current_treatments': (561403, 59, 2), 'static_features': (561403, 1), 'prev_outputs': (561403, 59, 1), 'outputs': (561403, 59, 1), 'unscaled_outputs': (561403, 59, 1), 'sequence_lengths': (561403,), 'active_entries': (561403, 59, 1)}\n",
      "INFO:src.models.msm:Input size of propensity_history: 4\n",
      "INFO:src.data.cancer_sim.dataset:Exploding train dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed train data: {'prev_treatments': (561403, 59, 2), 'current_treatments': (561403, 59, 2), 'static_features': (561403, 1), 'prev_outputs': (561403, 59, 1), 'outputs': (561403, 59, 1), 'unscaled_outputs': (561403, 59, 1), 'sequence_lengths': (561403,), 'active_entries': (561403, 59, 1)}\n",
      "INFO:src.models.msm:Input size of msm_regressor: 4\n",
      "INFO:src.models.msm:Propensity scores for train.\n",
      "INFO:src.data.cancer_sim.dataset:Exploding train dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed train data: {'prev_treatments': (580000, 59, 2), 'current_treatments': (580000, 59, 2), 'static_features': (580000, 1), 'prev_outputs': (580000, 59, 1), 'outputs': (580000, 59, 1), 'unscaled_outputs': (580000, 59, 1), 'sequence_lengths': (580000,), 'active_entries': (580000, 59, 1)}\n",
      "INFO:src.models.msm:Propensity scores for train.\n",
      "INFO:src.data.cancer_sim.dataset:Exploding train dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed train data: {'prev_treatments': (580000, 59, 2), 'current_treatments': (580000, 59, 2), 'static_features': (580000, 1), 'prev_outputs': (580000, 59, 1), 'outputs': (580000, 59, 1), 'unscaled_outputs': (580000, 59, 1), 'sequence_lengths': (580000,), 'active_entries': (580000, 59, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding train dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed train data: {'prev_treatments': (561403, 59, 2), 'current_treatments': (561403, 59, 2), 'static_features': (561403, 1), 'prev_outputs': (561403, 59, 1), 'outputs': (561403, 59, 1), 'unscaled_outputs': (561403, 59, 1), 'sequence_lengths': (561403,), 'active_entries': (561403, 59, 1), 'stabilized_weights': (561403, 59)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding train dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed train data: {'prev_treatments': (551418, 59, 2), 'current_treatments': (551418, 59, 2), 'static_features': (551418, 1), 'prev_outputs': (551418, 59, 1), 'outputs': (551418, 59, 1), 'unscaled_outputs': (551418, 59, 1), 'sequence_lengths': (551418,), 'active_entries': (551418, 59, 1), 'stabilized_weights': (551418, 59)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding train dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed train data: {'prev_treatments': (541531, 59, 2), 'current_treatments': (541531, 59, 2), 'static_features': (541531, 1), 'prev_outputs': (541531, 59, 1), 'outputs': (541531, 59, 1), 'unscaled_outputs': (541531, 59, 1), 'sequence_lengths': (541531,), 'active_entries': (541531, 59, 1), 'stabilized_weights': (541531, 59)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding train dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed train data: {'prev_treatments': (531713, 59, 2), 'current_treatments': (531713, 59, 2), 'static_features': (531713, 1), 'prev_outputs': (531713, 59, 1), 'outputs': (531713, 59, 1), 'unscaled_outputs': (531713, 59, 1), 'sequence_lengths': (531713,), 'active_entries': (531713, 59, 1), 'stabilized_weights': (531713, 59)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding train dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed train data: {'prev_treatments': (521932, 59, 2), 'current_treatments': (521932, 59, 2), 'static_features': (521932, 1), 'prev_outputs': (521932, 59, 1), 'outputs': (521932, 59, 1), 'unscaled_outputs': (521932, 59, 1), 'sequence_lengths': (521932,), 'active_entries': (521932, 59, 1), 'stabilized_weights': (521932, 59)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding train dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed train data: {'prev_treatments': (512170, 59, 2), 'current_treatments': (512170, 59, 2), 'static_features': (512170, 1), 'prev_outputs': (512170, 59, 1), 'outputs': (512170, 59, 1), 'unscaled_outputs': (512170, 59, 1), 'sequence_lengths': (512170,), 'active_entries': (512170, 59, 1), 'stabilized_weights': (512170, 59)}\n",
      "INFO:src.models.time_varying_model:RMSE calculation for test.\n",
      "INFO:src.models.msm:Predictions for test.\n",
      "INFO:src.data.cancer_sim.dataset:Exploding test dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'prev_treatments': (580000, 59, 2), 'current_treatments': (580000, 59, 2), 'static_features': (580000, 1), 'prev_outputs': (580000, 59, 1), 'outputs': (580000, 59, 1), 'unscaled_outputs': (580000, 59, 1), 'sequence_lengths': (580000,), 'active_entries': (580000, 59, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding test dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'prev_treatments': (580000, 59, 2), 'current_treatments': (580000, 59, 2), 'static_features': (580000, 1), 'prev_outputs': (580000, 59, 1), 'outputs': (580000, 59, 1), 'unscaled_outputs': (580000, 59, 1), 'sequence_lengths': (580000,), 'active_entries': (580000, 59, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding test dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'prev_treatments': (580000, 59, 2), 'current_treatments': (580000, 59, 2), 'static_features': (580000, 1), 'prev_outputs': (580000, 59, 1), 'outputs': (580000, 59, 1), 'unscaled_outputs': (580000, 59, 1), 'sequence_lengths': (580000,), 'active_entries': (580000, 59, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding test dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'prev_treatments': (580000, 59, 2), 'current_treatments': (580000, 59, 2), 'static_features': (580000, 1), 'prev_outputs': (580000, 59, 1), 'outputs': (580000, 59, 1), 'unscaled_outputs': (580000, 59, 1), 'sequence_lengths': (580000,), 'active_entries': (580000, 59, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding test dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'prev_treatments': (580000, 59, 2), 'current_treatments': (580000, 59, 2), 'static_features': (580000, 1), 'prev_outputs': (580000, 59, 1), 'outputs': (580000, 59, 1), 'unscaled_outputs': (580000, 59, 1), 'sequence_lengths': (580000,), 'active_entries': (580000, 59, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding test dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'prev_treatments': (580000, 59, 2), 'current_treatments': (580000, 59, 2), 'static_features': (580000, 1), 'prev_outputs': (580000, 59, 1), 'outputs': (580000, 59, 1), 'unscaled_outputs': (580000, 59, 1), 'sequence_lengths': (580000,), 'active_entries': (580000, 59, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding test dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'prev_treatments': (580000, 59, 2), 'current_treatments': (580000, 59, 2), 'static_features': (580000, 1), 'prev_outputs': (580000, 59, 1), 'outputs': (580000, 59, 1), 'unscaled_outputs': (580000, 59, 1), 'sequence_lengths': (580000,), 'active_entries': (580000, 59, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding test dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'prev_treatments': (580000, 59, 2), 'current_treatments': (580000, 59, 2), 'static_features': (580000, 1), 'prev_outputs': (580000, 59, 1), 'outputs': (580000, 59, 1), 'unscaled_outputs': (580000, 59, 1), 'sequence_lengths': (580000,), 'active_entries': (580000, 59, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding test dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'prev_treatments': (580000, 59, 2), 'current_treatments': (580000, 59, 2), 'static_features': (580000, 1), 'prev_outputs': (580000, 59, 1), 'outputs': (580000, 59, 1), 'unscaled_outputs': (580000, 59, 1), 'sequence_lengths': (580000,), 'active_entries': (580000, 59, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding test dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'prev_treatments': (580000, 59, 2), 'current_treatments': (580000, 59, 2), 'static_features': (580000, 1), 'prev_outputs': (580000, 59, 1), 'outputs': (580000, 59, 1), 'unscaled_outputs': (580000, 59, 1), 'sequence_lengths': (580000,), 'active_entries': (580000, 59, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding test dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'prev_treatments': (580000, 59, 2), 'current_treatments': (580000, 59, 2), 'static_features': (580000, 1), 'prev_outputs': (580000, 59, 1), 'outputs': (580000, 59, 1), 'unscaled_outputs': (580000, 59, 1), 'sequence_lengths': (580000,), 'active_entries': (580000, 59, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding test dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'prev_treatments': (580000, 59, 2), 'current_treatments': (580000, 59, 2), 'static_features': (580000, 1), 'prev_outputs': (580000, 59, 1), 'outputs': (580000, 59, 1), 'unscaled_outputs': (580000, 59, 1), 'sequence_lengths': (580000,), 'active_entries': (580000, 59, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding test dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'prev_treatments': (580000, 59, 2), 'current_treatments': (580000, 59, 2), 'static_features': (580000, 1), 'prev_outputs': (580000, 59, 1), 'outputs': (580000, 59, 1), 'unscaled_outputs': (580000, 59, 1), 'sequence_lengths': (580000,), 'active_entries': (580000, 59, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding test dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'prev_treatments': (580000, 59, 2), 'current_treatments': (580000, 59, 2), 'static_features': (580000, 1), 'prev_outputs': (580000, 59, 1), 'outputs': (580000, 59, 1), 'unscaled_outputs': (580000, 59, 1), 'sequence_lengths': (580000,), 'active_entries': (580000, 59, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding test dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'prev_treatments': (580000, 59, 2), 'current_treatments': (580000, 59, 2), 'static_features': (580000, 1), 'prev_outputs': (580000, 59, 1), 'outputs': (580000, 59, 1), 'unscaled_outputs': (580000, 59, 1), 'sequence_lengths': (580000,), 'active_entries': (580000, 59, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding test dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'prev_treatments': (580000, 59, 2), 'current_treatments': (580000, 59, 2), 'static_features': (580000, 1), 'prev_outputs': (580000, 59, 1), 'outputs': (580000, 59, 1), 'unscaled_outputs': (580000, 59, 1), 'sequence_lengths': (580000,), 'active_entries': (580000, 59, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding test dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'prev_treatments': (580000, 59, 2), 'current_treatments': (580000, 59, 2), 'static_features': (580000, 1), 'prev_outputs': (580000, 59, 1), 'outputs': (580000, 59, 1), 'unscaled_outputs': (580000, 59, 1), 'sequence_lengths': (580000,), 'active_entries': (580000, 59, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding test dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'prev_treatments': (580000, 59, 2), 'current_treatments': (580000, 59, 2), 'static_features': (580000, 1), 'prev_outputs': (580000, 59, 1), 'outputs': (580000, 59, 1), 'unscaled_outputs': (580000, 59, 1), 'sequence_lengths': (580000,), 'active_entries': (580000, 59, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding test dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'prev_treatments': (580000, 59, 2), 'current_treatments': (580000, 59, 2), 'static_features': (580000, 1), 'prev_outputs': (580000, 59, 1), 'outputs': (580000, 59, 1), 'unscaled_outputs': (580000, 59, 1), 'sequence_lengths': (580000,), 'active_entries': (580000, 59, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding test dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'prev_treatments': (580000, 59, 2), 'current_treatments': (580000, 59, 2), 'static_features': (580000, 1), 'prev_outputs': (580000, 59, 1), 'outputs': (580000, 59, 1), 'unscaled_outputs': (580000, 59, 1), 'sequence_lengths': (580000,), 'active_entries': (580000, 59, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding test dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'prev_treatments': (580000, 59, 2), 'current_treatments': (580000, 59, 2), 'static_features': (580000, 1), 'prev_outputs': (580000, 59, 1), 'outputs': (580000, 59, 1), 'unscaled_outputs': (580000, 59, 1), 'sequence_lengths': (580000,), 'active_entries': (580000, 59, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding test dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'prev_treatments': (580000, 59, 2), 'current_treatments': (580000, 59, 2), 'static_features': (580000, 1), 'prev_outputs': (580000, 59, 1), 'outputs': (580000, 59, 1), 'unscaled_outputs': (580000, 59, 1), 'sequence_lengths': (580000,), 'active_entries': (580000, 59, 1)}\n",
      "INFO:src.data.cancer_sim.dataset:Exploding test dataset before testing (multiple sequences)\n",
      "INFO:src.data.cancer_sim.dataset:Shape of processed test data: {'prev_treatments': (417600, 59, 2), 'current_treatments': (417600, 59, 2), 'static_features': (417600, 1), 'prev_outputs': (417600, 59, 1), 'outputs': (417600, 59, 1), 'unscaled_outputs': (417600, 59, 1), 'sequence_lengths': (417600,), 'active_entries': (417600, 59, 1)}\n",
      "INFO:__main__:Test normalised RMSE (all): 2.7317362036025155; Test normalised RMSE (orig): 2.1275290025545286; Test normalised RMSE (only counterfactual): 1.966666032411937\n",
      "INFO:src.models.time_varying_model:RMSE calculation for test.\n",
      "INFO:src.models.msm:Autoregressive Prediction for test.\n",
      "INFO:__main__:Test normalised RMSE (n-step prediction): {'2-step': 3.8369426193723104, '3-step': 4.102038264183819, '4-step': 4.087582153521721, '5-step': 3.9701058554085225, '6-step': 3.7720720597800987}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run useful-crow-778 at: http://127.0.0.1:8081/#/experiments/997620564669772123/runs/c71385cdc3c14e718e8138b77ee63478\n",
      "🧪 View experiment at: http://127.0.0.1:8081/#/experiments/997620564669772123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'encoder_test_rmse_all': 2.7317362036025155,\n",
       " 'encoder_test_rmse_orig': 2.1275290025545286,\n",
       " 'encoder_test_rmse_last': 1.966666032411937,\n",
       " 'decoder_test_rmse_2-step': 3.8369426193723104,\n",
       " 'decoder_test_rmse_3-step': 4.102038264183819,\n",
       " 'decoder_test_rmse_4-step': 4.087582153521721,\n",
       " 'decoder_test_rmse_5-step': 3.9701058554085225,\n",
       " 'decoder_test_rmse_6-step': 3.7720720597800987}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import hydra\n",
    "import torch\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from hydra.utils import instantiate\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "from src.models.utils import FilteringMlFlowLogger\n",
    "from src.models.msm import MSM\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "torch.set_default_dtype(torch.double)\n",
    "\n",
    "# Load the configuration file\n",
    "config_path = '/work/postresearch/Shared/Researchers/Farbod/cancer/code/config/cancer_sim_MSM.yaml'\n",
    "args = OmegaConf.load(config_path)\n",
    "# @hydra.main(config_name=f'config.yaml', config_path='../config/')\n",
    "\n",
    "\n",
    "def main(args: DictConfig):\n",
    "    \"\"\"\n",
    "    Training / evaluation script for MSMs\n",
    "    Args:\n",
    "        args: arguments of run as DictConfig\n",
    "\n",
    "    Returns: dict with results (one and nultiple-step-ahead RMSEs)\n",
    "    \"\"\"\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # Non-strict access to fields\n",
    "    OmegaConf.set_struct(args, False)\n",
    "    OmegaConf.register_new_resolver(\"sum\", lambda x, y: x + y, replace=True)\n",
    "    logger.info('\\n' + OmegaConf.to_yaml(args, resolve=True))\n",
    "\n",
    "    # Initialisation of data to calculate dim_outcomes, dim_treatments, dim_vitals and dim_static_features\n",
    "    seed_everything(args.exp.seed)\n",
    "    dataset_collection = instantiate(args.dataset, _recursive_=True)\n",
    "    # Only binary multilabel regime possible\n",
    "    assert args.dataset.treatment_mode == 'multilabel'\n",
    "    dataset_collection.process_data_multi()\n",
    "    args.model.dim_outcomes = dataset_collection.train_f.data['outputs'].shape[-1]\n",
    "    args.model.dim_treatments = dataset_collection.train_f.data['current_treatments'].shape[-1]\n",
    "    args.model.dim_vitals = dataset_collection.train_f.data[\n",
    "        'vitals'].shape[-1] if dataset_collection.has_vitals else 0\n",
    "    args.model.dim_static_features = dataset_collection.train_f.data['static_features'].shape[-1]\n",
    "\n",
    "    # MlFlow Logger\n",
    "    if args.exp.logging:\n",
    "        experiment_name = f'{args.model.name}/{args.dataset.name}'\n",
    "        mlf_logger = FilteringMlFlowLogger(filter_submodels=MSM.possible_model_types, experiment_name=experiment_name,\n",
    "                                           tracking_uri=args.exp.mlflow_uri)\n",
    "    else:\n",
    "        mlf_logger = None\n",
    "\n",
    "    # ============================== Nominator (treatment propensity network) ==============================\n",
    "    propensity_treatment = instantiate(\n",
    "        args.model.propensity_treatment, args, dataset_collection, _recursive_=False)\n",
    "    mlf_logger.log_hyperparams(propensity_treatment.hparams)\n",
    "    propensity_treatment.fit()\n",
    "\n",
    "    # ============================== Denominator (history propensity network) ==============================\n",
    "    propensity_history = instantiate(\n",
    "        args.model.propensity_history, args, dataset_collection, _recursive_=False)\n",
    "    mlf_logger.log_hyperparams(propensity_history.hparams)\n",
    "    propensity_history.fit()\n",
    "\n",
    "    # ============================== Initialisation & Training of Encoder ==============================\n",
    "    msm_regressor = instantiate(args.model.msm_regressor, args, propensity_treatment, propensity_history, dataset_collection,\n",
    "                                _recursive_=False)\n",
    "    mlf_logger.log_hyperparams(msm_regressor.hparams)\n",
    "    msm_regressor.fit()\n",
    "    encoder_results = {}\n",
    "\n",
    "    if hasattr(dataset_collection, 'test_cf_one_step'):  # Test one_step_counterfactual rmse\n",
    "        test_rmse_orig, test_rmse_all, test_rmse_last = \\\n",
    "            msm_regressor.get_normalised_masked_rmse(\n",
    "                dataset_collection.test_cf_one_step, one_step_counterfactual=True)\n",
    "        logger.info(f'Test normalised RMSE (all): {test_rmse_all}; '\n",
    "                    f'Test normalised RMSE (orig): {test_rmse_orig}; '\n",
    "                    f'Test normalised RMSE (only counterfactual): {test_rmse_last}')\n",
    "        encoder_results = {\n",
    "            'encoder_test_rmse_all': test_rmse_all,\n",
    "            'encoder_test_rmse_orig': test_rmse_orig,\n",
    "            'encoder_test_rmse_last': test_rmse_last\n",
    "        }\n",
    "    elif hasattr(dataset_collection, 'test_f'):  # Test factual rmse\n",
    "        test_rmse_orig, test_rmse_all = msm_regressor.get_normalised_masked_rmse(\n",
    "            dataset_collection.test_f)\n",
    "        logger.info(f'Test normalised RMSE (all): {test_rmse_all}; '\n",
    "                    f'Test normalised RMSE (orig): {test_rmse_orig}.')\n",
    "        encoder_results = {\n",
    "            # 'encoder_val_rmse_all': val_rmse_all,\n",
    "            # 'encoder_val_rmse_orig': val_rmse_orig,\n",
    "            'encoder_test_rmse_all': test_rmse_all,\n",
    "            'encoder_test_rmse_orig': test_rmse_orig\n",
    "        }\n",
    "\n",
    "    mlf_logger.log_metrics(encoder_results) if args.exp.logging else None\n",
    "    results.update(encoder_results)\n",
    "\n",
    "    test_rmses = {}\n",
    "    if hasattr(dataset_collection, 'test_cf_treatment_seq'):  # Test n_step_counterfactual rmse\n",
    "        test_rmses = msm_regressor.get_normalised_n_step_rmses(\n",
    "            dataset_collection.test_cf_treatment_seq)\n",
    "    elif hasattr(dataset_collection, 'test_f_multi'):  # Test n_step_factual rmse\n",
    "        test_rmses = msm_regressor.get_normalised_n_step_rmses(\n",
    "            dataset_collection.test_f_multi)\n",
    "    test_rmses = {f'{k+2}-step': v for (k, v) in enumerate(test_rmses)}\n",
    "\n",
    "    logger.info(f'Test normalised RMSE (n-step prediction): {test_rmses}')\n",
    "    decoder_results = {('decoder_test_rmse_' + k)                       : v for (k, v) in test_rmses.items()}\n",
    "\n",
    "    mlf_logger.log_metrics(decoder_results) if args.exp.logging else None\n",
    "    results.update(decoder_results)\n",
    "\n",
    "    mlf_logger.experiment.set_terminated(\n",
    "        mlf_logger.run_id) if args.exp.logging else None\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_old",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
