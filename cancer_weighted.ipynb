{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/postresearch/Shared/Researchers/Farbod/cancer/code/CausalDiff\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# set wd to cancer\n",
    "os.chdir(\"/work/postresearch/Shared/Researchers/Farbod/cancer/code/CausalDiff\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import copy\n",
    "import logging\n",
    "import requests\n",
    "import zipfile\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from itertools import chain\n",
    "from typing import Union\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier, MultiOutputRegressor\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from omegaconf.errors import MissingMandatoryValue\n",
    "\n",
    "import ray\n",
    "from ray import tune, ray_constants\n",
    "\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "from einops import rearrange, reduce, repeat\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "from src.data import RealDatasetCollection, SyntheticDatasetCollection\n",
    "from src.models import TimeVaryingCausalModel\n",
    "from src.models.CausalDiff import *\n",
    "from src.models.utils import (\n",
    "    grad_reverse,\n",
    "    BRTreatmentOutcomeHead,\n",
    "    AlphaRise,\n",
    "    clip_normalize_stabilized_weights,\n",
    ")\n",
    "from src.models.utils_lstm import VariationalLSTM\n",
    "from copy import deepcopy\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "11.8\n",
      "Number of available GPUs: 1\n",
      "GPU 0: NVIDIA A100 80GB PCIe\n"
     ]
    }
   ],
   "source": [
    "# show pytorch version and cuda version\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of available GPUs: {num_gpus}\")\n",
    "    for i in range(num_gpus):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        print(f\"GPU {i}: {gpu_name}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. No GPUs detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting and preparing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class CausalDiff(TimeVaryingCausalModel):\n",
    "\n",
    "    model_type = None  # Will be defined in subclasses\n",
    "    possible_model_types = {'msm_regressor',\n",
    "                            'propensity_treatment', 'propensity_history'}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        args: DictConfig,\n",
    "        dataset_collection: Union[\n",
    "            RealDatasetCollection, SyntheticDatasetCollection\n",
    "        ] = None,\n",
    "        autoregressive: bool = None,\n",
    "        has_vitals: bool = None,\n",
    "        projection_horizon: int = None,\n",
    "        bce_weights: np.array = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:args: DictConfig of model hyperparameters\n",
    "            dataset_collection: Dataset collection\n",
    "            autoregressive: Flag of including previous outcomes to modelling\n",
    "            has_vitals: Flag of vitals in dataset\n",
    "            projection_horizon: Range of tau-step-ahead prediction (tau = projection_horizon + 1)\n",
    "            bce_weights: Re-weight BCE if used\n",
    "            **kwargs: Other arguments\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            args, dataset_collection, autoregressive, has_vitals, bce_weights\n",
    "        )\n",
    "\n",
    "        if self.dataset_collection is not None:\n",
    "            self.projection_horizon = self.dataset_collection.projection_horizon\n",
    "        else:\n",
    "            self.projection_horizon = projection_horizon\n",
    "\n",
    "        self.lag_features = args.model.lag_features\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        if (\n",
    "            self.dataset_collection is not None\n",
    "            and not self.dataset_collection.processed_data_multi\n",
    "        ):\n",
    "            self.dataset_collection.process_data_multi()\n",
    "\n",
    "    def get_exploded_dataset(self, dataset: Dataset, min_length: int, only_active_entries=True, max_length=None) -> Dataset:\n",
    "        exploded_dataset = deepcopy(dataset)\n",
    "        if max_length is None:\n",
    "            max_length = max(exploded_dataset.data['sequence_lengths'][:])\n",
    "        if not only_active_entries:\n",
    "            exploded_dataset.data['active_entries'][:, :, :] = 1.0\n",
    "            exploded_dataset.data['sequence_lengths'][:] = max_length\n",
    "        exploded_dataset.explode_trajectories(min_length)\n",
    "        return exploded_dataset\n",
    "\n",
    "    def get_propensity_scores(self, dataset: Dataset) -> np.array:\n",
    "        logger.info(f'Propensity scores for {dataset.subset_name}.')\n",
    "        exploded_dataset = self.get_exploded_dataset(\n",
    "            dataset, min_length=self.lag_features, only_active_entries=False)\n",
    "\n",
    "        inputs = self.get_inputs(exploded_dataset)\n",
    "        classifier = getattr(self, self.model_type)\n",
    "\n",
    "        propensity_scores = np.stack(\n",
    "            classifier.predict_proba(inputs), 1)[:, :, 1]\n",
    "        propensity_scores = propensity_scores.reshape(dataset.data['active_entries'].shape[0],\n",
    "                                                      dataset.data['active_entries'].shape[1] -\n",
    "                                                      self.lag_features,\n",
    "                                                      self.dim_treatments)\n",
    "        propensity_scores = np.concatenate([0.5 * np.ones((propensity_scores.shape[0], self.lag_features, self.dim_treatments)),\n",
    "                                            propensity_scores], axis=1)\n",
    "        return propensity_scores\n",
    "\n",
    "    # def get_propensity_scores(self, classifier, inputs, dataset: Dataset) -> np.array:\n",
    "    #     logger.info(f'Propensity scores for {dataset.subset_name}.')\n",
    "\n",
    "    #     propensity_scores = np.stack(\n",
    "    #         classifier.predict_proba(inputs), 1)[:, :, 1]\n",
    "    #     propensity_scores = propensity_scores.reshape(dataset.data['active_entries'].shape[0],\n",
    "    #                                                   dataset.data['active_entries'].shape[1] -\n",
    "    #                                                   self.lag_features,\n",
    "    #                                                   self.dim_treatments)\n",
    "    #     propensity_scores = np.concatenate([0.5 * np.ones((propensity_scores.shape[0], self.lag_features, self.dim_treatments)),\n",
    "    #                                         propensity_scores], axis=1)\n",
    "    #     return propensity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the configuration file\n",
    "# config_path = '/work/postresearch/Shared/Researchers/Farbod/cancer/code/CausalDiff/config/cancer_sim_notebook.yaml'\n",
    "# args = OmegaConf.load(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Instantiate the dataset collection\n",
    "# dataset_collection = instantiate(args.dataset, _recursive_=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an instance of CausalDiff\n",
    "# causal_diff = CausalDiff(args, dataset_collection)\n",
    "\n",
    "# # Test the prepare_data method\n",
    "# causal_diff.prepare_data()\n",
    "\n",
    "# # Test the get_exploded_dataset method\n",
    "# exploded_dataset = causal_diff.get_exploded_dataset(\n",
    "#     causal_diff.dataset_collection.train_f, min_length=args.model.min_length\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in causal_diff.dataset_collection.train_f.data.keys():\n",
    "#     print(key, causal_diff.dataset_collection.train_f.data[key][0])\n",
    "#     print(key, causal_diff.dataset_collection.train_f.data[key][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploded_dataset.data['outputs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in exploded_dataset.data.keys():\n",
    "#     print(key, exploded_dataset.data[key][0])\n",
    "#     print(key, exploded_dataset.data[key][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the configuration file\n",
    "config_path = '/work/postresearch/Shared/Researchers/Farbod/cancer/code/CausalDiff/config/cancer_sim_notebook.yaml'\n",
    "args = OmegaConf.load(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/postresearch/Shared/Researchers/Farbod/cancer/code/CausalDiff/src/data/cancer_sim/cancer_simulation.py:346: RuntimeWarning: overflow encountered in exp\n",
      "  if recovery_rvs[i, t] < np.exp(-cancer_volume[i, t] * TUMOUR_CELL_DENSITY):\n",
      "100%|██████████| 10000/10000 [00:11<00:00, 852.07it/s]\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 870.95it/s]\n",
      " 24%|██▍       | 24/100 [00:00<00:00, 234.34it/s]/work/postresearch/Shared/Researchers/Farbod/cancer/code/CausalDiff/src/data/cancer_sim/cancer_simulation.py:39: RuntimeWarning: invalid value encountered in scalar power\n",
      "  return ((volume / (4 / 3 * np.pi)) ** (1 / 3)) * 2\n",
      "100%|██████████| 100/100 [00:00<00:00, 235.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call to simulate counterfactuals data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:00<00:02, 47.37it/s]/work/postresearch/Shared/Researchers/Farbod/cancer/code/CausalDiff/src/data/cancer_sim/cancer_simulation.py:734: RuntimeWarning: invalid value encountered in log\n",
      "  (1 + rho * np.log(K / (counterfactual_cancer_volume[current_t] + 1e-07) + 1e-07) -\n",
      "100%|██████████| 100/100 [00:02<00:00, 49.60it/s]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the dataset collection\n",
    "dataset_collection = instantiate(args.dataset, _recursive_=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSMPropensityTreatment(CausalDiff):\n",
    "\n",
    "    model_type = 'propensity_treatment'\n",
    "\n",
    "    def __init__(self,\n",
    "                 args: DictConfig,\n",
    "                 dataset_collection: Union[RealDatasetCollection,\n",
    "                                           SyntheticDatasetCollection] = None,\n",
    "                 autoregressive: bool = None, has_vitals: bool = None, **kwargs):\n",
    "        super().__init__(args, dataset_collection, autoregressive, has_vitals)\n",
    "\n",
    "        self.input_size = self.dim_treatments\n",
    "        logger.info(f'Input size of {self.model_type}: {self.input_size}')\n",
    "        self.output_size = self.dim_treatments\n",
    "\n",
    "        self.propensity_treatment = MultiOutputClassifier(\n",
    "            LogisticRegression(penalty=None, max_iter=args.exp.max_epochs))\n",
    "        self.save_hyperparameters(args)\n",
    "\n",
    "    def get_inputs(self, dataset: Dataset) -> np.array:\n",
    "        active_entries = dataset.data['active_entries']\n",
    "        prev_treatments = dataset.data['prev_treatments']\n",
    "        inputs = (prev_treatments * active_entries).sum(1)\n",
    "        return inputs\n",
    "\n",
    "    def fit(self):\n",
    "        self.prepare_data()\n",
    "        train_f = self.get_exploded_dataset(\n",
    "            self.dataset_collection.train_f, min_length=self.lag_features)\n",
    "        active_entries = train_f.data['active_entries']\n",
    "        last_entries = active_entries - \\\n",
    "            np.concatenate([active_entries[:, 1:, :], np.zeros(\n",
    "                (active_entries.shape[0], 1, 1))], axis=1)\n",
    "\n",
    "        # Inputs\n",
    "        inputs = self.get_inputs(train_f)\n",
    "\n",
    "        # Outputs\n",
    "        current_treatments = train_f.data['current_treatments']\n",
    "        outputs = (current_treatments * last_entries).sum(1)\n",
    "\n",
    "        self.propensity_treatment.fit(inputs, outputs)\n",
    "\n",
    "\n",
    "class MSMPropensityHistory(CausalDiff):\n",
    "\n",
    "    model_type = 'propensity_history'\n",
    "\n",
    "    def __init__(self,\n",
    "                 args: DictConfig,\n",
    "                 dataset_collection: Union[RealDatasetCollection,\n",
    "                                           SyntheticDatasetCollection] = None,\n",
    "                 autoregressive: bool = None, has_vitals: bool = None, **kwargs):\n",
    "        super().__init__(args, dataset_collection, autoregressive, has_vitals)\n",
    "\n",
    "        self.input_size = self.dim_treatments + self.dim_static_features\n",
    "        self.input_size += self.dim_vitals if self.has_vitals else 0\n",
    "        self.input_size += self.dim_outcome if self.autoregressive else 0\n",
    "\n",
    "        logger.info(f'Input size of {self.model_type}: {self.input_size}')\n",
    "        self.output_size = self.dim_treatments\n",
    "\n",
    "        self.propensity_history = MultiOutputClassifier(\n",
    "            LogisticRegression(penalty=None, max_iter=args.exp.max_epochs))\n",
    "        self.save_hyperparameters(args)\n",
    "\n",
    "    def get_inputs(self, dataset: Dataset, projection_horizon=0) -> np.array:\n",
    "        active_entries = dataset.data['active_entries']\n",
    "        lagged_entries = active_entries - \\\n",
    "            np.concatenate([active_entries[:, self.lag_features + 1:, :],\n",
    "                            np.zeros((active_entries.shape[0], self.lag_features + 1, 1))], axis=1)\n",
    "        if projection_horizon > 0:\n",
    "            lagged_entries = np.concatenate([lagged_entries[:, projection_horizon:, :],\n",
    "                                             np.zeros((active_entries.shape[0], projection_horizon, 1))], axis=1)\n",
    "\n",
    "        active_entries_before_proection = np.concatenate([active_entries[:, projection_horizon:, :],\n",
    "                                                          np.zeros((active_entries.shape[0], projection_horizon, 1))], axis=1)\n",
    "\n",
    "        prev_treatments = dataset.data['prev_treatments']\n",
    "        inputs = [(prev_treatments * active_entries_before_proection).sum(1)]\n",
    "        if self.has_vitals:\n",
    "            vitals = dataset.data['vitals']\n",
    "            inputs.append(vitals[np.repeat(lagged_entries, self.dim_vitals, 2) == 1.0].reshape(vitals.shape[0],\n",
    "                                                                                               (self.lag_features + 1) *\n",
    "                                                                                               self.dim_vitals))\n",
    "        if self.autoregressive:\n",
    "            prev_outputs = dataset.data['prev_outputs']\n",
    "            inputs.append(prev_outputs[np.repeat(lagged_entries, self.dim_outcome, 2) == 1.0].reshape(prev_outputs.shape[0],\n",
    "                                                                                                      (self.lag_features + 1) *\n",
    "                                                                                                      self.dim_outcome))\n",
    "        static_features = dataset.data['static_features']\n",
    "        inputs.append(static_features)\n",
    "        return np.concatenate(inputs, axis=1)\n",
    "\n",
    "    def fit(self):\n",
    "        self.prepare_data()\n",
    "        train_f = self.get_exploded_dataset(\n",
    "            self.dataset_collection.train_f, min_length=self.lag_features)\n",
    "        active_entries = train_f.data['active_entries']\n",
    "        last_entries = active_entries - \\\n",
    "            np.concatenate([active_entries[:, 1:, :], np.zeros(\n",
    "                (active_entries.shape[0], 1, 1))], axis=1)\n",
    "\n",
    "        # Inputs\n",
    "        inputs = self.get_inputs(train_f)\n",
    "\n",
    "        # Outputs\n",
    "        current_treatments = train_f.data['current_treatments']\n",
    "        outputs = (current_treatments * last_entries).sum(1)\n",
    "\n",
    "        self.propensity_history.fit(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSMPropensityTreatment_model = MSMPropensityTreatment(args, dataset_collection)\n",
    "MSMPropensityTreatment_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       , 0.5       , 0.5       ],\n",
       "       [0.58432225, 0.16691045, 0.16648337, 0.09418818],\n",
       "       [0.59009062, 0.16505337, 0.16455521, 0.08939697],\n",
       "       [0.59583431, 0.16321291, 0.16264503, 0.08482665],\n",
       "       [0.59791013, 0.16307293, 0.16234886, 0.08243974],\n",
       "       [0.60361785, 0.16125029, 0.16045937, 0.07819456],\n",
       "       [0.60929749, 0.15944413, 0.1585877 , 0.07415032],\n",
       "       [0.61494766, 0.15765441, 0.15673379, 0.07029929],\n",
       "       [0.62056701, 0.15588104, 0.15489757, 0.06663388],\n",
       "       [0.62615421, 0.15412398, 0.15307895, 0.0631466 ],\n",
       "       [0.63170796, 0.15238314, 0.15127787, 0.05983013],\n",
       "       [0.63722701, 0.15065847, 0.14949423, 0.0566773 ],\n",
       "       [0.64271013, 0.14894988, 0.14772796, 0.05368113],\n",
       "       [0.64815613, 0.14725731, 0.14597898, 0.05083481],\n",
       "       [0.63967077, 0.14945075, 0.14814835, 0.05542171],\n",
       "       [0.64165684, 0.14932047, 0.14787392, 0.05381356],\n",
       "       [0.64711008, 0.14762442, 0.14612351, 0.0509606 ],\n",
       "       [0.65252528, 0.14594433, 0.1443903 , 0.04825117],\n",
       "       [0.65447877, 0.14581659, 0.14412165, 0.04684077],\n",
       "       [0.65984033, 0.14415359, 0.14240823, 0.04434015],\n",
       "       [0.66516126, 0.1425064 , 0.14071183, 0.04196715],\n",
       "       [0.66707996, 0.14238116, 0.1404489 , 0.04073257],\n",
       "       [0.67234387, 0.14075089, 0.13877207, 0.03854486],\n",
       "       [0.67756479, 0.13913626, 0.13711206, 0.03647017],\n",
       "       [0.68274177, 0.13753719, 0.13546878, 0.03450315],\n",
       "       [0.68787392, 0.13595359, 0.13384215, 0.03263863],\n",
       "       [0.69296038, 0.13438538, 0.13223206, 0.03087164],\n",
       "       [0.69479288, 0.13426616, 0.13198254, 0.02995326],\n",
       "       [0.69981579, 0.13271443, 0.13039145, 0.0283274 ],\n",
       "       [0.70479117, 0.13117792, 0.1288167 , 0.02678735],\n",
       "       [0.70971829, 0.12965653, 0.12725818, 0.02532885],\n",
       "       [0.71459647, 0.12815019, 0.1257158 , 0.0239478 ],\n",
       "       [0.71942508, 0.1266588 , 0.12418945, 0.0226403 ],\n",
       "       [0.72420353, 0.12518227, 0.12267903, 0.02140263],\n",
       "       [0.72504211, 0.1252855 , 0.12298461, 0.02082742],\n",
       "       [0.72976083, 0.12382272, 0.12148681, 0.01968685],\n",
       "       [0.73442823, 0.12237462, 0.12000476, 0.01860756],\n",
       "       [0.73610748, 0.12226455, 0.11977513, 0.01804722],\n",
       "       [0.73777991, 0.12215457, 0.11954587, 0.01750346],\n",
       "       [0.74235771, 0.12072329, 0.11808432, 0.01654185],\n",
       "       [0.746883  , 0.11930651, 0.11663826, 0.01563222],\n",
       "       [0.75135544, 0.11790412, 0.1152076 , 0.01477187],\n",
       "       [0.7557747 , 0.11651604, 0.11379223, 0.01395819],\n",
       "       [0.76014048, 0.11514216, 0.11239204, 0.01318874],\n",
       "       [0.76445254, 0.1137824 , 0.11100692, 0.01246116],\n",
       "       [0.76600243, 0.11367906, 0.11079234, 0.01208364],\n",
       "       [0.76754523, 0.1135758 , 0.11057812, 0.01171741],\n",
       "       [0.77176414, 0.11223219, 0.1092126 , 0.01107009],\n",
       "       [0.77250353, 0.11232612, 0.10948882, 0.01076952],\n",
       "       [0.77401611, 0.11222393, 0.10927681, 0.0104427 ],\n",
       "       [0.77815152, 0.11089431, 0.10792541, 0.0098651 ],\n",
       "       [0.78223255, 0.1095785 , 0.10658873, 0.00931915],\n",
       "       [0.78625913, 0.10827641, 0.10526665, 0.00880314],\n",
       "       [0.79023122, 0.10698792, 0.10395905, 0.00831547],\n",
       "       [0.79414883, 0.10571295, 0.10266584, 0.00785459],\n",
       "       [0.79801197, 0.1044514 , 0.10138689, 0.00741907],\n",
       "       [0.8018207 , 0.10320317, 0.1001221 , 0.00700753],\n",
       "       [0.80557511, 0.10196815, 0.09887135, 0.00661866],\n",
       "       [0.80927531, 0.10074625, 0.09763453, 0.00625124]])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propensity_scores_treatment = MSMPropensityTreatment_model.get_propensity_scores(\n",
    "    dataset_collection.train_f)\n",
    "propensity_scores_treatment[0]\n",
    "\n",
    "# compare to actual treatment\n",
    "train_f = dataset_collection.train_f\n",
    "train_f.data['current_treatments'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSMPropensityHistory_model = MSMPropensityHistory(args, dataset_collection)\n",
    "MSMPropensityHistory_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       , 0.5       , 0.5       ],\n",
       "       [0.64273237, 0.16444101, 0.16426105, 0.06486632],\n",
       "       [0.64662042, 0.16266469, 0.16240535, 0.06210274],\n",
       "       [0.65050755, 0.16090388, 0.16056678, 0.0594473 ],\n",
       "       [0.65046105, 0.16085495, 0.16034631, 0.05876648],\n",
       "       [0.65509812, 0.15910058, 0.15852144, 0.0561666 ],\n",
       "       [0.65894405, 0.15737056, 0.15671793, 0.05375044],\n",
       "       [0.66278799, 0.15565609, 0.15493163, 0.05143052],\n",
       "       [0.6665716 , 0.15395711, 0.15316192, 0.04920922],\n",
       "       [0.67035622, 0.15227336, 0.15140904, 0.04707698],\n",
       "       [0.67409035, 0.15060462, 0.14967226, 0.0450354 ],\n",
       "       [0.67784288, 0.14895079, 0.14795208, 0.04307489],\n",
       "       [0.68154537, 0.14731207, 0.14624815, 0.04119831],\n",
       "       [0.68523876, 0.1456878 , 0.14456001, 0.03939922],\n",
       "       [0.67751425, 0.14786838, 0.14671794, 0.04312444],\n",
       "       [0.67858479, 0.147812  , 0.14650924, 0.04253029],\n",
       "       [0.68284788, 0.14617651, 0.14481488, 0.04063237],\n",
       "       [0.68658576, 0.14456192, 0.14314003, 0.03885306],\n",
       "       [0.68666916, 0.14452055, 0.14294503, 0.0383868 ],\n",
       "       [0.69064398, 0.14291842, 0.14128696, 0.0366831 ],\n",
       "       [0.69429957, 0.14133447, 0.13964677, 0.0350725 ],\n",
       "       [0.69437213, 0.1412949 , 0.13945699, 0.03465027],\n",
       "       [0.69821535, 0.13972353, 0.1378333 , 0.03311181],\n",
       "       [0.70182183, 0.13816919, 0.13622673, 0.03165277],\n",
       "       [0.70540542, 0.13662947, 0.13463609, 0.03025585],\n",
       "       [0.7089529 , 0.13510418, 0.13306101, 0.02891944],\n",
       "       [0.71249054, 0.13359323, 0.13150162, 0.02763945],\n",
       "       [0.71256499, 0.13355573, 0.13132158, 0.02730383],\n",
       "       [0.71624776, 0.13205744, 0.12977841, 0.02608412],\n",
       "       [0.71972958, 0.13057545, 0.12825183, 0.02492651],\n",
       "       [0.72317574, 0.12910766, 0.12674055, 0.02381953],\n",
       "       [0.72660108, 0.12765384, 0.12524445, 0.0227603 ],\n",
       "       [0.73000294, 0.12621399, 0.12376347, 0.02174698],\n",
       "       [0.73337955, 0.12478811, 0.12229765, 0.02077773],\n",
       "       [0.73276303, 0.12495283, 0.12266131, 0.02056811],\n",
       "       [0.7361906 , 0.12353797, 0.1212058 , 0.01964729],\n",
       "       [0.73954312, 0.12213762, 0.11976574, 0.0187688 ],\n",
       "       [0.73963872, 0.12210318, 0.11960015, 0.01853764],\n",
       "       [0.73984318, 0.12206785, 0.11943453, 0.01830477],\n",
       "       [0.74322633, 0.12068132, 0.1180125 , 0.01748282],\n",
       "       [0.74649348, 0.11930934, 0.11660562, 0.01670045],\n",
       "       [0.749735  , 0.11795088, 0.11521336, 0.01595245],\n",
       "       [0.75294562, 0.11660585, 0.11383557, 0.01523754],\n",
       "       [0.75613039, 0.11527414, 0.11247217, 0.01455413],\n",
       "       [0.75928602, 0.11395571, 0.11112307, 0.01390098],\n",
       "       [0.75937292, 0.11392388, 0.11096866, 0.01372895],\n",
       "       [0.7595231 , 0.11389149, 0.11081424, 0.01355697],\n",
       "       [0.76269811, 0.11258625, 0.10948222, 0.01294647],\n",
       "       [0.76214438, 0.11273734, 0.1098132 , 0.0128142 ],\n",
       "       [0.76225511, 0.11270565, 0.10966038, 0.01265469],\n",
       "       [0.76540651, 0.11141225, 0.1083405 , 0.01208428],\n",
       "       [0.76848462, 0.11013235, 0.10703486, 0.01154052],\n",
       "       [0.77153366, 0.10886537, 0.1057431 , 0.01102098],\n",
       "       [0.77455395, 0.10761123, 0.10446514, 0.01052458],\n",
       "       [0.7775435 , 0.10636985, 0.10320085, 0.01005037],\n",
       "       [0.78050449, 0.10514108, 0.10195012, 0.00959732],\n",
       "       [0.78343779, 0.10392485, 0.10071283, 0.0091645 ],\n",
       "       [0.78634336, 0.10272107, 0.0994889 , 0.008751  ],\n",
       "       [0.78921927, 0.10152969, 0.09827824, 0.00835602]])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propensity_scores_history = MSMPropensityHistory_model.get_propensity_scores(\n",
    "    dataset_collection.train_f)\n",
    "propensity_scores_history[0]\n",
    "\n",
    "# compare to actual treatment\n",
    "train_f = dataset_collection.train_f\n",
    "train_f.data['current_treatments'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedCausalDiff(CausalDiff):\n",
    "\n",
    "    model_type = 'WeightedCausalDiff'\n",
    "\n",
    "    def __init__(self,\n",
    "                 args: DictConfig,\n",
    "                 propensity_treatment: MSMPropensityTreatment_model,\n",
    "                 propensity_history: MSMPropensityHistory_model,\n",
    "                 dataset_collection: Union[RealDatasetCollection,\n",
    "                                           SyntheticDatasetCollection] = None,\n",
    "                 autoregressive: bool = None, has_vitals: bool = None, **kwargs):\n",
    "        super().__init__(args, dataset_collection, autoregressive, has_vitals)\n",
    "\n",
    "        self.input_size = self.dim_treatments + self.dim_static_features\n",
    "        self.input_size += self.dim_vitals if self.has_vitals else 0\n",
    "        self.input_size += self.dim_outcome if self.autoregressive else 0\n",
    "\n",
    "        logger.info(f'Input size of {self.model_type}: {self.input_size}')\n",
    "        self.output_size = self.dim_outcome\n",
    "\n",
    "        self.propensity_treatment = propensity_treatment\n",
    "        self.propensity_history = propensity_history\n",
    "\n",
    "        self.save_hyperparameters(args)\n",
    "\n",
    "    def get_inputs(self, dataset: Dataset, projection_horizon=0, tau=0) -> np.array:\n",
    "        active_entries = dataset.data['active_entries']\n",
    "        lagged_entries = active_entries - np.concatenate([active_entries[:, self.lag_features + 1:, :],\n",
    "                                                          np.zeros((active_entries.shape[0], self.lag_features + 1, 1))], axis=1)\n",
    "        if projection_horizon > 0:\n",
    "            lagged_entries = np.concatenate([lagged_entries[:, projection_horizon:, :],\n",
    "                                             np.zeros((active_entries.shape[0], projection_horizon, 1))], axis=1)\n",
    "\n",
    "        active_entries_before_proection = np.concatenate([active_entries[:, projection_horizon:, :],\n",
    "                                                          np.zeros((active_entries.shape[0], projection_horizon, 1))], axis=1)\n",
    "\n",
    "        prev_treatments = dataset.data['prev_treatments']\n",
    "        inputs = [(prev_treatments * active_entries_before_proection).sum(1)]\n",
    "        if self.has_vitals:\n",
    "            vitals = dataset.data['vitals']\n",
    "            inputs.append(vitals[np.repeat(lagged_entries, self.dim_vitals, 2) == 1.0].reshape(vitals.shape[0],\n",
    "                                                                                               (self.lag_features + 1) *\n",
    "                                                                                               self.dim_vitals))\n",
    "        if self.autoregressive:\n",
    "            prev_outputs = dataset.data['prev_outputs']\n",
    "            inputs.append(\n",
    "                prev_outputs[np.repeat(lagged_entries, self.dim_outcome, 2) == 1.0].reshape(prev_outputs.shape[0],\n",
    "                                                                                            (self.lag_features + 1) *\n",
    "                                                                                            self.dim_outcome))\n",
    "        static_features = dataset.data['static_features']\n",
    "        inputs.append(static_features)\n",
    "\n",
    "        # Adding current actions\n",
    "        current_treatments = dataset.data['current_treatments']\n",
    "        prediction_entries = active_entries - np.concatenate(\n",
    "            [active_entries[:, tau + 1:, :], np.zeros((active_entries.shape[0], tau + 1, 1))], axis=1)\n",
    "        prediction_entries = np.concatenate([prediction_entries[:, projection_horizon - tau:, :],\n",
    "                                             np.zeros((prediction_entries.shape[0], projection_horizon - tau, 1))], axis=1)\n",
    "        inputs.append((current_treatments * prediction_entries).sum(1))\n",
    "\n",
    "        return np.concatenate(inputs, axis=1)\n",
    "\n",
    "    def get_sample_weights(self, dataset: Dataset, tau=0) -> np.array:\n",
    "        active_entries = dataset.data['active_entries']\n",
    "        stabilized_weights = dataset.data['stabilized_weights']\n",
    "\n",
    "        prediction_entries = active_entries - np.concatenate(\n",
    "            [active_entries[:, tau + 1:, :],\n",
    "                np.zeros((active_entries.shape[0], tau + 1, 1))],\n",
    "            axis=1)\n",
    "        stabilized_weights = stabilized_weights[np.squeeze(prediction_entries) == 1.0].reshape(stabilized_weights.shape[0],\n",
    "                                                                                               tau + 1)\n",
    "        sw = np.prod(stabilized_weights, axis=1)\n",
    "        sw_tilde = np.clip(sw, np.nanquantile(\n",
    "            sw, 0.01), np.nanquantile(sw, 0.99))\n",
    "        return sw_tilde\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        if self.dataset_collection is not None and not self.dataset_collection.processed_data_multi:\n",
    "            self.dataset_collection.process_data_multi()\n",
    "        if self.dataset_collection is not None and 'stabilized_weights' not in self.dataset_collection.train_f.data:\n",
    "            self.dataset_collection.process_propensity_train_f(\n",
    "                self.propensity_treatment, self.propensity_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_causal_diff = WeightedCausalDiff(\n",
    "    args, MSMPropensityTreatment_model, MSMPropensityHistory_model, dataset_collection)\n",
    "\n",
    "weighted_causal_diff.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.35802904, 1.35059066, 1.34290846, 1.32360759,\n",
       "       1.31601217, 1.30781922, 1.29943966, 1.29085614, 1.2821152 ,\n",
       "       1.27320063, 1.26416615, 1.25497977, 1.24568189, 1.23831427,\n",
       "       1.21991137, 1.21116708, 1.20197507, 1.18311686, 1.17404834,\n",
       "       1.1646859 , 1.14610624, 1.13688133, 1.12743764, 1.11794555,\n",
       "       1.10840251, 1.09883592, 1.08077649, 1.07140341, 1.0618597 ,\n",
       "       1.05229356, 1.04272352, 1.03315216, 1.02358223, 1.00725343,\n",
       "       0.99786006, 0.98843171, 0.97159685, 0.9551244 , 0.94597565,\n",
       "       0.93676452, 0.92758124, 0.91842374, 0.90929977, 0.90020863,\n",
       "       0.88452579, 0.86916072, 0.86038558, 0.84624577, 0.83143699,\n",
       "       0.82292834, 0.81441921, 0.80595583, 0.79754   , 0.78917114,\n",
       "       0.78085298, 0.77258772, 0.76437644, 0.75621809])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_causal_diff.dataset_collection.train_f.data['stabilized_weights'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer_volume (10000, 60)\n",
      "chemo_dosage (10000, 60)\n",
      "radio_dosage (10000, 60)\n",
      "chemo_application (10000, 60)\n",
      "radio_application (10000, 60)\n",
      "chemo_probabilities (10000, 60)\n",
      "radio_probabilities (10000, 60)\n",
      "sequence_lengths (10000,)\n",
      "death_flags (10000, 60)\n",
      "recovery_flags (10000, 60)\n",
      "patient_types (10000,)\n",
      "prev_treatments (10000, 59, 4)\n",
      "current_treatments (10000, 59, 4)\n",
      "current_covariates (10000, 59, 2)\n",
      "outputs (10000, 59, 1)\n",
      "active_entries (10000, 59, 1)\n",
      "unscaled_outputs (10000, 59, 1)\n",
      "prev_outputs (10000, 59, 1)\n",
      "static_features (10000, 1)\n",
      "stabilized_weights (10000, 59)\n"
     ]
    }
   ],
   "source": [
    "for key in weighted_causal_diff.dataset_collection.train_f.data.keys():\n",
    "    # print(key, weighted_causal_diff.dataset_collection.train_f.data[key])\n",
    "    print(\n",
    "        key, weighted_causal_diff.dataset_collection.train_f.data[key].shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "%matplotlib inline\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import statistics\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "def train(model, data_loader, data_loader_validation, epochs, lr, loss_func, weighted_loss_func = None, batch_embedder = None, gradient_clip = 1.0,\n",
    "          windowed_mode=False, window_mode=\"uniform\", window_start_mode=\"random\", min_window=50, max_window=100, neg_bin_p=0.95, train_on_all_every=4,\n",
    "          annealing_mode = False, annealing_window=5, annealing_multiplier=1.25, annealing_ratio = 0.5, annealing_minimum = 1e-6,\n",
    "          device=\"cuda\", num_gpus=1, verbose=False, plot_every=10,\n",
    "          validation_frequency=1, validation_prp=10, moving_avg_window=10):\n",
    "\n",
    "    # Check for GPU availability\n",
    "    available_gpus = torch.cuda.device_count()\n",
    "    if available_gpus < num_gpus:\n",
    "        print(f\"Requested {num_gpus} GPUs, but only {available_gpus} are available.\")\n",
    "        num_gpus = available_gpus\n",
    "    else:\n",
    "        print(f\"Using {num_gpus} GPUs for training.\")\n",
    "        #also print gpu model\n",
    "        print(f\"GPU model: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    if num_gpus > 1:\n",
    "        model = torch.nn.DataParallel(model, device_ids=list(range(num_gpus)))\n",
    "        if batch_embedder is not None:\n",
    "            batch_embedder = torch.nn.DataParallel(batch_embedder, device_ids=list(range(num_gpus)))\n",
    "\n",
    "    if batch_embedder is not None:\n",
    "        batch_embedder = batch_embedder.to(device)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    if batch_embedder is not None:\n",
    "        optimizer = torch.optim.Adam(\n",
    "            chain(batch_embedder.parameters(), model.parameters()),\n",
    "            lr=lr\n",
    "        )\n",
    "    else:\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=lr\n",
    "        )\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # if batch_embedder is not None:\n",
    "    #     batch_embedder.train()\n",
    "    \n",
    "    loss_list = []\n",
    "    initial_value = 1.0  # Initial value for equal probability\n",
    "    window_losses = torch.ones(max_window - min_window + 1, device=device) * initial_value  # Track losses for each window length\n",
    "    window_counts = torch.zeros(max_window - min_window + 1, device=device)  # Track counts for each window length\n",
    "    loss_deques = [deque(maxlen=moving_avg_window) for _ in range(max_window - min_window + 1)]  # Deques for moving average\n",
    "    if windowed_mode and window_mode == \"biased_loss\":\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 12))\n",
    "    else:\n",
    "        fig, ax1 = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    epoch_loss_list = []\n",
    "    val_loss = 0\n",
    "\n",
    "    total_time_start = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Annealing for the learning rate\n",
    "        if annealing_mode and epoch > annealing_window:\n",
    "            if len(epoch_loss_list) > 0 and epoch_loss_list[-1] >= annealing_multiplier * (statistics.mean(epoch_loss_list[-annealing_window:])):\n",
    "                for g in optimizer.param_groups:\n",
    "                    if g['lr'] * annealing_ratio < annealing_minimum:\n",
    "                        g['lr'] = annealing_minimum\n",
    "                    else:\n",
    "                        g['lr'] *= annealing_ratio\n",
    "\n",
    "        start = time.time()\n",
    "        for i, batch in enumerate(data_loader):\n",
    "\n",
    "            if 'stabilized_weights' in batch:\n",
    "                stabilized_weights = batch['stabilized_weights']\n",
    "            curr_treatments = batch['current_treatments']\n",
    "            vitals_or_prev_outputs = []\n",
    "            # vitals_or_prev_outputs.append(batch['vitals']) if self.has_vitals else None\n",
    "            # if self.autoregressive else None\n",
    "            vitals_or_prev_outputs.append(batch['prev_outputs'])\n",
    "            vitals_or_prev_outputs = torch.cat(vitals_or_prev_outputs, dim=-1)\n",
    "            static_features = batch['static_features']\n",
    "            outputs = batch['outputs']\n",
    "\n",
    "            batch = torch.cat((vitals_or_prev_outputs, curr_treatments), dim=-1)\n",
    "            batch = torch.cat((batch, static_features.unsqueeze(\n",
    "                1).expand(-1, batch.size(1), -1)), dim=-1)\n",
    "            batch = torch.cat((batch, outputs), dim=-1)\n",
    "\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            # if batch_embedder is not None:\n",
    "            #     batch = batch_embedder(batch)\n",
    "\n",
    "            batch_length = batch.shape[1]\n",
    "            # batch_length = max_window\n",
    "\n",
    "            # Windowed mode logic\n",
    "            if windowed_mode:\n",
    "                if batch_length < min_window:\n",
    "                    continue\n",
    "                if window_start_mode == \"random\":\n",
    "                    cut_start = torch.randint(0, batch_length - window_length + 1, (1,)).item()\n",
    "                elif window_start_mode == \"fixed\":\n",
    "                    cut_start = 0\n",
    "                if window_mode == \"uniform\":\n",
    "                    while True:\n",
    "                        window_length = torch.randint(min_window, batch_length + 1, (1,)).item()\n",
    "                        cut_end = cut_start + window_length\n",
    "                        if min_window <= (cut_end - cut_start) <= batch_length:\n",
    "                            break\n",
    "                    batch = batch[:, cut_start:cut_end, :]\n",
    "                    stabilized_weights = stabilized_weights[:, cut_start:cut_end]\n",
    "\n",
    "                elif window_mode == \"negative_binomial\":\n",
    "                    total_count = 1\n",
    "                    probs = neg_bin_p\n",
    "                    distribution = torch.distributions.NegativeBinomial(total_count=total_count, probs=probs)\n",
    "                    while True:\n",
    "                        window_length = distribution.sample().item() + min_window\n",
    "                        cut_end = cut_start + window_length\n",
    "                        if min_window <= window_length <= batch_length:\n",
    "                            break\n",
    "                    batch = batch[:, cut_start:cut_end, :]\n",
    "\n",
    "                elif window_mode == \"biased_loss\":\n",
    "                    if torch.min(window_counts) < 2:\n",
    "                        # Use uniform distribution until each length has been used at least twice\n",
    "                        window_probs = torch.ones_like(window_losses) / len(window_losses)\n",
    "                    elif torch.sum(window_counts) % train_on_all_every == 0:\n",
    "                        window_probs = torch.ones_like(window_losses) / len(window_losses)\n",
    "                    else:\n",
    "                        # Update probabilities based on moving average of losses\n",
    "                        avg_losses = torch.tensor([np.mean(loss_deque) if len(loss_deque) > 0 else initial_value for loss_deque in loss_deques], device=device)\n",
    "                        window_probs = avg_losses / avg_losses.sum()\n",
    "                    while True:\n",
    "                        window_length = torch.multinomial(window_probs, 1).item() + min_window\n",
    "                        #check if the window length does work with the batch length\n",
    "                        if window_length > batch_length:\n",
    "                            continue\n",
    "                        cut_end = cut_start + window_length\n",
    "                        if min_window <= window_length <= batch_length:\n",
    "                            break\n",
    "                    batch = batch[:, cut_start:cut_end, :]\n",
    "                    window_counts[window_length - min_window] += 1  # Update window counts\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predicted_noise, noise, noise_mask = model(batch)\n",
    "            \n",
    "            if weighted_loss_func is not None:\n",
    "                loss = weighted_loss_func(predicted_noise, noise, noise_mask, stabilized_weights)\n",
    "            else:\n",
    "                loss = loss_func(predicted_noise, noise, noise_mask)\n",
    "            \n",
    "            loss.backward()\n",
    "            # # Gradient clipping\n",
    "            if gradient_clip is not None:\n",
    "                max_grad_norm = gradient_clip\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "                if batch_embedder is not None:\n",
    "                    torch.nn.utils.clip_grad_norm_(batch_embedder.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "            epoch_loss = sum(loss_list[-len(data_loader):]) / len(data_loader)\n",
    "            epoch_loss_list.append(epoch_loss)\n",
    "            \n",
    "            # Update window losses and moving average deque\n",
    "            if windowed_mode and window_mode == \"biased_loss\":\n",
    "                window_idx = window_length - min_window\n",
    "                window_losses[window_idx] += loss.item()\n",
    "                loss_deques[window_idx].append(loss.item())\n",
    "\n",
    "            # Dynamic plot update\n",
    "            if i % plot_every == 0:\n",
    "                ax1.clear()\n",
    "                ax1.set_ylim(0, 1)\n",
    "                ax1.plot(loss_list)\n",
    "                if len(loss_list) > 100:\n",
    "                    ax1.plot(np.convolve(loss_list, np.ones((100,))/100, mode='valid'))\n",
    "                    ax1.text(len(loss_list) - 1, np.convolve(loss_list, np.ones((100,))/100, mode='valid')[-1],\n",
    "                            str(round(np.convolve(loss_list, np.ones((100,))/100, mode='valid')[-1], 3)))\n",
    "                if len(epoch_loss_list) > 0:\n",
    "                    ax1.text(0.1, 0.9, f\"Epoch: {epoch} | Learning rate: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "                # ax1.text(0.1, 0.8, f\"Learning rate: {optimizer.param_groups[0]['lr']:.4e}\")\n",
    "                ax1.text(0.1, 0.8, f\"Loss: {epoch_loss_list[-1]:.3e} | Validation loss: {val_loss:.3e}\")\n",
    "                ax1.text(0.1, 0.7, f\"Time per step: {((time.time() - start) / (i + 1)):.2f} s | Time per epoch: {((time.time() - start) / (i + 1) * len(data_loader)):.2f} s\")\n",
    "                ax1.text(0.1, 0.6, f\"Time till finish (est.): {((time.time() - start) / (i + 1) * len(data_loader) * (epochs - epoch)) / 60:.2f} min\")\n",
    "                if windowed_mode and window_mode == \"biased_loss\":\n",
    "                    ax2.clear()\n",
    "                    ax2.bar(range(min_window, max_window + 1), window_counts.cpu().numpy())\n",
    "                    ax2.set_ylabel(\"Counts\")\n",
    "                    ax2.set_title(\"Counts of Each Window Length Used\")\n",
    "\n",
    "                    moving_avg_losses = torch.tensor([np.mean(loss_deque) if len(loss_deque) > 0 else initial_value for loss_deque in loss_deques], device=device).cpu().numpy()\n",
    "                    ax3.clear()\n",
    "                    ax3.bar(range(min_window, max_window + 1), moving_avg_losses)\n",
    "                    ax3.set_xlabel(\"Window Length\")\n",
    "                    ax3.set_ylabel(\"Moving Average Loss\")\n",
    "                    ax3.set_title(\"Moving Average Loss for Each Window Length\")\n",
    "\n",
    "                display(fig)\n",
    "                clear_output(wait=True)\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        # Validation\n",
    "        if epoch % validation_frequency == 0:\n",
    "            loss_list_validation = []\n",
    "            for i, batch in enumerate(data_loader_validation):\n",
    "                curr_treatments = batch['current_treatments']\n",
    "                vitals_or_prev_outputs = []\n",
    "                # vitals_or_prev_outputs.append(batch['vitals']) if self.has_vitals else None\n",
    "                # if self.autoregressive else None\n",
    "                vitals_or_prev_outputs.append(batch['prev_outputs'])\n",
    "                vitals_or_prev_outputs = torch.cat(vitals_or_prev_outputs, dim=-1)\n",
    "                static_features = batch['static_features']\n",
    "                outputs = batch['outputs']\n",
    "\n",
    "                batch = torch.cat((vitals_or_prev_outputs, curr_treatments), dim=-1)\n",
    "                batch = torch.cat((batch, static_features.unsqueeze(\n",
    "                    1).expand(-1, batch.size(1), -1)), dim=-1)\n",
    "                batch = torch.cat((batch, outputs), dim=-1)\n",
    "\n",
    "                batch = batch.to(device)\n",
    "                # if batch_embedder is not None:\n",
    "                #     batch = batch_embedder(batch)\n",
    "                if i % validation_prp == 0:\n",
    "                    predicted_noise, noise, noise_mask = model(batch)\n",
    "                    loss = loss_func(predicted_noise, noise, noise_mask)\n",
    "                    loss_list_validation.append(loss.item())\n",
    "\n",
    "            val_loss = np.mean(loss_list_validation)\n",
    "\n",
    "        total_time_end = time.time()\n",
    "        total_time = total_time_end - total_time_start\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch} completed in {end - start} seconds, Loss: {epoch_loss}\")\n",
    "            print(f\"Validation Loss: {val_loss}\")\n",
    "    \n",
    "    print(f\"Took {total_time} seconds for {epoch} epochs.\")\n",
    "            \n",
    "\n",
    "\n",
    "    return model, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/postresearch/Shared/Researchers/Farbod/cancer/code/CausalDiff/src/models/CausalDiff.py:1205: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.alpha_torch = torch.tensor(self.alpha).float()\n"
     ]
    }
   ],
   "source": [
    "# re import src.models.CausalDiff\n",
    "import sys\n",
    "if 'src.models.CausalDiff' in sys.modules:\n",
    "    del sys.modules['src.models.CausalDiff']\n",
    "from src.models.CausalDiff import *\n",
    "\n",
    "diffusion_imputer = diffusion_imputation(\n",
    "    emb_dim=128,\n",
    "    # strategy=\"forecasting_last_n_time\",\n",
    "    # strategy=\"random\",\n",
    "    # missing_prp=0.5,\n",
    "    # strategy='selected_features',\n",
    "    strategy=\"selected_features_last_n_time\",\n",
    "    last_n_time=1,\n",
    "    features_to_impute=[6],\n",
    "    # excluded_features = [i for i in range(6)], #[2],#[0,1,2,3,5], #for the embedded stock names which we don't need to predict\n",
    "    # strategy='selected_features_and_selected_features_after_time',\n",
    "    # features_to_impute_completely=[2],\n",
    "    # features_to_impute_after_time=[3],\n",
    "    num_residual_layers=4,\n",
    "    diffusion_steps=50,\n",
    "    diffusion_beta_schedule=\"quadratic\",\n",
    "    num_heads=8,\n",
    "    kernel_size=(1, 1),\n",
    "    ff_dim=512,\n",
    "    num_cells=1,\n",
    "    dropout=0,\n",
    "    # csdi, csdi_moded_transformer, rsa, rsa_moded_transformer, moded_transformer_alone, rsa_csdi\n",
    "    method=\"csdi\",\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test batch\n",
      "cancer_volume torch.Size([100, 60])\n",
      "chemo_application torch.Size([100, 60])\n",
      "radio_application torch.Size([100, 60])\n",
      "sequence_lengths torch.Size([100])\n",
      "patient_types torch.Size([100])\n",
      "prev_treatments torch.Size([100, 59, 4])\n",
      "current_treatments torch.Size([100, 59, 4])\n",
      "current_covariates torch.Size([100, 59, 2])\n",
      "outputs torch.Size([100, 59, 1])\n",
      "active_entries torch.Size([100, 59, 1])\n",
      "unscaled_outputs torch.Size([100, 59, 1])\n",
      "prev_outputs torch.Size([100, 59, 1])\n",
      "static_features torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    weighted_causal_diff.dataset_collection.train_f, batch_size=50, shuffle=True)\n",
    "\n",
    "# for i, batch in enumerate(train_dataloader):\n",
    "#     if i == 0:\n",
    "#         print(\"Training batch\")\n",
    "#         for key in batch.keys():\n",
    "#             print(key, batch[key].shape)\n",
    "#     else:\n",
    "#         break\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    weighted_causal_diff.dataset_collection.val_f, batch_size=50, shuffle=True)\n",
    "\n",
    "# for i, batch in enumerate(val_dataloader):\n",
    "#     if i == 0:\n",
    "#         print(\"Validation batch\")\n",
    "#         for key in batch.keys():\n",
    "#             print(key, batch[key].shape)\n",
    "#     else:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_means': array([7.73415232, 2.0006    , 0.        , 0.        ]),\n",
       " 'inputs_stds': array([52.43550991,  0.81926775,  1.        ,  1.        ]),\n",
       " 'output_means': 7.734152322128,\n",
       " 'output_stds': 52.43550990660674}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., ..., 59., 59., 59.])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_causal_diff.dataset_collection.test_cf_one_step.scaling_params\n",
    "weighted_causal_diff.dataset_collection.test_cf_one_step.data['sequence_lengths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[243], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiffusion_imputer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_embedder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_clip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindowed_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muniform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_start_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfixed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# train_on_all_every=100,\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mannealing_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mannealing_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mannealing_multiplier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mannealing_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mannealing_minimum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiffusion_imputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweighted_loss_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiffusion_imputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweighted_loss_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_prp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\n\u001b[1;32m     28\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[129], line 153\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, data_loader_validation, epochs, lr, loss_func, weighted_loss_func, batch_embedder, gradient_clip, windowed_mode, window_mode, window_start_mode, min_window, max_window, neg_bin_p, train_on_all_every, annealing_mode, annealing_window, annealing_multiplier, annealing_ratio, annealing_minimum, device, num_gpus, verbose, plot_every, validation_frequency, validation_prp, moving_avg_window)\u001b[0m\n\u001b[1;32m    150\u001b[0m         window_counts[window_length \u001b[38;5;241m-\u001b[39m min_window] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Update window counts\u001b[39;00m\n\u001b[1;32m    152\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 153\u001b[0m predicted_noise, noise, noise_mask \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weighted_loss_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    156\u001b[0m     loss \u001b[38;5;241m=\u001b[39m weighted_loss_func(predicted_noise, noise, noise_mask, stabilized_weights)\n",
      "File \u001b[0;32m~/micromamba/envs/torch_old/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Farbod/cancer/code/CausalDiff/src/models/CausalDiff.py:1456\u001b[0m, in \u001b[0;36mdiffusion_imputation.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1453\u001b[0m noised_data \u001b[38;5;241m=\u001b[39m noised_data \u001b[38;5;241m+\u001b[39m conditional_data\n\u001b[1;32m   1454\u001b[0m noised_data \u001b[38;5;241m=\u001b[39m noised_data\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m-> 1456\u001b[0m predicted_noise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnoised_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiffusion_t\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1459\u001b[0m predicted_noise \u001b[38;5;241m=\u001b[39m predicted_noise \u001b[38;5;241m*\u001b[39m noise_mask\n\u001b[1;32m   1461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (predicted_noise, noise, noise_mask)\n",
      "File \u001b[0;32m~/micromamba/envs/torch_old/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Farbod/cancer/code/CausalDiff/src/models/CausalDiff.py:1057\u001b[0m, in \u001b[0;36mModelLoop.forward\u001b[0;34m(self, noised_data, noise_mask, diffusion_t)\u001b[0m\n\u001b[1;32m   1055\u001b[0m skip \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresidual_layers:\n\u001b[0;32m-> 1057\u001b[0m     x, skip_connection \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiffusion_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_embedding\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1060\u001b[0m     skip\u001b[38;5;241m.\u001b[39mappend(skip_connection)\n\u001b[1;32m   1061\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape(b, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb_dim, t \u001b[38;5;241m*\u001b[39m f)\n",
      "File \u001b[0;32m~/micromamba/envs/torch_old/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Farbod/cancer/code/CausalDiff/src/models/CausalDiff.py:894\u001b[0m, in \u001b[0;36mResidualBlock.forward\u001b[0;34m(self, noised_data, diffusion_emb, time_emb, feature_emb)\u001b[0m\n\u001b[1;32m    892\u001b[0m     y \u001b[38;5;241m=\u001b[39m (y \u001b[38;5;241m+\u001b[39m y_resid) \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m2.0\u001b[39m)\n\u001b[1;32m    893\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(y)\n\u001b[0;32m--> 894\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    895\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_feature(y)\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsdi_moded_transformer\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/work/postresearch/Shared/Researchers/Farbod/cancer/code/CausalDiff/src/models/CausalDiff.py:867\u001b[0m, in \u001b[0;36mResidualBlock.forward_feature\u001b[0;34m(self, y, base_shape)\u001b[0m\n\u001b[1;32m    865\u001b[0m b, t, f, e \u001b[38;5;241m=\u001b[39m base_shape\n\u001b[1;32m    866\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mreshape(b \u001b[38;5;241m*\u001b[39m t, f, e)\n\u001b[0;32m--> 867\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    868\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mreshape(b, t, f, e)\n\u001b[1;32m    869\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/micromamba/envs/torch_old/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/micromamba/envs/torch_old/lib/python3.11/site-packages/torch/nn/modules/transformer.py:306\u001b[0m, in \u001b[0;36mTransformerEncoder.forward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    303\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m make_causal\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 306\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc_key_padding_mask_for_layers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_nested:\n\u001b[1;32m    309\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_padded_tensor(\u001b[38;5;241m0.\u001b[39m)\n",
      "File \u001b[0;32m~/micromamba/envs/torch_old/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/micromamba/envs/torch_old/lib/python3.11/site-packages/torch/nn/modules/transformer.py:573\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    571\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 573\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sa_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    574\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ff_block(x))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/micromamba/envs/torch_old/lib/python3.11/site-packages/torch/nn/modules/transformer.py:581\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_sa_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor,\n\u001b[1;32m    580\u001b[0m               attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 581\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout1(x)\n",
      "File \u001b[0;32m~/micromamba/envs/torch_old/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/micromamba/envs/torch_old/lib/python3.11/site-packages/torch/nn/modules/activation.py:1189\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1175\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1176\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1177\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1186\u001b[0m         average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1187\u001b[0m         is_causal\u001b[38;5;241m=\u001b[39mis_causal)\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1189\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/micromamba/envs/torch_old/lib/python3.11/site-packages/torch/nn/functional.py:5272\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5269\u001b[0m         key_padding_mask \u001b[38;5;241m=\u001b[39m pad(key_padding_mask, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   5271\u001b[0m \u001b[38;5;66;03m# update source sequence length after adjustments\u001b[39;00m\n\u001b[0;32m-> 5272\u001b[0m src_len \u001b[38;5;241m=\u001b[39m \u001b[43mk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5274\u001b[0m \u001b[38;5;66;03m# merge key padding and attention masks\u001b[39;00m\n\u001b[1;32m   5275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key_padding_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(\n",
    "    diffusion_imputer,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    num_gpus=1,\n",
    "    batch_embedder=None,\n",
    "    gradient_clip=True,\n",
    "    windowed_mode=True,\n",
    "    window_mode=\"uniform\",\n",
    "    window_start_mode=\"fixed\",\n",
    "    # train_on_all_every=100,\n",
    "    min_window=2,\n",
    "    max_window=60,\n",
    "    device=\"cuda\",\n",
    "    epochs=100,\n",
    "    lr=1e-4,\n",
    "    annealing_mode=True,\n",
    "    annealing_window=2,\n",
    "    annealing_multiplier=1.0,\n",
    "    annealing_ratio=0.5,\n",
    "    annealing_minimum=1e-7,\n",
    "    loss_func=diffusion_imputer.loss_func,\n",
    "    weighted_loss_func=diffusion_imputer.weighted_loss_func,\n",
    "    validation_frequency=5,\n",
    "    validation_prp=1,\n",
    "    verbose=False,\n",
    "    plot_every=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_hybrid(\n",
    "#     diffusion_imputer,\n",
    "#     hybrid_model,\n",
    "#     train_loader,\n",
    "#     val_loader,\n",
    "#     batch_embedder = embedder,\n",
    "#     epochs = 20,\n",
    "#     lr = 0.001,\n",
    "#     annealing_window = 5,\n",
    "#     annealing_multiplier = 1,\n",
    "#     loss_func = diffusion_imputer.loss_func,\n",
    "#     hybrid_loss_func = hybrid_model.loss_func,\n",
    "#     hybrid_start_epoch = 0,\n",
    "#     hybrid_every_n_epoch = 5,\n",
    "#     validation_frequency=2,\n",
    "#     validation_prp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the entire model for further training\n",
    "# torch.save(diffusion_imputer, \"diffusion_imputer_cancer_aug9.pt\")\n",
    "# torch.save(data_embedder, \"data_embedder_cancer_aug9.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def calculate_quantiles(imputed_samples_tensor, qlist):\n",
    "    quantiles_imp = []\n",
    "    for q in qlist:\n",
    "        quantiles = torch.quantile(\n",
    "            imputed_samples_tensor, q, dim=0, interpolation=\"midpoint\"\n",
    "        )\n",
    "        quantiles_imp.append(quantiles)\n",
    "    return torch.stack(quantiles_imp, dim=0)\n",
    "\n",
    "\n",
    "# Calculate RMSE with denormalization\n",
    "\n",
    "\n",
    "def calculate_rmse(\n",
    "    final_samples, training_mean, training_std, qlist=[\n",
    "        0.05, 0.25, 0.50, 0.75, 0.95]\n",
    "):\n",
    "    all_data = []\n",
    "    all_imputed = []\n",
    "    imputed_samples_list = []\n",
    "    actual_data_list = []\n",
    "\n",
    "    # Extract one instance of the actual data and imputation mask\n",
    "    data_instance, imputation_mask_instance = None, None\n",
    "    sample_number = len(final_samples)\n",
    "\n",
    "    for sample in final_samples:\n",
    "        for imputed_samples, data, imputation_mask, _ in sample:\n",
    "            # Store imputed samples for quantile calculation\n",
    "            imputed_samples_list.append(\n",
    "                imputed_samples[imputation_mask != 0].cpu())\n",
    "            actual_data_list.append(data[imputation_mask != 0].cpu())\n",
    "            # Flatten the tensors and filter non-zero mask areas\n",
    "            all_data.append(data[imputation_mask != 0].cpu())\n",
    "            all_imputed.append(imputed_samples[imputation_mask != 0].cpu())\n",
    "\n",
    "    # Concatenate all filtered elements\n",
    "    all_data = torch.cat(all_data)\n",
    "    all_imputed = torch.cat(all_imputed)\n",
    "\n",
    "    # Concatenate all imputed samples and reshape to original dimensions\n",
    "    imputed_samples_tensor = torch.cat(\n",
    "        imputed_samples_list).reshape(sample_number, -1)\n",
    "\n",
    "    # Concatenate all actual data and reshape to original dimensions\n",
    "    actual_data_tensor = torch.cat(actual_data_list).reshape(sample_number, -1)\n",
    "    actual_data_tensor = actual_data_tensor[0]\n",
    "\n",
    "    # Denormalize the data\n",
    "    all_data = all_data * training_std + training_mean\n",
    "    all_imputed = all_imputed * training_std + training_mean\n",
    "\n",
    "    # Calculate RMSE for all imputed values\n",
    "    rmse = torch.sqrt(torch.mean((all_data - all_imputed) ** 2)).item()\n",
    "    rmse = rmse / 1150 * 100  # Adjust the RMSE as per your requirement\n",
    "\n",
    "    # Calculate quantiles\n",
    "    quantiles_imp = calculate_quantiles(imputed_samples_tensor, qlist)\n",
    "    medians = quantiles_imp[qlist.index(0.50)]  # Median is the 50th percentile\n",
    "\n",
    "    # Denormalize the medians\n",
    "    medians = medians * training_std + training_mean\n",
    "\n",
    "    # Use the median for the new RMSE calculation\n",
    "    actual_data_tensor = actual_data_tensor * training_std + training_mean\n",
    "\n",
    "    # Calculate RMSE with medians\n",
    "    rmse_median = torch.sqrt(torch.mean(\n",
    "        (actual_data_tensor - medians) ** 2)).item()\n",
    "    # Adjust the RMSE as per your requirement\n",
    "    rmse_median = rmse_median / 1150 * 100\n",
    "\n",
    "    return rmse, rmse_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple_evaluations(\n",
    "    dataloader,\n",
    "    imputer,\n",
    "    training_mean,\n",
    "    training_std,\n",
    "    sample_number,\n",
    "    batch_embedder=None,\n",
    "    old_sample=[],\n",
    "    min_sequence_len=2,\n",
    "    max_sequence_len=None,\n",
    "    scale=1,\n",
    "    verbose=True,\n",
    "    show_max_diff=False,\n",
    "    show_rmse=False,\n",
    "):\n",
    "    final_samples = old_sample\n",
    "    max_seq_len = 0\n",
    "    total_batches = len(dataloader) * sample_number\n",
    "    completed_batches = 0\n",
    "    sample_time = []\n",
    "    average_sample_time = 0\n",
    "\n",
    "    for i in range(sample_number):\n",
    "        sample_start = time.time()\n",
    "        # print a line to separate the samples\n",
    "        print(\"-------------------------------------------------\")\n",
    "        print(f\"Running sample {i + 1}/{sample_number}\")\n",
    "        all_samples = []\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            # Get the data from the batch (collate_fn returns a tuple)\n",
    "            sequence_lengths = batch['sequence_lengths']\n",
    "            imputer.sequence_length = sequence_lengths\n",
    "\n",
    "            curr_treatments = batch['current_treatments']\n",
    "            vitals_or_prev_outputs = []\n",
    "            # vitals_or_prev_outputs.append(batch['vitals']) if self.has_vitals else None\n",
    "            # if self.autoregressive else None\n",
    "            vitals_or_prev_outputs.append(batch['prev_outputs'])\n",
    "            vitals_or_prev_outputs = torch.cat(vitals_or_prev_outputs, dim=-1)\n",
    "            static_features = batch['static_features']\n",
    "            outputs = batch['outputs']\n",
    "\n",
    "            batch = torch.cat(\n",
    "                (vitals_or_prev_outputs, curr_treatments), dim=-1)\n",
    "            batch = torch.cat((batch, static_features.unsqueeze(\n",
    "                1).expand(-1, batch.size(1), -1)), dim=-1)\n",
    "            batch = torch.cat((batch, outputs), dim=-1)\n",
    "\n",
    "            batch = batch.to(imputer.device)\n",
    "            # if batch_embedder is not None:\n",
    "            #     batch = batch_embedder(batch)\n",
    "            # seq_length = batch.shape[1]\n",
    "            # if seq_length < min_sequence_len:\n",
    "            #     # print(f\"Skipping batch {batch_idx + 1} as sequence length is less than {min_sequence_len}\")\n",
    "            #     completed_batches += 1\n",
    "            #     continue\n",
    "            # if max_sequence_len is not None and seq_length > max_sequence_len:\n",
    "            #     # print(f\"Skipping batch {batch_idx + 1} as sequence length is greater than {max_sequence_len}\")\n",
    "            #     completed_batches += 1\n",
    "            #     continue\n",
    "\n",
    "            # print(f\"sequence length: {sequence_lengths}\")\n",
    "\n",
    "            # Generate imputation masks for the current batch\n",
    "            imputation_masks = imputer.get_mask(\n",
    "                batch, strategy=\"selected_features_last_n_sequence_length\"\n",
    "            ).to(imputer.device)\n",
    "\n",
    "            imputed_samples = imputer.eval(\n",
    "                batch,\n",
    "                imputation_masks,\n",
    "                mean=training_mean,\n",
    "                std=training_std,\n",
    "                scale=scale,\n",
    "                verbose=verbose,\n",
    "                show_max_diff=show_max_diff,\n",
    "                show_rmse=show_rmse,\n",
    "            )\n",
    "\n",
    "            all_samples.append(imputed_samples)\n",
    "\n",
    "            completed_batches += 1\n",
    "            progress = completed_batches / total_batches\n",
    "            print(f\"Overall Progress: {progress * 100:.2f}%\")\n",
    "            print(\n",
    "                f\"Time to finish (est.): {average_sample_time * (sample_number - i - 1) / 60:.2f} min\"\n",
    "            )\n",
    "\n",
    "        sample_end = time.time()\n",
    "        sample_time.append(sample_end - sample_start)\n",
    "        average_sample_time = sum(sample_time) / len(sample_time)\n",
    "        final_samples.append(all_samples)\n",
    "\n",
    "        rmse, rmse_median = calculate_rmse(\n",
    "            final_samples, training_mean, training_std)\n",
    "        print(f\"RMSE: {rmse:.3f} | RMSE (Median): {rmse_median:.3f}\")\n",
    "\n",
    "    return final_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffusion_imputer = torch.load(\"diffusion_imputer_cancer_jul23.pt\")\n",
    "# data_embedder = torch.load(\"data_embedder_cancer_jul23.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test batch\n",
      "cancer_volume torch.Size([1000, 60])\n",
      "chemo_application torch.Size([1000, 60])\n",
      "radio_application torch.Size([1000, 60])\n",
      "sequence_lengths torch.Size([1000])\n",
      "patient_types torch.Size([1000])\n",
      "prev_treatments torch.Size([1000, 59, 4])\n",
      "current_treatments torch.Size([1000, 59, 4])\n",
      "current_covariates torch.Size([1000, 59, 2])\n",
      "outputs torch.Size([1000, 59, 1])\n",
      "active_entries torch.Size([1000, 59, 1])\n",
      "unscaled_outputs torch.Size([1000, 59, 1])\n",
      "prev_outputs torch.Size([1000, 59, 1])\n",
      "static_features torch.Size([1000, 1])\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = DataLoader(\n",
    "    weighted_causal_diff.dataset_collection.test_cf_one_step, batch_size=1000, shuffle=False)\n",
    "\n",
    "for i, batch in enumerate(test_dataloader):\n",
    "    if i == 0:\n",
    "        print(\"Test batch\")\n",
    "        for key in batch.keys():\n",
    "            print(key, batch[key].shape)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffusion_imputer.features_to_impute = [3]\n",
    "# diffusion_imputer.last_n_time = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.734152322128"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "52.43550990660674"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_standard_deviation = weighted_causal_diff.dataset_collection.test_cf_one_step.scaling_params[\n",
    "    'output_means']\n",
    "training_mean = weighted_causal_diff.dataset_collection.test_cf_one_step.scaling_params[\n",
    "    'output_stds']\n",
    "\n",
    "training_standard_deviation\n",
    "training_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change working directory\n",
    "# os.chdir(\"/work/postresearch/Shared/Researchers/Farbod/cancer/\")\n",
    "# sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Running sample 1/5\n",
      "mae =  0.4262493598253924\n",
      "rmse =  1.189124916372555\n",
      "Overall Progress: 0.87%\n",
      "Time to finish (est.): 0.00 min\n",
      "mae =  1.1010070539811632\n",
      "rmse =  1.8109346520100444\n",
      "Overall Progress: 1.74%\n",
      "Time to finish (est.): 0.00 min\n",
      "mae =  0.23160126680149784\n",
      "rmse =  0.5059371103114899\n",
      "Overall Progress: 2.61%\n",
      "Time to finish (est.): 0.00 min\n",
      "mae =  0.1736854999951422\n",
      "rmse =  0.42961343882409314\n",
      "Overall Progress: 3.48%\n",
      "Time to finish (est.): 0.00 min\n",
      "mae =  0.07169518388885482\n",
      "rmse =  0.3931632476978003\n",
      "Overall Progress: 4.35%\n",
      "Time to finish (est.): 0.00 min\n",
      "mae =  1.2454316146835689\n",
      "rmse =  2.1988412215129443\n",
      "Overall Progress: 5.22%\n",
      "Time to finish (est.): 0.00 min\n",
      "mae =  0.23823536333550935\n",
      "rmse =  0.4125952565859955\n",
      "Overall Progress: 6.09%\n",
      "Time to finish (est.): 0.00 min\n",
      "mae =  0.0714922274130571\n",
      "rmse =  0.11189188532170811\n",
      "Overall Progress: 6.96%\n",
      "Time to finish (est.): 0.00 min\n",
      "mae =  0.03568153722661911\n",
      "rmse =  0.09930310230945254\n",
      "Overall Progress: 7.83%\n",
      "Time to finish (est.): 0.00 min\n",
      "mae =  0.3576233608130897\n",
      "rmse =  0.6926681491567723\n",
      "Overall Progress: 8.70%\n",
      "Time to finish (est.): 0.00 min\n",
      "mae =  0.3562625814950952\n",
      "rmse =  1.0852741975832523\n",
      "Overall Progress: 9.57%\n",
      "Time to finish (est.): 0.00 min\n",
      "mae =  0.27851620633072316\n",
      "rmse =  0.4667327595972783\n",
      "Overall Progress: 10.43%\n",
      "Time to finish (est.): 0.00 min\n",
      "mae =  0.9852638158340182\n",
      "rmse =  1.525297129028714\n",
      "Overall Progress: 11.30%\n",
      "Time to finish (est.): 0.00 min\n",
      "mae =  0.8326861739075991\n",
      "rmse =  1.2809771403195207\n",
      "Overall Progress: 12.17%\n",
      "Time to finish (est.): 0.00 min\n",
      "mae =  0.833731558343142\n",
      "rmse =  1.729378133118941\n",
      "Overall Progress: 13.04%\n",
      "Time to finish (est.): 0.00 min\n",
      "mae =  0.06256528475744205\n",
      "rmse =  0.10447408100807154\n",
      "Overall Progress: 13.91%\n",
      "Time to finish (est.): 0.00 min\n",
      "mae =  0.069687418829031\n",
      "rmse =  0.16789349592752728\n",
      "Overall Progress: 14.78%\n",
      "Time to finish (est.): 0.00 min\n",
      "mae =  0.08417724387440707\n",
      "rmse =  0.3081161777831185\n",
      "Overall Progress: 15.65%\n",
      "Time to finish (est.): 0.00 min\n",
      "mae =  0.4143065441417181\n",
      "rmse =  1.1508995087242526\n",
      "Overall Progress: 16.52%\n",
      "Time to finish (est.): 0.00 min\n",
      "mae =  0.4830610707692128\n",
      "rmse =  0.8113469223685875\n",
      "Overall Progress: 17.39%\n",
      "Time to finish (est.): 0.00 min\n",
      "mae =  0.00541294483308592\n",
      "rmse =  0.015006288886444986\n",
      "Overall Progress: 18.26%\n",
      "Time to finish (est.): 0.00 min\n",
      "mae =  0.012581109387587884\n",
      "rmse =  0.03118492918788263\n",
      "Overall Progress: 19.13%\n",
      "Time to finish (est.): 0.00 min\n",
      "mae =  0.02265894428598448\n",
      "rmse =  0.03791285507461973\n",
      "Overall Progress: 20.00%\n",
      "Time to finish (est.): 0.00 min\n",
      "RMSE: 0.973 | RMSE (Median): 0.973\n",
      "-------------------------------------------------\n",
      "Running sample 2/5\n",
      "mae =  0.425100396076562\n",
      "rmse =  1.1863685809318303\n",
      "Overall Progress: 20.87%\n",
      "Time to finish (est.): 23.94 min\n",
      "mae =  1.0600855811322731\n",
      "rmse =  1.5840291946276417\n",
      "Overall Progress: 21.74%\n",
      "Time to finish (est.): 23.94 min\n",
      "mae =  0.2299195053551075\n",
      "rmse =  0.507744239941363\n",
      "Overall Progress: 22.61%\n",
      "Time to finish (est.): 23.94 min\n",
      "mae =  0.1747396363141193\n",
      "rmse =  0.428579887386609\n",
      "Overall Progress: 23.48%\n",
      "Time to finish (est.): 23.94 min\n",
      "mae =  0.07273350144221749\n",
      "rmse =  0.3965657456106974\n",
      "Overall Progress: 24.35%\n",
      "Time to finish (est.): 23.94 min\n",
      "mae =  1.2589807254740908\n",
      "rmse =  2.2084475694006285\n",
      "Overall Progress: 25.22%\n",
      "Time to finish (est.): 23.94 min\n",
      "mae =  0.23569803058142047\n",
      "rmse =  0.40989360774020206\n",
      "Overall Progress: 26.09%\n",
      "Time to finish (est.): 23.94 min\n",
      "mae =  0.07096270441558475\n",
      "rmse =  0.1083853959960661\n",
      "Overall Progress: 26.96%\n",
      "Time to finish (est.): 23.94 min\n",
      "mae =  0.03429645005096137\n",
      "rmse =  0.09423965540599867\n",
      "Overall Progress: 27.83%\n",
      "Time to finish (est.): 23.94 min\n",
      "mae =  0.3607973881358432\n",
      "rmse =  0.6999185730263692\n",
      "Overall Progress: 28.70%\n",
      "Time to finish (est.): 23.94 min\n",
      "mae =  0.35507194802002107\n",
      "rmse =  1.0808264750755272\n",
      "Overall Progress: 29.57%\n",
      "Time to finish (est.): 23.94 min\n",
      "mae =  0.28133555389151665\n",
      "rmse =  0.47001353206151764\n",
      "Overall Progress: 30.43%\n",
      "Time to finish (est.): 23.94 min\n",
      "mae =  0.9878547471378297\n",
      "rmse =  1.527716416066447\n",
      "Overall Progress: 31.30%\n",
      "Time to finish (est.): 23.94 min\n",
      "mae =  0.8320267163712465\n",
      "rmse =  1.2819813266849776\n",
      "Overall Progress: 32.17%\n",
      "Time to finish (est.): 23.94 min\n",
      "mae =  0.8337903731387186\n",
      "rmse =  1.728815340264011\n",
      "Overall Progress: 33.04%\n",
      "Time to finish (est.): 23.94 min\n",
      "mae =  0.06338198013340682\n",
      "rmse =  0.10640082053368714\n",
      "Overall Progress: 33.91%\n",
      "Time to finish (est.): 23.94 min\n",
      "mae =  0.06959279057504017\n",
      "rmse =  0.16998697663774698\n",
      "Overall Progress: 34.78%\n",
      "Time to finish (est.): 23.94 min\n",
      "mae =  0.08422042185063756\n",
      "rmse =  0.30852321717069375\n",
      "Overall Progress: 35.65%\n",
      "Time to finish (est.): 23.94 min\n",
      "mae =  0.4152339175271004\n",
      "rmse =  1.1514561407617354\n",
      "Overall Progress: 36.52%\n",
      "Time to finish (est.): 23.94 min\n",
      "mae =  0.4822975641559534\n",
      "rmse =  0.8106869239997943\n",
      "Overall Progress: 37.39%\n",
      "Time to finish (est.): 23.94 min\n",
      "mae =  0.0054860790941130885\n",
      "rmse =  0.01497975039930932\n",
      "Overall Progress: 38.26%\n",
      "Time to finish (est.): 23.94 min\n",
      "mae =  0.012376927634774236\n",
      "rmse =  0.03132285049787905\n",
      "Overall Progress: 39.13%\n",
      "Time to finish (est.): 23.94 min\n",
      "mae =  0.023081810505041857\n",
      "rmse =  0.03870506589880172\n",
      "Overall Progress: 40.00%\n",
      "Time to finish (est.): 23.94 min\n",
      "RMSE: 0.965 | RMSE (Median): 0.960\n",
      "-------------------------------------------------\n",
      "Running sample 3/5\n",
      "mae =  0.42620377713135094\n",
      "rmse =  1.1908462768058474\n",
      "Overall Progress: 40.87%\n",
      "Time to finish (est.): 15.94 min\n",
      "mae =  1.0643493674477087\n",
      "rmse =  1.584253455537463\n",
      "Overall Progress: 41.74%\n",
      "Time to finish (est.): 15.94 min\n",
      "mae =  0.23164278060333063\n",
      "rmse =  0.5124201932330797\n",
      "Overall Progress: 42.61%\n",
      "Time to finish (est.): 15.94 min\n",
      "mae =  0.17434144710201083\n",
      "rmse =  0.42910459253648847\n",
      "Overall Progress: 43.48%\n",
      "Time to finish (est.): 15.94 min\n",
      "mae =  0.0723621710471835\n",
      "rmse =  0.3980605437393242\n",
      "Overall Progress: 44.35%\n",
      "Time to finish (est.): 15.94 min\n",
      "mae =  1.2487619859219923\n",
      "rmse =  2.2019225031242495\n",
      "Overall Progress: 45.22%\n",
      "Time to finish (est.): 15.94 min\n",
      "mae =  0.23897475658183198\n",
      "rmse =  0.4099065110519904\n",
      "Overall Progress: 46.09%\n",
      "Time to finish (est.): 15.94 min\n",
      "mae =  0.07273366129661546\n",
      "rmse =  0.11363119880695338\n",
      "Overall Progress: 46.96%\n",
      "Time to finish (est.): 15.94 min\n",
      "mae =  0.03589282272730317\n",
      "rmse =  0.09994499318097685\n",
      "Overall Progress: 47.83%\n",
      "Time to finish (est.): 15.94 min\n",
      "mae =  0.3605031951037625\n",
      "rmse =  0.7004815843676184\n",
      "Overall Progress: 48.70%\n",
      "Time to finish (est.): 15.94 min\n",
      "mae =  0.3563537991448768\n",
      "rmse =  1.0863563095227284\n",
      "Overall Progress: 49.57%\n",
      "Time to finish (est.): 15.94 min\n",
      "mae =  0.2819981877517214\n",
      "rmse =  0.469294356071139\n",
      "Overall Progress: 50.43%\n",
      "Time to finish (est.): 15.94 min\n",
      "mae =  0.9845692113814724\n",
      "rmse =  1.5260237274786508\n",
      "Overall Progress: 51.30%\n",
      "Time to finish (est.): 15.94 min\n",
      "mae =  0.8339121939066909\n",
      "rmse =  1.2845954116893243\n",
      "Overall Progress: 52.17%\n",
      "Time to finish (est.): 15.94 min\n",
      "mae =  0.8350791535797123\n",
      "rmse =  1.7316505101323851\n",
      "Overall Progress: 53.04%\n",
      "Time to finish (est.): 15.94 min\n",
      "mae =  0.06490593324075208\n",
      "rmse =  0.10848199308247596\n",
      "Overall Progress: 53.91%\n",
      "Time to finish (est.): 15.94 min\n",
      "mae =  0.06987852768987755\n",
      "rmse =  0.1700228124455418\n",
      "Overall Progress: 54.78%\n",
      "Time to finish (est.): 15.94 min\n",
      "mae =  0.08316056941449637\n",
      "rmse =  0.30528117804570526\n",
      "Overall Progress: 55.65%\n",
      "Time to finish (est.): 15.94 min\n",
      "mae =  0.4158063036261919\n",
      "rmse =  1.1520604478718655\n",
      "Overall Progress: 56.52%\n",
      "Time to finish (est.): 15.94 min\n",
      "mae =  0.4832043264549123\n",
      "rmse =  0.8079265302036842\n",
      "Overall Progress: 57.39%\n",
      "Time to finish (est.): 15.94 min\n",
      "mae =  0.005462116931306571\n",
      "rmse =  0.015821068843481445\n",
      "Overall Progress: 58.26%\n",
      "Time to finish (est.): 15.94 min\n",
      "mae =  0.012718736580383276\n",
      "rmse =  0.03246640079845216\n",
      "Overall Progress: 59.13%\n",
      "Time to finish (est.): 15.94 min\n",
      "mae =  0.022418609714213562\n",
      "rmse =  0.037745347844575304\n",
      "Overall Progress: 60.00%\n",
      "Time to finish (est.): 15.94 min\n",
      "RMSE: 0.962 | RMSE (Median): 0.957\n",
      "-------------------------------------------------\n",
      "Running sample 4/5\n",
      "mae =  0.42661176767790504\n",
      "rmse =  1.1919030226315754\n",
      "Overall Progress: 60.87%\n",
      "Time to finish (est.): 7.97 min\n",
      "mae =  1.0657674019897414\n",
      "rmse =  1.5811955700473321\n",
      "Overall Progress: 61.74%\n",
      "Time to finish (est.): 7.97 min\n",
      "mae =  0.23079660511306693\n",
      "rmse =  0.5086984678332408\n",
      "Overall Progress: 62.61%\n",
      "Time to finish (est.): 7.97 min\n",
      "mae =  0.17387992828802493\n",
      "rmse =  0.42661527284913525\n",
      "Overall Progress: 63.48%\n",
      "Time to finish (est.): 7.97 min\n",
      "mae =  0.0723538240535631\n",
      "rmse =  0.39833994821306307\n",
      "Overall Progress: 64.35%\n",
      "Time to finish (est.): 7.97 min\n",
      "mae =  1.240172942380646\n",
      "rmse =  2.193866774535454\n",
      "Overall Progress: 65.22%\n",
      "Time to finish (est.): 7.97 min\n",
      "mae =  0.23732481093189095\n",
      "rmse =  0.41046910316066404\n",
      "Overall Progress: 66.09%\n",
      "Time to finish (est.): 7.97 min\n"
     ]
    }
   ],
   "source": [
    "sample_number = 5\n",
    "final_samples = run_multiple_evaluations(\n",
    "    dataloader=test_dataloader,\n",
    "    imputer=diffusion_imputer,\n",
    "    batch_embedder=None,\n",
    "    training_mean=training_mean,\n",
    "    training_std=training_standard_deviation,\n",
    "    old_sample=[],  # final_samples,\n",
    "    # min_sequence_len=2,\n",
    "    # max_sequence_len=2,\n",
    "    sample_number=sample_number,\n",
    "    scale=1,\n",
    "    show_rmse=True\n",
    ")\n",
    "\n",
    "# Set the start method to 'spawn' for the notebook environment\n",
    "\n",
    "# from custom_classes_and_functions import * #wrapper_run_multiple_evaluations, create_dataloader, load_diffusion_imputer, diffusion_imputation, ModelLoop, DiffusionEmbedding, TimeEmbedding\n",
    "\n",
    "# import numpy as np\n",
    "# os.environ['MKL_THREADING_LAYER'] = 'GNU'\n",
    "\n",
    "# import multiprocessing as mp\n",
    "# mp.set_start_method('spawn', force=True)\n",
    "\n",
    "# import os\n",
    "# import sys\n",
    "\n",
    "# # Ensure the current directory is in sys.path\n",
    "\n",
    "# # Define your dataloader\n",
    "# test_loader = create_dataloader(\n",
    "#     test_data_counterfactuals_tensor, test_data_counterfactuals_sequence_lengths, batch_size=10000, min_seq_length=2, max_seq_length=2)\n",
    "\n",
    "# diffusion_imputer = load_diffusion_imputer(\"diffusion_imputer_cancer_jul23.pt\")\n",
    "\n",
    "# # Assuming other necessary objects are defined (`diffusion_imputer`, `training_mean`, `training_standard_deviation`)\n",
    "# if __name__ == \"__main__\":\n",
    "#     diffusion_imputer =  diffusion_imputer # Initialize your imputer with appropriate parameters\n",
    "#     final_samples = wrapper_run_multiple_evaluations(\n",
    "#         dataloader=test_loader,\n",
    "#         imputer=diffusion_imputer,\n",
    "#         training_mean=training_mean,\n",
    "#         training_std=training_standard_deviation,\n",
    "#         sample_number=6,\n",
    "#         num_gpus=3\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final samples\n",
    "# torch.save(final_samples, \"final_samples_cancer_jul23.pt\")\n",
    "# final_samples = torch.load(\"final_samples_cancer_jul20.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 20.37842858355978\n",
      "RMSE using median: 6.875697260317596\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE\n",
    "rmse, rmse_median = calculate_rmse(\n",
    "    final_samples, training_mean, training_standard_deviation\n",
    ")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"RMSE using median: {rmse_median}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def quantile_loss(target, forecast, q: float, eval_points) -> float:\n",
    "#     return 2 * torch.sum(\n",
    "#         torch.abs((forecast - target) * eval_points * ((target <= forecast) * 1.0 - q))\n",
    "#     )\n",
    "\n",
    "\n",
    "# def calc_denominator(target, eval_points):\n",
    "#     return torch.sum(torch.abs(target * eval_points))\n",
    "\n",
    "\n",
    "# def calc_quantile_CRPS(target, forecast, eval_points, mean_scaler, scaler):\n",
    "#     target = target * scaler + mean_scaler\n",
    "#     forecast = forecast * scaler + mean_scaler\n",
    "\n",
    "#     quantiles = np.arange(0.05, 1.0, 0.05)\n",
    "#     denom = calc_denominator(target, eval_points)\n",
    "#     CRPS = 0\n",
    "#     for i in range(len(quantiles)):\n",
    "#         q_pred = []\n",
    "#         for j in range(len(forecast)):\n",
    "#             q_pred.append(torch.quantile(forecast[j : j + 1], quantiles[i], dim=1))\n",
    "#         q_pred = torch.cat(q_pred, 0)\n",
    "#         q_loss = quantile_loss(target, q_pred, quantiles[i], eval_points)\n",
    "#         CRPS += q_loss / denom\n",
    "#     return CRPS.item() / len(quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_number = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_target = samples[0][1]  # input_data same for all samples (B, L, K)\n",
    "# all_generated_samples = torch.stack([samples[i][0] for i in range(sample_number)]).permute(1,0,2,3)  # (B, sample_num, L, K)\n",
    "# all_evalpoint = samples[0][2]  # mask same for all samples (B, L, K)\n",
    "# CRPS = calc_quantile_CRPS(all_target, all_generated_samples, all_evalpoint, training_mean, training_standard_deviation)\n",
    "# print(CRPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"last_expr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L = test_data.shape[1]\n",
    "# K = test_data.shape[2]\n",
    "\n",
    "# dataind = 40  # Number of samples to visualize\n",
    "# start_time = 40\n",
    "# n_skip = 0  # Number of columns to skip\n",
    "\n",
    "# plt.rcParams[\"font.size\"] = 16\n",
    "# fig, axes = plt.subplots(nrows=dataind, ncols=K - n_skip, figsize=(24.0, 6 * dataind))\n",
    "\n",
    "# for i in range(dataind):\n",
    "#     for k in range(n_skip, K):  # Start from n_skip instead of 0\n",
    "#         df = pd.DataFrame({\n",
    "#             \"x\": np.arange(start_time, L),\n",
    "#             \"val\": denormed_data[i, start_time:, k],\n",
    "#             \"y\": eval_points[i, start_time:, k]\n",
    "#         })\n",
    "#         df = df[df.y != 0]\n",
    "#         df2 = pd.DataFrame({\n",
    "#             \"x\": np.arange(start_time, L),\n",
    "#             \"val\": denormed_data[i, start_time:, k],\n",
    "#             \"y\": given_points[i, start_time:, k]\n",
    "#         })\n",
    "#         df2 = df2[df2.y != 0]\n",
    "#         indices = df.x.astype(int).to_numpy()\n",
    "#         row = i\n",
    "#         col = k - n_skip  # Adjust column index for skipped columns\n",
    "\n",
    "#         axes[row][col].plot(range(start_time, L), quantiles_imp[2][i, start_time:, k], color='g', linestyle='solid', label='median')\n",
    "#         axes[row][col].fill_between(range(start_time, L), quantiles_imp[0][i, start_time:, k], quantiles_imp[4][i, start_time:, k], color='g', alpha=0.3)\n",
    "#         axes[row][col].plot(df.x, df.val, color='b', marker='o', linestyle='None')\n",
    "#         axes[row][col].plot(df.x, quantiles_imp[5][i, indices, k], color='r', linestyle='None', label='median', marker='x')\n",
    "#         axes[row][col].plot(df.x, quantiles_imp[0][i, indices, k], color='r', linestyle='None', marker=1)\n",
    "#         axes[row][col].plot(df.x, quantiles_imp[4][i, indices, k], color='r', linestyle='None', marker=1)\n",
    "\n",
    "#         if col == 0:  # Only label the first of the remaining columns\n",
    "#             axes[row][col].set_ylabel('Value')\n",
    "#         if row == dataind - 1:  # Only label the last row\n",
    "#             axes[row][col].set_xlabel('Time')\n",
    "\n",
    "# # Optional: Adjust the layout for better spacing\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_old",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
