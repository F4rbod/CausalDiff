{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/postresearch/Shared/Researchers/Farbod/cancer/code\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# set wd to cancer\n",
    "os.chdir(\"/work/postresearch/Shared/Researchers/Farbod/cancer/code/\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import copy\n",
    "import logging\n",
    "import requests\n",
    "import zipfile\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from itertools import chain\n",
    "from typing import Union\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier, MultiOutputRegressor\n",
    "\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from omegaconf.errors import MissingMandatoryValue\n",
    "\n",
    "import ray\n",
    "from ray import tune, ray_constants\n",
    "\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "from einops import rearrange, reduce, repeat\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "from src.data import RealDatasetCollection, SyntheticDatasetCollection\n",
    "from src.models import TimeVaryingCausalModel\n",
    "from src.models.utils import (\n",
    "    grad_reverse,\n",
    "    BRTreatmentOutcomeHead,\n",
    "    AlphaRise,\n",
    "    clip_normalize_stabilized_weights,\n",
    ")\n",
    "from src.models.utils_lstm import VariationalLSTM\n",
    "from copy import deepcopy\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "11.8\n",
      "Number of available GPUs: 1\n",
      "GPU 0: NVIDIA A100 80GB PCIe\n"
     ]
    }
   ],
   "source": [
    "# show pytorch version and cuda version\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of available GPUs: {num_gpus}\")\n",
    "    for i in range(num_gpus):\n",
    "        gpu_name = torch.cuda.get_device_name(i)\n",
    "        print(f\"GPU {i}: {gpu_name}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. No GPUs detected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting and preparing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class CausalDiff(TimeVaryingCausalModel):\n",
    "\n",
    "    model_type = None  # Will be defined in subclasses\n",
    "    possible_model_types = {'msm_regressor',\n",
    "                            'propensity_treatment', 'propensity_history'}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        args: DictConfig,\n",
    "        dataset_collection: Union[\n",
    "            RealDatasetCollection, SyntheticDatasetCollection\n",
    "        ] = None,\n",
    "        autoregressive: bool = None,\n",
    "        has_vitals: bool = None,\n",
    "        projection_horizon: int = None,\n",
    "        bce_weights: np.array = None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:args: DictConfig of model hyperparameters\n",
    "            dataset_collection: Dataset collection\n",
    "            autoregressive: Flag of including previous outcomes to modelling\n",
    "            has_vitals: Flag of vitals in dataset\n",
    "            projection_horizon: Range of tau-step-ahead prediction (tau = projection_horizon + 1)\n",
    "            bce_weights: Re-weight BCE if used\n",
    "            **kwargs: Other arguments\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            args, dataset_collection, autoregressive, has_vitals, bce_weights\n",
    "        )\n",
    "\n",
    "        if self.dataset_collection is not None:\n",
    "            self.projection_horizon = self.dataset_collection.projection_horizon\n",
    "        else:\n",
    "            self.projection_horizon = projection_horizon\n",
    "\n",
    "        self.lag_features = args.model.lag_features\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        if (\n",
    "            self.dataset_collection is not None\n",
    "            and not self.dataset_collection.processed_data_multi\n",
    "        ):\n",
    "            self.dataset_collection.process_data_multi()\n",
    "\n",
    "    def get_exploded_dataset(self, dataset: Dataset, min_length: int, only_active_entries=True, max_length=None) -> Dataset:\n",
    "        exploded_dataset = deepcopy(dataset)\n",
    "        if max_length is None:\n",
    "            max_length = max(exploded_dataset.data['sequence_lengths'][:])\n",
    "        if not only_active_entries:\n",
    "            exploded_dataset.data['active_entries'][:, :, :] = 1.0\n",
    "            exploded_dataset.data['sequence_lengths'][:] = max_length\n",
    "        exploded_dataset.explode_trajectories(min_length)\n",
    "        return exploded_dataset\n",
    "\n",
    "    def get_propensity_scores(self, dataset: Dataset) -> np.array:\n",
    "        logger.info(f'Propensity scores for {dataset.subset_name}.')\n",
    "        exploded_dataset = self.get_exploded_dataset(\n",
    "            dataset, min_length=self.lag_features, only_active_entries=False)\n",
    "\n",
    "        inputs = self.get_inputs(exploded_dataset)\n",
    "        classifier = getattr(self, self.model_type)\n",
    "\n",
    "        propensity_scores = np.stack(\n",
    "            classifier.predict_proba(inputs), 1)[:, :, 1]\n",
    "        propensity_scores = propensity_scores.reshape(dataset.data['active_entries'].shape[0],\n",
    "                                                      dataset.data['active_entries'].shape[1] -\n",
    "                                                      self.lag_features,\n",
    "                                                      self.dim_treatments)\n",
    "        propensity_scores = np.concatenate([0.5 * np.ones((propensity_scores.shape[0], self.lag_features, self.dim_treatments)),\n",
    "                                            propensity_scores], axis=1)\n",
    "        return propensity_scores\n",
    "\n",
    "    # def get_propensity_scores(self, classifier, inputs, dataset: Dataset) -> np.array:\n",
    "    #     logger.info(f'Propensity scores for {dataset.subset_name}.')\n",
    "\n",
    "    #     propensity_scores = np.stack(\n",
    "    #         classifier.predict_proba(inputs), 1)[:, :, 1]\n",
    "    #     propensity_scores = propensity_scores.reshape(dataset.data['active_entries'].shape[0],\n",
    "    #                                                   dataset.data['active_entries'].shape[1] -\n",
    "    #                                                   self.lag_features,\n",
    "    #                                                   self.dim_treatments)\n",
    "    #     propensity_scores = np.concatenate([0.5 * np.ones((propensity_scores.shape[0], self.lag_features, self.dim_treatments)),\n",
    "    #                                         propensity_scores], axis=1)\n",
    "    #     return propensity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/postresearch/Shared/Researchers/Farbod/cancer/code/src/data/cancer_sim/cancer_simulation.py:346: RuntimeWarning: overflow encountered in exp\n",
      "  if recovery_rvs[i, t] < np.exp(-cancer_volume[i, t] * TUMOUR_CELL_DENSITY):\n",
      "100%|██████████| 100/100 [00:00<00:00, 929.72it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 903.07it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 239.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call to simulate counterfactuals data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [00:00<00:01, 49.89it/s]/work/postresearch/Shared/Researchers/Farbod/cancer/code/src/data/cancer_sim/cancer_simulation.py:734: RuntimeWarning: invalid value encountered in log\n",
      "  (1 + rho * np.log(K / (counterfactual_cancer_volume[current_t] + 1e-07) + 1e-07) -\n",
      "100%|██████████| 100/100 [00:01<00:00, 50.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the configuration file\n",
    "config_path = '/work/postresearch/Shared/Researchers/Farbod/cancer/code/config/dataset/cancer_sim.yaml'\n",
    "args = OmegaConf.load(config_path)\n",
    "\n",
    "# Instantiate the dataset collection\n",
    "dataset_collection = instantiate(args.dataset, _recursive_=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of CausalDiff\n",
    "causal_diff = CausalDiff(args, dataset_collection)\n",
    "\n",
    "# Test the prepare_data method\n",
    "causal_diff.prepare_data()\n",
    "\n",
    "# Test the get_exploded_dataset method\n",
    "exploded_dataset = causal_diff.get_exploded_dataset(\n",
    "    causal_diff.dataset_collection.train_f, min_length=args.model.min_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cancer_volume [2.78624489e+01 2.89048123e+01 1.13790743e+01 1.21165813e+01\n",
      " 1.26081969e+01 5.10246383e+00 5.37313739e+00 5.65768451e+00\n",
      " 5.96264580e+00 6.20452763e+00 5.63053154e+00 5.54531396e+00\n",
      " 4.95235820e+00 4.80593945e+00 4.84404381e+00 5.04908069e+00\n",
      " 5.28180897e+00 5.51750633e+00 5.78630283e+00 6.09696352e+00\n",
      " 6.49909683e+00 2.54229495e+00 1.02825443e+00 1.11009838e+00\n",
      " 1.18762023e+00 1.27231522e+00 1.35179917e+00 5.58786983e-01\n",
      " 5.94196776e-01 6.28060038e-01 6.63652064e-01 7.14179325e-01\n",
      " 7.77089110e-01 8.10076255e-01 3.56043871e-01 3.29671338e-01\n",
      " 3.29529299e-01 3.42630901e-01 3.62050358e-01 3.87888159e-01\n",
      " 1.66015007e-01 1.80624972e-01 1.91582445e-01 2.06882306e-01\n",
      " 2.18490609e-01 2.37422364e-01 2.25192201e-01 8.63117595e-02\n",
      " 9.10487926e-02 3.71768196e-02 4.06294024e-02 4.40896018e-02\n",
      " 4.81877284e-02 5.27188040e-02 5.74430810e-02 6.25429221e-02\n",
      " 2.79390514e-02 1.25844157e-02 3.96793484e-03 4.14090469e-03]\n",
      "cancer_volume (60,)\n",
      "chemo_dosage [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 5.00000000e+00 2.50000000e+00 6.25000000e+00\n",
      " 3.12500000e+00 1.56250000e+00 7.81250000e-01 3.90625000e-01\n",
      " 1.95312500e-01 9.76562500e-02 4.88281250e-02 2.44140625e-02\n",
      " 1.22070312e-02 6.10351562e-03 3.05175781e-03 1.52587891e-03\n",
      " 7.62939453e-04 3.81469727e-04 1.90734863e-04 9.53674316e-05\n",
      " 4.76837158e-05 2.38418579e-05 1.19209290e-05 5.96046448e-06\n",
      " 2.98023224e-06 1.49011612e-06 5.00000075e+00 2.50000037e+00\n",
      " 1.25000019e+00 6.25000093e-01 3.12500047e-01 1.56250023e-01\n",
      " 7.81250116e-02 3.90625058e-02 1.95312529e-02 9.76562646e-03\n",
      " 4.88281323e-03 5.00244141e+00 2.50122070e+00 1.25061035e+00\n",
      " 6.25305176e-01 3.12652588e-01 1.56326294e-01 7.81631470e-02\n",
      " 3.90815735e-02 1.95407867e-02 9.77039337e-03 4.88519669e-03\n",
      " 2.44259834e-03 5.00122130e+00 2.50061065e+00 1.25030532e+00]\n",
      "chemo_dosage (60,)\n",
      "radio_dosage [0. 2. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 2. 2. 0. 0.\n",
      " 0. 0. 2. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 2. 0.\n",
      " 2. 0. 0. 0. 0. 0. 0. 2. 2. 2. 0. 0.]\n",
      "radio_dosage (60,)\n",
      "chemo_application [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "chemo_application (60,)\n",
      "radio_application [0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.]\n",
      "radio_application (60,)\n",
      "chemo_probabilities [0.         0.30097255 0.30247432 0.28141036 0.27211816 0.26709386\n",
      " 0.2563593  0.24917214 0.24413837 0.24051477 0.23780984 0.23524685\n",
      " 0.23307437 0.2309054  0.22897586 0.22733268 0.22150316 0.21573238\n",
      " 0.2136633  0.21152662 0.20940948 0.21001937 0.20839129 0.2051664\n",
      " 0.20195671 0.1987821  0.19597822 0.19332788 0.18985572 0.18656282\n",
      " 0.1833569  0.18016505 0.17700054 0.17387976 0.17074703 0.16675557\n",
      " 0.16264052 0.16031755 0.15925975 0.15816316 0.15704913 0.15525838\n",
      " 0.15346304 0.15264757 0.15182881 0.15099795 0.15017419 0.14924935\n",
      " 0.14771307 0.14617436 0.1449872  0.14389575 0.14284104 0.14179769\n",
      " 0.14075483 0.139701   0.1392347  0.13843798 0.13739742 0.13609618]\n",
      "chemo_probabilities (60,)\n",
      "radio_probabilities [0.         0.30097255 0.30247432 0.28141036 0.27211816 0.26709386\n",
      " 0.2563593  0.24917214 0.24413837 0.24051477 0.23780984 0.23524685\n",
      " 0.23307437 0.2309054  0.22897586 0.22733268 0.22150316 0.21573238\n",
      " 0.2136633  0.21152662 0.20940948 0.21001937 0.20839129 0.2051664\n",
      " 0.20195671 0.1987821  0.19597822 0.19332788 0.18985572 0.18656282\n",
      " 0.1833569  0.18016505 0.17700054 0.17387976 0.17074703 0.16675557\n",
      " 0.16264052 0.16031755 0.15925975 0.15816316 0.15704913 0.15525838\n",
      " 0.15346304 0.15264757 0.15182881 0.15099795 0.15017419 0.14924935\n",
      " 0.14771307 0.14617436 0.1449872  0.14389575 0.14284104 0.14179769\n",
      " 0.14075483 0.139701   0.1392347  0.13843798 0.13739742 0.13609618]\n",
      "radio_probabilities (60,)\n",
      "sequence_lengths 59.0\n",
      "sequence_lengths ()\n",
      "death_flags [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "death_flags (60,)\n",
      "recovery_flags [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "recovery_flags (60,)\n",
      "patient_types 1\n",
      "patient_types ()\n",
      "prev_treatments [[0. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "prev_treatments (59, 4)\n",
      "current_treatments [[1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]]\n",
      "current_treatments (59, 4)\n",
      "current_covariates [[ 0.25432814 -1.32424438]\n",
      " [ 0.26889231 -1.32424438]\n",
      " [ 0.02401812 -1.32424438]\n",
      " [ 0.03432276 -1.32424438]\n",
      " [ 0.04119174 -1.32424438]\n",
      " [-0.06368033 -1.32424438]\n",
      " [-0.05989841 -1.32424438]\n",
      " [-0.05592264 -1.32424438]\n",
      " [-0.05166164 -1.32424438]\n",
      " [-0.048282   -1.32424438]\n",
      " [-0.05630203 -1.32424438]\n",
      " [-0.05749271 -1.32424438]\n",
      " [-0.06577764 -1.32424438]\n",
      " [-0.06782344 -1.32424438]\n",
      " [-0.06729104 -1.32424438]\n",
      " [-0.06442621 -1.32424438]\n",
      " [-0.06117447 -1.32424438]\n",
      " [-0.05788125 -1.32424438]\n",
      " [-0.05412555 -1.32424438]\n",
      " [-0.04978492 -1.32424438]\n",
      " [-0.04416621 -1.32424438]\n",
      " [-0.09945168 -1.32424438]\n",
      " [-0.12060625 -1.32424438]\n",
      " [-0.1194627  -1.32424438]\n",
      " [-0.11837955 -1.32424438]\n",
      " [-0.11719617 -1.32424438]\n",
      " [-0.1160856  -1.32424438]\n",
      " [-0.12716577 -1.32424438]\n",
      " [-0.12667102 -1.32424438]\n",
      " [-0.12619787 -1.32424438]\n",
      " [-0.12570057 -1.32424438]\n",
      " [-0.12499459 -1.32424438]\n",
      " [-0.1241156  -1.32424438]\n",
      " [-0.12365469 -1.32424438]\n",
      " [-0.12999855 -1.32424438]\n",
      " [-0.13036703 -1.32424438]\n",
      " [-0.13036902 -1.32424438]\n",
      " [-0.13018596 -1.32424438]\n",
      " [-0.12991463 -1.32424438]\n",
      " [-0.12955361 -1.32424438]\n",
      " [-0.13265368 -1.32424438]\n",
      " [-0.13244955 -1.32424438]\n",
      " [-0.13229645 -1.32424438]\n",
      " [-0.13208267 -1.32424438]\n",
      " [-0.13192048 -1.32424438]\n",
      " [-0.13165596 -1.32424438]\n",
      " [-0.13182684 -1.32424438]\n",
      " [-0.13376732 -1.32424438]\n",
      " [-0.13370113 -1.32424438]\n",
      " [-0.13445384 -1.32424438]\n",
      " [-0.1344056  -1.32424438]\n",
      " [-0.13435726 -1.32424438]\n",
      " [-0.1343     -1.32424438]\n",
      " [-0.13423669 -1.32424438]\n",
      " [-0.13417068 -1.32424438]\n",
      " [-0.13409942 -1.32424438]\n",
      " [-0.13458292 -1.32424438]\n",
      " [-0.13479746 -1.32424438]\n",
      " [-0.13491785 -1.32424438]]\n",
      "current_covariates (59, 2)\n",
      "outputs [[ 0.26889231]\n",
      " [ 0.02401812]\n",
      " [ 0.03432276]\n",
      " [ 0.04119174]\n",
      " [-0.06368033]\n",
      " [-0.05989841]\n",
      " [-0.05592264]\n",
      " [-0.05166164]\n",
      " [-0.048282  ]\n",
      " [-0.05630203]\n",
      " [-0.05749271]\n",
      " [-0.06577764]\n",
      " [-0.06782344]\n",
      " [-0.06729104]\n",
      " [-0.06442621]\n",
      " [-0.06117447]\n",
      " [-0.05788125]\n",
      " [-0.05412555]\n",
      " [-0.04978492]\n",
      " [-0.04416621]\n",
      " [-0.09945168]\n",
      " [-0.12060625]\n",
      " [-0.1194627 ]\n",
      " [-0.11837955]\n",
      " [-0.11719617]\n",
      " [-0.1160856 ]\n",
      " [-0.12716577]\n",
      " [-0.12667102]\n",
      " [-0.12619787]\n",
      " [-0.12570057]\n",
      " [-0.12499459]\n",
      " [-0.1241156 ]\n",
      " [-0.12365469]\n",
      " [-0.12999855]\n",
      " [-0.13036703]\n",
      " [-0.13036902]\n",
      " [-0.13018596]\n",
      " [-0.12991463]\n",
      " [-0.12955361]\n",
      " [-0.13265368]\n",
      " [-0.13244955]\n",
      " [-0.13229645]\n",
      " [-0.13208267]\n",
      " [-0.13192048]\n",
      " [-0.13165596]\n",
      " [-0.13182684]\n",
      " [-0.13376732]\n",
      " [-0.13370113]\n",
      " [-0.13445384]\n",
      " [-0.1344056 ]\n",
      " [-0.13435726]\n",
      " [-0.1343    ]\n",
      " [-0.13423669]\n",
      " [-0.13417068]\n",
      " [-0.13409942]\n",
      " [-0.13458292]\n",
      " [-0.13479746]\n",
      " [-0.13491785]\n",
      " [-0.13491543]]\n",
      "outputs (59, 1)\n",
      "active_entries [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "active_entries (59, 1)\n",
      "unscaled_outputs [[2.89048123e+01]\n",
      " [1.13790743e+01]\n",
      " [1.21165813e+01]\n",
      " [1.26081969e+01]\n",
      " [5.10246383e+00]\n",
      " [5.37313739e+00]\n",
      " [5.65768451e+00]\n",
      " [5.96264580e+00]\n",
      " [6.20452763e+00]\n",
      " [5.63053154e+00]\n",
      " [5.54531396e+00]\n",
      " [4.95235820e+00]\n",
      " [4.80593945e+00]\n",
      " [4.84404381e+00]\n",
      " [5.04908069e+00]\n",
      " [5.28180897e+00]\n",
      " [5.51750633e+00]\n",
      " [5.78630283e+00]\n",
      " [6.09696352e+00]\n",
      " [6.49909683e+00]\n",
      " [2.54229495e+00]\n",
      " [1.02825443e+00]\n",
      " [1.11009838e+00]\n",
      " [1.18762023e+00]\n",
      " [1.27231522e+00]\n",
      " [1.35179917e+00]\n",
      " [5.58786983e-01]\n",
      " [5.94196776e-01]\n",
      " [6.28060038e-01]\n",
      " [6.63652064e-01]\n",
      " [7.14179325e-01]\n",
      " [7.77089110e-01]\n",
      " [8.10076255e-01]\n",
      " [3.56043871e-01]\n",
      " [3.29671338e-01]\n",
      " [3.29529299e-01]\n",
      " [3.42630901e-01]\n",
      " [3.62050358e-01]\n",
      " [3.87888159e-01]\n",
      " [1.66015007e-01]\n",
      " [1.80624972e-01]\n",
      " [1.91582445e-01]\n",
      " [2.06882306e-01]\n",
      " [2.18490609e-01]\n",
      " [2.37422364e-01]\n",
      " [2.25192201e-01]\n",
      " [8.63117595e-02]\n",
      " [9.10487926e-02]\n",
      " [3.71768196e-02]\n",
      " [4.06294024e-02]\n",
      " [4.40896018e-02]\n",
      " [4.81877284e-02]\n",
      " [5.27188040e-02]\n",
      " [5.74430810e-02]\n",
      " [6.25429221e-02]\n",
      " [2.79390514e-02]\n",
      " [1.25844157e-02]\n",
      " [3.96793484e-03]\n",
      " [4.14090469e-03]]\n",
      "unscaled_outputs (59, 1)\n",
      "prev_outputs [[ 0.25432814]\n",
      " [ 0.26889231]\n",
      " [ 0.02401812]\n",
      " [ 0.03432276]\n",
      " [ 0.04119174]\n",
      " [-0.06368033]\n",
      " [-0.05989841]\n",
      " [-0.05592264]\n",
      " [-0.05166164]\n",
      " [-0.048282  ]\n",
      " [-0.05630203]\n",
      " [-0.05749271]\n",
      " [-0.06577764]\n",
      " [-0.06782344]\n",
      " [-0.06729104]\n",
      " [-0.06442621]\n",
      " [-0.06117447]\n",
      " [-0.05788125]\n",
      " [-0.05412555]\n",
      " [-0.04978492]\n",
      " [-0.04416621]\n",
      " [-0.09945168]\n",
      " [-0.12060625]\n",
      " [-0.1194627 ]\n",
      " [-0.11837955]\n",
      " [-0.11719617]\n",
      " [-0.1160856 ]\n",
      " [-0.12716577]\n",
      " [-0.12667102]\n",
      " [-0.12619787]\n",
      " [-0.12570057]\n",
      " [-0.12499459]\n",
      " [-0.1241156 ]\n",
      " [-0.12365469]\n",
      " [-0.12999855]\n",
      " [-0.13036703]\n",
      " [-0.13036902]\n",
      " [-0.13018596]\n",
      " [-0.12991463]\n",
      " [-0.12955361]\n",
      " [-0.13265368]\n",
      " [-0.13244955]\n",
      " [-0.13229645]\n",
      " [-0.13208267]\n",
      " [-0.13192048]\n",
      " [-0.13165596]\n",
      " [-0.13182684]\n",
      " [-0.13376732]\n",
      " [-0.13370113]\n",
      " [-0.13445384]\n",
      " [-0.1344056 ]\n",
      " [-0.13435726]\n",
      " [-0.1343    ]\n",
      " [-0.13423669]\n",
      " [-0.13417068]\n",
      " [-0.13409942]\n",
      " [-0.13458292]\n",
      " [-0.13479746]\n",
      " [-0.13491785]]\n",
      "prev_outputs (59, 1)\n",
      "static_features [-1.32424438]\n",
      "static_features (1,)\n"
     ]
    }
   ],
   "source": [
    "for key in causal_diff.dataset_collection.train_f.data.keys():\n",
    "    print(key, causal_diff.dataset_collection.train_f.data[key][0])\n",
    "    print(key, causal_diff.dataset_collection.train_f.data[key][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5366, 59, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploded_dataset.data['outputs'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prev_treatments [[0. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "prev_treatments (59, 4)\n",
      "current_treatments [[1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "current_treatments (59, 4)\n",
      "static_features [-1.32424438]\n",
      "static_features (1,)\n",
      "prev_outputs [[0.25432814]\n",
      " [0.26889231]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n",
      "prev_outputs (59, 1)\n",
      "outputs [[0.26889231]\n",
      " [0.02401812]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.        ]]\n",
      "outputs (59, 1)\n",
      "unscaled_outputs [[28.9048123 ]\n",
      " [11.37907427]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]\n",
      " [ 9.66008878]]\n",
      "unscaled_outputs (59, 1)\n",
      "sequence_lengths 2.0\n",
      "sequence_lengths ()\n",
      "active_entries [[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "active_entries (59, 1)\n"
     ]
    }
   ],
   "source": [
    "for key in exploded_dataset.data.keys():\n",
    "    print(key, exploded_dataset.data[key][0])\n",
    "    print(key, exploded_dataset.data[key][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/postresearch/Shared/Researchers/Farbod/cancer/code/src/data/cancer_sim/cancer_simulation.py:346: RuntimeWarning: overflow encountered in exp\n",
      "  if recovery_rvs[i, t] < np.exp(-cancer_volume[i, t] * TUMOUR_CELL_DENSITY):\n",
      "100%|██████████| 10000/10000 [00:11<00:00, 892.10it/s]\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 896.82it/s]\n",
      "100%|██████████| 1000/1000 [00:04<00:00, 242.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call to simulate counterfactuals data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 124/1000 [00:02<00:17, 50.37it/s]/work/postresearch/Shared/Researchers/Farbod/cancer/code/src/data/cancer_sim/cancer_simulation.py:734: RuntimeWarning: invalid value encountered in log\n",
      "  (1 + rho * np.log(K / (counterfactual_cancer_volume[current_t] + 1e-07) + 1e-07) -\n",
      "100%|██████████| 1000/1000 [00:19<00:00, 50.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the configuration file\n",
    "config_path = '/work/postresearch/Shared/Researchers/Farbod/cancer/code/config/dataset/cancer_sim.yaml'\n",
    "args = OmegaConf.load(config_path)\n",
    "\n",
    "# Instantiate the dataset collection\n",
    "dataset_collection = instantiate(args.dataset, _recursive_=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSMPropensityTreatment(CausalDiff):\n",
    "\n",
    "    model_type = 'propensity_treatment'\n",
    "\n",
    "    def __init__(self,\n",
    "                 args: DictConfig,\n",
    "                 dataset_collection: Union[RealDatasetCollection,\n",
    "                                           SyntheticDatasetCollection] = None,\n",
    "                 autoregressive: bool = None, has_vitals: bool = None, **kwargs):\n",
    "        super().__init__(args, dataset_collection, autoregressive, has_vitals)\n",
    "\n",
    "        self.input_size = self.dim_treatments\n",
    "        logger.info(f'Input size of {self.model_type}: {self.input_size}')\n",
    "        self.output_size = self.dim_treatments\n",
    "\n",
    "        self.propensity_treatment = MultiOutputClassifier(\n",
    "            LogisticRegression(penalty=None, max_iter=args.exp.max_epochs))\n",
    "        self.save_hyperparameters(args)\n",
    "\n",
    "    def get_inputs(self, dataset: Dataset) -> np.array:\n",
    "        active_entries = dataset.data['active_entries']\n",
    "        prev_treatments = dataset.data['prev_treatments']\n",
    "        inputs = (prev_treatments * active_entries).sum(1)\n",
    "        return inputs\n",
    "\n",
    "    def fit(self):\n",
    "        self.prepare_data()\n",
    "        train_f = self.get_exploded_dataset(\n",
    "            self.dataset_collection.train_f, min_length=self.lag_features)\n",
    "        active_entries = train_f.data['active_entries']\n",
    "        last_entries = active_entries - \\\n",
    "            np.concatenate([active_entries[:, 1:, :], np.zeros(\n",
    "                (active_entries.shape[0], 1, 1))], axis=1)\n",
    "\n",
    "        # Inputs\n",
    "        inputs = self.get_inputs(train_f)\n",
    "\n",
    "        # Outputs\n",
    "        current_treatments = train_f.data['current_treatments']\n",
    "        outputs = (current_treatments * last_entries).sum(1)\n",
    "\n",
    "        self.propensity_treatment.fit(inputs, outputs)\n",
    "\n",
    "\n",
    "class MSMPropensityHistory(CausalDiff):\n",
    "\n",
    "    model_type = 'propensity_history'\n",
    "\n",
    "    def __init__(self,\n",
    "                 args: DictConfig,\n",
    "                 dataset_collection: Union[RealDatasetCollection,\n",
    "                                           SyntheticDatasetCollection] = None,\n",
    "                 autoregressive: bool = None, has_vitals: bool = None, **kwargs):\n",
    "        super().__init__(args, dataset_collection, autoregressive, has_vitals)\n",
    "\n",
    "        self.input_size = self.dim_treatments + self.dim_static_features\n",
    "        self.input_size += self.dim_vitals if self.has_vitals else 0\n",
    "        self.input_size += self.dim_outcome if self.autoregressive else 0\n",
    "\n",
    "        logger.info(f'Input size of {self.model_type}: {self.input_size}')\n",
    "        self.output_size = self.dim_treatments\n",
    "\n",
    "        self.propensity_history = MultiOutputClassifier(\n",
    "            LogisticRegression(penalty=None, max_iter=args.exp.max_epochs))\n",
    "        self.save_hyperparameters(args)\n",
    "\n",
    "    def get_inputs(self, dataset: Dataset, projection_horizon=0) -> np.array:\n",
    "        active_entries = dataset.data['active_entries']\n",
    "        lagged_entries = active_entries - \\\n",
    "            np.concatenate([active_entries[:, self.lag_features + 1:, :],\n",
    "                            np.zeros((active_entries.shape[0], self.lag_features + 1, 1))], axis=1)\n",
    "        if projection_horizon > 0:\n",
    "            lagged_entries = np.concatenate([lagged_entries[:, projection_horizon:, :],\n",
    "                                             np.zeros((active_entries.shape[0], projection_horizon, 1))], axis=1)\n",
    "\n",
    "        active_entries_before_proection = np.concatenate([active_entries[:, projection_horizon:, :],\n",
    "                                                          np.zeros((active_entries.shape[0], projection_horizon, 1))], axis=1)\n",
    "\n",
    "        prev_treatments = dataset.data['prev_treatments']\n",
    "        inputs = [(prev_treatments * active_entries_before_proection).sum(1)]\n",
    "        if self.has_vitals:\n",
    "            vitals = dataset.data['vitals']\n",
    "            inputs.append(vitals[np.repeat(lagged_entries, self.dim_vitals, 2) == 1.0].reshape(vitals.shape[0],\n",
    "                                                                                               (self.lag_features + 1) *\n",
    "                                                                                               self.dim_vitals))\n",
    "        if self.autoregressive:\n",
    "            prev_outputs = dataset.data['prev_outputs']\n",
    "            inputs.append(prev_outputs[np.repeat(lagged_entries, self.dim_outcome, 2) == 1.0].reshape(prev_outputs.shape[0],\n",
    "                                                                                                      (self.lag_features + 1) *\n",
    "                                                                                                      self.dim_outcome))\n",
    "        static_features = dataset.data['static_features']\n",
    "        inputs.append(static_features)\n",
    "        return np.concatenate(inputs, axis=1)\n",
    "\n",
    "    def fit(self):\n",
    "        self.prepare_data()\n",
    "        train_f = self.get_exploded_dataset(\n",
    "            self.dataset_collection.train_f, min_length=self.lag_features)\n",
    "        active_entries = train_f.data['active_entries']\n",
    "        last_entries = active_entries - \\\n",
    "            np.concatenate([active_entries[:, 1:, :], np.zeros(\n",
    "                (active_entries.shape[0], 1, 1))], axis=1)\n",
    "\n",
    "        # Inputs\n",
    "        inputs = self.get_inputs(train_f)\n",
    "\n",
    "        # Outputs\n",
    "        current_treatments = train_f.data['current_treatments']\n",
    "        outputs = (current_treatments * last_entries).sum(1)\n",
    "\n",
    "        self.propensity_history.fit(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSMPropensityTreatment_model = MSMPropensityTreatment(args, dataset_collection)\n",
    "MSMPropensityTreatment_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       , 0.5       , 0.5       ],\n",
       "       [0.58432225, 0.16691045, 0.16648337, 0.09418818],\n",
       "       [0.59009062, 0.16505337, 0.16455521, 0.08939697],\n",
       "       [0.59583431, 0.16321291, 0.16264503, 0.08482665],\n",
       "       [0.59791013, 0.16307293, 0.16234886, 0.08243974],\n",
       "       [0.60361785, 0.16125029, 0.16045937, 0.07819456],\n",
       "       [0.60929749, 0.15944413, 0.1585877 , 0.07415032],\n",
       "       [0.61494766, 0.15765441, 0.15673379, 0.07029929],\n",
       "       [0.62056701, 0.15588104, 0.15489757, 0.06663388],\n",
       "       [0.62615421, 0.15412398, 0.15307895, 0.0631466 ],\n",
       "       [0.63170796, 0.15238314, 0.15127787, 0.05983013],\n",
       "       [0.63722701, 0.15065847, 0.14949423, 0.0566773 ],\n",
       "       [0.64271013, 0.14894988, 0.14772796, 0.05368113],\n",
       "       [0.64815613, 0.14725731, 0.14597898, 0.05083481],\n",
       "       [0.63967077, 0.14945075, 0.14814835, 0.05542171],\n",
       "       [0.64165684, 0.14932047, 0.14787392, 0.05381356],\n",
       "       [0.64711008, 0.14762442, 0.14612351, 0.0509606 ],\n",
       "       [0.65252528, 0.14594433, 0.1443903 , 0.04825117],\n",
       "       [0.65447877, 0.14581659, 0.14412165, 0.04684077],\n",
       "       [0.65984033, 0.14415359, 0.14240823, 0.04434015],\n",
       "       [0.66516126, 0.1425064 , 0.14071183, 0.04196715],\n",
       "       [0.66707996, 0.14238116, 0.1404489 , 0.04073257],\n",
       "       [0.67234387, 0.14075089, 0.13877207, 0.03854486],\n",
       "       [0.67756479, 0.13913626, 0.13711206, 0.03647017],\n",
       "       [0.68274177, 0.13753719, 0.13546878, 0.03450315],\n",
       "       [0.68787392, 0.13595359, 0.13384215, 0.03263863],\n",
       "       [0.69296038, 0.13438538, 0.13223206, 0.03087164],\n",
       "       [0.69479288, 0.13426616, 0.13198254, 0.02995326],\n",
       "       [0.69981579, 0.13271443, 0.13039145, 0.0283274 ],\n",
       "       [0.70479117, 0.13117792, 0.1288167 , 0.02678735],\n",
       "       [0.70971829, 0.12965653, 0.12725818, 0.02532885],\n",
       "       [0.71459647, 0.12815019, 0.1257158 , 0.0239478 ],\n",
       "       [0.71942508, 0.1266588 , 0.12418945, 0.0226403 ],\n",
       "       [0.72420353, 0.12518227, 0.12267903, 0.02140263],\n",
       "       [0.72504211, 0.1252855 , 0.12298461, 0.02082742],\n",
       "       [0.72976083, 0.12382272, 0.12148681, 0.01968685],\n",
       "       [0.73442823, 0.12237462, 0.12000476, 0.01860756],\n",
       "       [0.73610748, 0.12226455, 0.11977513, 0.01804722],\n",
       "       [0.73777991, 0.12215457, 0.11954587, 0.01750346],\n",
       "       [0.74235771, 0.12072329, 0.11808432, 0.01654185],\n",
       "       [0.746883  , 0.11930651, 0.11663826, 0.01563222],\n",
       "       [0.75135544, 0.11790412, 0.1152076 , 0.01477187],\n",
       "       [0.7557747 , 0.11651604, 0.11379223, 0.01395819],\n",
       "       [0.76014048, 0.11514216, 0.11239204, 0.01318874],\n",
       "       [0.76445254, 0.1137824 , 0.11100692, 0.01246116],\n",
       "       [0.76600243, 0.11367906, 0.11079234, 0.01208364],\n",
       "       [0.76754523, 0.1135758 , 0.11057812, 0.01171741],\n",
       "       [0.77176414, 0.11223219, 0.1092126 , 0.01107009],\n",
       "       [0.77250353, 0.11232612, 0.10948882, 0.01076952],\n",
       "       [0.77401611, 0.11222393, 0.10927681, 0.0104427 ],\n",
       "       [0.77815152, 0.11089431, 0.10792541, 0.0098651 ],\n",
       "       [0.78223255, 0.1095785 , 0.10658873, 0.00931915],\n",
       "       [0.78625913, 0.10827641, 0.10526665, 0.00880314],\n",
       "       [0.79023122, 0.10698792, 0.10395905, 0.00831547],\n",
       "       [0.79414883, 0.10571295, 0.10266584, 0.00785459],\n",
       "       [0.79801197, 0.1044514 , 0.10138689, 0.00741907],\n",
       "       [0.8018207 , 0.10320317, 0.1001221 , 0.00700753],\n",
       "       [0.80557511, 0.10196815, 0.09887135, 0.00661866],\n",
       "       [0.80927531, 0.10074625, 0.09763453, 0.00625124]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propensity_scores_treatment = MSMPropensityTreatment_model.get_propensity_scores(\n",
    "    dataset_collection.train_f)\n",
    "propensity_scores_treatment[0]\n",
    "\n",
    "# compare to actual treatment\n",
    "train_f = dataset_collection.train_f\n",
    "train_f.data['current_treatments'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSMPropensityHistory_model = MSMPropensityHistory(args, dataset_collection)\n",
    "MSMPropensityHistory_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       , 0.5       , 0.5       ],\n",
       "       [0.64273237, 0.16444101, 0.16426105, 0.06486632],\n",
       "       [0.64662042, 0.16266469, 0.16240535, 0.06210274],\n",
       "       [0.65050755, 0.16090388, 0.16056678, 0.0594473 ],\n",
       "       [0.65046105, 0.16085495, 0.16034631, 0.05876648],\n",
       "       [0.65509812, 0.15910058, 0.15852144, 0.0561666 ],\n",
       "       [0.65894405, 0.15737056, 0.15671793, 0.05375044],\n",
       "       [0.66278799, 0.15565609, 0.15493163, 0.05143052],\n",
       "       [0.6665716 , 0.15395711, 0.15316192, 0.04920922],\n",
       "       [0.67035622, 0.15227336, 0.15140904, 0.04707698],\n",
       "       [0.67409035, 0.15060462, 0.14967226, 0.0450354 ],\n",
       "       [0.67784288, 0.14895079, 0.14795208, 0.04307489],\n",
       "       [0.68154537, 0.14731207, 0.14624815, 0.04119831],\n",
       "       [0.68523876, 0.1456878 , 0.14456001, 0.03939922],\n",
       "       [0.67751425, 0.14786838, 0.14671794, 0.04312444],\n",
       "       [0.67858479, 0.147812  , 0.14650924, 0.04253029],\n",
       "       [0.68284788, 0.14617651, 0.14481488, 0.04063237],\n",
       "       [0.68658576, 0.14456192, 0.14314003, 0.03885306],\n",
       "       [0.68666916, 0.14452055, 0.14294503, 0.0383868 ],\n",
       "       [0.69064398, 0.14291842, 0.14128696, 0.0366831 ],\n",
       "       [0.69429957, 0.14133447, 0.13964677, 0.0350725 ],\n",
       "       [0.69437213, 0.1412949 , 0.13945699, 0.03465027],\n",
       "       [0.69821535, 0.13972353, 0.1378333 , 0.03311181],\n",
       "       [0.70182183, 0.13816919, 0.13622673, 0.03165277],\n",
       "       [0.70540542, 0.13662947, 0.13463609, 0.03025585],\n",
       "       [0.7089529 , 0.13510418, 0.13306101, 0.02891944],\n",
       "       [0.71249054, 0.13359323, 0.13150162, 0.02763945],\n",
       "       [0.71256499, 0.13355573, 0.13132158, 0.02730383],\n",
       "       [0.71624776, 0.13205744, 0.12977841, 0.02608412],\n",
       "       [0.71972958, 0.13057545, 0.12825183, 0.02492651],\n",
       "       [0.72317574, 0.12910766, 0.12674055, 0.02381953],\n",
       "       [0.72660108, 0.12765384, 0.12524445, 0.0227603 ],\n",
       "       [0.73000294, 0.12621399, 0.12376347, 0.02174698],\n",
       "       [0.73337955, 0.12478811, 0.12229765, 0.02077773],\n",
       "       [0.73276303, 0.12495283, 0.12266131, 0.02056811],\n",
       "       [0.7361906 , 0.12353797, 0.1212058 , 0.01964729],\n",
       "       [0.73954312, 0.12213762, 0.11976574, 0.0187688 ],\n",
       "       [0.73963872, 0.12210318, 0.11960015, 0.01853764],\n",
       "       [0.73984318, 0.12206785, 0.11943453, 0.01830477],\n",
       "       [0.74322633, 0.12068132, 0.1180125 , 0.01748282],\n",
       "       [0.74649348, 0.11930934, 0.11660562, 0.01670045],\n",
       "       [0.749735  , 0.11795088, 0.11521336, 0.01595245],\n",
       "       [0.75294562, 0.11660585, 0.11383557, 0.01523754],\n",
       "       [0.75613039, 0.11527414, 0.11247217, 0.01455413],\n",
       "       [0.75928602, 0.11395571, 0.11112307, 0.01390098],\n",
       "       [0.75937292, 0.11392388, 0.11096866, 0.01372895],\n",
       "       [0.7595231 , 0.11389149, 0.11081424, 0.01355697],\n",
       "       [0.76269811, 0.11258625, 0.10948222, 0.01294647],\n",
       "       [0.76214438, 0.11273734, 0.1098132 , 0.0128142 ],\n",
       "       [0.76225511, 0.11270565, 0.10966038, 0.01265469],\n",
       "       [0.76540651, 0.11141225, 0.1083405 , 0.01208428],\n",
       "       [0.76848462, 0.11013235, 0.10703486, 0.01154052],\n",
       "       [0.77153366, 0.10886537, 0.1057431 , 0.01102098],\n",
       "       [0.77455395, 0.10761123, 0.10446514, 0.01052458],\n",
       "       [0.7775435 , 0.10636985, 0.10320085, 0.01005037],\n",
       "       [0.78050449, 0.10514108, 0.10195012, 0.00959732],\n",
       "       [0.78343779, 0.10392485, 0.10071283, 0.0091645 ],\n",
       "       [0.78634336, 0.10272107, 0.0994889 , 0.008751  ],\n",
       "       [0.78921927, 0.10152969, 0.09827824, 0.00835602]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "propensity_scores_history = MSMPropensityHistory_model.get_propensity_scores(\n",
    "    dataset_collection.train_f)\n",
    "propensity_scores_history[0]\n",
    "\n",
    "# compare to actual treatment\n",
    "train_f = dataset_collection.train_f\n",
    "train_f.data['current_treatments'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedCausalDiff(CausalDiff):\n",
    "\n",
    "    model_type = 'WeightedCausalDiff'\n",
    "\n",
    "    def __init__(self,\n",
    "                 args: DictConfig,\n",
    "                 propensity_treatment: MSMPropensityTreatment_model,\n",
    "                 propensity_history: MSMPropensityHistory_model,\n",
    "                 dataset_collection: Union[RealDatasetCollection,\n",
    "                                           SyntheticDatasetCollection] = None,\n",
    "                 autoregressive: bool = None, has_vitals: bool = None, **kwargs):\n",
    "        super().__init__(args, dataset_collection, autoregressive, has_vitals)\n",
    "\n",
    "        self.input_size = self.dim_treatments + self.dim_static_features\n",
    "        self.input_size += self.dim_vitals if self.has_vitals else 0\n",
    "        self.input_size += self.dim_outcome if self.autoregressive else 0\n",
    "\n",
    "        logger.info(f'Input size of {self.model_type}: {self.input_size}')\n",
    "        self.output_size = self.dim_outcome\n",
    "\n",
    "        self.propensity_treatment = propensity_treatment\n",
    "        self.propensity_history = propensity_history\n",
    "\n",
    "        self.save_hyperparameters(args)\n",
    "\n",
    "    def get_inputs(self, dataset: Dataset, projection_horizon=0, tau=0) -> np.array:\n",
    "        active_entries = dataset.data['active_entries']\n",
    "        lagged_entries = active_entries - np.concatenate([active_entries[:, self.lag_features + 1:, :],\n",
    "                                                          np.zeros((active_entries.shape[0], self.lag_features + 1, 1))], axis=1)\n",
    "        if projection_horizon > 0:\n",
    "            lagged_entries = np.concatenate([lagged_entries[:, projection_horizon:, :],\n",
    "                                             np.zeros((active_entries.shape[0], projection_horizon, 1))], axis=1)\n",
    "\n",
    "        active_entries_before_proection = np.concatenate([active_entries[:, projection_horizon:, :],\n",
    "                                                          np.zeros((active_entries.shape[0], projection_horizon, 1))], axis=1)\n",
    "\n",
    "        prev_treatments = dataset.data['prev_treatments']\n",
    "        inputs = [(prev_treatments * active_entries_before_proection).sum(1)]\n",
    "        if self.has_vitals:\n",
    "            vitals = dataset.data['vitals']\n",
    "            inputs.append(vitals[np.repeat(lagged_entries, self.dim_vitals, 2) == 1.0].reshape(vitals.shape[0],\n",
    "                                                                                               (self.lag_features + 1) *\n",
    "                                                                                               self.dim_vitals))\n",
    "        if self.autoregressive:\n",
    "            prev_outputs = dataset.data['prev_outputs']\n",
    "            inputs.append(\n",
    "                prev_outputs[np.repeat(lagged_entries, self.dim_outcome, 2) == 1.0].reshape(prev_outputs.shape[0],\n",
    "                                                                                            (self.lag_features + 1) *\n",
    "                                                                                            self.dim_outcome))\n",
    "        static_features = dataset.data['static_features']\n",
    "        inputs.append(static_features)\n",
    "\n",
    "        # Adding current actions\n",
    "        current_treatments = dataset.data['current_treatments']\n",
    "        prediction_entries = active_entries - np.concatenate(\n",
    "            [active_entries[:, tau + 1:, :], np.zeros((active_entries.shape[0], tau + 1, 1))], axis=1)\n",
    "        prediction_entries = np.concatenate([prediction_entries[:, projection_horizon - tau:, :],\n",
    "                                             np.zeros((prediction_entries.shape[0], projection_horizon - tau, 1))], axis=1)\n",
    "        inputs.append((current_treatments * prediction_entries).sum(1))\n",
    "\n",
    "        return np.concatenate(inputs, axis=1)\n",
    "\n",
    "    def get_sample_weights(self, dataset: Dataset, tau=0) -> np.array:\n",
    "        active_entries = dataset.data['active_entries']\n",
    "        stabilized_weights = dataset.data['stabilized_weights']\n",
    "\n",
    "        prediction_entries = active_entries - np.concatenate(\n",
    "            [active_entries[:, tau + 1:, :],\n",
    "                np.zeros((active_entries.shape[0], tau + 1, 1))],\n",
    "            axis=1)\n",
    "        stabilized_weights = stabilized_weights[np.squeeze(prediction_entries) == 1.0].reshape(stabilized_weights.shape[0],\n",
    "                                                                                               tau + 1)\n",
    "        sw = np.prod(stabilized_weights, axis=1)\n",
    "        sw_tilde = np.clip(sw, np.nanquantile(\n",
    "            sw, 0.01), np.nanquantile(sw, 0.99))\n",
    "        return sw_tilde\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        if self.dataset_collection is not None and not self.dataset_collection.processed_data_multi:\n",
    "            self.dataset_collection.process_data_multi()\n",
    "        if self.dataset_collection is not None and 'stabilized_weights' not in self.dataset_collection.train_f.data:\n",
    "            self.dataset_collection.process_propensity_train_f(\n",
    "                self.propensity_treatment, self.propensity_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_causal_diff = WeightedCausalDiff(\n",
    "    args, MSMPropensityTreatment_model, MSMPropensityHistory_model, dataset_collection)\n",
    "\n",
    "weighted_causal_diff.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.35802904, 1.35059066, 1.34290846, 1.32360759,\n",
       "       1.31601217, 1.30781922, 1.29943966, 1.29085614, 1.2821152 ,\n",
       "       1.27320063, 1.26416615, 1.25497977, 1.24568189, 1.23831427,\n",
       "       1.21991137, 1.21116708, 1.20197507, 1.18311686, 1.17404834,\n",
       "       1.1646859 , 1.14610624, 1.13688133, 1.12743764, 1.11794555,\n",
       "       1.10840251, 1.09883592, 1.08077649, 1.07140341, 1.0618597 ,\n",
       "       1.05229356, 1.04272352, 1.03315216, 1.02358223, 1.00725343,\n",
       "       0.99786006, 0.98843171, 0.97159685, 0.9551244 , 0.94597565,\n",
       "       0.93676452, 0.92758124, 0.91842374, 0.90929977, 0.90020863,\n",
       "       0.88452579, 0.86916072, 0.86038558, 0.84624577, 0.83143699,\n",
       "       0.82292834, 0.81441921, 0.80595583, 0.79754   , 0.78917114,\n",
       "       0.78085298, 0.77258772, 0.76437644, 0.75621809])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_causal_diff.dataset_collection.train_f.data['stabilized_weights'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data embedding before feeding into the model\n",
    "\n",
    "This will first one-hot encode all the categorical features and then embed them to n columns. The resulting columns will then be concatenated with the numerical features. The result will then be used to create the torch tensor for the model. The torch tensor will be shaped as (Cases, Time, Features).\n",
    "\n",
    "The input data will be a dataframe like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataEmbedder(nn.Module):\n",
    "    def __init__(self, categorical_indices_sizes, numerical_indices, dataset):\n",
    "        super(DataEmbedder, self).__init__()\n",
    "        # dictionary with feature name, and a list of index and size\n",
    "        self.categoricals = categorical_indices_sizes\n",
    "        self.numerics = numerical_indices  # dictionary with feature name and index\n",
    "        self.embeddings = nn.ModuleDict()\n",
    "        self.mapping_dicts = {}\n",
    "\n",
    "        # Initialize embeddings and mapping dictionaries\n",
    "        for key in self.categoricals:\n",
    "            unique_values = np.unique(dataset[:, :, self.categoricals[key][0]])\n",
    "            self.mapping_dicts[key] = {\n",
    "                name: idx for idx, name in enumerate(unique_values)\n",
    "            }\n",
    "            self.embeddings[key] = nn.Embedding(\n",
    "                num_embeddings=len(unique_values),\n",
    "                embedding_dim=self.categoricals[key][1],\n",
    "            )\n",
    "            print(\n",
    "                f\"Feature: {key}, Categories: {len(unique_values)}, Embedding Size: {self.categoricals[key][1]}\"\n",
    "            )\n",
    "\n",
    "    def forward(self, dataset):\n",
    "        # Apply embeddings to the categorical indices\n",
    "        if len(self.categoricals) == 0:\n",
    "            return dataset\n",
    "        else:\n",
    "            embedded_features = []\n",
    "            for key in self.categoricals:\n",
    "                # Map the categorical values to their corresponding indices\n",
    "                indices = dataset[:, :,\n",
    "                                  self.categoricals[key][0]].cpu().numpy()\n",
    "                mapped_indices = np.vectorize(\n",
    "                    self.mapping_dicts[key].get)(indices)\n",
    "                mapped_indices = torch.tensor(\n",
    "                    mapped_indices, dtype=torch.long, device=dataset.device\n",
    "                )\n",
    "                # print(f\"Feature: {key}, Mapped Indices: {mapped_indices}\")\n",
    "                embedded_features.append(self.embeddings[key](mapped_indices))\n",
    "\n",
    "            embedded_features = torch.cat(embedded_features, dim=-1)\n",
    "\n",
    "            numeric_features = dataset[:, :, list(\n",
    "                self.numerics.values())].float()\n",
    "\n",
    "            # Concatenate the embedded features with the numerical data\n",
    "            result = torch.cat([embedded_features, numeric_features], dim=-1)\n",
    "\n",
    "            feature_count_embedded = len(self.numerics) + sum(\n",
    "                [self.categoricals[key][1] for key in self.categoricals]\n",
    "            )\n",
    "\n",
    "            result = result.reshape(\n",
    "                dataset.shape[0], -1, feature_count_embedded)\n",
    "\n",
    "            return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moded Transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class moded_TimesSeriesAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    A module that computes multi-head attention given query, key, and value tensors for time series data of shape (b, t, f, e)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim: int, num_heads: int):\n",
    "        \"\"\"\n",
    "        Constructor.\n",
    "\n",
    "        Inputs:\n",
    "        - input_dim: Dimension of the input query, key, and value. We assume they all have\n",
    "          the same dimensions. This is basically the dimension of the embedding.\n",
    "        - num_heads: Number of attention heads\n",
    "        \"\"\"\n",
    "        super(moded_TimesSeriesAttention, self).__init__()\n",
    "\n",
    "        assert embed_dim % num_heads == 0\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dim_per_head = embed_dim // num_heads\n",
    "\n",
    "        self.linear_query = nn.Linear(embed_dim, embed_dim)\n",
    "        self.linear_key = nn.Linear(embed_dim, embed_dim)\n",
    "        self.linear_value = nn.Linear(\n",
    "            embed_dim, embed_dim\n",
    "        )  # (self.num_heads * self.dim_per_head * self.dim_per_head))\n",
    "        self.output_linear = nn.Linear(embed_dim, embed_dim)\n",
    "        self.softmax = nn.Softmax2d()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        query: torch.Tensor,\n",
    "        key: torch.Tensor,\n",
    "        value: torch.Tensor,\n",
    "        mask: torch.Tensor = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Compute the attended feature representations.\n",
    "\n",
    "        Inputs:\n",
    "        - query: Tensor of the shape BxTxFXE, where B is the batch size, T is the time dimension, F is the feature dimension,\n",
    "        and E is the embedding dimension\n",
    "        - key: Tensor of the shape BxTxFXE\n",
    "        - value: Tensor of the shape BxTxFXE\n",
    "        - mask: Tensor indicating where the attention should *not* be performed\n",
    "        \"\"\"\n",
    "        b = query.shape[0]\n",
    "        t = query.shape[1]\n",
    "        f = query.shape[2]\n",
    "        e = query.shape[3]\n",
    "        d = self.dim_per_head\n",
    "        h = self.num_heads\n",
    "\n",
    "        query_linear = self.linear_query(query)\n",
    "        key_linear = self.linear_key(key)\n",
    "        value_linear = self.linear_value(value)\n",
    "\n",
    "        query_reshaped = query_linear.reshape(\n",
    "            b, t, f, self.num_heads, self.dim_per_head\n",
    "        )\n",
    "        key_reshaped = key_linear.reshape(\n",
    "            b, t, f, self.num_heads, self.dim_per_head)\n",
    "        value_reshaped = value_linear.reshape(\n",
    "            b, t, f, self.num_heads, self.dim_per_head\n",
    "        )  # , self.dim_per_head)\n",
    "\n",
    "        query_reshaped = query_reshaped.permute(0, 3, 1, 2, 4)  # BxHxTxFxD\n",
    "        key_reshaped = key_reshaped.permute(0, 3, 1, 2, 4)  # BxHxTxFxD\n",
    "        value_reshaped = value_reshaped.permute(\n",
    "            0, 3, 1, 2, 4)  # , 5) # BxHxTxFxDxD\n",
    "\n",
    "        kq = torch.einsum(\"bhtfd,bhxyd->bhtfxy\", key_reshaped, query_reshaped)\n",
    "\n",
    "        dot_prod_scores = kq / math.sqrt(self.dim_per_head)\n",
    "\n",
    "        # softmax across last 2 features (use softmax2d)\n",
    "        dot_prod_scores = dot_prod_scores.reshape(b * h, t * f, t, f)\n",
    "        dot_prod_scores = self.softmax(dot_prod_scores)\n",
    "        dot_prod_scores = dot_prod_scores.reshape(b, h, t, f, t, f)\n",
    "\n",
    "        out = torch.einsum(\"bhtfxy,bhtfd->bhtfd\",\n",
    "                           dot_prod_scores, value_reshaped)\n",
    "        out = out.permute(0, 2, 3, 1, 4).reshape(b, t, f, e)\n",
    "        out = self.output_linear(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class moded_TransformerEncoderCell(nn.Module):\n",
    "    \"\"\"\n",
    "    A single cell (unit) for the Transformer encoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim: int, num_heads: int, ff_dim: int, dropout: float):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - embed_dim: embedding dimension for each element in the time series data\n",
    "        - num_heads: Number of attention heads in a multi-head attention module\n",
    "        - ff_dim: The hidden dimension for a feedforward network\n",
    "        - dropout: Dropout ratio for the output of the multi-head attention and feedforward\n",
    "          modules.\n",
    "        \"\"\"\n",
    "        super(moded_TransformerEncoderCell, self).__init__()\n",
    "\n",
    "        self.time_series_attention = moded_TimesSeriesAttention(\n",
    "            embed_dim, num_heads)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(embed_dim, ff_dim)\n",
    "        self.linear2 = nn.Linear(ff_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - x: Tensor of the shape BxTxFXE, where B is the batch size, T is the time dimension, F is the feature dimension,\n",
    "        and E is the embedding dimension\n",
    "        - mask: Tensor for multi-head attention\n",
    "        \"\"\"\n",
    "\n",
    "        attention2 = self.time_series_attention(x, x, x, mask)\n",
    "        attention = x + self.dropout1(attention2)\n",
    "        attention = self.layer_norm(attention)\n",
    "\n",
    "        attention2 = self.linear2(\n",
    "            self.dropout(self.activation(self.linear1(attention)))\n",
    "        )\n",
    "        attention = attention + self.dropout2(attention2)\n",
    "        attention = self.layer_norm(attention)\n",
    "\n",
    "        return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class moded_TransformerEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A full encoder consisting of a set of TransformerEncoderCell.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim: int,\n",
    "        num_heads: int,\n",
    "        ff_dim: int,\n",
    "        num_cells: int,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - embed_dim: embedding dimension for each element in the time series data\n",
    "        - num_heads: Number of attention heads in a multi-head attention module\n",
    "        - ff_dim: The hidden dimension for a feedforward network\n",
    "        - num_cells: Number of time series attention cells in the encoder\n",
    "        - dropout: Dropout ratio for the output of the multi-head attention and feedforward\n",
    "          modules.\n",
    "        \"\"\"\n",
    "        super(moded_TransformerEncoder, self).__init__()\n",
    "\n",
    "        self.norm = None\n",
    "\n",
    "        self.encoder_modules = nn.ModuleList(\n",
    "            moded_TransformerEncoderCell(embed_dim, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_cells)\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - x: Tensor of the shape BxTxFXE, where B is the batch size, T is the time dimension, F is the feature dimension,\n",
    "        and E is the embedding dimension\n",
    "        - mask: Tensor for multi-head attention\n",
    "\n",
    "        Return:\n",
    "        - y: Tensor of the shape BxTxFXE\n",
    "        \"\"\"\n",
    "\n",
    "        # run encoder modules and add residual connections\n",
    "        for encoder_module in self.encoder_modules:\n",
    "            x = encoder_module(x, mask)\n",
    "\n",
    "        y = x\n",
    "\n",
    "        return y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RSA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimesSeriesAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_in,\n",
    "        d_out,\n",
    "        nh=8,\n",
    "        dk=0,\n",
    "        dv=0,\n",
    "        dd=0,\n",
    "        kernel_size=(3, 7),\n",
    "        stride=(1, 1, 1),\n",
    "        kernel_type=\"VplusR\",  # ['V', 'R', 'VplusR']\n",
    "        feat_type=\"VplusR\",  # ['V', 'R', 'VplusR']\n",
    "    ):\n",
    "        super(TimesSeriesAttention, self).__init__()\n",
    "\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.nh = nh\n",
    "        self.dv = dv = d_out // nh if dv == 0 else dv\n",
    "        self.dk = dk = dv if dk == 0 else dk\n",
    "        self.dd = dd = dk if dd == 0 else dd\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.kernel_type = kernel_type\n",
    "        self.feat_type = feat_type\n",
    "\n",
    "        assert self.kernel_type in [\n",
    "            \"V\",\n",
    "            \"R\",\n",
    "            \"VplusR\",\n",
    "        ], \"Not implemented involution type: {}\".format(self.kernel_type)\n",
    "        assert self.feat_type in [\n",
    "            \"V\",\n",
    "            \"R\",\n",
    "            \"VplusR\",\n",
    "        ], \"Not implemented feature type: {}\".format(self.feat_type)\n",
    "\n",
    "        # print(\"d_in: {}, d_out: {}, nh: {}, dk: {}, dv: {}, dd:{}, kernel_size: {}, kernel_type: {}, feat_type: {}\"\n",
    "        #       .format(d_in, d_out, nh, dk, dv, self.dd, kernel_size, kernel_type, feat_type))\n",
    "\n",
    "        self.ksize = ksize = kernel_size[0] * kernel_size[1]\n",
    "        self.pad = pad = tuple(k // 2 for k in kernel_size)\n",
    "\n",
    "        # hidden dimension\n",
    "        d_hid = nh * dk + dv if self.kernel_type == \"V\" else nh * dk + dk + dv\n",
    "\n",
    "        # Linear projection\n",
    "        # self.projection = nn.Conv2d(d_in, d_hid, 1, bias=False)\n",
    "        self.projection_linear = nn.Sequential(\n",
    "            nn.Linear(d_in, d_hid, bias=False),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Linear(d_hid, d_hid, bias=False),\n",
    "        )\n",
    "\n",
    "        # Intervolution Kernel\n",
    "        if self.kernel_type == \"V\":\n",
    "            self.H2 = nn.Conv2d(1, dd, kernel_size,\n",
    "                                padding=self.pad, bias=False)\n",
    "        elif self.kernel_type == \"R\":\n",
    "            self.H1 = nn.Conv2d(\n",
    "                dk, dk * dd, kernel_size, padding=self.pad, groups=dk, bias=False\n",
    "            )\n",
    "            self.H2 = nn.Conv2d(1, dd, kernel_size,\n",
    "                                padding=self.pad, bias=False)\n",
    "        elif self.kernel_type == \"VplusR\":\n",
    "            self.P1 = nn.Parameter(\n",
    "                torch.randn(dk, dd).unsqueeze(0) * np.sqrt(1 / (ksize * dd)),\n",
    "                requires_grad=True,\n",
    "            )\n",
    "            self.H1 = nn.Conv2d(\n",
    "                dk, dk * dd, kernel_size, padding=self.pad, groups=dk, bias=False\n",
    "            )\n",
    "            self.H2 = nn.Conv2d(1, dd, kernel_size,\n",
    "                                padding=self.pad, bias=False)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # Feature embedding layer\n",
    "        if self.feat_type == \"V\":\n",
    "            pass\n",
    "        elif self.feat_type == \"R\":\n",
    "            self.G = nn.Conv2d(1, dv, kernel_size,\n",
    "                               padding=self.pad, bias=False)\n",
    "        elif self.feat_type == \"VplusR\":\n",
    "            self.G = nn.Conv2d(1, dv, kernel_size,\n",
    "                               padding=self.pad, bias=False)\n",
    "            self.I = nn.Parameter(\n",
    "                torch.eye(dk).unsqueeze(0), requires_grad=True)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # Downsampling layer\n",
    "        if max(self.stride) > 1:\n",
    "            self.avgpool = nn.AvgPool2d(\n",
    "                kernel_size=(1, 3), stride=(1, 2), padding=(0, 1)\n",
    "            )\n",
    "\n",
    "    def L2norm(self, x, d=1):\n",
    "        eps = 1e-6\n",
    "        norm = x**2\n",
    "        norm = norm.sum(dim=d, keepdim=True) + eps\n",
    "        norm = norm ** (0.5)\n",
    "        return x / norm\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # print(x.shape)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        N, C, T, H = x.shape\n",
    "\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "\n",
    "        \"\"\"Linear projection\"\"\"\n",
    "        # x_proj = self.projection(x)\n",
    "        x_proj = self.projection_linear(x)\n",
    "        x_proj = x_proj.permute(0, 3, 1, 2)\n",
    "        # print(x_proj.shape)\n",
    "\n",
    "        if self.kernel_type != \"V\":\n",
    "            q, k, v = torch.split(\n",
    "                x_proj, [self.nh * self.dk, self.dk, self.dv], dim=1)\n",
    "        else:\n",
    "            q, v = torch.split(x_proj, [self.nh * self.dk, self.dv], dim=1)\n",
    "\n",
    "        \"\"\"Normalization\"\"\"\n",
    "        q = rearrange(q, \"b (nh k) t h -> b nh k t h\", k=self.dk)\n",
    "        q = self.L2norm(q, d=2)\n",
    "        q = rearrange(q, \"b nh k t h -> (b t h) nh k\")\n",
    "\n",
    "        v = self.L2norm(v, d=1)\n",
    "\n",
    "        if self.kernel_type != \"V\":\n",
    "            k = self.L2norm(k, d=1)\n",
    "\n",
    "        \"\"\"\n",
    "        q = (b t h) nh k\n",
    "        k = b k t h\n",
    "        v = b v t h\n",
    "        \"\"\"\n",
    "\n",
    "        # Intervolution generation\n",
    "        # Basic kernel\n",
    "        if self.kernel_type == \"V\":\n",
    "            kernel = q\n",
    "        # Relational kernel\n",
    "        else:\n",
    "            K_H1 = self.H1(k)\n",
    "            K_H1 = rearrange(K_H1, \"b (k d) t h-> (b t h) k d\", k=self.dk)\n",
    "\n",
    "            if self.kernel_type == \"VplusR\":\n",
    "                K_H1 = K_H1 + self.P1\n",
    "\n",
    "            kernel = torch.einsum(\n",
    "                \"abc,abd->acd\", q.transpose(1, 2), K_H1\n",
    "            )  # (bth, nh, d)\n",
    "\n",
    "        # feature generation\n",
    "        # Appearance feature\n",
    "        v = rearrange(v, \"b (v 1) t h-> (b v) 1 t h\")\n",
    "\n",
    "        V = self.H2(v)  # (bv, d, t, h)\n",
    "        feature = rearrange(V, \"(b v) d t h -> (b t h) v d\", v=self.dv)\n",
    "\n",
    "        # Relational feature\n",
    "        if self.feat_type in [\"R\", \"VplusR\"]:\n",
    "            V_G = self.G(v)  # (bv, v2, t, h)\n",
    "            V_G = rearrange(V_G, \"(b v) v2 t h -> (b t h) v v2\", v=self.dv)\n",
    "\n",
    "            if self.feat_type == \"VplusR\":\n",
    "                V_G = V_G + self.I\n",
    "\n",
    "            feature = torch.einsum(\"abc,abd->acd\", V_G,\n",
    "                                   feature)  # (bth, v2, d)\n",
    "\n",
    "        # kernel * feat\n",
    "        out = torch.einsum(\"abc,adc->adb\", kernel, feature)  # (bth, nh, v2)\n",
    "\n",
    "        out = rearrange(out, \"(b t h) nh v -> b (nh v) t h\", t=T, h=H)\n",
    "\n",
    "        if max(self.stride) > 1:\n",
    "            out = self.avgpool(out)\n",
    "\n",
    "        out = out.permute(0, 2, 3, 1)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderCell(nn.Module):\n",
    "    \"\"\"\n",
    "    A single cell (unit) for the Transformer encoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, embed_dim: int, num_heads: int, kernel_size, ff_dim: int, dropout: float\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - embed_dim: embedding dimension for each element in the time series data\n",
    "        - num_heads: Number of attention heads in a multi-head attention module\n",
    "        - ff_dim: The hidden dimension for a feedforward network\n",
    "        - dropout: Dropout ratio for the output of the multi-head attention and feedforward\n",
    "          modules.\n",
    "        \"\"\"\n",
    "        super(TransformerEncoderCell, self).__init__()\n",
    "\n",
    "        self.time_series_attention = TimesSeriesAttention(\n",
    "            embed_dim, embed_dim, nh=num_heads, kernel_size=kernel_size\n",
    "        )\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(embed_dim, ff_dim)\n",
    "        self.linear2 = nn.Linear(ff_dim, embed_dim)\n",
    "\n",
    "    def forward(self, data: torch.Tensor, embeddings, mask: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - x: Tensor of the shape BxTxFXE, where B is the batch size, T is the time dimension, F is the feature dimension,\n",
    "        and E is the embedding dimension\n",
    "        - mask: Tensor for multi-head attention\n",
    "        \"\"\"\n",
    "\n",
    "        # attention2 = self.time_series_attention(x, x, x, mask)\n",
    "        attention2 = self.time_series_attention(data)\n",
    "        attention = data + self.dropout1(attention2)\n",
    "        attention = self.layer_norm(attention)\n",
    "\n",
    "        attention2 = self.linear2(\n",
    "            self.dropout(self.activation(self.linear1(attention)))\n",
    "        )\n",
    "        attention = attention + self.dropout2(attention2)\n",
    "        attention = self.layer_norm(attention)\n",
    "\n",
    "        return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A full encoder consisting of a set of TransformerEncoderCell.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim: int,\n",
    "        num_heads: int,\n",
    "        kernel_size,\n",
    "        ff_dim: int,\n",
    "        num_cells: int,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - embed_dim: embedding dimension for each element in the time series data\n",
    "        - num_heads: Number of attention heads in a multi-head attention module\n",
    "        - ff_dim: The hidden dimension for a feedforward network\n",
    "        - num_cells: Number of time series attention cells in the encoder\n",
    "        - dropout: Dropout ratio for the output of the multi-head attention and feedforward\n",
    "          modules.\n",
    "        \"\"\"\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "\n",
    "        self.norm = None\n",
    "\n",
    "        self.encoder_modules = nn.ModuleList(\n",
    "            TransformerEncoderCell(embed_dim, num_heads,\n",
    "                                   kernel_size, ff_dim, dropout)\n",
    "            for _ in range(num_cells)\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - x: Tensor of the shape BxTxFXE, where B is the batch size, T is the time dimension, F is the feature dimension,\n",
    "        and E is the embedding dimension\n",
    "        - mask: Tensor for multi-head attention\n",
    "\n",
    "        Return:\n",
    "        - y: Tensor of the shape BxTxFXE\n",
    "        \"\"\"\n",
    "\n",
    "        # run encoder modules and add residual connections\n",
    "        for encoder_module in self.encoder_modules:\n",
    "            x = encoder_module(x, mask)\n",
    "\n",
    "        y = x\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSDI transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_torch_trans(num_heads=8, num_cells=1, embed_dim=128, ff_dim=512, dropout=0.1):\n",
    "    encoder_layer = nn.TransformerEncoderLayer(\n",
    "        d_model=embed_dim,\n",
    "        nhead=num_heads,\n",
    "        dim_feedforward=ff_dim,\n",
    "        activation=\"gelu\",\n",
    "        dropout=dropout,\n",
    "    )\n",
    "    return nn.TransformerEncoder(encoder_layer, num_layers=num_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionEmbedding(nn.Module):\n",
    "    def __init__(self, num_steps, embedding_dim, projection_dim=None):\n",
    "        super(DiffusionEmbedding, self).__init__()\n",
    "        if projection_dim is None:\n",
    "            projection_dim = embedding_dim\n",
    "        self.register_buffer(\n",
    "            \"embedding\",\n",
    "            self._build_embedding(num_steps, embedding_dim / 2),\n",
    "            persistent=False,\n",
    "        )\n",
    "        self.projection1 = nn.Linear(embedding_dim, projection_dim)\n",
    "        self.projection2 = nn.Linear(projection_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, diffusion_step, data, device=\"cpu\"):\n",
    "        x = self.embedding[diffusion_step]\n",
    "        x = self.projection1(x)\n",
    "        x = F.silu(x)\n",
    "        x = self.projection2(x)\n",
    "        x = F.silu(x)\n",
    "        x = torch.zeros(data.shape).to(device) + x.unsqueeze(1).unsqueeze(1)\n",
    "        return x\n",
    "\n",
    "    def _build_embedding(self, num_steps, dim=64):\n",
    "        steps = torch.arange(num_steps).unsqueeze(1)  # (T,1)\n",
    "        frequencies = 10.0 ** (torch.arange(dim) / (dim - 1) * 4.0).unsqueeze(\n",
    "            0\n",
    "        )  # (1,dim)\n",
    "        table = steps * frequencies  # (T,dim)\n",
    "        table = torch.cat(\n",
    "            [torch.sin(table), torch.cos(table)], dim=1)  # (T,dim*2)\n",
    "        return table\n",
    "\n",
    "\n",
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim, max_len=10000.0):\n",
    "        super(TimeEmbedding, self).__init__()\n",
    "        self.max_len = max_len\n",
    "        self.learnable = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, data, device=\"cpu\"):\n",
    "\n",
    "        b, l, f, e = data.shape\n",
    "        pe = None\n",
    "        pe_row = torch.arange(l)\n",
    "\n",
    "        pe = pe_row.unsqueeze(0)\n",
    "        pe = pe.unsqueeze(2)\n",
    "\n",
    "        pe = pe.repeat((b, 1, e))\n",
    "        pe = pe.float()\n",
    "\n",
    "        pe[:, :, 0::2] = torch.sin(\n",
    "            pe[:, :, 0::2] / (self.max_len ** (torch.arange(0, e, 2) / e))\n",
    "        )\n",
    "        pe[:, :, 1::2] = torch.cos(\n",
    "            pe[:, :, 1::2] / (self.max_len ** (torch.arange(0, e, 2) / e))\n",
    "        )\n",
    "\n",
    "        pe = pe.to(device).unsqueeze(2).repeat((1, 1, f, 1))\n",
    "\n",
    "        # pe = torch.arange(l).unsqueeze(0).unsqueeze(-1).unsqueeze(-1).to(device)\n",
    "        # pe = torch.zeros(data.shape).to(device) + pe\n",
    "\n",
    "        # div_term = 1 / torch.pow(\n",
    "        #     self.max_len, torch.arange(0, f, 2) / f\n",
    "        # ).unsqueeze(-1).to(device)\n",
    "\n",
    "        # pe[:, :, 0::2] = torch.sin(pe[:, :, 0::2] * div_term)\n",
    "        # pe[:, :, 1::2] = torch.cos(pe[:, :, 1::2] * div_term)\n",
    "\n",
    "        return self.learnable(pe)\n",
    "\n",
    "\n",
    "class FeatureEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim, max_len=10000.0):\n",
    "        super(FeatureEmbedding, self).__init__()\n",
    "        self.max_len = max_len\n",
    "        self.learnable = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, data, device=\"cpu\"):\n",
    "        b, l, f, e = data.shape\n",
    "\n",
    "        pe = None\n",
    "        pe_row = torch.arange(f)\n",
    "\n",
    "        pe = pe_row.unsqueeze(0)\n",
    "        pe = pe.unsqueeze(2)\n",
    "\n",
    "        pe = pe.repeat((b, 1, e))\n",
    "        pe = pe.float()\n",
    "\n",
    "        pe[:, :, 0::2] = torch.sin(\n",
    "            pe[:, :, 0::2] / (self.max_len ** (torch.arange(0, e, 2) / e))\n",
    "        )\n",
    "        pe[:, :, 1::2] = torch.cos(\n",
    "            pe[:, :, 1::2] / (self.max_len ** (torch.arange(0, e, 2) / e))\n",
    "        )\n",
    "\n",
    "        pe = pe.to(device).unsqueeze(1).repeat((1, l, 1, 1))\n",
    "\n",
    "        # pe = torch.arange(f).unsqueeze(0).unsqueeze(0).unsqueeze(-1).to(device)\n",
    "        # pe = torch.zeros(data.shape).to(device) + pe\n",
    "\n",
    "        # div_term = 1 / torch.pow(\n",
    "        #     self.max_len, torch.arange(0, e, 2) / e\n",
    "        # ).to(device)\n",
    "\n",
    "        # pe[:, :, :, 0::2] = torch.sin(pe[:, :, :, 0::2] * div_term)\n",
    "        # pe[:, :, :, 1::2] = torch.cos(pe[:, :, :, 1::2] * div_term)\n",
    "\n",
    "        return self.learnable(pe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv1d_with_init(in_channels, out_channels, kernel_size):\n",
    "    layer = nn.Conv1d(in_channels, out_channels, kernel_size)\n",
    "    nn.init.kaiming_normal_(layer.weight)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_heads=8,\n",
    "        num_cells=1,\n",
    "        kernel_size=(3, 7),\n",
    "        embed_dim=128,\n",
    "        ff_dim=512,\n",
    "        dropout=0.1,\n",
    "        method=\"rsa\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.method = method\n",
    "\n",
    "        self.embedding_add = nn.Sequential(\n",
    "            nn.Linear(embed_dim * 4, embed_dim * 4),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embed_dim * 4, embed_dim * 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embed_dim * 2, embed_dim),\n",
    "        )\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        self.mid_projection = Conv1d_with_init(embed_dim, 2 * embed_dim, 1)\n",
    "        # nn.Linear(embed_dim, embed_dim*2)\n",
    "        self.output_projection = Conv1d_with_init(embed_dim, 2 * embed_dim, 1)\n",
    "        # self.output_projection = nn.Linear(embed_dim, embed_dim*2)\n",
    "\n",
    "        if method == \"rsa\":\n",
    "            self.feature_and_time_transformer = TransformerEncoder(\n",
    "                embed_dim=embed_dim,\n",
    "                num_heads=num_heads,\n",
    "                kernel_size=kernel_size,\n",
    "                ff_dim=ff_dim,\n",
    "                num_cells=num_cells,\n",
    "                dropout=dropout,\n",
    "            )\n",
    "            self.linear_time_and_feature = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "        elif method == \"csdi\":\n",
    "            self.time_layer = get_torch_trans(\n",
    "                num_heads=num_heads,\n",
    "                num_cells=num_cells,\n",
    "                embed_dim=embed_dim,\n",
    "                ff_dim=ff_dim,\n",
    "                dropout=dropout,\n",
    "            )\n",
    "            self.feature_layer = get_torch_trans(\n",
    "                num_heads=num_heads,\n",
    "                num_cells=num_cells,\n",
    "                embed_dim=embed_dim,\n",
    "                ff_dim=ff_dim,\n",
    "                dropout=dropout,\n",
    "            )\n",
    "            self.linear_time = nn.Linear(embed_dim, embed_dim)\n",
    "            self.linear_feature = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "        elif method == \"csdi_moded_transformer\":\n",
    "            self.time_layer = get_torch_trans(\n",
    "                num_heads=num_heads,\n",
    "                num_cells=num_cells,\n",
    "                embed_dim=embed_dim,\n",
    "                ff_dim=ff_dim,\n",
    "                dropout=dropout,\n",
    "            )\n",
    "            self.feature_layer = get_torch_trans(\n",
    "                num_heads=num_heads,\n",
    "                num_cells=num_cells,\n",
    "                embed_dim=embed_dim,\n",
    "                ff_dim=ff_dim,\n",
    "                dropout=dropout,\n",
    "            )\n",
    "            self.linear_time = nn.Linear(embed_dim, embed_dim)\n",
    "            self.linear_feature = nn.Linear(embed_dim, embed_dim)\n",
    "            self.feature_and_time_transformer = moded_TransformerEncoder(\n",
    "                embed_dim=embed_dim,\n",
    "                num_heads=num_heads,\n",
    "                ff_dim=ff_dim,\n",
    "                num_cells=num_cells,\n",
    "                dropout=dropout,\n",
    "            )\n",
    "            self.linear_time_and_feature = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "        elif method == \"rsa_csdi\":\n",
    "            self.time_layer = get_torch_trans(\n",
    "                num_heads=num_heads,\n",
    "                num_cells=num_cells,\n",
    "                embed_dim=embed_dim,\n",
    "                ff_dim=ff_dim,\n",
    "                dropout=dropout,\n",
    "            )\n",
    "            self.feature_layer = get_torch_trans(\n",
    "                num_heads=num_heads,\n",
    "                num_cells=num_cells,\n",
    "                embed_dim=embed_dim,\n",
    "                ff_dim=ff_dim,\n",
    "                dropout=dropout,\n",
    "            )\n",
    "            self.linear_time = nn.Linear(embed_dim, embed_dim)\n",
    "            self.linear_feature = nn.Linear(embed_dim, embed_dim)\n",
    "            self.feature_and_time_transformer = TransformerEncoder(\n",
    "                embed_dim=embed_dim,\n",
    "                num_heads=num_heads,\n",
    "                kernel_size=kernel_size,\n",
    "                ff_dim=ff_dim,\n",
    "                num_cells=num_cells,\n",
    "                dropout=dropout,\n",
    "            )\n",
    "            self.linear_time_and_feature = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "        elif method == \"rsa_moded_transformer\":\n",
    "            self.feature_and_time_transformer = TransformerEncoder(\n",
    "                embed_dim=embed_dim,\n",
    "                num_heads=num_heads,\n",
    "                kernel_size=kernel_size,\n",
    "                ff_dim=ff_dim,\n",
    "                num_cells=num_cells,\n",
    "                dropout=dropout,\n",
    "            )\n",
    "            self.linear_time_and_feature = nn.Linear(embed_dim, embed_dim)\n",
    "            self.moded_feature_and_time_transformer = moded_TransformerEncoder(\n",
    "                embed_dim=embed_dim,\n",
    "                num_heads=num_heads,\n",
    "                ff_dim=ff_dim,\n",
    "                num_cells=num_cells,\n",
    "                dropout=dropout,\n",
    "            )\n",
    "            self.moded_linear_time_and_feature = nn.Linear(\n",
    "                embed_dim, embed_dim)\n",
    "\n",
    "        elif method == \"moded_transformer_alone\":\n",
    "            self.moded_feature_and_time_transformer = moded_TransformerEncoder(\n",
    "                embed_dim=embed_dim,\n",
    "                num_heads=num_heads,\n",
    "                ff_dim=ff_dim,\n",
    "                num_cells=num_cells,\n",
    "                dropout=dropout,\n",
    "            )\n",
    "            self.moded_linear_time_and_feature = nn.Linear(\n",
    "                embed_dim, embed_dim)\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def forward_time(self, y, base_shape):\n",
    "        b, t, f, e = base_shape\n",
    "        y = y.permute(0, 2, 1, 3).reshape(b * f, t, e)\n",
    "        y = self.time_layer(y.permute(1, 0, 2)).permute(1, 0, 2)\n",
    "        y = y.reshape(b, f, t, e).permute(0, 2, 1, 3)\n",
    "        return y\n",
    "\n",
    "    def forward_feature(self, y, base_shape):\n",
    "        b, t, f, e = base_shape\n",
    "        y = y.reshape(b * t, f, e)\n",
    "        y = self.feature_layer(y.permute(1, 0, 2)).permute(1, 0, 2)\n",
    "        y = y.reshape(b, t, f, e)\n",
    "        return y\n",
    "\n",
    "    def forward(self, noised_data, diffusion_emb, time_emb, feature_emb):\n",
    "\n",
    "        b, t, f, e = noised_data.shape\n",
    "        base_shape = noised_data.shape\n",
    "\n",
    "        y = torch.stack((noised_data, diffusion_emb,\n",
    "                        time_emb, feature_emb), dim=-1)\n",
    "        y = y.reshape(b, t, f, -1)\n",
    "        y = self.embedding_add(y)\n",
    "        y_resid = y\n",
    "\n",
    "        if self.method == \"rsa\":\n",
    "            y = self.feature_and_time_transformer(y)\n",
    "            y = y.squeeze(-1)\n",
    "            y = self.linear_time_and_feature(y)\n",
    "\n",
    "        elif self.method == \"csdi\":\n",
    "            y = self.forward_time(y, base_shape)\n",
    "            y = self.linear_time(y)\n",
    "            y = (y + y_resid) / math.sqrt(2.0)\n",
    "            y = self.layer_norm(y)\n",
    "            y = self.forward_feature(y, base_shape)\n",
    "            y = self.linear_feature(y)\n",
    "\n",
    "        elif self.method == \"csdi_moded_transformer\":\n",
    "            y = self.forward_time(y, base_shape)\n",
    "            y = self.linear_time(y)\n",
    "            y = (y + y_resid) / math.sqrt(2.0)\n",
    "            y = self.layer_norm(y)\n",
    "            y = self.forward_feature(y, base_shape)\n",
    "            y = self.linear_feature(y)\n",
    "            y = (y + y_resid) / math.sqrt(2.0)\n",
    "            y_resid = y\n",
    "            y = self.layer_norm(y)\n",
    "            y = self.feature_and_time_transformer(y)\n",
    "            y = self.linear_time_and_feature(y)\n",
    "\n",
    "        elif self.method == \"rsa_csdi\":\n",
    "            y = self.forward_time(y, base_shape)\n",
    "            y = self.linear_time(y)\n",
    "            y = (y + y_resid) / math.sqrt(2.0)\n",
    "            y = self.layer_norm(y)\n",
    "            y = self.forward_feature(y, base_shape)\n",
    "            y = self.linear_feature(y)\n",
    "            y = (y + y_resid) / math.sqrt(2.0)\n",
    "            y_resid = y\n",
    "            y = self.layer_norm(y)\n",
    "            y = self.feature_and_time_transformer(y)\n",
    "            y = y.squeeze(-1)\n",
    "            y = self.linear_time_and_feature(y)\n",
    "\n",
    "        elif self.method == \"rsa_moded_transformer\":\n",
    "            y = self.feature_and_time_transformer(y)\n",
    "            y = y.squeeze(-1)\n",
    "            y = self.linear_time_and_feature(y)\n",
    "            y = (y + y_resid) / math.sqrt(2.0)\n",
    "            y = self.layer_norm(y)\n",
    "            y = self.moded_feature_and_time_transformer(y)\n",
    "            y = self.moded_linear_time_and_feature(y)\n",
    "\n",
    "        elif self.method == \"moded_transformer_alone\":\n",
    "            y = self.moded_feature_and_time_transformer(y)\n",
    "            y = self.moded_linear_time_and_feature(y)\n",
    "\n",
    "        y = (y + y_resid) / math.sqrt(2.0)\n",
    "        y = self.layer_norm(y)\n",
    "        y = y.permute(0, 3, 1, 2).reshape(b, e, t * f)\n",
    "        y = self.mid_projection(y)\n",
    "        # y = y.permute(0, 3, 2, 1).reshape(b, 2*e, t*f)\n",
    "\n",
    "        gate, filter = torch.chunk(y, 2, dim=1)\n",
    "        y = torch.sigmoid(gate) * torch.tanh(filter)  # (b,e,f*t)\n",
    "        # y = y.permute(0, 2, 1)\n",
    "        y = self.output_projection(y)\n",
    "        # y = y.permute(0, 2, 1)\n",
    "\n",
    "        residual, skip = torch.chunk(y, 2, dim=1)\n",
    "        residual = residual.permute(0, 2, 1)\n",
    "        skip = skip.permute(0, 2, 1)\n",
    "        residual = residual.reshape(base_shape)\n",
    "        skip = skip.reshape(base_shape)\n",
    "        return (noised_data + residual) / math.sqrt(2.0), skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelLoop(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim=128,\n",
    "        diffusion_steps=1000,\n",
    "        num_heads=8,\n",
    "        kernel_size=(3, 7),\n",
    "        num_cells=1,\n",
    "        num_residual_layers=4,\n",
    "        ff_dim=512,\n",
    "        dropout=0.1,\n",
    "        method=\"rsa\",\n",
    "        device=\"cpu\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.emb_dim = embed_dim\n",
    "\n",
    "        # self.data_embedding_linear = nn.Sequential(\n",
    "        #     nn.Linear(1, self.emb_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.emb_dim, self.emb_dim)\n",
    "        # )\n",
    "        # self.x_embedding = nn.Sequential(\n",
    "        #     nn.Linear(1, self.emb_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.emb_dim, self.emb_dim)\n",
    "        # )\n",
    "\n",
    "        self.data_embedding_linear = Conv1d_with_init(1, self.emb_dim, 1)\n",
    "        self.x_embedding = Conv1d_with_init(2, self.emb_dim, 1)\n",
    "\n",
    "        self.output = Conv1d_with_init(self.emb_dim, 1, 1)\n",
    "        self.output_final = Conv1d_with_init(self.emb_dim, 1, 1)\n",
    "\n",
    "        # self.x_add = nn.Sequential(\n",
    "        #     nn.Linear(embed_dim*num_residual_layers, embed_dim*num_residual_layers),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(embed_dim*num_residual_layers, embed_dim)\n",
    "        # )\n",
    "\n",
    "        self.diffusion_embedding = DiffusionEmbedding(\n",
    "            diffusion_steps, embed_dim)\n",
    "        self.time_embedding = TimeEmbedding(embed_dim)\n",
    "        self.feature_embedding = FeatureEmbedding(embed_dim)\n",
    "\n",
    "        self.residual_layers = nn.ModuleList(\n",
    "            ResidualBlock(\n",
    "                num_heads=num_heads,\n",
    "                num_cells=num_cells,\n",
    "                kernel_size=kernel_size,\n",
    "                embed_dim=embed_dim,\n",
    "                ff_dim=ff_dim,\n",
    "                dropout=dropout,\n",
    "                method=method,\n",
    "            )\n",
    "            for _ in range(num_residual_layers)\n",
    "        )\n",
    "\n",
    "        # self.output = nn.Sequential(\n",
    "        #     nn.Linear(self.emb_dim, self.emb_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.emb_dim, 1)\n",
    "        # )\n",
    "\n",
    "        # self.output_final = nn.Sequential(\n",
    "        #     nn.Linear(self.emb_dim, self.emb_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.emb_dim, 1)\n",
    "        # )\n",
    "\n",
    "    def forward(self, noised_data, noise_mask, diffusion_t):\n",
    "\n",
    "        b, t, f, a = noised_data.shape\n",
    "\n",
    "        noised_data_reshaped = noised_data.permute(\n",
    "            0, 3, 1, 2).reshape(b, 1, t * f)\n",
    "        noised_data_embedded = (\n",
    "            self.data_embedding_linear(noised_data_reshaped)\n",
    "            .permute(0, 2, 1)\n",
    "            .reshape(b, t, f, self.emb_dim)\n",
    "        )\n",
    "        diffusion_embedding = self.diffusion_embedding(\n",
    "            diffusion_t, noised_data_embedded, device=self.device\n",
    "        )\n",
    "        time_embedding = self.time_embedding(\n",
    "            noised_data_embedded, device=self.device)\n",
    "        feature_embedding = self.feature_embedding(\n",
    "            noised_data_embedded, device=self.device\n",
    "        )\n",
    "\n",
    "        x = noised_data_embedded\n",
    "        skip = []\n",
    "        for layer in self.residual_layers:\n",
    "            x, skip_connection = layer(\n",
    "                x, diffusion_embedding, time_embedding, feature_embedding\n",
    "            )\n",
    "            skip.append(skip_connection)\n",
    "            x = x.permute(0, 3, 1, 2).reshape(b, self.emb_dim, t * f)\n",
    "            x = self.output(x).permute(0, 2, 1).reshape(b, t, f)\n",
    "            x = torch.stack((x, noised_data.squeeze(-1)), dim=-1)\n",
    "            # x = x * noise_mask + noised_data * (1 - noise_mask)\n",
    "            x = x.permute(0, 3, 1, 2).reshape(b, 2, t * f)\n",
    "            x = self.x_embedding(x).permute(\n",
    "                0, 2, 1).reshape(b, t, f, self.emb_dim)\n",
    "\n",
    "        x = torch.sum(torch.stack(skip, dim=-1), dim=-1) / math.sqrt(\n",
    "            len(self.residual_layers)\n",
    "        )\n",
    "        # x = torch.stack(skip, dim = -1).reshape(b, t, f, -1)\n",
    "        # x = self.x_add(x)\n",
    "        x = x.permute(0, 3, 1, 2).reshape(b, self.emb_dim, t * f)\n",
    "        x = self.output_final(x).permute(\n",
    "            0, 2, 1).reshape(b, t, f, 1).squeeze(-1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta Schedules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_named_beta_schedule(schedule_name, num_diffusion_timesteps):\n",
    "    \"\"\"\n",
    "    Get a pre-defined beta schedule for the given name.\n",
    "\n",
    "    The beta schedule library consists of beta schedules which remain similar\n",
    "    in the limit of num_diffusion_timesteps.\n",
    "    Beta schedules may be added, but should not be removed or changed once\n",
    "    they are committed to maintain backwards compatibility.\n",
    "    \"\"\"\n",
    "    if schedule_name == \"linear\":\n",
    "        # Linear schedule from Ho et al, extended to work for any number of\n",
    "        # diffusion steps.\n",
    "        scale = 1000 / num_diffusion_timesteps\n",
    "        beta_start = scale * 0.0001\n",
    "        beta_end = scale * 0.02\n",
    "        return torch.linspace(beta_start, beta_end, num_diffusion_timesteps)\n",
    "    elif schedule_name == \"cosine\":\n",
    "        return betas_for_alpha_bar(\n",
    "            num_diffusion_timesteps,\n",
    "            lambda t: math.cos((t + 0.008) / 1.008 * math.pi / 2) ** 2,\n",
    "        )\n",
    "    elif schedule_name == \"quadratic\":\n",
    "        scale = 50 / num_diffusion_timesteps\n",
    "        beta_start = scale * 0.0001\n",
    "        beta_end = scale * 0.5\n",
    "        return (\n",
    "            torch.linspace(beta_start**0.5, beta_end**0.5,\n",
    "                           num_diffusion_timesteps) ** 2\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(f\"unknown beta schedule: {schedule_name}\")\n",
    "\n",
    "\n",
    "def betas_for_alpha_bar(num_diffusion_timesteps, alpha_bar, max_beta=0.999):\n",
    "    \"\"\"\n",
    "    Create a beta schedule that discretizes the given alpha_t_bar function,\n",
    "    which defines the cumulative product of (1-beta) over time from t = [0,1].\n",
    "\n",
    "    :param num_diffusion_timesteps: the number of betas to produce.\n",
    "    :param alpha_bar: a lambda that takes an argument t from 0 to 1 and\n",
    "                      produces the cumulative product of (1-beta) up to that\n",
    "                      part of the diffusion process.\n",
    "    :param max_beta: the maximum beta to use; use values lower than 1 to\n",
    "                     prevent singularities.\n",
    "    \"\"\"\n",
    "    betas = []\n",
    "    for i in range(num_diffusion_timesteps):\n",
    "        t1 = i / num_diffusion_timesteps\n",
    "        t2 = (i + 1) / num_diffusion_timesteps\n",
    "        betas.append(min(1 - alpha_bar(t2) / alpha_bar(t1), max_beta))\n",
    "    return torch.tensor(betas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class diffusion_imputation(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        emb_dim,\n",
    "        excluded_features=None,\n",
    "        # vocab_size,\n",
    "        # pad_idx= None,\n",
    "        strategy=\"random\",\n",
    "        num_residual_layers=4,\n",
    "        features_to_impute=None,\n",
    "        features_to_impute_completely=None,\n",
    "        features_to_impute_after_time=None,\n",
    "        last_n_time=1,\n",
    "        missing_prp=0.1,\n",
    "        diffusion_steps=1000,\n",
    "        diffusion_beta_schedule=\"quadratic\",\n",
    "        num_heads=8,\n",
    "        kernel_size=(3, 7),\n",
    "        ff_dim=512,\n",
    "        num_cells=2,\n",
    "        dropout=0.1,\n",
    "        method=\"rsa\",\n",
    "        device=\"cpu\",\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.emb_dim = emb_dim\n",
    "        self.strategy = strategy\n",
    "        self.features_to_impute = features_to_impute\n",
    "        self.missing_prp = missing_prp\n",
    "        self.diffusion_steps = diffusion_steps\n",
    "        self.last_n_time = last_n_time\n",
    "        self.exclude_features = excluded_features\n",
    "        self.features_to_impute_completely = features_to_impute_completely\n",
    "        self.features_to_impute_after_time = features_to_impute_after_time\n",
    "\n",
    "        # set device to cuda if available\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = \"cuda\"\n",
    "\n",
    "        self.model_loop = ModelLoop(\n",
    "            embed_dim=self.emb_dim,\n",
    "            diffusion_steps=diffusion_steps,\n",
    "            num_heads=num_heads,\n",
    "            kernel_size=kernel_size,\n",
    "            ff_dim=ff_dim,\n",
    "            num_cells=num_cells,\n",
    "            dropout=dropout,\n",
    "            num_residual_layers=num_residual_layers,\n",
    "            method=method,\n",
    "            device=self.device,\n",
    "        )\n",
    "\n",
    "        self.beta = get_named_beta_schedule(\n",
    "            diffusion_beta_schedule, diffusion_steps)\n",
    "\n",
    "        # self.beta = torch.linspace(0.0001, 0.5, diffusion_steps)\n",
    "\n",
    "        # self.beta = torch.linspace(\n",
    "        #         0.0001 ** 0.5, 0.5 ** 0.5, diffusion_steps\n",
    "        #     ) ** 2\n",
    "\n",
    "        self.alpha_hat = 1 - self.beta\n",
    "        self.alpha = torch.cumprod(self.alpha_hat, dim=0)\n",
    "        self.alpha_torch = torch.tensor(self.alpha).float()\n",
    "\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def get_mask(self, data, strategy=\"random\"):\n",
    "\n",
    "        b = data.shape[0]\n",
    "        t = data.shape[1]\n",
    "        f = data.shape[2]\n",
    "\n",
    "        if strategy == \"forecasting\":\n",
    "            forecasted_time = torch.randint(2, t, (b, 1, 1))\n",
    "            mask = torch.zeros_like(data)\n",
    "            for i in range(b):\n",
    "                mask[i, forecasted_time[i]:, :] = 1\n",
    "\n",
    "        if strategy == \"forecasting_last_n_time\":\n",
    "            mask = torch.zeros_like(data)\n",
    "            mask[:, -self.last_n_time, :] = 1\n",
    "\n",
    "        if strategy == \"death_prediction\":\n",
    "            mask = torch.zeros_like(data)\n",
    "            # death is the last 7 columns of the data\n",
    "            mask[:, :, -1] = 1\n",
    "\n",
    "        if strategy == \"random_features\":\n",
    "            selected_features = torch.randint(0, f, (b, 1, 1))\n",
    "            mask = torch.zeros_like(data)\n",
    "            mask[:, :, selected_features] = 1\n",
    "\n",
    "        if strategy == \"selected_features\":\n",
    "            mask = torch.zeros_like(data)\n",
    "            mask[:, :, self.features_to_impute] = 1\n",
    "\n",
    "        if strategy == \"selected_features_after_time\":\n",
    "            selected_time = torch.randint(1, t, (b, 1, 1))\n",
    "            mask = torch.zeros_like(data)\n",
    "            mask[:, selected_time:, self.features_to_impute] = 1\n",
    "\n",
    "        if strategy == \"selected_features_last_n_time\":\n",
    "            mask = torch.zeros_like(data)\n",
    "            mask[:, -self.last_n_time:, self.features_to_impute] = 1\n",
    "\n",
    "        if strategy == \"random\":\n",
    "            mask = torch.rand(size=(b, t, f))\n",
    "            mask = mask < self.missing_prp\n",
    "            mask = mask.float()\n",
    "\n",
    "        if strategy == \"selected_features_and_selected_features_after_time\":\n",
    "            mask = torch.zeros_like(data)\n",
    "            mask[:, :, self.features_to_impute_completely] = 1\n",
    "            mask[:, -self.last_n_time:, self.features_to_impute_after_time] = 1\n",
    "\n",
    "        if self.exclude_features is not None:\n",
    "            mask[:, :, self.exclude_features] = 0\n",
    "\n",
    "        return mask\n",
    "\n",
    "    def loss_func(self, predicted_noise, noise, noise_mask):\n",
    "        # noise = torch.nan_to_num(noise, nan=0.0)\n",
    "        # predicted_noise = torch.nan_to_num(predicted_noise, nan=0.0)\n",
    "        residual = noise - predicted_noise\n",
    "        num_obs = torch.sum(noise_mask)\n",
    "        loss = (residual**2).sum() / num_obs\n",
    "        return loss\n",
    "\n",
    "    def forward(self, data):\n",
    "\n",
    "        b, t, f = data.shape\n",
    "\n",
    "        noise_mask = self.get_mask(data, self.strategy).to(self.device)\n",
    "        noise = torch.randn((b, t, f)).to(self.device)\n",
    "        noise = noise_mask * noise\n",
    "\n",
    "        diffusion_t = torch.randint(0, self.diffusion_steps, (b, 1)).squeeze(1)\n",
    "        alpha = self.alpha_torch[diffusion_t].unsqueeze(\n",
    "            1).unsqueeze(2).to(self.device)\n",
    "\n",
    "        noised_data = data * noise_mask\n",
    "        noised_data = noised_data * (alpha**0.5) + noise * ((1 - alpha) ** 0.5)\n",
    "        conditional_data = data * (1 - noise_mask)\n",
    "        noised_data = noised_data + conditional_data\n",
    "        noised_data = noised_data.float()\n",
    "\n",
    "        predicted_noise = self.model_loop(\n",
    "            noised_data.unsqueeze(3), noise_mask.unsqueeze(3), diffusion_t\n",
    "        )\n",
    "        predicted_noise = predicted_noise * noise_mask\n",
    "\n",
    "        return (predicted_noise, noise, noise_mask)\n",
    "\n",
    "    def eval_with_grad(self, data, scale=1):\n",
    "\n",
    "        # with torch.no_grad():\n",
    "        imputation_mask = self.get_mask(data, self.strategy).to(self.device)\n",
    "        conditional_data = data * (1 - imputation_mask)\n",
    "        random_noise = torch.randn_like(data) * imputation_mask * scale\n",
    "        data_2 = (conditional_data + random_noise).unsqueeze(3)\n",
    "\n",
    "        b, ti, f, e = data_2.shape\n",
    "        imputed_samples = torch.zeros((b, ti, f)).to(self.device)\n",
    "        x = conditional_data + random_noise\n",
    "\n",
    "        for t in range(self.diffusion_steps - 1, -1, -1):\n",
    "\n",
    "            x = x.unsqueeze(3).float()\n",
    "            predicted_noise = self.model_loop(\n",
    "                x, imputation_mask.unsqueeze(\n",
    "                    3), torch.tensor([t]).to(self.device)\n",
    "            )\n",
    "            predicted_noise = predicted_noise * imputation_mask\n",
    "\n",
    "            coeff1 = 1 / self.alpha_hat[t] ** 0.5\n",
    "            coeff2 = (1 - self.alpha_hat[t]) / (1 - self.alpha[t]) ** 0.5\n",
    "\n",
    "            x = x.squeeze(3)\n",
    "            x = coeff1 * (x - coeff2 * predicted_noise)\n",
    "\n",
    "            if t > 0:\n",
    "                noise = torch.randn_like(x)\n",
    "                sigma = (\n",
    "                    (1.0 - self.alpha[t - 1]) /\n",
    "                    (1.0 - self.alpha[t]) * self.beta[t]\n",
    "                ) ** 0.5\n",
    "                x += sigma * noise\n",
    "\n",
    "            x = data_2.squeeze(3) * (1 - imputation_mask) + x * imputation_mask\n",
    "\n",
    "            imputed_samples = x\n",
    "\n",
    "        return (imputed_samples, data, imputation_mask)\n",
    "\n",
    "    def eval(\n",
    "        self,\n",
    "        data,\n",
    "        imputation_mask,\n",
    "        mean,\n",
    "        std,\n",
    "        scale=1,\n",
    "        verbose=True,\n",
    "        show_max_diff=False,\n",
    "        show_rmse=False,\n",
    "    ):\n",
    "\n",
    "        conditional_data = data * (1 - imputation_mask)\n",
    "        random_noise = torch.randn_like(data) * imputation_mask * scale\n",
    "        data_2 = (conditional_data + random_noise).unsqueeze(3)\n",
    "\n",
    "        b, ti, f, e = data_2.shape\n",
    "        imputed_samples = torch.zeros((b, ti, f)).to(self.device)\n",
    "        x = conditional_data + random_noise\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for t in range(self.diffusion_steps - 1, -1, -1):\n",
    "\n",
    "                x = x.unsqueeze(3).float()\n",
    "                predicted_noise = self.model_loop(\n",
    "                    x, imputation_mask.unsqueeze(\n",
    "                        3), torch.tensor([t]).to(self.device)\n",
    "                )\n",
    "                predicted_noise = predicted_noise * imputation_mask\n",
    "\n",
    "                coeff1 = 1 / self.alpha_hat[t] ** 0.5\n",
    "                coeff2 = (1 - self.alpha_hat[t]) / (1 - self.alpha[t]) ** 0.5\n",
    "\n",
    "                x = x.squeeze(3)\n",
    "                x = coeff1 * (x - coeff2 * predicted_noise)\n",
    "\n",
    "                if t > 0:\n",
    "                    noise = torch.randn_like(x)\n",
    "                    sigma = (\n",
    "                        (1.0 - self.alpha[t - 1]) /\n",
    "                        (1.0 - self.alpha[t]) * self.beta[t]\n",
    "                    ) ** 0.5\n",
    "                    x += sigma * noise\n",
    "\n",
    "                x = data_2.squeeze(3) * (1 - imputation_mask) + \\\n",
    "                    x * imputation_mask\n",
    "\n",
    "            imputed_samples = x.detach()\n",
    "\n",
    "        if show_max_diff == True:\n",
    "            # show the data at torch.max(torch.abs(data[imputation_mask !=0] - imputed_samples[imputation_mask !=0]))\n",
    "            print(\n",
    "                \"max difference = \",\n",
    "                torch.max(\n",
    "                    torch.abs(\n",
    "                        data[imputation_mask != 0]\n",
    "                        - imputed_samples[imputation_mask != 0]\n",
    "                    )\n",
    "                ).item(),\n",
    "            )\n",
    "            print(\n",
    "                \"data at max difference = \",\n",
    "                data[imputation_mask != 0][\n",
    "                    torch.argmax(\n",
    "                        torch.abs(\n",
    "                            data[imputation_mask != 0]\n",
    "                            - imputed_samples[imputation_mask != 0]\n",
    "                        )\n",
    "                    )\n",
    "                ].item(),\n",
    "            )\n",
    "            print(\n",
    "                \"imputed at max difference = \",\n",
    "                imputed_samples[imputation_mask != 0][\n",
    "                    torch.argmax(\n",
    "                        torch.abs(\n",
    "                            data[imputation_mask != 0]\n",
    "                            - imputed_samples[imputation_mask != 0]\n",
    "                        )\n",
    "                    )\n",
    "                ].item(),\n",
    "            )\n",
    "\n",
    "        mae = torch.mean(\n",
    "            torch.abs(\n",
    "                data[imputation_mask != 0] -\n",
    "                imputed_samples[imputation_mask != 0]\n",
    "            )\n",
    "        ).item()\n",
    "        if verbose == True:\n",
    "            print(\"mae = \", mae)\n",
    "\n",
    "        if show_rmse == True:\n",
    "            # descale the data\n",
    "            imputed_samples_copy = imputed_samples.detach().clone()\n",
    "            imputed_samples_copy = imputed_samples_copy * std + mean\n",
    "            data_copy = data.detach().clone()\n",
    "            data_copy = data_copy * std + mean\n",
    "            rmse = torch.sqrt(\n",
    "                torch.mean(\n",
    "                    (\n",
    "                        data_copy[imputation_mask != 0]\n",
    "                        - imputed_samples_copy[imputation_mask != 0]\n",
    "                    )\n",
    "                    ** 2\n",
    "                )\n",
    "            ).item()\n",
    "            rmse = rmse / 1150 * 100\n",
    "            print(\"rmse = \", rmse)\n",
    "        # data_to_print = data[imputation_mask !=0]\n",
    "        # imputed_samples_to_print = imputed_samples[imputation_mask !=0]\n",
    "        # print(\"data:\", data_to_print)\n",
    "        # print(\"imputed:\", imputed_samples_to_print)\n",
    "        # print(\"absolute difference in the first 100 : \", torch.abs(data_to_print - imputed_samples_to_print)[:100])\n",
    "        # print(\"mae = \", torch.mean(torch.abs(data_to_print - imputed_samples_to_print)).item())\n",
    "\n",
    "        return (imputed_samples, data, imputation_mask, mae)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# from IPython.display import display, clear_output\n",
    "# import matplotlib.pyplot as plt\n",
    "# import time\n",
    "# import statistics\n",
    "# from itertools import chain\n",
    "# import numpy as np\n",
    "# from collections import deque\n",
    "\n",
    "# def train(model, data_loader, data_loader_validation, epochs, lr, loss_func, batch_embedder,\n",
    "#           windowed_mode=False, window_mode=\"uniform\", window_start_mode=\"random\", min_window=50, max_window=100, neg_bin_p=0.95, train_on_all_every=4,\n",
    "#           annealing_mode = False, annealing_window=5, annealing_multiplier=1.25, annealing_ratio = 0.5, annealing_minimum = 1e-6,\n",
    "#           device=\"cuda\", verbose=False, plot_every=10,\n",
    "#           validation_frequency=1, validation_prp=10, moving_avg_window=10):\n",
    "\n",
    "#     batch_embedder = batch_embedder.to(device)\n",
    "#     model = model.to(device)\n",
    "\n",
    "#     optimizer = torch.optim.Adam(\n",
    "#         chain(batch_embedder.parameters(), model.parameters()),\n",
    "#         lr=lr\n",
    "#     )\n",
    "\n",
    "#     model.train()\n",
    "#     batch_embedder.train()\n",
    "#     loss_list = []\n",
    "#     initial_value = 1.0  # Initial value for equal probability\n",
    "#     window_losses = torch.ones(max_window - min_window + 1, device=device) * initial_value  # Track losses for each window length\n",
    "#     window_counts = torch.zeros(max_window - min_window + 1, device=device)  # Track counts for each window length\n",
    "#     loss_deques = [deque(maxlen=moving_avg_window) for _ in range(max_window - min_window + 1)]  # Deques for moving average\n",
    "#     if windowed_mode and window_mode == \"biased_loss\":\n",
    "#         fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 12))\n",
    "#     else:\n",
    "#         fig, ax1 = plt.subplots(1, 1, figsize=(10, 6))\n",
    "#     epoch_loss_list = []\n",
    "#     val_loss = 0\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         # Annealing for the learning rate\n",
    "#         if annealing_mode and epoch > annealing_window:\n",
    "#             if len(epoch_loss_list) > 0 and epoch_loss_list[-1] >= annealing_multiplier * (statistics.mean(epoch_loss_list[-annealing_window:])):\n",
    "#                 for g in optimizer.param_groups:\n",
    "#                     if g['lr'] * annealing_ratio < annealing_minimum:\n",
    "#                         g['lr'] = annealing_minimum\n",
    "#                     else:\n",
    "#                         g['lr'] *= annealing_ratio\n",
    "\n",
    "#         start = time.time()\n",
    "#         for i, batch in enumerate(data_loader):\n",
    "\n",
    "#             batch = batch.to(device)\n",
    "#             batch = batch_embedder(batch)\n",
    "\n",
    "#             batch_length = batch.shape[1]\n",
    "\n",
    "#             # Windowed mode logic\n",
    "#             if windowed_mode:\n",
    "#                 if batch_length < min_window:\n",
    "#                     continue\n",
    "#                 if window_start_mode == \"random\":\n",
    "#                     cut_start = torch.randint(0, batch_length - window_length + 1, (1,)).item()\n",
    "#                 elif window_start_mode == \"fixed\":\n",
    "#                     cut_start = 0\n",
    "#                 if window_mode == \"uniform\":\n",
    "#                     while True:\n",
    "#                         window_length = torch.randint(min_window, batch_length + 1, (1,)).item()\n",
    "#                         cut_end = cut_start + window_length\n",
    "#                         if min_window <= (cut_end - cut_start) <= batch_length:\n",
    "#                             break\n",
    "#                     batch = batch[:, cut_start:cut_end, :]\n",
    "\n",
    "#                 elif window_mode == \"negative_binomial\":\n",
    "#                     total_count = 1\n",
    "#                     probs = neg_bin_p\n",
    "#                     distribution = torch.distributions.NegativeBinomial(total_count=total_count, probs=probs)\n",
    "#                     while True:\n",
    "#                         window_length = distribution.sample().item() + min_window\n",
    "#                         cut_end = cut_start + window_length\n",
    "#                         if min_window <= window_length <= batch_length:\n",
    "#                             break\n",
    "#                     batch = batch[:, cut_start:cut_end, :]\n",
    "\n",
    "#                 elif window_mode == \"biased_loss\":\n",
    "#                     if torch.min(window_counts) < 2:\n",
    "#                         # Use uniform distribution until each length has been used at least twice\n",
    "#                         window_probs = torch.ones_like(window_losses) / len(window_losses)\n",
    "#                     elif torch.sum(window_counts) % train_on_all_every == 0:\n",
    "#                         window_probs = torch.ones_like(window_losses) / len(window_losses)\n",
    "#                     else:\n",
    "#                         # Update probabilities based on moving average of losses\n",
    "#                         avg_losses = torch.tensor([np.mean(loss_deque) if len(loss_deque) > 0 else initial_value for loss_deque in loss_deques], device=device)\n",
    "#                         window_probs = avg_losses / avg_losses.sum()\n",
    "#                     while True:\n",
    "#                         window_length = torch.multinomial(window_probs, 1).item() + min_window\n",
    "#                         #check if the window length does work with the batch length\n",
    "#                         if window_length > batch_length:\n",
    "#                             continue\n",
    "#                         cut_end = cut_start + window_length\n",
    "#                         if min_window <= window_length <= batch_length:\n",
    "#                             break\n",
    "#                     batch = batch[:, cut_start:cut_end, :]\n",
    "#                     window_counts[window_length - min_window] += 1  # Update window counts\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             predicted_noise, noise, noise_mask = model(batch)\n",
    "#             loss = loss_func(predicted_noise, noise, noise_mask)\n",
    "#             loss.backward()\n",
    "#             # # Gradient clipping\n",
    "#             max_grad_norm = 1.0\n",
    "#             torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "#             torch.nn.utils.clip_grad_norm_(batch_embedder.parameters(), max_grad_norm)\n",
    "#             optimizer.step()\n",
    "#             loss_list.append(loss.item())\n",
    "\n",
    "#             epoch_loss = sum(loss_list[-len(data_loader):]) / len(data_loader)\n",
    "#             epoch_loss_list.append(epoch_loss)\n",
    "\n",
    "#             # Update window losses and moving average deque\n",
    "#             if windowed_mode and window_mode == \"biased_loss\":\n",
    "#                 window_idx = window_length - min_window\n",
    "#                 window_losses[window_idx] += loss.item()\n",
    "#                 loss_deques[window_idx].append(loss.item())\n",
    "\n",
    "#             # Dynamic plot update\n",
    "#             if i % plot_every == 0:\n",
    "#                 ax1.clear()\n",
    "#                 ax1.set_ylim(0, 1)\n",
    "#                 ax1.plot(loss_list)\n",
    "#                 if len(loss_list) > 100:\n",
    "#                     ax1.plot(np.convolve(loss_list, np.ones((100,))/100, mode='valid'))\n",
    "#                     ax1.text(len(loss_list) - 1, np.convolve(loss_list, np.ones((100,))/100, mode='valid')[-1],\n",
    "#                             str(round(np.convolve(loss_list, np.ones((100,))/100, mode='valid')[-1], 3)))\n",
    "#                 if len(epoch_loss_list) > 0:\n",
    "#                     ax1.text(0.1, 0.9, f\"Epoch: {epoch} | Learning rate: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "#                 # ax1.text(0.1, 0.8, f\"Learning rate: {optimizer.param_groups[0]['lr']:.4e}\")\n",
    "#                 ax1.text(0.1, 0.8, f\"Loss: {epoch_loss_list[-1]:.3e} | Validation loss: {val_loss:.3e}\")\n",
    "#                 ax1.text(0.1, 0.7, f\"Time per step: {((time.time() - start) / (i + 1)):.2f} s | Time per epoch: {((time.time() - start) / (i + 1) * len(data_loader)):.2f} s\")\n",
    "#                 ax1.text(0.1, 0.6, f\"Time till finish (est.): {((time.time() - start) / (i + 1) * len(data_loader) * (epochs - epoch)) / 60:.2f} min\")\n",
    "#                 if windowed_mode and window_mode == \"biased_loss\":\n",
    "#                     ax2.clear()\n",
    "#                     ax2.bar(range(min_window, max_window + 1), window_counts.cpu().numpy())\n",
    "#                     ax2.set_ylabel(\"Counts\")\n",
    "#                     ax2.set_title(\"Counts of Each Window Length Used\")\n",
    "\n",
    "#                     moving_avg_losses = torch.tensor([np.mean(loss_deque) if len(loss_deque) > 0 else initial_value for loss_deque in loss_deques], device=device).cpu().numpy()\n",
    "#                     ax3.clear()\n",
    "#                     ax3.bar(range(min_window, max_window + 1), moving_avg_losses)\n",
    "#                     ax3.set_xlabel(\"Window Length\")\n",
    "#                     ax3.set_ylabel(\"Moving Average Loss\")\n",
    "#                     ax3.set_title(\"Moving Average Loss for Each Window Length\")\n",
    "\n",
    "#                 display(fig)\n",
    "#                 clear_output(wait=True)\n",
    "\n",
    "#         end = time.time()\n",
    "\n",
    "#         # Validation\n",
    "#         if epoch % validation_frequency == 0:\n",
    "#             loss_list_validation = []\n",
    "#             for i, batch in enumerate(data_loader_validation):\n",
    "#                 batch = batch.to(device)\n",
    "#                 batch = batch_embedder(batch)\n",
    "#                 if i % validation_prp == 0:\n",
    "#                     predicted_noise, noise, noise_mask = model(batch)\n",
    "#                     loss = loss_func(predicted_noise, noise, noise_mask)\n",
    "#                     loss_list_validation.append(loss.item())\n",
    "\n",
    "#             val_loss = np.mean(loss_list_validation)\n",
    "\n",
    "#         if verbose:\n",
    "#             print(f\"Epoch {epoch} completed in {end - start} seconds, Loss: {epoch_loss}\")\n",
    "#             print(f\"Validation Loss: {val_loss}\")\n",
    "\n",
    "\n",
    "#     return model, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "%matplotlib inline\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import statistics\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "def train(model, data_loader, data_loader_validation, epochs, lr, loss_func, batch_embedder = None, gradient_clip = 1.0,\n",
    "          windowed_mode=False, window_mode=\"uniform\", window_start_mode=\"random\", min_window=50, max_window=100, neg_bin_p=0.95, train_on_all_every=4,\n",
    "          annealing_mode = False, annealing_window=5, annealing_multiplier=1.25, annealing_ratio = 0.5, annealing_minimum = 1e-6,\n",
    "          device=\"cuda\", num_gpus=1, verbose=False, plot_every=10,\n",
    "          validation_frequency=1, validation_prp=10, moving_avg_window=10):\n",
    "\n",
    "    # Check for GPU availability\n",
    "    available_gpus = torch.cuda.device_count()\n",
    "    if available_gpus < num_gpus:\n",
    "        print(f\"Requested {num_gpus} GPUs, but only {available_gpus} are available.\")\n",
    "        num_gpus = available_gpus\n",
    "    else:\n",
    "        print(f\"Using {num_gpus} GPUs for training.\")\n",
    "        #also print gpu model\n",
    "        print(f\"GPU model: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    if num_gpus > 1:\n",
    "        model = torch.nn.DataParallel(model, device_ids=list(range(num_gpus)))\n",
    "        if batch_embedder is not None:\n",
    "            batch_embedder = torch.nn.DataParallel(batch_embedder, device_ids=list(range(num_gpus)))\n",
    "\n",
    "    if batch_embedder is not None:\n",
    "        batch_embedder = batch_embedder.to(device)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    if batch_embedder is not None:\n",
    "        optimizer = torch.optim.Adam(\n",
    "            chain(batch_embedder.parameters(), model.parameters()),\n",
    "            lr=lr\n",
    "        )\n",
    "    else:\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr=lr\n",
    "        )\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    if batch_embedder is not None:\n",
    "        batch_embedder.train()\n",
    "    \n",
    "    loss_list = []\n",
    "    initial_value = 1.0  # Initial value for equal probability\n",
    "    window_losses = torch.ones(max_window - min_window + 1, device=device) * initial_value  # Track losses for each window length\n",
    "    window_counts = torch.zeros(max_window - min_window + 1, device=device)  # Track counts for each window length\n",
    "    loss_deques = [deque(maxlen=moving_avg_window) for _ in range(max_window - min_window + 1)]  # Deques for moving average\n",
    "    if windowed_mode and window_mode == \"biased_loss\":\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 12))\n",
    "    else:\n",
    "        fig, ax1 = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    epoch_loss_list = []\n",
    "    val_loss = 0\n",
    "\n",
    "    total_time_start = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Annealing for the learning rate\n",
    "        if annealing_mode and epoch > annealing_window:\n",
    "            if len(epoch_loss_list) > 0 and epoch_loss_list[-1] >= annealing_multiplier * (statistics.mean(epoch_loss_list[-annealing_window:])):\n",
    "                for g in optimizer.param_groups:\n",
    "                    if g['lr'] * annealing_ratio < annealing_minimum:\n",
    "                        g['lr'] = annealing_minimum\n",
    "                    else:\n",
    "                        g['lr'] *= annealing_ratio\n",
    "\n",
    "        start = time.time()\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            \n",
    "            batch = batch.to(device)\n",
    "\n",
    "            if batch_embedder is not None:\n",
    "                batch = batch_embedder(batch)\n",
    "\n",
    "            batch_length = batch.shape[1]\n",
    "\n",
    "            # Windowed mode logic\n",
    "            if windowed_mode:\n",
    "                if batch_length < min_window:\n",
    "                    continue\n",
    "                if window_start_mode == \"random\":\n",
    "                    cut_start = torch.randint(0, batch_length - window_length + 1, (1,)).item()\n",
    "                elif window_start_mode == \"fixed\":\n",
    "                    cut_start = 0\n",
    "                if window_mode == \"uniform\":\n",
    "                    while True:\n",
    "                        window_length = torch.randint(min_window, batch_length + 1, (1,)).item()\n",
    "                        cut_end = cut_start + window_length\n",
    "                        if min_window <= (cut_end - cut_start) <= batch_length:\n",
    "                            break\n",
    "                    batch = batch[:, cut_start:cut_end, :]\n",
    "\n",
    "                elif window_mode == \"negative_binomial\":\n",
    "                    total_count = 1\n",
    "                    probs = neg_bin_p\n",
    "                    distribution = torch.distributions.NegativeBinomial(total_count=total_count, probs=probs)\n",
    "                    while True:\n",
    "                        window_length = distribution.sample().item() + min_window\n",
    "                        cut_end = cut_start + window_length\n",
    "                        if min_window <= window_length <= batch_length:\n",
    "                            break\n",
    "                    batch = batch[:, cut_start:cut_end, :]\n",
    "\n",
    "                elif window_mode == \"biased_loss\":\n",
    "                    if torch.min(window_counts) < 2:\n",
    "                        # Use uniform distribution until each length has been used at least twice\n",
    "                        window_probs = torch.ones_like(window_losses) / len(window_losses)\n",
    "                    elif torch.sum(window_counts) % train_on_all_every == 0:\n",
    "                        window_probs = torch.ones_like(window_losses) / len(window_losses)\n",
    "                    else:\n",
    "                        # Update probabilities based on moving average of losses\n",
    "                        avg_losses = torch.tensor([np.mean(loss_deque) if len(loss_deque) > 0 else initial_value for loss_deque in loss_deques], device=device)\n",
    "                        window_probs = avg_losses / avg_losses.sum()\n",
    "                    while True:\n",
    "                        window_length = torch.multinomial(window_probs, 1).item() + min_window\n",
    "                        #check if the window length does work with the batch length\n",
    "                        if window_length > batch_length:\n",
    "                            continue\n",
    "                        cut_end = cut_start + window_length\n",
    "                        if min_window <= window_length <= batch_length:\n",
    "                            break\n",
    "                    batch = batch[:, cut_start:cut_end, :]\n",
    "                    window_counts[window_length - min_window] += 1  # Update window counts\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predicted_noise, noise, noise_mask = model(batch)\n",
    "            loss = loss_func(predicted_noise, noise, noise_mask)\n",
    "            loss.backward()\n",
    "            # # Gradient clipping\n",
    "            if gradient_clip is not None:\n",
    "                max_grad_norm = gradient_clip\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "                if batch_embedder is not None:\n",
    "                    torch.nn.utils.clip_grad_norm_(batch_embedder.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "            epoch_loss = sum(loss_list[-len(data_loader):]) / len(data_loader)\n",
    "            epoch_loss_list.append(epoch_loss)\n",
    "            \n",
    "            # Update window losses and moving average deque\n",
    "            if windowed_mode and window_mode == \"biased_loss\":\n",
    "                window_idx = window_length - min_window\n",
    "                window_losses[window_idx] += loss.item()\n",
    "                loss_deques[window_idx].append(loss.item())\n",
    "\n",
    "            # Dynamic plot update\n",
    "            if i % plot_every == 0:\n",
    "                ax1.clear()\n",
    "                ax1.set_ylim(0, 1)\n",
    "                ax1.plot(loss_list)\n",
    "                if len(loss_list) > 100:\n",
    "                    ax1.plot(np.convolve(loss_list, np.ones((100,))/100, mode='valid'))\n",
    "                    ax1.text(len(loss_list) - 1, np.convolve(loss_list, np.ones((100,))/100, mode='valid')[-1],\n",
    "                            str(round(np.convolve(loss_list, np.ones((100,))/100, mode='valid')[-1], 3)))\n",
    "                if len(epoch_loss_list) > 0:\n",
    "                    ax1.text(0.1, 0.9, f\"Epoch: {epoch} | Learning rate: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "                # ax1.text(0.1, 0.8, f\"Learning rate: {optimizer.param_groups[0]['lr']:.4e}\")\n",
    "                ax1.text(0.1, 0.8, f\"Loss: {epoch_loss_list[-1]:.3e} | Validation loss: {val_loss:.3e}\")\n",
    "                ax1.text(0.1, 0.7, f\"Time per step: {((time.time() - start) / (i + 1)):.2f} s | Time per epoch: {((time.time() - start) / (i + 1) * len(data_loader)):.2f} s\")\n",
    "                ax1.text(0.1, 0.6, f\"Time till finish (est.): {((time.time() - start) / (i + 1) * len(data_loader) * (epochs - epoch)) / 60:.2f} min\")\n",
    "                if windowed_mode and window_mode == \"biased_loss\":\n",
    "                    ax2.clear()\n",
    "                    ax2.bar(range(min_window, max_window + 1), window_counts.cpu().numpy())\n",
    "                    ax2.set_ylabel(\"Counts\")\n",
    "                    ax2.set_title(\"Counts of Each Window Length Used\")\n",
    "\n",
    "                    moving_avg_losses = torch.tensor([np.mean(loss_deque) if len(loss_deque) > 0 else initial_value for loss_deque in loss_deques], device=device).cpu().numpy()\n",
    "                    ax3.clear()\n",
    "                    ax3.bar(range(min_window, max_window + 1), moving_avg_losses)\n",
    "                    ax3.set_xlabel(\"Window Length\")\n",
    "                    ax3.set_ylabel(\"Moving Average Loss\")\n",
    "                    ax3.set_title(\"Moving Average Loss for Each Window Length\")\n",
    "\n",
    "                display(fig)\n",
    "                clear_output(wait=True)\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        # Validation\n",
    "        if epoch % validation_frequency == 0:\n",
    "            loss_list_validation = []\n",
    "            for i, batch in enumerate(data_loader_validation):\n",
    "                batch = batch.to(device)\n",
    "                if batch_embedder is not None:\n",
    "                    batch = batch_embedder(batch)\n",
    "                if i % validation_prp == 0:\n",
    "                    predicted_noise, noise, noise_mask = model(batch)\n",
    "                    loss = loss_func(predicted_noise, noise, noise_mask)\n",
    "                    loss_list_validation.append(loss.item())\n",
    "\n",
    "            val_loss = np.mean(loss_list_validation)\n",
    "\n",
    "        total_time_end = time.time()\n",
    "        total_time = total_time_end - total_time_start\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch} completed in {end - start} seconds, Loss: {epoch_loss}\")\n",
    "            print(f\"Validation Loss: {val_loss}\")\n",
    "    \n",
    "    print(f\"Took {total_time} seconds for {epoch} epochs.\")\n",
    "            \n",
    "\n",
    "\n",
    "    return model, loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Sampler\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class CustomTimeSeriesDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, data_tensor, sequence_lengths, min_seq_length=None, max_seq_length=None\n",
    "    ):\n",
    "        # Store the initial sequences and lengths\n",
    "        self.data_tensor = data_tensor\n",
    "        self.sequence_lengths = sequence_lengths\n",
    "        self.min_seq_length = min_seq_length\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "        # Filter sequences based on min and max sequence length\n",
    "        if self.min_seq_length is not None:\n",
    "            valid_indices = [\n",
    "                i\n",
    "                for i, length in enumerate(self.sequence_lengths)\n",
    "                if length >= self.min_seq_length\n",
    "            ]\n",
    "        else:\n",
    "            valid_indices = list(range(len(self.sequence_lengths)))\n",
    "\n",
    "        if self.max_seq_length is not None:\n",
    "            valid_indices = [\n",
    "                i\n",
    "                for i in valid_indices\n",
    "                if self.sequence_lengths[i] <= self.max_seq_length\n",
    "            ]\n",
    "\n",
    "        self.data_tensor = self.data_tensor[valid_indices]\n",
    "        self.sequence_lengths = [self.sequence_lengths[i]\n",
    "                                 for i in valid_indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence_lengths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq_length = int(self.sequence_lengths[idx])\n",
    "        return self.data_tensor[idx, :seq_length, :], seq_length\n",
    "\n",
    "\n",
    "# class CustomTimeSeriesDataset(Dataset):\n",
    "#     def __init__(self, data_tensor, sequence_lengths, min_seq_length=None, max_seq_length=None):\n",
    "#         self.data_tensor = data_tensor\n",
    "#         self.sequence_lengths = sequence_lengths\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.sequence_lengths)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         seq_length = int(self.sequence_lengths[idx])\n",
    "#         return self.data_tensor[idx, :seq_length, :], seq_length\n",
    "\n",
    "\n",
    "class LengthBatchSampler(Sampler):\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        self.sequence_lengths = dataset.sequence_lengths\n",
    "        self.batch_size = batch_size\n",
    "        self.batches = self._create_batches()\n",
    "\n",
    "    def _create_batches(self):\n",
    "        length_to_indices = defaultdict(list)\n",
    "        for idx, length in enumerate(self.sequence_lengths):\n",
    "            length_to_indices[length].append(idx)\n",
    "\n",
    "        batches = []\n",
    "        for length, indices in length_to_indices.items():\n",
    "            # Split indices into batches of the specified batch size\n",
    "            for i in range(0, len(indices), self.batch_size):\n",
    "                batches.append(indices[i: i + self.batch_size])\n",
    "        return batches\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.batches:\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batches)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    data, lengths = zip(*batch)\n",
    "    data = torch.stack(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def create_dataloader(\n",
    "    data_tensor, sequence_lengths, batch_size, min_seq_length=None, max_seq_length=None\n",
    "):\n",
    "    dataset = CustomTimeSeriesDataset(\n",
    "        data_tensor, sequence_lengths, min_seq_length, max_seq_length\n",
    "    )\n",
    "    sampler = LengthBatchSampler(dataset, batch_size)\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_sampler=sampler, collate_fn=collate_fn)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "class BalancedLengthBatchSampler(Sampler):\n",
    "    def __init__(self, dataset, batch_size, balance_factor=1.0):\n",
    "        self.sequence_lengths = dataset.sequence_lengths\n",
    "        self.batch_size = batch_size\n",
    "        self.balance_factor = balance_factor\n",
    "        self.batches = self._create_balanced_batches()\n",
    "\n",
    "    def _create_balanced_batches(self):\n",
    "        # Group indices by sequence length\n",
    "        length_to_indices = defaultdict(list)\n",
    "        for idx, length in enumerate(self.sequence_lengths):\n",
    "            length_to_indices[length].append(idx)\n",
    "\n",
    "        # Calculate the maximum count of indices for balancing\n",
    "        max_count = max(len(indices) for indices in length_to_indices.values())\n",
    "\n",
    "        # Balance the distribution of sequence lengths by oversampling shorter sequences\n",
    "        balanced_batches = []\n",
    "        for length, indices in length_to_indices.items():\n",
    "            count = len(indices)\n",
    "            if count < max_count:\n",
    "                repeat_factor = int(self.balance_factor * (max_count / count))\n",
    "                # Correctly oversample the list elements\n",
    "                oversampled_indices = indices * repeat_factor\n",
    "                # oversampled_indices = oversampled_indices[:max_count]\n",
    "            else:\n",
    "                oversampled_indices = indices\n",
    "\n",
    "            # Shuffle the indices of this particular length\n",
    "            random.shuffle(oversampled_indices)\n",
    "\n",
    "            # Create batches for this length\n",
    "            for i in range(0, len(oversampled_indices), self.batch_size):\n",
    "                batch = oversampled_indices[i: i + self.batch_size]\n",
    "                if len(batch) == self.batch_size:\n",
    "                    balanced_batches.append(batch)\n",
    "\n",
    "        # Shuffle the list of balanced batches to ensure random order\n",
    "        random.shuffle(balanced_batches)\n",
    "\n",
    "        return balanced_batches\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.batches:\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batches)\n",
    "\n",
    "\n",
    "def create_balanced_dataloader(\n",
    "    data_tensor,\n",
    "    sequence_lengths,\n",
    "    batch_size,\n",
    "    balance_factor=1.0,\n",
    "    min_seq_length=None,\n",
    "    max_seq_length=None,\n",
    "):\n",
    "    dataset = CustomTimeSeriesDataset(\n",
    "        data_tensor, sequence_lengths, min_seq_length, max_seq_length\n",
    "    )\n",
    "    sampler = BalancedLengthBatchSampler(dataset, batch_size, balance_factor)\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_sampler=sampler, collate_fn=collate_fn)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5141\n",
      "153\n"
     ]
    }
   ],
   "source": [
    "train_loader = create_balanced_dataloader(\n",
    "    training_data_tensor,\n",
    "    training_data_sequence_lengths,\n",
    "    batch_size=100,\n",
    "    balance_factor=1.0,\n",
    "    min_seq_length=2,\n",
    "    max_seq_length=None,\n",
    ")\n",
    "\n",
    "val_loader = create_balanced_dataloader(\n",
    "    validation_data_tensor,\n",
    "    validation_data_sequence_lengths,\n",
    "    batch_size=100,\n",
    "    balance_factor=1.0,\n",
    "    min_seq_length=2,\n",
    "    max_seq_length=None,\n",
    ")\n",
    "\n",
    "# check the size of the train, val, and test sets\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 60, 4])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_indices_sizes = {\n",
    "#     # 'time_step' : [0, 1],\n",
    "#     \"chemo_application_prev\": [0, 1],\n",
    "#     \"radio_application_prev\": [1, 1],\n",
    "#     \"patient_type_tile\": [2, 1],\n",
    "# }\n",
    "\n",
    "# numerical_indices = {\"cancer_volume\": 3}\n",
    "\n",
    "# numerical_indices = {\n",
    "#     'chemo_application_prev': 0,\n",
    "#     'radio_application_prev': 1,\n",
    "#     'patient_type_tile': 2,\n",
    "#     'cancer_volume': 3\n",
    "# }\n",
    "\n",
    "\n",
    "# training_data_tensor_embedded = data_embedder(training_data_tensor)\n",
    "# validation_data_tensor_embedded = data_embedder(validation_data_tensor)\n",
    "# test_data_factuals_tensor_embedded = data_embedder(test_data_factuals_tensor)\n",
    "# test_data_counterfactuals_tensor_embedded = data_embedder(test_data_counterfactuals_tensor)\n",
    "# test_data_seq_tensor_embedded = data_embedder(test_data_seq_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11296"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_221024/1760555923.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.alpha_torch = torch.tensor(self.alpha).float()\n"
     ]
    }
   ],
   "source": [
    "diffusion_imputer = diffusion_imputation(\n",
    "    emb_dim=128,\n",
    "    # strategy=\"forecasting_last_n_time\",\n",
    "    # strategy=\"random\",\n",
    "    # missing_prp=0.5,\n",
    "    # strategy='selected_features',\n",
    "    strategy=\"selected_features_last_n_time\",\n",
    "    last_n_time=1,\n",
    "    features_to_impute=[0, 1, 2, 3],\n",
    "    # excluded_features = [i for i in range(6)], #[2],#[0,1,2,3,5], #for the embedded stock names which we don't need to predict\n",
    "    # strategy='selected_features_and_selected_features_after_time',\n",
    "    # features_to_impute_completely=[2],\n",
    "    # features_to_impute_after_time=[3],\n",
    "    num_residual_layers=2,\n",
    "    diffusion_steps=50,\n",
    "    diffusion_beta_schedule=\"quadratic\",\n",
    "    num_heads=8,\n",
    "    kernel_size=(1, 1),\n",
    "    ff_dim=512,\n",
    "    num_cells=1,\n",
    "    dropout=0,\n",
    "    # csdi, csdi_moded_transformer, rsa, rsa_moded_transformer, moded_transformer_alone, rsa_csdi\n",
    "    method=\"rsa_moded_transformer\",\n",
    "    device=\"cuda\",\n",
    ")\n",
    "\n",
    "# data_embedder = DataEmbedder(\n",
    "#     categorical_indices_sizes, numerical_indices, training_data_tensor\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiffusion_imputer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_embedder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_clip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindowed_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbiased_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwindow_start_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfixed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_on_all_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m59\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mannealing_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mannealing_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mannealing_multiplier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mannealing_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mannealing_minimum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdiffusion_imputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_prp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[42], line 135\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, data_loader_validation, epochs, lr, loss_func, batch_embedder, gradient_clip, windowed_mode, window_mode, window_start_mode, min_window, max_window, neg_bin_p, train_on_all_every, annealing_mode, annealing_window, annealing_multiplier, annealing_ratio, annealing_minimum, device, num_gpus, verbose, plot_every, validation_frequency, validation_prp, moving_avg_window)\u001b[0m\n\u001b[1;32m    132\u001b[0m         window_counts[window_length \u001b[38;5;241m-\u001b[39m min_window] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Update window counts\u001b[39;00m\n\u001b[1;32m    134\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 135\u001b[0m predicted_noise, noise, noise_mask \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(predicted_noise, noise, noise_mask)\n\u001b[1;32m    137\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_118/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_118/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[40], line 151\u001b[0m, in \u001b[0;36mdiffusion_imputation.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    148\u001b[0m noised_data \u001b[38;5;241m=\u001b[39m noised_data \u001b[38;5;241m+\u001b[39m conditional_data\n\u001b[1;32m    149\u001b[0m noised_data \u001b[38;5;241m=\u001b[39m noised_data\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m--> 151\u001b[0m predicted_noise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnoised_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiffusion_t\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m predicted_noise \u001b[38;5;241m=\u001b[39m predicted_noise \u001b[38;5;241m*\u001b[39m noise_mask\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (predicted_noise, noise, noise_mask)\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_118/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_118/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[38], line 85\u001b[0m, in \u001b[0;36mModelLoop.forward\u001b[0;34m(self, noised_data, noise_mask, diffusion_t)\u001b[0m\n\u001b[1;32m     77\u001b[0m noised_data_embedded \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_embedding_linear(noised_data_reshaped)\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;241m.\u001b[39mreshape(b, t, f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memb_dim)\n\u001b[1;32m     81\u001b[0m )\n\u001b[1;32m     82\u001b[0m diffusion_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiffusion_embedding(\n\u001b[1;32m     83\u001b[0m     diffusion_t, noised_data_embedded, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m     84\u001b[0m )\n\u001b[0;32m---> 85\u001b[0m time_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoised_data_embedded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m feature_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_embedding(\n\u001b[1;32m     87\u001b[0m     noised_data_embedded, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m     88\u001b[0m )\n\u001b[1;32m     90\u001b[0m x \u001b[38;5;241m=\u001b[39m noised_data_embedded\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_118/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_118/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[35], line 55\u001b[0m, in \u001b[0;36mTimeEmbedding.forward\u001b[0;34m(self, data, device)\u001b[0m\n\u001b[1;32m     52\u001b[0m pe \u001b[38;5;241m=\u001b[39m pe\u001b[38;5;241m.\u001b[39mrepeat((b, \u001b[38;5;241m1\u001b[39m, e))\n\u001b[1;32m     53\u001b[0m pe \u001b[38;5;241m=\u001b[39m pe\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 55\u001b[0m pe[:, :, \u001b[38;5;241m0\u001b[39m::\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpe\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m pe[:, :, \u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcos(\n\u001b[1;32m     59\u001b[0m     pe[:, :, \u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_len \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, e, \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m e))\n\u001b[1;32m     60\u001b[0m )\n\u001b[1;32m     62\u001b[0m pe \u001b[38;5;241m=\u001b[39m pe\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, f, \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1200 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(\n",
    "    diffusion_imputer,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    num_gpus=1,\n",
    "    batch_embedder=None,\n",
    "    gradient_clip=None,\n",
    "    windowed_mode=True,\n",
    "    window_mode=\"biased_loss\",\n",
    "    window_start_mode=\"fixed\",\n",
    "    train_on_all_every=100,\n",
    "    min_window=2,\n",
    "    max_window=59,\n",
    "    device=\"cuda\",\n",
    "    epochs=20,\n",
    "    lr=1e-3,\n",
    "    annealing_mode=True,\n",
    "    annealing_window=2,\n",
    "    annealing_multiplier=1.0,\n",
    "    annealing_ratio=0.2,\n",
    "    annealing_minimum=1e-7,\n",
    "    loss_func=diffusion_imputer.loss_func,\n",
    "    validation_frequency=2,\n",
    "    validation_prp=1,\n",
    "    verbose=False,\n",
    "    plot_every=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_hybrid(\n",
    "#     diffusion_imputer,\n",
    "#     hybrid_model,\n",
    "#     train_loader,\n",
    "#     val_loader,\n",
    "#     batch_embedder = embedder,\n",
    "#     epochs = 20,\n",
    "#     lr = 0.001,\n",
    "#     annealing_window = 5,\n",
    "#     annealing_multiplier = 1,\n",
    "#     loss_func = diffusion_imputer.loss_func,\n",
    "#     hybrid_loss_func = hybrid_model.loss_func,\n",
    "#     hybrid_start_epoch = 0,\n",
    "#     hybrid_every_n_epoch = 5,\n",
    "#     validation_frequency=2,\n",
    "#     validation_prp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the entire model for further training\n",
    "# torch.save(diffusion_imputer, \"diffusion_imputer_cancer_aug9.pt\")\n",
    "# torch.save(data_embedder, \"data_embedder_cancer_aug9.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def calculate_quantiles(imputed_samples_tensor, qlist):\n",
    "    quantiles_imp = []\n",
    "    for q in qlist:\n",
    "        quantiles = torch.quantile(\n",
    "            imputed_samples_tensor, q, dim=0, interpolation=\"midpoint\"\n",
    "        )\n",
    "        quantiles_imp.append(quantiles)\n",
    "    return torch.stack(quantiles_imp, dim=0)\n",
    "\n",
    "\n",
    "# Calculate RMSE with denormalization\n",
    "\n",
    "\n",
    "def calculate_rmse(\n",
    "    final_samples, training_mean, training_std, qlist=[\n",
    "        0.05, 0.25, 0.50, 0.75, 0.95]\n",
    "):\n",
    "    all_data = []\n",
    "    all_imputed = []\n",
    "    imputed_samples_list = []\n",
    "    actual_data_list = []\n",
    "\n",
    "    # Extract one instance of the actual data and imputation mask\n",
    "    data_instance, imputation_mask_instance = None, None\n",
    "    sample_number = len(final_samples)\n",
    "\n",
    "    for sample in final_samples:\n",
    "        for imputed_samples, data, imputation_mask, _ in sample:\n",
    "            # Store imputed samples for quantile calculation\n",
    "            imputed_samples_list.append(\n",
    "                imputed_samples[imputation_mask != 0].cpu())\n",
    "            actual_data_list.append(data[imputation_mask != 0].cpu())\n",
    "            # Flatten the tensors and filter non-zero mask areas\n",
    "            all_data.append(data[imputation_mask != 0].cpu())\n",
    "            all_imputed.append(imputed_samples[imputation_mask != 0].cpu())\n",
    "\n",
    "    # Concatenate all filtered elements\n",
    "    all_data = torch.cat(all_data)\n",
    "    all_imputed = torch.cat(all_imputed)\n",
    "\n",
    "    # Concatenate all imputed samples and reshape to original dimensions\n",
    "    imputed_samples_tensor = torch.cat(\n",
    "        imputed_samples_list).reshape(sample_number, -1)\n",
    "\n",
    "    # Concatenate all actual data and reshape to original dimensions\n",
    "    actual_data_tensor = torch.cat(actual_data_list).reshape(sample_number, -1)\n",
    "    actual_data_tensor = actual_data_tensor[0]\n",
    "\n",
    "    # Denormalize the data\n",
    "    all_data = all_data * training_std + training_mean\n",
    "    all_imputed = all_imputed * training_std + training_mean\n",
    "\n",
    "    # Calculate RMSE for all imputed values\n",
    "    rmse = torch.sqrt(torch.mean((all_data - all_imputed) ** 2)).item()\n",
    "    rmse = rmse / 1150 * 100  # Adjust the RMSE as per your requirement\n",
    "\n",
    "    # Calculate quantiles\n",
    "    quantiles_imp = calculate_quantiles(imputed_samples_tensor, qlist)\n",
    "    medians = quantiles_imp[qlist.index(0.50)]  # Median is the 50th percentile\n",
    "\n",
    "    # Denormalize the medians\n",
    "    medians = medians * training_std + training_mean\n",
    "\n",
    "    # Use the median for the new RMSE calculation\n",
    "    actual_data_tensor = actual_data_tensor * training_std + training_mean\n",
    "\n",
    "    # Calculate RMSE with medians\n",
    "    rmse_median = torch.sqrt(torch.mean(\n",
    "        (actual_data_tensor - medians) ** 2)).item()\n",
    "    # Adjust the RMSE as per your requirement\n",
    "    rmse_median = rmse_median / 1150 * 100\n",
    "\n",
    "    return rmse, rmse_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple_evaluations(\n",
    "    dataloader,\n",
    "    imputer,\n",
    "    training_mean,\n",
    "    training_std,\n",
    "    sample_number,\n",
    "    batch_embedder=None,\n",
    "    old_sample=[],\n",
    "    min_sequence_len=2,\n",
    "    max_sequence_len=None,\n",
    "    scale=1,\n",
    "    verbose=True,\n",
    "    show_max_diff=False,\n",
    "    show_rmse=False,\n",
    "):\n",
    "    final_samples = old_sample\n",
    "    max_seq_len = 0\n",
    "    total_batches = len(dataloader) * sample_number\n",
    "    completed_batches = 0\n",
    "    sample_time = []\n",
    "    average_sample_time = 0\n",
    "\n",
    "    for i in range(sample_number):\n",
    "        sample_start = time.time()\n",
    "        # print a line to separate the samples\n",
    "        print(\"-------------------------------------------------\")\n",
    "        print(f\"Running sample {i + 1}/{sample_number}\")\n",
    "        all_samples = []\n",
    "        for batch_idx, data_batch in enumerate(dataloader):\n",
    "            # Get the data from the batch (collate_fn returns a tuple)\n",
    "            data_batch = data_batch.to(imputer.device)\n",
    "            if batch_embedder is not None:\n",
    "                data_batch = batch_embedder(data_batch)\n",
    "            seq_length = data_batch.shape[1]\n",
    "            if seq_length < min_sequence_len:\n",
    "                # print(f\"Skipping batch {batch_idx + 1} as sequence length is less than {min_sequence_len}\")\n",
    "                completed_batches += 1\n",
    "                continue\n",
    "            if max_sequence_len is not None and seq_length > max_sequence_len:\n",
    "                # print(f\"Skipping batch {batch_idx + 1} as sequence length is greater than {max_sequence_len}\")\n",
    "                completed_batches += 1\n",
    "                continue\n",
    "\n",
    "            print(f\"sequence length: {seq_length}\")\n",
    "\n",
    "            # Generate imputation masks for the current batch\n",
    "            imputation_masks = imputer.get_mask(\n",
    "                data_batch, strategy=\"selected_features_last_n_time\"\n",
    "            ).to(imputer.device)\n",
    "\n",
    "            imputed_samples = imputer.eval(\n",
    "                data_batch,\n",
    "                imputation_masks,\n",
    "                mean=training_mean,\n",
    "                std=training_std,\n",
    "                scale=scale,\n",
    "                verbose=verbose,\n",
    "                show_max_diff=show_max_diff,\n",
    "                show_rmse=show_rmse,\n",
    "            )\n",
    "\n",
    "            all_samples.append(imputed_samples)\n",
    "\n",
    "            completed_batches += 1\n",
    "            progress = completed_batches / total_batches\n",
    "            print(f\"Overall Progress: {progress * 100:.2f}%\")\n",
    "            print(\n",
    "                f\"Time to finish (est.): {average_sample_time * (sample_number - i - 1) / 60:.2f} min\"\n",
    "            )\n",
    "\n",
    "        sample_end = time.time()\n",
    "        sample_time.append(sample_end - sample_start)\n",
    "        average_sample_time = sum(sample_time) / len(sample_time)\n",
    "        final_samples.append(all_samples)\n",
    "\n",
    "        rmse, rmse_median = calculate_rmse(\n",
    "            final_samples, training_mean, training_std)\n",
    "        print(f\"RMSE: {rmse:.3f} | RMSE (Median): {rmse_median:.3f}\")\n",
    "\n",
    "    return final_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffusion_imputer = torch.load(\"diffusion_imputer_cancer_jul23.pt\")\n",
    "# data_embedder = torch.load(\"data_embedder_cancer_jul23.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in test loader: 1\n"
     ]
    }
   ],
   "source": [
    "test_loader = create_dataloader(\n",
    "    test_data_counterfactuals_tensor,\n",
    "    test_data_counterfactuals_sequence_lengths,\n",
    "    batch_size=10000,\n",
    "    min_seq_length=20,\n",
    "    max_seq_length=20,\n",
    ")\n",
    "\n",
    "print(f\"Number of batches in test loader: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_imputer.features_to_impute = [3]\n",
    "diffusion_imputer.last_n_time = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(39.31261593724658)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "np.float64(11.007834958263928)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_standard_deviation = stds[\"cancer_volume\"]\n",
    "training_mean = means[\"cancer_volume\"]\n",
    "\n",
    "training_standard_deviation\n",
    "training_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38029"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change working directory\n",
    "# os.chdir(\"/work/postresearch/Shared/Researchers/Farbod/cancer/\")\n",
    "# sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "Running sample 1/20\n",
      "sequence length: 20\n",
      "mae =  1.1894255876541138\n",
      "Overall Progress: 5.00%\n",
      "Time to finish (est.): 0.00 min\n",
      "RMSE: 11.481 | RMSE (Median): 11.481\n",
      "-------------------------------------------------\n",
      "Running sample 2/20\n",
      "sequence length: 20\n",
      "mae =  1.2223831415176392\n",
      "Overall Progress: 10.00%\n",
      "Time to finish (est.): 1.63 min\n",
      "RMSE: 11.630 | RMSE (Median): 11.176\n",
      "-------------------------------------------------\n",
      "Running sample 3/20\n",
      "sequence length: 20\n",
      "mae =  1.2284389734268188\n",
      "Overall Progress: 15.00%\n",
      "Time to finish (est.): 1.53 min\n",
      "RMSE: 11.678 | RMSE (Median): 10.971\n",
      "-------------------------------------------------\n",
      "Running sample 4/20\n",
      "sequence length: 20\n",
      "mae =  1.1940314769744873\n",
      "Overall Progress: 20.00%\n",
      "Time to finish (est.): 1.44 min\n",
      "RMSE: 11.613 | RMSE (Median): 10.941\n",
      "-------------------------------------------------\n",
      "Running sample 5/20\n",
      "sequence length: 20\n",
      "mae =  1.1930040121078491\n",
      "Overall Progress: 25.00%\n",
      "Time to finish (est.): 1.34 min\n",
      "RMSE: 11.592 | RMSE (Median): 10.958\n",
      "-------------------------------------------------\n",
      "Running sample 6/20\n",
      "sequence length: 20\n",
      "mae =  1.2393673658370972\n",
      "Overall Progress: 30.00%\n",
      "Time to finish (est.): 1.22 min\n",
      "RMSE: 11.841 | RMSE (Median): 10.985\n",
      "-------------------------------------------------\n",
      "Running sample 7/20\n",
      "sequence length: 20\n",
      "mae =  1.1996549367904663\n",
      "Overall Progress: 35.00%\n",
      "Time to finish (est.): 1.13 min\n",
      "RMSE: 11.813 | RMSE (Median): 10.989\n",
      "-------------------------------------------------\n",
      "Running sample 8/20\n",
      "sequence length: 20\n",
      "mae =  1.198791742324829\n",
      "Overall Progress: 40.00%\n",
      "Time to finish (est.): 1.05 min\n",
      "RMSE: 11.776 | RMSE (Median): 10.975\n",
      "-------------------------------------------------\n",
      "Running sample 9/20\n",
      "sequence length: 20\n",
      "mae =  1.216241717338562\n",
      "Overall Progress: 45.00%\n",
      "Time to finish (est.): 0.96 min\n",
      "RMSE: 11.762 | RMSE (Median): 10.991\n",
      "-------------------------------------------------\n",
      "Running sample 10/20\n",
      "sequence length: 20\n",
      "mae =  1.2087881565093994\n",
      "Overall Progress: 50.00%\n",
      "Time to finish (est.): 0.87 min\n",
      "RMSE: 11.742 | RMSE (Median): 10.989\n",
      "-------------------------------------------------\n",
      "Running sample 11/20\n",
      "sequence length: 20\n",
      "mae =  1.2027925252914429\n",
      "Overall Progress: 55.00%\n",
      "Time to finish (est.): 0.77 min\n",
      "RMSE: 11.746 | RMSE (Median): 11.020\n",
      "-------------------------------------------------\n",
      "Running sample 12/20\n",
      "sequence length: 20\n",
      "mae =  1.227161169052124\n",
      "Overall Progress: 60.00%\n",
      "Time to finish (est.): 0.68 min\n",
      "RMSE: 11.748 | RMSE (Median): 11.018\n",
      "-------------------------------------------------\n",
      "Running sample 13/20\n",
      "sequence length: 20\n",
      "mae =  1.237348198890686\n",
      "Overall Progress: 65.00%\n",
      "Time to finish (est.): 0.59 min\n",
      "RMSE: 11.811 | RMSE (Median): 11.011\n",
      "-------------------------------------------------\n",
      "Running sample 14/20\n",
      "sequence length: 20\n",
      "mae =  1.281772494316101\n",
      "Overall Progress: 70.00%\n",
      "Time to finish (est.): 0.50 min\n",
      "RMSE: 12.054 | RMSE (Median): 11.010\n",
      "-------------------------------------------------\n",
      "Running sample 15/20\n",
      "sequence length: 20\n",
      "mae =  1.2117236852645874\n",
      "Overall Progress: 75.00%\n",
      "Time to finish (est.): 0.41 min\n",
      "RMSE: 12.027 | RMSE (Median): 11.015\n",
      "-------------------------------------------------\n",
      "Running sample 16/20\n",
      "sequence length: 20\n",
      "mae =  1.2350832223892212\n",
      "Overall Progress: 80.00%\n",
      "Time to finish (est.): 0.33 min\n",
      "RMSE: 12.024 | RMSE (Median): 11.014\n",
      "-------------------------------------------------\n",
      "Running sample 17/20\n",
      "sequence length: 20\n",
      "mae =  1.2041864395141602\n",
      "Overall Progress: 85.00%\n",
      "Time to finish (est.): 0.24 min\n",
      "RMSE: 12.003 | RMSE (Median): 11.013\n",
      "-------------------------------------------------\n",
      "Running sample 18/20\n",
      "sequence length: 20\n",
      "mae =  1.2333694696426392\n",
      "Overall Progress: 90.00%\n",
      "Time to finish (est.): 0.16 min\n",
      "RMSE: 11.987 | RMSE (Median): 10.998\n",
      "-------------------------------------------------\n",
      "Running sample 19/20\n",
      "sequence length: 20\n",
      "mae =  1.237273097038269\n",
      "Overall Progress: 95.00%\n",
      "Time to finish (est.): 0.08 min\n",
      "RMSE: 11.984 | RMSE (Median): 10.988\n",
      "-------------------------------------------------\n",
      "Running sample 20/20\n",
      "sequence length: 20\n",
      "mae =  1.2369639873504639\n",
      "Overall Progress: 100.00%\n",
      "Time to finish (est.): 0.00 min\n",
      "RMSE: 11.985 | RMSE (Median): 10.984\n"
     ]
    }
   ],
   "source": [
    "sample_number = 20\n",
    "final_samples = run_multiple_evaluations(\n",
    "    dataloader=test_loader,\n",
    "    imputer=diffusion_imputer,\n",
    "    batch_embedder=None,\n",
    "    training_mean=training_mean,\n",
    "    training_std=training_standard_deviation,\n",
    "    old_sample=[],  # final_samples,\n",
    "    # min_sequence_len=2,\n",
    "    # max_sequence_len=2,\n",
    "    sample_number=sample_number,\n",
    "    scale=1,\n",
    ")\n",
    "\n",
    "# Set the start method to 'spawn' for the notebook environment\n",
    "\n",
    "# from custom_classes_and_functions import * #wrapper_run_multiple_evaluations, create_dataloader, load_diffusion_imputer, diffusion_imputation, ModelLoop, DiffusionEmbedding, TimeEmbedding\n",
    "\n",
    "# import numpy as np\n",
    "# os.environ['MKL_THREADING_LAYER'] = 'GNU'\n",
    "\n",
    "# import multiprocessing as mp\n",
    "# mp.set_start_method('spawn', force=True)\n",
    "\n",
    "# import os\n",
    "# import sys\n",
    "\n",
    "# # Ensure the current directory is in sys.path\n",
    "\n",
    "# # Define your dataloader\n",
    "# test_loader = create_dataloader(\n",
    "#     test_data_counterfactuals_tensor, test_data_counterfactuals_sequence_lengths, batch_size=10000, min_seq_length=2, max_seq_length=2)\n",
    "\n",
    "# diffusion_imputer = load_diffusion_imputer(\"diffusion_imputer_cancer_jul23.pt\")\n",
    "\n",
    "# # Assuming other necessary objects are defined (`diffusion_imputer`, `training_mean`, `training_standard_deviation`)\n",
    "# if __name__ == \"__main__\":\n",
    "#     diffusion_imputer =  diffusion_imputer # Initialize your imputer with appropriate parameters\n",
    "#     final_samples = wrapper_run_multiple_evaluations(\n",
    "#         dataloader=test_loader,\n",
    "#         imputer=diffusion_imputer,\n",
    "#         training_mean=training_mean,\n",
    "#         training_std=training_standard_deviation,\n",
    "#         sample_number=6,\n",
    "#         num_gpus=3\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final samples\n",
    "# torch.save(final_samples, \"final_samples_cancer_jul23.pt\")\n",
    "# final_samples = torch.load(\"final_samples_cancer_jul20.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 20.37842858355978\n",
      "RMSE using median: 6.875697260317596\n"
     ]
    }
   ],
   "source": [
    "# Calculate RMSE\n",
    "rmse, rmse_median = calculate_rmse(\n",
    "    final_samples, training_mean, training_standard_deviation\n",
    ")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"RMSE using median: {rmse_median}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def quantile_loss(target, forecast, q: float, eval_points) -> float:\n",
    "#     return 2 * torch.sum(\n",
    "#         torch.abs((forecast - target) * eval_points * ((target <= forecast) * 1.0 - q))\n",
    "#     )\n",
    "\n",
    "\n",
    "# def calc_denominator(target, eval_points):\n",
    "#     return torch.sum(torch.abs(target * eval_points))\n",
    "\n",
    "\n",
    "# def calc_quantile_CRPS(target, forecast, eval_points, mean_scaler, scaler):\n",
    "#     target = target * scaler + mean_scaler\n",
    "#     forecast = forecast * scaler + mean_scaler\n",
    "\n",
    "#     quantiles = np.arange(0.05, 1.0, 0.05)\n",
    "#     denom = calc_denominator(target, eval_points)\n",
    "#     CRPS = 0\n",
    "#     for i in range(len(quantiles)):\n",
    "#         q_pred = []\n",
    "#         for j in range(len(forecast)):\n",
    "#             q_pred.append(torch.quantile(forecast[j : j + 1], quantiles[i], dim=1))\n",
    "#         q_pred = torch.cat(q_pred, 0)\n",
    "#         q_loss = quantile_loss(target, q_pred, quantiles[i], eval_points)\n",
    "#         CRPS += q_loss / denom\n",
    "#     return CRPS.item() / len(quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_number = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_target = samples[0][1]  # input_data same for all samples (B, L, K)\n",
    "# all_generated_samples = torch.stack([samples[i][0] for i in range(sample_number)]).permute(1,0,2,3)  # (B, sample_num, L, K)\n",
    "# all_evalpoint = samples[0][2]  # mask same for all samples (B, L, K)\n",
    "# CRPS = calc_quantile_CRPS(all_target, all_generated_samples, all_evalpoint, training_mean, training_standard_deviation)\n",
    "# print(CRPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"last_expr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L = test_data.shape[1]\n",
    "# K = test_data.shape[2]\n",
    "\n",
    "# dataind = 40  # Number of samples to visualize\n",
    "# start_time = 40\n",
    "# n_skip = 0  # Number of columns to skip\n",
    "\n",
    "# plt.rcParams[\"font.size\"] = 16\n",
    "# fig, axes = plt.subplots(nrows=dataind, ncols=K - n_skip, figsize=(24.0, 6 * dataind))\n",
    "\n",
    "# for i in range(dataind):\n",
    "#     for k in range(n_skip, K):  # Start from n_skip instead of 0\n",
    "#         df = pd.DataFrame({\n",
    "#             \"x\": np.arange(start_time, L),\n",
    "#             \"val\": denormed_data[i, start_time:, k],\n",
    "#             \"y\": eval_points[i, start_time:, k]\n",
    "#         })\n",
    "#         df = df[df.y != 0]\n",
    "#         df2 = pd.DataFrame({\n",
    "#             \"x\": np.arange(start_time, L),\n",
    "#             \"val\": denormed_data[i, start_time:, k],\n",
    "#             \"y\": given_points[i, start_time:, k]\n",
    "#         })\n",
    "#         df2 = df2[df2.y != 0]\n",
    "#         indices = df.x.astype(int).to_numpy()\n",
    "#         row = i\n",
    "#         col = k - n_skip  # Adjust column index for skipped columns\n",
    "\n",
    "#         axes[row][col].plot(range(start_time, L), quantiles_imp[2][i, start_time:, k], color='g', linestyle='solid', label='median')\n",
    "#         axes[row][col].fill_between(range(start_time, L), quantiles_imp[0][i, start_time:, k], quantiles_imp[4][i, start_time:, k], color='g', alpha=0.3)\n",
    "#         axes[row][col].plot(df.x, df.val, color='b', marker='o', linestyle='None')\n",
    "#         axes[row][col].plot(df.x, quantiles_imp[5][i, indices, k], color='r', linestyle='None', label='median', marker='x')\n",
    "#         axes[row][col].plot(df.x, quantiles_imp[0][i, indices, k], color='r', linestyle='None', marker=1)\n",
    "#         axes[row][col].plot(df.x, quantiles_imp[4][i, indices, k], color='r', linestyle='None', marker=1)\n",
    "\n",
    "#         if col == 0:  # Only label the first of the remaining columns\n",
    "#             axes[row][col].set_ylabel('Value')\n",
    "#         if row == dataind - 1:  # Only label the last row\n",
    "#             axes[row][col].set_xlabel('Time')\n",
    "\n",
    "# # Optional: Adjust the layout for better spacing\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_old",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
