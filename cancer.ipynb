{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "import enum\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "import zipfile\n",
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import copy\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from einops import rearrange, reduce, repeat\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n",
      "11.8\n"
     ]
    }
   ],
   "source": [
    "# show pytorch version and cuda version\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "\n",
    "# #show if metal is available\n",
    "# if torch.backends.mps.is_available():\n",
    "#     mps_device = torch.device(\"mps\")\n",
    "#     x = torch.ones(1, device=mps_device)\n",
    "#     print (x)\n",
    "# else:\n",
    "#     print (\"MPS device not found.\")\n",
    "    \n",
    "# # show python version\n",
    "# !python -V\n",
    "\n",
    "# torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collecting and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/alinezhad.f'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change working directory\n",
    "os.chdir('/work/postresearch/Shared/Researchers/Farbod/cancer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cancer data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read from pickle file\n",
    "training_data = pd.read_pickle('training_data.pkl')\n",
    "validation_data = pd.read_pickle('validation_data.pkl')\n",
    "\n",
    "test_data_factuals = pd.read_pickle('test_data_factuals.pkl')\n",
    "#:return: simulated data dict with number of rows equal to num_patients * seq_length * num_treatments\n",
    "test_data_counterfactuals = pd.read_pickle('test_data_counterfactuals.pkl')\n",
    "#:return: simulated data dict with number of rows equal to num_patients * seq_length * 2 * projection_horizon\n",
    "test_data_seq = pd.read_pickle('test_data_seq.pkl')\n",
    "means = pd.read_pickle('means.pkl')\n",
    "stds = pd.read_pickle('stds.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale the data\n",
    "for key in training_data.keys():\n",
    "    if key in means.keys():\n",
    "        training_data[key] = (training_data[key] - means[key]) / stds[key]\n",
    "        validation_data[key] = (validation_data[key] - means[key]) / stds[key]\n",
    "        test_data_factuals[key] = (test_data_factuals[key] - means[key]) / stds[key]\n",
    "\n",
    "for key in test_data_counterfactuals.keys():\n",
    "    if key in means.keys():\n",
    "        test_data_counterfactuals[key] = (test_data_counterfactuals[key] - means[key]) / stds[key]\n",
    "        test_data_seq[key] = (test_data_seq[key] - means[key]) / stds[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkoAAAGiCAYAAAAY3OnrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAADCN0lEQVR4nOydd5hU1f3/33f6LttYYNmlgwVYkBKwgA2j4hcVNTGJSYwticbYYogakRSTPLqaGH8kIWIssQTbN1/UaKzECKiASrOB2GiuLEjbPvXe3x+3zL0zt5xzy8ydnfN6nnlm9s4tZ8/ce87nfConCIIABoPBYDAYDEYegWI3gMFgMBgMBsOvMEGJwWAwGAwGwwAmKDEYDAaDwWAYwAQlBoPBYDAYDAOYoMRgMBgMBoNhABOUGAwGg8FgMAxgghKDwWAwGAyGAUxQYjAYDAaDwTCACUoMBoPBYDAYBjBBicFgMBgMBsMAJigxGAwGg8EoOIsXL8akSZNQU1ODmpoazJgxAy+88ILh/suXLwfHcXmvDz/80NN2hjw9O4PBYDAYDIYOw4YNw2233YZDDz0UAPDQQw/h7LPPxoYNGzBhwgTD47Zs2YKamhrl70GDBnnaTo4VxWUwGAwGg+EH6uvr8Yc//AE/+MEP8r5bvnw5TjrpJBw4cAB1dXUFa5PvNErpdBobNmzA4MGDEQgwyyCDwWAwGKUAz/PYsWMHmpubEQplxYtoNIpoNGp6bCaTwT//+U90d3djxowZpvtOnToV8Xgczc3N+MUvfoGTTjrJlfYbIviMt956SwDAXuzFXuzFXuzFXn3g9etf/9pwzn/33XeFfv36CcFgUKitrRWee+45w30//PBD4Z577hHWrVsnrFq1Svjxj38scBwnrFixwgNpJIvvTG87duzAyJEj8dZbb6GpqanYzWEwGAwGg0HArl27cNRRR+H999/H8OHDle1mGqVkMokdO3bg4MGDWLp0Ke677z6sWLECzc3NRNecO3cuOI7DM88848r/oIfvTG+yua2pqQnDhg0rcmsYDAaDwWDQUFtbq3G2NiMSiSjO3NOnT8fbb7+NP/3pT/jb3/5GdPwxxxyDJUuW2G4rCcwJiMFgMBgMhi8QBAGJRIJ4/w0bNnhuffKdRonBYDAYDEbf56abbsKcOXMwfPhwdHZ24vHHH8fy5cvx4osvAgDmz5+P1tZWPPzwwwCAhQsXYtSoUZgwYQKSySSWLFmCpUuXYunSpZ62kwlKDAaDwWAwCs7u3btxwQUXYNeuXaitrcWkSZPw4osv4tRTTwUg+jzt2LFD2T+ZTOK6665Da2srKioqMGHCBDz33HM4/fTTPW2n75y5P//8cwwfPhw7d+5kPkoMBoNRIgiCgHQ6jUwmU+ymMDwkGAwiFAqB47i87/rq/M00SgwGg8FwRDKZxK5du9DT01PspjAKQGVlJZqamhCJRIrdlILABCUGg8Fg2IbneWzduhXBYBBDhgxBJBLR1TYwSh9BEJBMJvHll19i69atOOyww8oiMTQTlBgMBoNhm2QyCZ7nMXz4cFRWVha7OQyPqaioQDgcxvbt25FMJhGLxYrdJM/p+6Igg8FgMDynHDQLDJFy+63L679lMBgMBoPBoIAJSgwGg8FgMBgGMEGJwWAwGAwLLrjgAtx6662m+/z73//G1KlTwfN8gVrFKARMUGIwGAxGWXLxxReD4zjcdtttmu1PP/20JnLv3XffxXPPPYerr75a2TZq1CgsXLhQc9yZZ54JjuPw6KOPetpuRmFhgpJEMs3jgTe2YuvebvdPnuoFVv8VaP/c/XMzGAwGwzaxWAy33347Dhw4YLjPokWL8M1vfhPV1dWW57vkkkvwl7/8xc0mMooME5Qk7l7xKX7z7Cb88eUt7p985R+Al24CXrvT/XMzGAyGzxAEAT3JdFFetMUmTjnlFDQ2NqKlpUX3e57n8c9//hNnnXWWsm3WrFnYvn07fvrTn4LjOI326ayzzsJbb72Fzz77zF7nMXwHy6MEUZv0jzXbAQAHepLunlwQgPf+T/zcvcfdczMYDIYP6U1l0Pyrl4py7U2/PQ2VEfKpLRgM4tZbb8V3v/tdXHPNNXmlN959910cPHgQ06dPV7Y9+eSTmDx5Mi677DJceumlmv1HjhyJhoYGvPbaaxgzZoyzf4bhC5hGCcDz7+3Cl50JAEAi5bIT3hfrgYOiEIakB2Y9BoPBYDjia1/7GqZMmYJf//rXed9t27YNwWAQDQ0Nyrb6+noEg0FUV1ejsbERjY2NmmOGDh2Kbdu2ed1sRoEoe42SIAh44I2tyt+JtMuC0vtPZj8nWR0kBoPR96kIB7Hpt6cV7dp2uP322/HVr34VP/vZzzTbe3t7EY1GqcqyVFRUsLp3fYiyF5TW7ziIdz5vV/5OpF2sfM3zwAdPZ/9mGiUGg1EGcBxHZf7yAyeccAJOO+003HTTTbj44ouV7QMHDkRPTw+SySRxEdj9+/dj0KBBHrWUUWjK3vQma5MOGdQPgMsapc/fAjpUkW7JLvfOzWAwGAxXue222/Dss89i1apVyrYpU6YAADZt2qTZNxKJIJPJX1jH43F8+umnmDp1qqdtZRSOshaUdrX34oX32wAAPzrhEAAu+yjJZrfBE8X3FFPFMhgMhl854ogjcP7552vC+wcNGoSvfOUreP311zX7jho1CitXrkRrayv27t2rbF+zZg2i0ShmzJhRsHYzvKWsBaV/rN6ODC/gqNH1mDqiDoCLpjc+A2x6Wvw89QLxnZneGAwGw9f87ne/y0sxcNlll+GRRx7RbPvtb3+Lbdu24ZBDDtGY2R577DGcf/75qKysLEh7Gd5TtoJSPJXBY2/tAAB8/9hRiIZEB0DXTG/b3wC6dgOxOmD8meK2ZLeYLoDBYDAYRefBBx/E008/rdk2cuRIxONxjbB00UUX4YsvvsDq1auVbccccwzeeecdzb5ffvkl/u///g8///nPC9J+RmEoW0Hp6Q2tONCTwtC6Cpza3IhoWOwK1wQl2ew2fq4oLAEABDFLN4PBYDBKhlgshocfflhjYtNj69atuOuuuzB69OgCtYxRCKgFpZUrV2Lu3LkYMmQIOI7Lk8bV/OhHPwLHcXn1cIqNIAh4cNU2AMBFM0ciGOAQDYldkeEFpDMOhaVMCtj8jPh54teBsEoFy8xvDAaDUXKceOKJmDt3ruk+Rx11FM4777wCtYhRKKgFpe7ubkyePBmLFi0y3e/pp5/Gm2++iSFDhthunFes/mwfPmzrREU4iPOmjwAAxfQGuKBV2roC6NkHVA4ERp0ABAJZYYlFvjEYDAaDUTJQJ7qYM2cO5syZY7pPa2srrrrqKrz00ks444wzbDfOKx54YxsA4NxpQ1FbGQYAREJZmTGZ5tEv6uAC7z8lvjefDQSlLo70E6PeWOQbg8FgMBglg+sZwXiexwUXXIDrr78eEyZMsNw/kUggkUgof3d2drrdJA079vXgP5t3AwAunpm1IwcDHMJBDqmM4EyjlE4AHz4rfp54bna7olFipjcGg8FgMEoF1525b7/9doRCIVxzzTVE+7e0tKC2tlZ5NTc3u90kDQ+t3gZBAE44fBAObajSfJeNfHOQIuDT/wLxdqC6CRihyqMRka7FTG8MBoPBYJQMrgpK69atw5/+9Cc8+OCDxHVx5s+fj/b2duWVm/3UTboSafzv2zsBAJccOyrve9mh25FGSY52az5H9E2SiYiZv1m9NwaDwWAwSgdXBaXXXnsNe/bswYgRIxAKhRAKhbB9+3b87Gc/w6hRo3SPiUajqKmpUV7V1dVuNknD0nWfozORxpiB/XDiYfl1eBRByW527lQvsOV58bPa7AYAEWZ6YzAYDAaj1HDVR+mCCy7AKaecotl22mmn4YILLsAll1zi5qWo4flsSoCLjx2FQCBf4xUNOzS9ffyyaFqrHQEMm679Tja9pZigxGAwGAxGqUCtUerq6sLGjRuxceNGAGKCrY0bN2LHjh0YMGAAJk6cqHmFw2E0NjZi7Nixbredik++7MKu9l5Ux0I49yvDdPdxbHqTzW4TzgFyTY+K6Y0JSgwGg1Fq/Pe//8W4cePA88bzQyKRwIgRI7Bu3Tqic/7yl7/EZZddZrmfVc7CXJYvXw6O43Dw4EHiYwD69pcL1ILS2rVrMXXqVKUy8rx58zB16lT86le/cr1xbnL44GqsmX8y/nbBNPSL6ivSsoKSDY1Sogv46CXxc67ZDWBRbwwGg+FD2tracPXVV2PMmDGIRqMYPnw45s6di1deeUWz3w033IAFCxYgIPme3nzzzZgyZYpmn2g0iuuuu46ohMnu3bvxpz/9CTfddJPlvrt27bJMy0OL0/aXE9Smt1mzZuUVDDRj27ZttJfwjLrKCGYeMtDw+4gTH6WPXgTSvUD9GKBpss7JmUaJwWAw/MS2bdtw7LHHoq6uDr///e8xadIkpFIpvPTSS7jyyivx4YcfAgBWrVqFjz/+GN/85jctz3n++efj+uuvx+bNmzF+/HjD/e6//37MmDHD0H8XAJLJJCKRCBobG6n/N7uQtr+cKNtab3o4KoyrmN2+nm92A1TpAZigxGAw+jiCII51xXhRLOSvuOIKcByHt956C9/4xjdw+OGHY8KECZg3bx7WrFmj7Pf4449j9uzZiMViAMRiur/5zW/wzjvvgOM4cByHBx98EAAwYMAAzJw5E4899pjptR9//HGcddZZmm2zZs3CVVddhXnz5mHgwIE49dRTAeSb3latWoUpU6YgFoth+vTpePrpp8FxnOISI7Nu3TpMnz4dlZWVmDlzJrZs2eJa+91g8eLFmDRpkhLMNWPGDLzwwgumx6xYsQLTpk1DLBbDmDFjcPfdd3veTtcTTpYytk1viS7gk2XiZz2zG8Ci3hgMRvmQ6gFuLVL5qpu+yGrwTdi/fz9efPFF3HLLLejXL3//uro65fPKlSvxne98R/n7vPPOw/vvv48XX3wR//nPfwAAtbW1yvdHHXUUXnvtNcNrHzhwAO+//z6mT5+e991DDz2EH//4x3jjjTd0rTednZ2YO3cuTj/9dDz66KPYvn07rr32Wt3rLFiwAH/84x8xaNAgXH755fj+97+PN954w3H73WLYsGG47bbbcOihhwIQ//ezzz4bGzZs0E1YvXXrVpx++um49NJLsWTJErzxxhu44oorMGjQIJx7rsHc6wJMUFIRDdt05t6zGcgkgapGYLBBwkz5wWVRbwwGg1F0PvnkEwiCgHHjxlnuu23bNk3d0oqKClRVVSEUCumaxYYOHWrqdrJ9+3YIgqBbC/XQQw/F73//e8NjH3nkEXAch3vvvRexWAzNzc1obW3FpZdemrfvLbfcghNPPBEAcOONN+KMM85APB533H63yC0yfMstt2Dx4sVYs2aNrqB09913Y8SIEVi4cCEAYPz48Vi7di3uuOMOJigVCsX0RuujtEdKkmkkJAHM9MZgMMqHcKWo2SnWtQmQtTUkyZF7e3sVsxsJFRUV6OkxTi7c29sLALrn1NMyqdmyZQsmTZqkOfaoo47S3XfSpEnK56amJgBQch2aYdV+Kzo7O9HR0aH8HY1GEY2aF1DNZDL45z//ie7ubsyYMUN3n9WrV2P27Nmabaeddhruv/9+pFIphMNh2202g/koqbBtetuzWXxvMBGUWNQbg8EoFzhO1KIX40VYFeKwww4Dx3HYvHmz5b4DBw7EgQMHiP/9/fv3Y9Cg/KTG6vMB0D2nnhlQjSAIecKdUYCVWnCQjzFLbyBj1X4rmpubNaXJWlpaDPd97733UFVVhWg0issvvxxPPfWUYSmztrY2DB48WLNt8ODBSKfT2Lt3r+32WsEEJRW28yh9KT1og0xUuKyECYPBYPiG+vp6nHbaafjrX/+K7u78Baw6B9HUqVPzymtFIhFkMvqL6vfff19JoaPHIYccgpqaGlslu8aNG4d3331XU0x+7dq11Odx0n4rNm3apClNNn/+fMN9x44di40bN2LNmjX48Y9/jIsuusi0X4yERNKyaXZggpKKbGZuGz5KgLlGiRXFZTAYDF9x1113IZPJ4KijjsLSpUvx8ccfY/Pmzfjzn/+sMf+cdtppeP311zXHjho1Skm4vHfvXo3g8tprr+WZiNQEAgGccsopeeck4bvf/S54nsdll12GzZs346WXXsIdd9wBgE5YcNJ+K6qrqzWlyczMbpFIBIceeiimT5+OlpYWTJ48GX/60590921sbERbW5tm2549exAKhTBgwADb7bWCCUoqsrXeKExvPfuBrt3i50Em2cdZ1BuDwWD4itGjR2P9+vU46aST8LOf/QwTJ07EqaeeildeeQWLFy9W9vve976HTZs2KeH1AHDuuefif/7nf3DSSSdh0KBBSjj96tWr0d7ejm984xum177sssvw+OOPE5nC1NTU1ODZZ5/Fxo0bMWXKFCxYsEBJ+EzjR+W0/V4hCIJGaFMzY8YMLFu2TLPt5ZdfxvTp0z3zTwKYM7cGW6Y3WZtUNwKIVhnvp0S9MdMbg8Fg+IWmpiYsWrQIixYtMtynf//+uOqqq3DnnXfib3/7GwDRQfn//u//8va98847cf3116OiosL0urNnz8bQoUPxxBNPKKkHli9frrtvrg/SzJkz8c477yh/P/LIIwiHw4qTtl5i6ClTpmi2OW2/G9x0002YM2cOhg8fjs7OTjz++ONYvnw5XnzxRQDA/Pnz0draiocffhgAcPnll2PRokWYN28eLr30UqxevRr333+/5zmfmKCkwlbCSTnizczsBgBhVWZuQSB2OGQwGAxG8VmwYAH++te/IpPJIBgM6u6TSCQwefJk/PSnP7U8H8dxuOeee/Duu+9St+Xhhx/GmDFjMHToULzzzjv4+c9/jm9961uOhRua9rvB7t27ccEFF2DXrl2ora3FpEmT8OKLLyqJNnft2oUdO3Yo+48ePRrPP/88fvrTn+Kvf/0rhgwZgj//+c+epgYAmKCkIZtHicL0pvgnWaR6VxKgCUCqN2uKYzAYDIbvqa2ttazLFo1G8Ytf/IL4nJMnT8bkyTolryxoa2vDr371K7S1taGpqQnf/OY3ccstt1CfJxfa9jvl/vvvN/1ezhau5sQTT8T69es9apE+TFBSEbVT6+1LsRYQBlkISurcHsluJigxGAwGwxY33HADbrjhhmI3o2xgztwqqE1vgqAyvVkISoGAKpcSi3xjMBgMBqMUYIKSCuqEk127gd4DABcABh5uvT9z6GYwGAwGo6RggpIK6lpvsn9S/RggTBCWGVE5dDMYDAaDwfA9TFBSIZvekrSCkpXZTUaJfGOmNwaDwWAwSgEmKKmgzqNEmhpAhpUxYTAYDAajpGCCkgrFmZs0M7cS8WZS400NM70xGAwGg1FSMEFJBZWPkiCQ1XhTE2GmNwaDwfAzs2bNwrXXXqvZtmXLFjQ2NqKzs9P02COPPBJPPvkk0XXuv/9+onpqo0aNwsKFC4nOCQDbtm0Dx3HYuHEj8TEyNO0vJ5igpILK9Na+UxR4AmFgwCFkF2BRbwwGg1FyLFiwAFdeeSWqq6sBiIkQ6+rq8vb75S9/iRtvvNGyflsikcCvfvUr/PKXv7S89ttvv43LLrvMVruNcNr+coMJSiqyeZQITG97JLPbwMOAIGExPmZ6YzAYjJLi888/xzPPPINLLrnEct8zzjgD7e3teOmll0z3W7p0KaqqqnD88ccb7pNMJgEAgwYNQmVlYRIUk7a/3GCCkgpZo5TKCMjwgvnOpIkm1bCEkwwGowwQBAE9qZ6ivHKLwZrR3d2NCy+8EFVVVWhqasIf//jHvH3+93//F5MnT8awYcMAiIVrL7nkErS3t4PjOHAch5tvvhkAEAwGcfrpp1sWaX388cdx1llnabZdfPHFOOecc9DS0oIhQ4bg8MPF3Hy5prcPP/wQxx13HGKxGJqbm/Gf//wHHMfh6aef1pzvs88+w0knnYTKykpMnjwZq1evdq395QYrYaIiEsrKjck0j4qIfuFDAPSpAQAgUiWdnJneGAxG36U33YujHz26KNd+87tvojJMpoG5/vrr8eqrr+Kpp55CY2MjbrrpJqxbtw5TpkxR9lm5ciWmT5+u/D1z5kwsXLgQv/rVr7BlyxYAQFVVlfL9UUcdhd///vem133ttddw/vnn521/5ZVXUFNTg2XLlukKfDzP45xzzsGIESPw5ptvorOzEz/72c90r7FgwQLccccdOOyww7BgwQJ85zvfwSeffOJK+8sNJiipiKoEpUQ6Yy4ofSkJSlY13tQw0xuDwWD4gq6uLtx///14+OGHlWr1Dz30kKI5ktm2bRumTZum/B2JRFBbWwuO49DY2Jh33qFDh2LHjh3geR6BQL7R5uDBgzh48CCGDBmS912/fv1w3333IRKJ6Lb55Zdfxqefforly5cr177llluU9qu57rrrcMYZZwAAfvOb32DChAn45JNPMG7cOEftL0eYoKQiFAwgGOCQ4QVzh24+A3wpSuJ0GiVplZNighKDwei7VIQq8OZ33yzatUn49NNPkUwmMWPGDGVbfX09xo4dq9mvt7cXsRhB5QX5+hUV4HkeiUQCFRX5bent7QUA3XMeccQRhkISIEbfDR8+XCPgHHXUUbr7Tpo0Sfnc1NQEANizZw/GjTNPZ2PV/nKECUo5REMB9CQzSKRMBKUD24B0HAhVAP1HkZ9cMb0xQYnBYPRdOI4jNn8VC1JfpoEDB+LAgQPE592/fz8qKysNhYwBAwaA4zjdc/br18/03IIggOM4onaEw9kgI/kYkmg2q/aXI0yvlgNRYVzZP2nQ4UDAxDyXi+LMzQQlBoPBKCaHHnoowuEw1qxZo2w7cOAAPvroI81+U6dOxaZNmzTbIpEIMhn9OeL999/HV77yFcPrRiIRNDc3552ThHHjxmHHjh3YvXu3su3tt9+mPo+T9pcjTFDKIZsiwETypk00KcNKmDAYDIYvqKqqwg9+8ANcf/31eOWVV/D+++/j4osvzvPLOe2007B69WqNYDFq1Ch0dXXhlVdewd69e9HTkx3TX3vtNctEkqeddhpef/116jafeuqpOOSQQ3DRRRfh3XffxRtvvIEFCxYAALGmyY32lxtMUMohm53bTKNkIzUAoDK9sfQADAaDUWz+8Ic/4IQTTsBZZ52FU045Bccdd5zGcRsATj/9dITDYfznP/9Rts2cOROXX345zjvvPAwaNEiJEmttbcWqVasscy5deumleP7559He3k7V3mAwiKeffhpdXV048sgj8cMf/hC/+MUvAOj7PBnhtP3lBifQJJ0oAJ9//jmGDx+OnTt35kUfFILZ/28FPtrdhUd/eDRmHjpQf6e7ZojC0nf/CRxOIXm3vQfcfRzQrwG4/mN3GsxgMBhFJB6PY+vWrRg9ejTVZF1K3HXXXfjXv/5lmYjx+uuvR3t7O+655x7Lc37rW9/C1KlTMX/+fEdte+ONN3Dcccfhk08+wSGHEFaJMIC0/Ua/ebHnb69gztw5WJre0klgr2TDptYosRImDAaDUWpcdtllOHDgADo7O5UyJno0NDTguuuuIzrnH/7wBzzzzDPUbXnqqadQVVWFww47DJ988gl+8pOf4Nhjj3UsJAF07S8nmKCUg6Uz9/5PAT4NRKqBWkqJWR31xvMAy1HBYDAYvicUCim+QGZcf/31xOccOXIkrr76auq2dHZ24oYbbsDOnTsxcOBAnHLKKboZxe1A0/5ygglKOWR9lAw0Sooj9ziAwnkOQDbqDQKQ7s1qmBgMBoPBIODCCy/EhRdeWOxmlBVMpZGDYnozyqNkp3SJjDqvCIt8YzAYDAbD9zBBKQdL05sS8UaZGgAQTW1hOUUAi3xjMBh9B5/FBTE8pNx+a2pBaeXKlZg7dy6GDBmSV7E4lUrh5z//OY444gj069cPQ4YMwYUXXogvvvjCzTZ7SlZQMtAoffmh+D7IPA28IRGWdJLBYPQd5AzQ6lw8jL6N/Furs3/3Zah9lLq7uzF58mRccsklOPfcczXf9fT0YP369fjlL3+JyZMn48CBA7j22mtx1llnYe3ata412ktMo95SvcD+z8TPdjRKgOiX1P0li3xjMBh9gmAwiLq6OuzZswcAUFlZSZX8kFE6CIKAnp4e7NmzB3V1dQgGKSpTlDDUgtKcOXMwZ84c3e9qa2uxbNkyzba//OUvOOqoo7Bjxw6MGDEi75hEIoFEIqH83dnZSdskV1GcuVM6pre9HwECD1TUA1UN9i7Akk4yGIw+hlykVRaWGH2buro6TWHevo7nUW/t7e3gOA51dXW637e0tOA3v/mN180gxtT0tkcyuzWMp494k2H13hgMRh+D4zg0NTWhoaEBqVSq2M1heEg4HC4bTZKMp4JSPB7HjTfeiO9+97uoqanR3Wf+/PmYN2+e8ndrayuam22atVzA1PRmt3SJGlbvjcFg9FGCwWDZTaKMvo9nglIqlcK3v/1t8DyPu+66y3C/aDSKaDSq/N3R0eFVk4gw1yg5SA0gE2FRbwwGg8FglAqeCEqpVArf+ta3sHXrVvz3v/811Cb5EdOiuF9KgtIgFwQl5szNYDAYDIbvcT2Pkiwkffzxx/jPf/6DAQMGuH0JTzE0vSU6gYM7xM+uaJTK3Efp4/8A//g6cHBnsVvCYDAYjCLQ0tKCI488EtXV1WhoaMA555yDLVu2mB6zfPlycByX9/rwww89aye1RqmrqwuffPKJ8vfWrVuxceNG1NfXY8iQIfjGN76B9evX49///jcymQza2toAAPX19YhEIu613CMU01tuZu4vpR+vqhGorLd/AcWZu8xNb2/fC3z6CrDleeDoHxW7NQwGg8EoMCtWrMCVV16JI488Eul0GgsWLMDs2bOxadMm9OtnXuJry5YtGmvVoEGDPGsntaC0du1anHTSScrfsiP2RRddhJtvvlmphjxlyhTNca+++ipmzZplv6UFwtD05oZ/EqBKD1Dmpreu3eJ7vLg+aQwGg8EoDi+++KLm7wceeAANDQ1Yt24dTjjhBNNjGxoaDKPp3YZaUJo1a5Zp+vJST20eCRqY3lwTlJjpDQDQ9aX4nmCCEoPBYPQlOjs7NYFZuUFbRrS3twMQLVBWTJ06FfF4HM3NzfjFL36hUeC4Dav1loNh1NteyfRmt3SJTISZ3iAIYnZygAlKDAaD0cdobm5GbW2t8mppabE8RhAEzJs3D8cddxwmTpxouF9TUxPuueceLF26FE8++STGjh2Lk08+GStXrnTzX9DgecLJUsMwM3enZCqqHebsArLprZyj3hIdQEbKxp4obiZ2BoPBYLjLpk2bMHToUOVvEm3SVVddhXfffRevv/666X5jx47F2LFjlb9nzJiBnTt34o477rA019mFaZRykKPekrkaJVkD0m+gswsw01vW7AYwQYnBYDD6GNXV1aipqVFeVoLS1VdfjWeeeQavvvoqhg2jV0Ycc8wx+Pjjj+021xKmUcpB1/TG80DPXvFzP4ee9ayECdCtqgfFnLkZDAajLBEEAVdffTWeeuopLF++HKNHj7Z1ng0bNqCpqcnl1mVhglIOulFv8YMAnxY/VzrVKMlRb+UsKDGNEoPBYJQ7V155JR599FH861//QnV1tZJOqLa2FhUVFQDEMmetra14+OGHAQALFy7EqFGjMGHCBCSTSSxZsgRLly7F0qVLPWsnE5RyUBJOqvModUvapFgtEHKYC4qZ3oAulUaJCUoMBoNRlixevBgA8lIHPfDAA7j44osBALt27cKOHTuU75LJJK677jq0traioqICEyZMwHPPPYfTTz/ds3YyQSkHXdOb4p/kQkKrCDO9aTVK7cVrB4PBYDCKBkk6oQcffFDz9w033IAbbrjBoxbpw5y5c5AFpWSGB89LP6Jb/kmANuqN1ym8Ww7kmt5KPPcWg8FgMPouTFDKIRoOKp+TGUmQkSf2Shfq1smmNwhAutf5+UoRtelN4Mtbu8ZgMBgMX8MEpRxkjRKg8lPqdlGjFKrIfi7XMiZqjRLA/JQYDAaD4VuYoJRDKMAhwImflcg3N32UAgEgLDt0l2l2brVGCWCCEoPBYDB8CxOUcuA4Lhv5ls4xvbkhKAEs8k3W0EGWSFkuJQaDwWD4EyYo6ZCXS0kxvTnMoSQjR76VYxmTVC+QlDRItcPFdyYoMRgMBsOnMEFJB9lPKe6FjxKgSjpZhqY32ewWjAA1Q8TPzPTGYDAYDJ/CBCUdjE1vLmmUyrmMiSJ0NgCxGvEzK2PCYDAYDJ/CBCUdskknM0AmDfTuF79w3UepDE1vcp23qkFAVBKUmEaJwWAwGD6FCUo6ZH2UeKBnn7iRCwAV/d25QKSMo95k01u/QUC0WvzMfJQYDAaD4VNYCRMdNPXeZFNR5QAgEDQ5ioJyjnqTNUr9GlSCEtMoMRgMBsOfMEFJB3UZE9dTAwBZQakco95kwbNqULYfmEaJwWAwGD6FCUo6KD5KqUzW9OaWIzfATG+AqFGSNXTMmZvBYDAYPoUJSjpoot7Scp03FwWlcDmb3lQaOj4tfmamNwaDwWD4FCYo6aBx5k54aHory6g3qT+rBgEJSaPGBCUGg8Fg+BQmKOkQCarSA3jpo1TupjdWwoTBYDAYPocJSjooGiV11JsXPkrl5sydSWlzUmUS4memUWIwGAyGT2F5lHTQ+Ch5qlEqMx8ldU6qyvpswknmzM1gMBgMn8IEJR00mbndrvMGlK+gJJvdKgeKEW+yoJTsBHi+eO1iMBgMBsMAZnpTsT++H+2JdvQKbeAiX2JfIoStif1AOAQICaB9q+nxw6qGIRwMW18oJ+qNF3js7NwJXjAWFoZXD0coUOI/V3c2K7cgCGhNdSAVlv6nvR8A0SrN7kOqhiAajFJfRhAEdKW6UB2pdtriPHiBR0+qB1WRKuudfUSKTyGVSaFSrjNIgZf9ycjHyW/lJYIg4PPOz5EW0ob7DKsehnCAYAwsITqTnZ7c++y5Kh1KfOZ1j3e+fAcXvnChIqxUHQK82g28OrgWQC2w/ErLc4yrH4d/zv2n9cVyNEq/eP0XePazZ00PObrxaNx32n3W5/YzXdmIt7vfvRt3bbwLGDZE3PbCd/N2H1o1FP/+2r+pBcTb374dT3z4BB4/83GMrR/rtNUaFry+AC9vexnPfu1ZDKka4uq5veSiFy5Ca1crXjr3JcRCMapjF7+zGH9792+4f/b9mN443aMWMmQufP5C7OrehRfPfZH6t/KSlrda8NiHj5nu0zygGU+c+USBWuQ9SzYtwe1v345FX12EE4ef6Oq5/7rxr7j3vXvxwGkP4CuDv+LquRnuwkxvElv2bwEv8AgFQogGqiBkKhBGBWoyGdRkeNREagxf1WFxRfDh/g+R4TPWF8sRlN7f9z4AoDJUmXfuqrCoudi0b5P7/3ShUfy9GvDB3g8AABWCIPZxuJ/m/waA1q5WdCbpHb0/2PsB0kIaHx34yLWmy7y/930k+SQ+OfiJ6+f2CkEQ8MG+D7A/vh+7e3ZTH//Bvg/ACzy2HNjiQesYauTfal98H/b07Cl2czQoz2yownAM3LRvEwRBKGYzXUUemzftd3/8lZ+rD/d/6Pq5Ge7CNEoS8XQcADB75GxMjl6Jm556Dz885CB+0XoFUDMU+P4bhsf2pHpw9KNHAwASmQQqAxYqc3XUG88jkRajv+6dfS8mDZqk2XVX1y7MXjob8Uzc5n/mI2TTW1UD4hlxwv5VTwBn7tkJ/OBBYPhRyq5T/zEVaT6NhBwZR4F8jBd9Jp/bTruKRZpPK5pS+T6nQb4/7RzLoCPFpyBAFDT89szL7Vk4ayFmDp2p+a4z2YmZj4nbknzSlsncj8j3vvzu6rlLcCwpV5hGSUK+WWOhmOLMHUvKoezmqQHU6nGim14WlCAA6V5lANIbXKIhcVuKT5Fpq/yMbHrrN1AZeGKhCnFbTuRbLCj2qZ3JWe5PLwe3UhIa1BOunUFZ6U82oHuO5rfy4P51gvz7y2OSGvl5BUrr2bDCy3tfWYD4TCBm5MMEJQm1sCLnUapMqnL+mBDgAooDI9EDJQsHAJDs1ghpuagHoJKfqFSmN2XQDesXxpWFRlsaJQ8HIHkSKKXfQt1Wv2noGFrUwpHf+lu+99VjkkwoEEKAk6KFS+jZsMLLe9/LBR3DXZigJKFoOIIxJY9SZfqg+CVBnTcqDUggoIl8k6+tq1FSbSv5AUhjepMGXQNBSRYa7QxQnq4CS1Bdrr4nbWno0mxALxROtX9eoixudMYpjuOyi5s+dJ8w0xsDYIKSgqJRCkUV01uVLCgRZOWW1dHEN71kfkvHO5RwW72VWjAQVKK+Sv6B0jG9ReWUADnZuZ0MusoA5PLgluJTyAii+bOUzAtuaZRK/v4rAdT3rN8EDjPTG6BaLPpME+YE+X/xUjvdl/qrr0ItKK1cuRJz587FkCFDwHEcnn76ac33giDg5ptvxpAhQ1BRUYFZs2bhgw8+cKu9nqFeLcmCUnXmgPglQbJJeWInvukjosN3In4wew6rAaiEJuc8eF5jelMEUzmHiIGgZGcQ8cr0ppnESkhoUPeDrf5kpreCob6v/NTfgiCYmt4AG4vFEsDLRYJXCzqG+1ALSt3d3Zg8eTIWLVqk+/3vf/973HnnnVi0aBHefvttNDY24tRTT0Vnp7/reWlMb2HR9FbDHxS/JBCU5MGD+KaXEhbGEweVTUaRIk78dXxD/CAgaWPQb1DWLysqCUq5ztyS6Y32f07zaUVD53Z/ORU4ioVTLQUzvRUOv5re1NF4fXpBl4OX9z5bgJQO1OkB5syZgzlz5uh+JwgCFi5ciAULFuDrX/86AOChhx7C4MGD8eijj+JHP/qRs9Z6iJ7prY5vF78k0SiFaDVKouktkRCvEQlEFGfIXJz46/gGuXxJrA4IRVSmtzpxu5FGiXLQ1azIXR6wNSasEhIamEapdNA4c/tI4FD/9oYapb6woMvBq3tfraHrS/3VV3HVR2nr1q1oa2vD7NmzlW3RaBQnnngiVq1apXtMIpFAR0eH8iqW5knRcASz6QH6QxaUyJ25iW96qTxBXHJiNlqlAc78dXyDqnyJWusTi9aK23OduWn7U0I9ubg9AJWq6c1Ju9V+WaX0P5cqftUoyfcQB86wRAn1YrEE8Mr0ptbQlfS47pCWlhYceeSRqK6uRkNDA8455xxs2WKd2HbFihWYNm0aYrEYxowZg7vvvtvTdroqKLW1tQEABg8erNk+ePBg5btcWlpaUFtbq7yam5vdbBIx8gQrpgcIAhDQX5AmbxJnbloNiKJREgVDo1Wa5tylPADJ/klVDZpBJ1pRL37ITQ9g09/BSx+PkjW9OdCE+dm5uC/iVx8lJUo1FAPHcbr7ULsf+By11sdt7V6pjiVus2LFClx55ZVYs2YNli1bhnQ6jdmzZ6O727hg/NatW3H66afj+OOPx4YNG3DTTTfhmmuuwdKlSz1rpyeZuXMfJEEQDB+u+fPnY968ecrfra2tRRGWchNOVqEXUS4lfkmQHoA+6k30UUoku8TjTTLZ2vXX8RVKxNsgzaATregvfnDJ9OZlwr5yNL2xAb2waDSiPrrHzFKYyPQ105tG68O0057w4osvav5+4IEH0NDQgHXr1uGEE07QPebuu+/GiBEjsHDhQgDA+PHjsXbtWtxxxx0499xzPWmnqxqlxsZGAMjTHu3ZsydPyyQTjUZRU1OjvKqri1NJOTfqbQAnajiESJUSoWYGtalIOmc8JUrOZsUv7QoNvkJlepP7KBKIIBCTTG8GmbmpNUoeDkCafEQlJDQ46ROnqQUYdPi1v81yKMn0CV9KFV6aQTULkFIe1w3o7OzUuNQkEmT9194uurvU19cb7rN69WqNew8AnHbaaVi7di1SqZT9RpvgqqA0evRoNDY2YtmyZcq2ZDKJFStWYObMmSZHFh+N6S0UxACIEzdPoE2Sj1OfxxLZ9JYi0CjZFBp8RVd+ssloKApExQK4eRolm/4OXpou/DqJWeFkUParc3FfpRRMb0b0CV9KFV7e+31do9Tc3KxxqWlpabE8RhAEzJs3D8cddxwmTpxouF9bW5uue086ncbevXsdt10PatNbV1cXPvkkWzl969at2LhxI+rr6zFixAhce+21uPXWW3HYYYfhsMMOw6233orKykp897vfdbXhbqM2vYWDHAYGRMmWrxiAIMHx1OYxOT1AqgeAhUq7L+Qn6ZZu4H6DNKkYENXPo2TX38FL05uf63CZ4UTA86tzcV+lL5je/CTgOcHLe79UF12kbNq0CUOHDlX+jkatiyRfddVVePfdd/H6669b7qvn3qO33S2oBaW1a9fipJNOUv6W/YsuuugiPPjgg7jhhhvQ29uLK664AgcOHMDRRx+Nl19+uWgmNVLUtd44jkNjUJy40xUDoR/joYV6kJCi3hLpXgDlaXqLBlUapVQ3kEkDwVD2OzgzvXmZcLKUJgMnkYB9fUD3G77XKJkEnfQJX0oV6uc9I2SQ4lOGEX+09HXTW3V1NWpqaoj3v/rqq/HMM89g5cqVGDZsmOm+jY2Nuu49oVAIAwYMsNVeK6gFpVmzZinSmx4cx+Hmm2/GzTff7KRdBUej5QAwKCCaxFLRelQQHE+tdpZMb3FJUOr7prds1JtGjR9VCdDJTkBy7rbr78BWgfk4yS2VWyfOLDCD4Ry/avCUxU3HF0AqDoTzBaY+saBTkdv/iXQC4Yg7glJRTW+JLuClm4BYDXDKb8Xao0VCEARcffXVeOqpp7B8+XKMHj3a8pgZM2bg2Wef1Wx7+eWXMX36dITD7vw+ubBabwB4gUeSTwLImrkGBUQfpWTU2KlMjV3TW8KiLIC6TX5aYVIhCKryJYO0avxQBJC1aSrzm11/By8j05wWly0WTgQ89f4CBKR4b5wlGSJ+Tceg+HAe3Al8/LLuPn1iQacid7x1c/xVn0vWVhWM3v3A+oeAN+8pqpAEAFdeeSWWLFmCRx99FNXV1Whra0NbWxt6e3uVfebPn48LL7xQ+fvyyy/H9u3bMW/ePGzevBl///vfcf/99+O6667zrJ1MUIL2wZYf9oFS1FucUFCyXestoxXQ9Cj5/CTJLkDSnGmcuWUtmk4ZE7v+DrmRaWbaT1pKVaPkJFrPy8mCkY9f0zEoPpzqRU8OfcKXUkXueOvm/6WnrSoY8jgbIzeNecXixYvR3t6OWbNmoampSXk98cQTyj67du3Cjh07lL9Hjx6N559/HsuXL8eUKVPwu9/9Dn/+8589Sw0AeJRHqdRQ36TyBF0vRb31hgk1StS13iTTG58Agg7yk3y5BXj1FuDEnwODJ5Bdu9DIEW/hSiDST+M4D0D0U+r+UqNRsuvvkLt/kk+a9i0NfjWLWOFWwknl74grzWLo4FdhXDG9CQLQe0B3n75messVVN0UZnL7KJ6JowpVrp3fFHmcjRbfb5hkIfvggw/mbTvxxBOxfv16D1qkD9MoIftAhAIhBANijFu9IEa99UQINUq05rGwlB5A0iiROEnqnnvjo8CmfwHrHya7bjFQmd0AbSoG8UN+5Jsbpjf1tdwgN1zYTW2VlzgR8PL600dajr6IX9MxyG2JCYJY4FqHvmZ68/Lez9MoFbLP5CoI0eJrlEoFJihBpVZWCSt1kqDUHawjOgd9wklZoyTWPLNd600etHr2kV23GKjKlwA6/S2rgFVlTJRK5A5Mb+pruYG6LaXkr+MkWi+vP0vV/Fsi+FVrmZDN5byJRqnUfSlz8HIsKarpzUcapVKBCUrQ0XDwPGqkOm9doTqic9iNekvIxWHt1nqTb/reg2TXLQZd2dQAgEqNLwuH0XxByY1ab4C7A1Cpalccmd6KufItQ/xqeovLpZYEwXCsKXlfyhy81E7rmd4KRlwq9i5XRWBYwgQlaJNNAgB6DyAAHgDQGSC7mahXU7JGSarMbrvWmyIo6a/yfAGp6S2uo1FyEM4OuKwu1/PXKQHcqvVm53gGHX6NrEwkpeLdJoJSX6v15uUiwR+mN6ZRIoUJSlBpOOSJW5rYDwhViPNkXWTX9JaQctLYLg0gCxelICgZmd50ypjYTjjp4QBUqkJDbs4WGt+qUhUOSxX/apTEmpRRgTf2Ueprtd48XHTljSWFFIoV0xvzUSKFCUrQ0XBIE/s+oQaJFE90DkWjRHrDhyoAcIqgRJJw0tT0ZjB4+YIc05vS3yETZ26bpjcvB6Ci+hU4QN0nvMAjLfnF0R6r9zfDXdT3WMHz65iQkIt3E0S9lcpzYYWnZnwPUw9YEmcaJVqYoAQd05ssKKEGiTSZoEStUQoEgHAl4rKgZObMbSY0qE1vPFlbC06O6S1foyQLSvqmN0caEDc1Sh46d3qJE98q5qNUWPzqPJ+Qa1ISmN76ijCdlx6gr2in5TnDB3mUSgUmKEFb5w2AUsB1r1CDRDpDdA5bpqJIPyQCkunNLD2Amb9OQnLME3ixBIgfkTVKkuktr79jOqY3STikjS4rZEhvqUwIToTH3GP95DfTF/HrPaaUWuIFsS5jOpm3T1+u9Qb0Ie00Sw9ADROUkL1JFWGlRxSU9gsUGqWQDQ1IpF9Wo2Qn4aQgaIQL30a+SYIn+kk+SukcDZ5O1JtacKSZLLxMEtcXTG8A3YDv5aqakY9f+1uTmRvQNfX3NdObl79FUU1vLD0ANUxQgkrDEcrxUQKFj1LQhgYk0o/MmdvI9JbqETVJMn506E7Fs1qvfgMB6DjPy4KSKuotHAiDg9g3NAOvvK9yrAemN/ncflntm5Hhs34udvpE3teL/mRoyfAZxX/Mzr3vJXF1Zm5Ad1EmL27SQprKD86v5N77XjhzK+cupKaWpQeghglKMI562yvUEpvebGlAVIISkTN3rrYqkWNq86OgJPsnBcJARX8AOoKpjjM3x3G2omjkfasj1dTHWiHfJ/K5S0FoULfRTp/IA7hyLDO9eYbT38pLlAoCiqCUP9ao/SxL4dmwQhZSlefdA+10UcYSplGihglK0DG9SaaifRSmt1AghAAX0JzPEpXpzTThpJG/jkoDI/59kOy6hUTtyM1pV8lmztyAPVW+PODURmupj7VCnrTkc5eC0KAegGsioubOUX/2gQnQr6iFIuW38kl/J6RxJ0pgegNK49mwIu95d1OjlPbu3JYwHyVqmKAEE9MbhaDEcRx91Ee4MqtRMol6M9RWlZJGSTK7AWTO3Orv7Tgf10bcH4Byz+2XScwMuY2hQAiV4UoA9qLevOhPhhb5/goHwqgIVwDwj8ARlysImGiUAlwAkYBYMbkUng0rcu99LxJOKuculIlVEFh6ABswQQk64eoaHyUy05v6eNKbXgj3QyIg/gRmpjdDf50cDYwvBaWciDdAJx2D/MCm45poGiemN7c1ILzAI8knPTm3lyjFTIMxWyUmcle+fvGZ6YvI967mt/LJPZaQKwjwxj5KQN+q9+blvZ+rqS1Yf6UTgGyVYOkBiGGCEnISTqaTirMbjUYJoE+SmIhUKJ/NTG+G/joloVGSk02qBKV0jk9YRLWy0cvObcNUVCOpld1akWtMWC6f20vU/nd2knjm9WcfmAD9iroGot9yEsWlkk4xSStpNNb0pXpvXt778tghn7tgArF6cR2pKsw1+wBMUEKOhqNnHwCA54JoRz9iZ26AvuJ9IpzVIpmZ3gADoSFPo3SQ6LoFRU4NUDVI2aReOQMAgiEgLJZ00U06SdifgiB4pi5X97vf/EfMUPo6FLM1+SoauhIyN5Yq6gWbItT6QODI8BnIMWzR6qHiBwN/yL5U761Pmt7khWikGggEC3PNPgATlJAT9SaZ3VLReggI0GmUKDUgcUlLFASHcCBMdm71w1oKGqWc8iWAduWs4EIZE/V+bpvHZIEhxIXQTxLq/LLaN0OtvbOz2lf8spjpzXPULgB+Mr2p2xCtHSF+MNIo9aF6b3kO1y5qkL10FDe/sJwagJndaGCCEnJMb7KgFBsAAMR5lAB6+3wiKApHUcn/yAxT05scveBLjZLW9KbW+mj8smL5SScVDQjhAKUX4eW26S0asidwFAu14zzt/annl9UXJkC/omt684F5V/2bx+pGih8sypiUwrNhhVcRn+p8WQX3d2SpAWzBBCXkmN4kU1G6QhKUbJjeSG/6eEiMEIkRCEqmpjd58PJlegCt6U3dNxq/LB2NEnV/pvO1Pq5plHTMIqUgNKjvbdr+9FJDx8hH43jvo3IgSjSeICDQXxaUzAvjlsKzYYVXgSF6z1XBBGKWGsAWTFBCTri6pFHiK8Rw9mSG3vRGrAGh0Sjp+evIYZ51w8X3EjC9adT4eqY3VW4ou6a3aMh9YUZtFiklPwyNgEd7f+r4ZflBw9FX0Tje+0jgiCe7AAAxXgDqJNObwaLMTwKeEzRan4i7wkxR82UxjZItmKCE7IQQC8aUOm9CJb3pjXaQiAdFZ7ooQW04XaFBvunrzP0GikYmrTjHy6Y3ebAJckGtX5ZJvTfSAUot8LptHitV05tGwKMUPPX8skp9AvQz6nxufrrHEvH9AKRxymJR5ieToRO81KbKv2kkECm8YCkvRJmPEhVMUEKOc7E6kzRgz5mbVAMSDAFQJXEjOLdmAMoVlFI9Yp4Mv9CzD4AAgANkwVPPPwlQCUo66QFI+zPtndZHbRYpRdObZvK1o6ErIS1aqaK5f310j8UloSgKZIMyeg+KyQtz8JMTuhP0tD5u/RZ6AnHhTG9Mo2QHJighJ1xd8qnhFEGJ3EeJ2rQhhWdGeWthTHcAkrUvNUMBqXyKrxy6ZaGzsl5MAQBtuLoGnTImtJOFZgByOfpGLeCV0mTgxPTm5FgGPRrHex8JpgnJzBYDB8TqxI18SlyY5WAnV5cf0WRJD1Votjk+dzHN+HKBcuajRAUTlKANoZYn90B1VqMkEGh8ABumN8k3KcZbC2OmprdYbbYStJ/MbyTJJmV0ypjQmh90ByCXBje1EFZKQoMm5Jzy/nRyLIMeXcd7H2iIZUEpygWBSD+xwDWgXxi3hJ4NM9SLZ3nsTfJJ8AK5hcHw3MUMDFFMb7WFuV4fgQlKyKn1JglKoerBAETtcipDJijROmAmpN6PZqwFJV0VrTo9QEV/8bOfIt+6JI2STrLJfNObTh4l2v5UCWFuO8OqzSKlJDToCnik/enjTNF9Ec396yfTm6SFiHFBsbB1RZ34hY72upS0rWbomazV2904d1EEYmZ6s0XZC0rqvD5q01u4Rq0FITO/0d70skYpyqcBC/ObfsJJlWOeLCj5SqMk+3uZ1HmTkVXBqqg3ag2djunN7YSTfjOLWKHrt0V6f+rUiUvzaWQINKAMenSDEXxwjyWS4uQalTVJJmONIuCVukZJx+wMuCPQ6EU3uqWtsr44Sw9gh7IXlNJ8WrlBo3xGsbtHalSZpAkduqkTTnKipirGC0C6l+7cgqBdHci+A74SlHSychuZ3kw0Sn4wvakFvFIyL2h8q2ya3tQaDprjGXT49R6LJ3IEJXms0dFe+0nAc4J6LAkGgggFtD6WTlALYeoFY0H6jGmUbFH2gpIm62xczBeCUAxctBqRkNg9xIISpaYhLlfkFngg2W26b562KtkNyCuQaLU/NUompre8IsBK1Ft7dhOluUczAMkaECGt5ENxgqYUSAma3uzUetMz29Ecz6BDbwL1wz2WSEl5lOR7wEyj1EdMtLllltwUAPUEYqBA5jeWHsAWZS8oyTctBw5h2ebebxDAcYjKglLKG9NbIiOWh4gJAiAldTMibwCSVwZcEAhXqgavg0TXLggmpre8IsB6ztx2nY9DMdc1IHqmt1KYDJzUelOb7QJcAJFAhOp4Bh1+TWoal7TsyqRu5qMUorvH/Ira7Ay466SuHktCgRBCnHvaKkuYRskWZS8oKQ9EKAZOSjaJfmJW7mhIDN/3zPQmCw2CACTzQ23V5AkN6hte42DpI42SjulNU1dPjZkzt42EkxoNiAuDm54DZin46zip9ZbreO8nB+O+iF8jKxOSoKSYiQg0Sn4Q8JyQm+/NTQ2fJsExCpxSQfFRYlFvNJS9oKR5IHKSTUYpTW/UtcnkgVEQLE1veT43uU55JWJ60zjOq1GXMJHSMVAnSFRpTzQaEDc0SjohvW6d20vcqPUmTxJ9xf/Er/g1sjIh+U9GpXxCZj5KfUWY1kRCw10B0OjcngvFPM80SjYpe0FJr86bIiiF6Uxvdmtp2TO9yYKSdMP7LT2AIOia3nIHCQVZ4ONTSnZxu7Xe5EnGzUFbzyzi1rm9RC9lAq3pTdEo+UjL0Rfxba03uV1SGRuzRZmf8j85IU/r4+K9n6etKtQCJNkFsVICfOWjtHLlSsydOxdDhgwBx3F4+umnTfdfvnw5OI7Le3344YeetdF1QSmdTuMXv/gFRo8ejYqKCowZMwa//e1vwRNkny4GygMRyqYGkMtt0JrebIez84JullvTc+euDPwW9RY/KAo9gG7UW55GKVIFyMWBpf/NSa039fGuhvSGoiXlr6N2nqfNVp7Xnz7ScvRFfFvrTV4kKIJSnfiu46PkJwHPCV7e+0UzvcmL60AYyE3PUkS6u7sxefJkLFq0iOq4LVu2YNeuXcrrsMMO86iFQMjtE95+++24++678dBDD2HChAlYu3YtLrnkEtTW1uInP/mJ25dzjOaBUHyU7JneqGuTZdQaJTLTmyI0KFm5fWp6k81u0RognB8Cm+ejFAiIQl+iQ3xVDXJU6019DTdNb+rBLZlM+n5C0EsameJTyPAZBKUSOlbHKhq6PuJ/4lf0ar3J+XUCXPGU//FMEggB0UiVuMFkUdZXhGmje9+V9AA5WvWC1XvL9Wv1kM7OTnR0qMpRRaOIRqO6+86ZMwdz5syhvkZDQwPq6ursNpEK15++1atX4+yzz8YZZ5yBUaNG4Rvf+AZmz56NtWvXun0pV9BMroY+St6a3qIEprc89WzcwPTml6g3HUduwMT0BiC33pttDUhIuwp00/RWcHW5QzTFfNWhyATtznW8Z6Y3b9HTKAHFv8cSkmY4FslZlOn5KLmcv6xY5JqdvdBOe7GgM6WAqQGam5tRW1urvFpaWly/xtSpU9HU1ISTTz4Zr776quvnV+O6Rum4447D3XffjY8++giHH3443nnnHbz++utYuHCh7v6JRAKJRPYG6ezs1N3PKzTh6t3bxY2Kj5Jkekt5a3qLEUS95alnc01vsjo8flB02gsU2f2sZ7/4LkUQyhia3gCtQzeyA4gcXUasAckdgFwY3IrmgOkQvYST8vbKcCXRsXJ/9hVtgV8x8oNLpBNKYdZiEBfSAEKI5o41Jj5Kfte0WuFlxGfeAqRQDvAFdOTetGkThg4dqvxtpE2yQ1NTE+655x5MmzYNiUQC//jHP3DyySdj+fLlOOGEE1y7jhrXBaWf//znaG9vx7hx4xAMBpHJZHDLLbfgO9/5ju7+LS0t+M1vfuN2M4jROnPnpgewZ3qzlx6ALOFk1vSWo1GS1eECL34nD2bFQv5/Iv00mw1rvQGqpJOdefskMglUBiwmdiPnYzc0SunSFBpyfavCgTBSfIqo3bk5r/qK/4lfUd+/cjboNJ8ubn8LAhJCBkAIMbmQqqJR6shblBU01N1DvDQ7G0aTeq2Fk5P5FiA1QHV1NWpqvNFcjR07FmPHjlX+njFjBnbu3Ik77rjDM0HJdbXDE088gSVLluDRRx/F+vXr8dBDD+GOO+7AQw89pLv//Pnz0d7errw2bdrkdpNMyU6AZukB6BJOkubXUVYWggCkCNMDKBqlnHwY4ZiYeBLwR+SbbErMEZQMa70BebmU1PuQTBZGpjc3B7dcIczPE4IgCHm+VTT+EEbHlrpZxY8IgqDJog74xLyb6oV89ai8GJPfIUCdSR/QPheCQFZM3I/kan3cvPfztFWFWoD04dQAxxxzDD7++GPPzu+6Run666/HjTfeiG9/+9sAgCOOOALbt29HS0sLLrroorz9c5281A5ghUC5aREA5FIXDhNOAoQaEFlo4Ak0Srn+Nno3faxOjJ7rPQD0H0XUZs+Qo/jCOYKSUa03IM9HSaMBIRigjExvbmbTzXPu9LHpLcWnIEjhwIpWKBRFZ6qTTqPEEk56TpJPKp/VE2hXqqu491iiE/GAVLw7WiduC0XE5zrVLY41soYJyPOt0l0QlQB5Y4mbqUZy0p8UTDvdh8uXbNiwAU1NTZ6d33VBqaenB4Ec/5hgMOjf9ADqyDNANP/Ik4qSR4nO9AaIDxSpDwhNwknFX0dPUKroD3R+4Y/IN8X0pu0Dw1pvgKqMSVZYjgVjSPEpMo2S0SrQxZDeUgqV19QxzBUebWjoSkGLVqqohSFfmXcTHUhIEVIaoaeiThKUDmp2z10slqqgZBSZ5qrpzQNfSvML+1Oj1NXVhU8++UT5e+vWrdi4cSPq6+sxYsQIzJ8/H62trXj44YcBAAsXLsSoUaMwYcIEJJNJLFmyBEuXLsXSpUs9a6PrgtLcuXNxyy23YMSIEZgwYQI2bNiAO++8E9///vfdvpQrKJOrLMipnI9pTW9yfp0knyS66RXTBoWgBEjaKiNBCfBH5JuBj5JhrTcgz0dJ3o9WA5KbcNLNbLp2BI5iId+DHDiEpcrvNCaEPL8sZnrzDPkeDXABpVK9J4JpJgWAA4KEQ3+8A3FJUNI8sxX9gY7WvEVZOBBGkAsiI2QQT8dRW6KlMrxMOFk801tONQefsHbtWpx00knK3/PmzQMAXHTRRXjwwQexa9cu7NixQ/k+mUziuuuuQ2trKyoqKjBhwgQ899xzOP300z1ro+uC0l/+8hf88pe/xBVXXIE9e/ZgyJAh+NGPfoRf/epXbl/KFZSJO5OfHJHW9CYeQ55fh8qZO8dfp1JPjeqnem8GpjfDWm9A9gGOq/JvUAxQRn5ETgc3QRCMq4n7WGhQmwu5nMmO6v4sVdPbe/8HfLwMOOvPipbYr6g1lspv5bZ5l+eBu48XAz6uWA1YRJGKDVNplNRaYLMyJsEoetI9Ja15LEitt5ADzWHHLuD564AjfwAc8lWyY3xqeps1a5apP9uDDz6o+fuGG27ADTfc4HGrtLguKFVXV2PhwoWG6QD8hqKFyEj+SRX1yne0GiVAHEw6Ya0BSfEpZATxvCQapTx/HV2NUp347gdBycD0ZljrDchz5lbvR5P3J08D4nBwS/Np8IIoLJeS0KDnD0bVn350LqbhtT8CezYBk74JHHpKsVtjip5J2nXTW6Id+HKz+Ln7S6C6keCYrKCkWdyYpQgIxdCT7vH1s2FFQWq9OVnQbXke+PDfooaQVFDKjZRmEMNqvakjzwCNqSgiCUpJGo0S4U2v1kSIUW/meZSAnBwliqCk1ij5KDu3LdNbvqBEYz7LC2cPubMi1/j6lFCWar0s6FQaulKv9SbfR3KWeB+j91y4bpJR52rrJusTId6BuORzmuejBJiWMfGzttWKQtR6c7Sgk6OK5cS+RBfOiZRmEFP2glI28kzSGqk0ILR5lADyVaB68CPJzK05dzqub2/2U2FcC9NbRVAngZ6BM7f6OMPLqTR0bjtzy8dz4JQabwUrO+CAXI0QQCd45mo5lMhLH//PGmRhnVAoKCa52lD1Z9cEjhS9oJRULbo0WmCzwrguZsQvFl5m+VcW5zkLOjpBSfot5dx/JPjUmbsUKHtBKVuYVhKUVJFqtJm5AfLJWRHQAhGxFKyF6Q1QrWriB6BUgc5NDwCUsDO3jumNUPBUTyZu12dS+1Xl+fr4WGhwYnrT88sqBS2aBlkwKAFBSVf757Z5Vz3GdO8jOiSuWnRpnlkTH6WSM9Hq4FVkmua5ylnQUY0lKdUigDRflU99lEqBsheUlMlET1Cy4aNEOoHmTWIWJUwAldAgD05cEAirNDO+Mr1J/49KQ6en9dEgq4T1nLktJgv5e43WJ+TOilxPuCuFyUDP74XUhFCqflkKfAaQ/0eaVXeR0KuB6LpgmurNfiYUHhNSQsmgKnISQNmY3vKEGYf3vvq3dFTrTR5f03GiRbZ4AaZRsgsTlOSVQ1qKenNqeiOcQPMGxlS3GJVigvJAyYJSbhVoP6UHkFc8KtObntZHQ07CSYDc/KBepeVGDTmdaPTKrpREegA9Ac+GabjgpRbcwIZQUEz0aiC6b3pTa5QIBSVprIlyORFyJmNNSQnUOuhlSXcr1Yj6+DxfSpr+smFG9Wt6gFKg7AUlZRKU0wOoJnZb6QEIJ1Dd6C8Lh+6s6U0qG5CrQvVl1Fu2P/W0PhrUpjdBm1Hasj/T+UKBWwO27iTmkrbKS/RSMdDen+rfqhSEQwX1s9Tjf41SYUxv9JNrPCmVE1JrkwCVmd+4MK6fta1m6GVJd8snUT4+yAVt5TbLNlIt9BLc3+lkVsPKTG/UlL2gpEyCehqlsH3Tm9VNn3XoqwAgaYUsBCVlclaKG+YKSn40vak0SjpaHw3yAyxklL4g1QrpaX3cWpEXxCziAXrCOKlZRM8vyxeZokmhnUiKjJ7jvesCh0YLQdYnCUlQiuYKSiaBIyUXHZmDXpZ0t553s0hUqnPTapRUfp+IMNMbLWUvKGU1StJNqtEo0ZUwAcht2Zos0rIwYRH5pgxASQNbszx4pXuBVBEHKXWRX5XPl57WR0O4EuCkW1IujEtpetP1x/FAo1QK5gUnpjezcHU/a9EUcicSnxdo1XO8d13gUAuPhFq2uPQc5/kUmvgolZRArYNulnSXTG+6ArGdiDpa7aC8uA73I8/KzlAoe0FJmWBT0gOg8VGyb3qj0oDIwoSFQ7ciNMgCVa6gFKnOChrFTBGQjovZfwFd05uuIzcg+lvlRL6RCiS5IbeAewO23iqwFPx19ELOaZ3j9f5nPwuHCupnKR0nSr9RTHT7222Bw4ZfS0ISrmJ5gpK0KEt1i2YdFSVlotVBL0u62vRmlkWa5twythYgdjVKzJHbFkxQkm9cWVByGPVG6rui0a4oGiWLem+y0CBra3JNb4GAqe9AwVBPUjqmN92s3DI5kW/U6RZsmJmsMDO9+XkycCLgmWnRSkJTkMp5lnzu0J1bpxDwwLybpDe9xdOiU3w0N/giWgvFZSBnUVZSmkcddKNFpXtfgIAUn3J8bscLEI0PHkGqB5YawBFlLygpD0Uq36cmFqaPerPlzB2tkjZ2mhyhGoDktuqtDvwQ+Sav3oNRTT0pPa1PHjmRb6TmBy81IKbO3D4WGnQFPFINnYVflpNVdUHI1c763E/J1PHeLdObWnhMdhGlJElIglIslJMgNhAAYtKiJmdRVgrPhhlm6UAAZ+OJrkAcsvFcUZvemEbJCWUtKGX4jLI6iCalcOKwjumNxkeJNPxaPTBWDhQ3WtzwWW2AmaBUJ74XU6OkI3QChBqlnOzctAkn9YQCL9MD+HnVbBpyTtifeseSHF90cgMjfC4o6T0brgscuYKRlZ8Sn8kKDTkZ9gEY+imVgrbVDD2TdTgQBidp0Jw882amN17gkebTZCeiTfXAUgM4oqwFJU1Oi1R+gkS16Y1U0ieu9aZeWVQNFjd27TY/d24yS72b3g+RbzoRbwCBjxKQ76PkIN2CWxoQvVVgKfjrOBHwzMLV1d/7llwzdomY3jw179IKj4lOxOWcZBE9QUl/rCkF/z0z9O59juNcKWNiVvyY6ty0ZlSmUXIEE5QkYon8BImyRokXgDRPJyhROXNXDRI3EmuUTPJh+EJQkkxvuRolq6g3wNCZmyacXcYtDYiuWaQE/HXM1Px2TG/hQBhBKfGg70O/84QCfwtKZvevawJHnvBoJSh1IKGkhqjM/96gjEkpRISaoXfvA+5okfUE4kggktVWkYwnfAZQ70dybxvl3mMQwQQliBNAQK6dpioJIudRAsj9lEhXHRrTRr8GcWOXeSXo7ApTijLRWx2Y1GAqGEpBXO3gSubMLT3Idp25dYQCkuOJzu2BtspLnNR60zO9qc/lZwERAL1QUGR07zG3hXFa4THRiXhAW9tQg5VGye/3iAFe3vt6AjHHcXT+aHr3tkVVh6xGqZa4rYwsZS0oZW3RqizRKi1IJKgSlFJkkW/ECf3UqxbZ9NZtLigpPgu8iaDkC42SfkFcvUEiDyNnbhvh7G5pQKycO/06Ieia3ghrERqZSUumMrxSwkSKzPK7RklHi+G6eVc218iLCas+ias0SnqLGwsfpb5kegPcufeNFotUQrEi8Er3tpCxXhgrPkrM9GaHshaUlAdCLqeRE6UVCHCKsESsUaLUgGhMb6QaJdnhr8QEJT2tTx6yRklOOEmZbqFQq8BS8Ncx862yo6EDSmgSlCeTmiHiu88FJd10DG73tewAXDdCfLdy5lb7KOktbgxSkfQV05sX976VWY+oz9Tjqxx5aKUxZekBHFHWglKvnCNETs8fybfD0xbGpa1NRmV6k1cdgiwomfkoHSRqrycYmN6InLlzot6oNUqhwqwCS8FfxyzknCoqU0XJRDTJk0ndSPG9RExvBan1JgtKFD5Kpqa3HG1GXzG95WmUXNDwGS3oqPzR1ONrPzL/VubM7YyyFpSUCVBKUw+dEFjaem+kN7zW9CYJSj37gIxxeKhybkFqi66gVCe++0KjlOOjZDBIaMhx5raloVOfrgCrQL9OCGYh51YZho1MBCWTI0eeTPpLgpLPC+Na1XpzxQ8ulSsoWU2upKa3HI1Sqdd6M1jQueEzZjhO0QjFSVWENmFqGZYewBlMUAIQ5SRBSVejRJdLyVY4e+UAqfSIYDqgK+eG1Bbfm96qNJuNBA4NOc7cpFFvVqY3T1aBPvfXMQs5t8owrHes+njfm94U7YlKo2Tl8FpEdPPrhGzk1zEjT8tm7aNkanoz0F6XjDBtgJXZ2YkAaKj5ptIoqSK0+5EKSkyj5ISyFpQUZ27JhJJrKgLsm96oTBuBYHZlYGJ+UwYgafAyFZR8HPVmN4+S2arayvTmySrQ50KDXuI80gzDRqa3UsgfBUDljzNcfCdxeC0iZpnl1d87IlfLRmJ6C4jjn65foVF6AJ9rWq2wuvcdjSVu+FKqNUqK6Y3UR4lFvdmhrAWlrEZJ6gadpGoRynpv1NXu5QFINr+ZRL4pQgPHAYGQJpVBtgF14nvvweKtoD0wvQFAkk/qHSHubhRN4qLpzXCF6VOhQU/ACwVCCHDyPW3cJ65E5xQTeTKJ1aocXv3r0K2nxdBkg3ba3zwvFgcGtFo2M5OelTO3RXqAUjW9eXnvW5n1iMYSOaJT7aNk6ZjPTG9OKGtBSblp5TBLPY1S2L7pzVQDkrtqkQWlLuPBXBHCOE4UKGTNkhrZbwACkGgnarPrODG9yZNaoiNvX7OB10sNiKFzp89NDHoCHmnOFqO6fCXjf2LH4bWI6N1jmmzQTvtbnUNJFpQyCZjWl6RJD6Aa60pGmDbAyOzshgBoZNazZXqL9CO7twWBmd4cUtaCkqLhkAUlF6Le1A+A2UCRt7JQIt+My5goA5AsKOkRimad0osV+eYo4aRKo8TzxNFlhlofL1eBPja9ZfiM4tdiR3jUK7Wg/tv3k2CScjIpImk+jbQUyepZgk917p3K+uwYYdYniU6yqDc+pUmCKLc5I2RM/eD8ilXEpxumN0fRpEn1IkD2UTLRKKV6RNMzwNID2KSsBSVlApQXQ3pRb5SmN/UDYPZA5ZverAdz5WEKBCCYqVCLHfnmRsJJCMrKiWSAshyAPFwF+tH0pqljaCN6x5XonGKSopxMiojmt3KSX8cM+ZkMV4qaaJI+SVg4c4crATm1ispPSbNY9OEiwgor05vbtd4ASu10SuXaQOLMLfsncUFdqwnDmrIWlJQHQlYbm2iUkoQapVAghJAURWc2OedN7AS5lDT+OmYq1GJHvjlJOBmKqQbfDs3+JBoQLx0wvQgX9gp1XxkKeASmN0cmgmKiLsxM6vBaJNS/g6F512l/5xb9JtGyWaUH4DjdsUZdu8z3ArUOrkSmGWAVTUpWwoTSrKw2u+m5azAsKW9BSZ4AZadnHedoJT0AoaAkHmM9geatLOQyJgSmNwCI61Xzlim2oOQk6k1tVsyJfCNyPjYwvXmxCvSzv47cV+FAWHHeliHS0FlF+vlQOFQQBFUINUWumSIh92UkEDH8rZxrlHKeSVkTYeYEHO8wr/UG6JYxUfvB+fo+McDLVCOuRNTp+d/1HgAyBmZO5sjtmLIWlJQJUNYouWB6A6wfqAyftd0rAxCB6S0cCCMoR8HoaL8UZIfoYoVDGzlzk5jeAFvZua2y6dpdBer+Vrnn9uFkYCTcAWTCY0mb3jJJQJAWNhH/O3ObBTm4psFL5Wh5SUw2VholwHBRRpr/zI9Y1Xpzu8A2QKmdVkcVV/SXcvAB6Nmvv39cCuph/km2KWtBSblpM5IQpGd6kzNzE0a9AdaDm/phUB4Y0jImkmNzImoiKBVbo2SUHoDE9AYgtzAuyQBlpfWxO7jp/lbyuX0sNBip+AGyybekTW/q6uqapHz+NL2Zpc1wzbybp1EiMEeqnbmNFjcWuZT8+GxY4WWtN1dMb4pGqZ+Ug2+A+LeR0Msi3hxT1oKSouGQs97qJpy0b3ozGiR0HW1l05tVGRPpJ4vr5VCSKXa9Nye13gDkFsa1GqDMtD5OhRkzp2g/Cw1m2js3TG++ngDl+y8YAYIh32uUzEzSrvU3rY9SKo50Jom0rFEyWtwYBI74WdtqhSuRaQboJYFV/02dcBKw/i19bnpbuXIl5s6diyFDhoDjODz99NOWx6xYsQLTpk1DLBbDmDFjcPfdd3vaxrIWlLIaJcm2q+P3Y8f0ZnXTy9tDgRCCASkreGU9WRkT2fQWNhE2dPwGCgafySa2yzG9ESWcBJBbxsQqusxM6+NUmNH9reRm+tgPwywVA41zfEnWejPSnvi03puRBgNwURhXot5k05vV5JrVJgEmixuDRZmyQPGh/54VhoEhXmb5p0o4mfNbKholg/tb1ij51PTW3d2NyZMnY9GiRUT7b926FaeffjqOP/54bNiwATfddBOuueYaLF261LM2hjw7cwmgPBAZM40SXR4lwFoDoruqkMuYdO8RzW/Vjfrnls9hlrSxmKY3tdlDZXrjBV7JrG2acBLId+a2MD+YhsI7XAUarQDV7fKjdsXM9EaioVNyMJVirbc8f5wch9dguDjtMsBIgwG4eI/lapSUyXWfQaOyqQGM2gZAVQmgD2mUPKr1luJTyEj5jByZtGk1SnJ6AJ+a3ubMmYM5c+YQ73/33XdjxIgRWLhwIQBg/PjxWLt2Le644w6ce+65nrSxvDVK8gCVlkpj6GmUKDNzA+Smt7zBh6CMiex4njAzXxVTUFIntjNIvmmtUTKo92YwQJlpfZyuAs3MIqVgetMV8CyERxINnR+FQwVFoySZpzUOrwaCQRExM0m7JnCo8ygBROaaRCDrn8QZhZUb1JYsCROtAZaBIXbHkrT1go466g0g0g6KFymcRqmzsxMdHR3KK5Fwb4xcvXo1Zs+erdl22mmnYe3atUilvElwWt6CkrxykG9gU42Se6Y3Q1V7lbVDd5QXBaV4yEQZWMzCuOqIN9XgajZI5JET9WbZnwRCgV1hxsws4ufJwFTAsxAe1f9PKeWOUsidSAIBa4fXImIW5OBaCoqUKq8UoDVH6tWEjFskm5QxMPOXatSbaZZ0h/e+2XNFYg5XyM1TZ2ValktZFVCj1NzcjNraWuXV0tLi2rnb2towePBgzbbBgwcjnU5j715vzOvM9AYgKj/MLpQwAQg0IEaqdpKkk3wGCACJgMlPZ6AOLwgGEW9yX+tpffLIiXqzraGDcw2ImVnEz/46ZiHnpPenmV+Wr31P9BKe9hskCkk+FJRMHe9dj3qTtGyy4Cjw4jjRb4B2f5WPkqkG2KIwrh+fDTPMsqQ7rfWmHqdyNXRUCzp1UVzAOqpT8VGqpWqvEzZt2oShQ4cqf0ejFotjSnL7T66raqj5dIgnGqXW1lZ873vfw4ABA1BZWYkpU6Zg3bp1XlzKEYpzcVK68XXzKNFHvZGu2PNNbwRlTHhRs5UwEzb8YHqzU+dNxsCZ29Dny0zr49Iq0DR6zIerZjPHeWKNp41jfYHePejjFAGmjvdu9XeuA3Aokl1Q6Y03qhxK5kWspXMYmd78LFDrYJYl3XGqETNfNBrtdF4Eo0VOrCL4KFVXV6OmpkZ5uSkoNTY2oq2tTbNtz549CIVCGDBggMFRznBdo3TgwAEce+yxOOmkk/DCCy+goaEBn376Kerq6ty+lGOUSVCW0M3yKLmYcNJQ1a5k5zYxvWVSACKIBwkEpXRcXH2YpRJwm2SX+G432SRgnB7AyJmbZAByuAo0i0jyo+nNVMAjdI73VMPhJXpaTR+nCCBxvHcscOQ6AAPiBBs/qG+yITa9GWiUfKxtNcMsSzqVeUwH0wUIaX8Jgo0IRn+nB6BlxowZePbZZzXbXn75ZUyfPh3hsDeBGq4LSrfffjuGDx+OBx54QNk2atQow/0TiYTG0auzs9PtJhlfW0kPIDlzm/ko0ThzE0a9GZveduufmOcRS4uCUsJMxRitFgsgChnRd6CggpLOgAxzgSMPg6g3owHKS2fYgphFPMCJ34tRsknAufmhIKgT8sn4uN6b2T3mmsChq2UbBOz7xECjRGp6qxPf4x1iahBJ0+1n/z0zSEzWaT6NDJ+xdiHIwUkkqkI6DiCnNqnVve3zhJNdXV345JNPlL+3bt2KjRs3or6+HiNGjMD8+fPR2tqKhx9+GABw+eWXY9GiRZg3bx4uvfRSrF69Gvfffz8ee+wxz9rouuntmWeewfTp0/HNb34TDQ0NmDp1Ku69917D/VtaWjROX83NzW43yRBFE6GUMHEn4aTV4GaoarcyvSW7EJVKM5gOPxxnmAjOcywK4hJplIycuS0ynXthejMzi/jZvGDqW0WY58tussqiY6Q9AXytUbIToUhMrjM3YG6OTLRnNUokpjcI2VIZ8HdEqBmmWdJVz4Od+99UICbVTsv3NpDvo5Ts0n6vXFjSKPk0j9LatWsxdepUTJ06FQAwb948TJ06Fb/61a8AALt27cKOHTuU/UePHo3nn38ey5cvx5QpU/C73/0Of/7znz1LDQB4oFH67LPPsHjxYsybNw833XQT3nrrLVxzzTWIRqO48MIL8/afP38+5s2bp/zd2tpaEGFJEITs6oEXxPBhPUnfg1pvhisLK2fuRGc2PYBgnL0bgKgS79lXeEEplROGLEFnejNID2CkUSIZgJw6YJqVAvGh0EBierPlHC8JoxlBzIYeDvgrJxEAfe1JpX99lJT714mmwYrcJJyAuckm0YlEQBz7TDVKoYiouUt1i2a8ynqx3T7OMWYGyb0PiP9Xpc7CmuTcZjnZUnzKXFslj6/BqKK9Q7RGzEKfSYpm1MiInAsXPj0ADbNmzVKcsfV48MEH87adeOKJWL9+vYet0uK6oMTzPKZPn45bb70VADB16lR88MEHWLx4sa6gFI1GNY5eHR0dbjdJFzn5ISDlJgprw9mV9oXpo94snY+NJvbcMibBnJ8n0aFov+JWk7OBk6XnJHVWrnBmerOtoYNzDUhfNL2R3p9mZjv5+HDEx4JSbtQbUHIaJddNb6R+W6Q+SoC4KEt1axZlJaF51MEsMCTABRAOhJHiU7YEV5Lix4DYZ5UBAyFMT1vKceJv2dEqLgTqVIJSJp0VrnwqKJUCrpvempqa8jRC48eP16jO/IAmukEQdB25AZXpzYOEk3kDo1UZk0SnIihZDkDFinwzML0R13kDgKgUxprsAviM5araVOuTowGhhSQiyY+mNye13khMb4CPtQW02pMiQxJZ6bivcx2AAXMtm7ogrlUmfZ1cSqVuejMap5wEcLhi1suNXpQxKmOSVPn8+tRHqRRwXVA69thjsWXLFs22jz76CCNHjnT7Uo6Qb8YgF0AY0PVPAuyZ3kjDr/MGILmMCaBvfkt0ZE1vfhWUDExvxHXeAK0tvfeA5eBEIhSo20ADiXOnH1fNTmq9mUXncBzn6/8bQH4JE8Df6QHS9rV/xOhqlMwEpQ4yZ25AN29bqZrerBZ0TrTIZguQYCCIkJQbz/TcBsEyhgsB2T8pFBPNpAxbuC4o/fSnP8WaNWtw66234pNPPsGjjz6Ke+65B1deeaXbl3KEsnKQfSx0ypcA9py5LTUgZkKDbH7TK2MS78hm5rbSYhSrMK6B6c1M4MgjGM76a3V8QRzOXhHKj+5zqgExzUfkUFvlJU4KrZpN3OrtvtUWmGmUUt36Dq9FhCQYwblGiVLLRmV6q5OOOahs8rP/nhlmYwngTItsZtIGgIpghfW5DfLUGf6WPvdPKhVcF5SOPPJIPPXUU3jssccwceJE/O53v8PChQtx/vnnu30pRygTCSf5ARlplGz4KDlxllUi33Q1Sp3+1yi5EfUGADVDxPeOVutwdpNVIMdxjgZtU18fdS07nwkNykJAN0DBfroF9XbfaguUyUQ12UWrRQdYwLjUQ5HwvNabIBho2SycuWWNkpVfoU6ErZ8jQs2wCjpx4jNm5adJpK0yGF8NozoThU822RfxpITJmWeeiTPPPNOLU7uGMnHLgpKhj5IoKGV4AekMj1DQWra0XesNMI98U/koWU5SpWx6A4DaYcCujUD754jVDxPPYSPhJCAOQPFM3JnpTefckUAEHDgIECMoq1CVt0+xcJLt2WpA9722QG8y4ThxMuloFSeTuhH6xxYBEt8VR4J4OiGWKgH0NUrxg0AmJWpylUZ1IF6lzYlkiDLWHFQ2lXrCSSPNtxOzsysLEEuNUs4iwOepAUqFsi2Kq6wc5OyrOuVLgKzpDSDXKtmu9QZkC+MarPIUjZLVwOmzqDcq0xsA1Eh1gjpaiU1vhis1BxoQs0nMz/46TkqvkAiegI+1BYaTiT/9lEyjoRxmgwaQ7Q9A+1xW9JeCRyBG2srwPJ1GSfFROqhs8utzYYVVqSUnmjKrxSKRP5qVj1KutpSZ3lyhbAUl5YGQBwoDjVIklO0iUkHJdq03ICso6WXnVqUHKFXTG7lGSRaUvrD0C7BaqTnRgFgJeH6tkm7qICxtSwtppPn8fFxe9mdBoHV4LTIk6S3k/Dq2kJ9Jde4dAAgEVNFSqj5JdgEQ6NIDAJpFGTO96ZybcCwh0yiRmt6kJKDM9OaIshWUlJtW7gIDH6VggEMoIA4YpJFvpOHX9Ka3jhIyveVolGgSTgJZjVJ7q3V/WqzUnGhAiFeYPvPXIdEoAfp96qWGriAYhVD7VVAiqFUIOBBM9SLeZPT6RNJCJAKkprc68b0Pmd480U5b+GkSLUCMfksjbamsUYrVUrWVoaVsBSVlcpU3mGRZlf2UkqQaJQsNiLnpzdzBMsYTmt6KHvXmoNYboDK9fW4ZXWa1UnPkzE2YV8VvEwKJlgLQv0ethFq/atEUDDVKpWt6AxzcY3o5lGT0+kRyAE5ICW+tnbnzF2W+F6YNsNQoOUjXYLmgI9HCJfV9QDUCrzrLdZw5c7tB+QpKsnQv31MGpjcAiIbpUgRY+dSY5alR0gO45cwdbxeLVRYKt6LeVKa3KJd1MtUboLzU+hCry31mYjCLerPyrbLqT78KhwDEe11ul6FGyV+Ckll/y9mg1ftRoxcFKKOnUZIm17gkKFk+szr+kCWbcJIwMs3LsYRMo5SbcFISeDPJbKQbwHyUXKJsBSXlpjUpiCujJJ0kzM4tDyxGGhDTyArZ9CaXMdE0miLhpEGxSs8xsKFTm96qmwBwQCaJaKIrex6dAYrU+djWKrAEhQZNHUMbETaWA7qf/U80jss5z3Sl/wrjCoJAbJKx3d9GGjZAPzt3junN0q9QT6Mk3TtJPgleIE+tUmxInxtH6QGcjCVJA6E3UglEpKhbHe0g0yg5o2wFJUUNKpmyjBJOAvTZua3y6yiJx/QeGLMyJuoSJlaTfiiSfXAK5ackCJIjKJzVegPEUGVJu8Z1mvspeWl6MytYCvjTxKCpY2gjwsYyOsfP/idKMklOzEasxoc+Suo+dJRfxwwjny3AwEdJXFjFpUAX4hImqR4xFQHya5eVCsSmdjupRqxM2iQLEIP0KwAMzKiyjxLTKDmhbAWlrEZJEn5MNUp0pjc5v476OmpMV5CBYHbwyjW/qdIDpIW0dTboQqcIUOdryVm9UmuUgKz5Te3Q7cD01pvuJb+2hKmZFP7019HUMbSh5rfScPhROFRQJ1bMLXLtQx8lzW9l0d927l8A5holk8k1LnWfpUYpWgtI453sE2nlB+dXTHPcwZnpzTI/GUkqCIP0KwD0NabMR8kVylZQUm7ajCQomWmUwnQaJVIfEMOVmlHkm0qjJLbHZykC1GaPXNObhcChiyqXklm9Nyutj6NsuiXozC33R5ALKv4tuTgxvfna/0SvVIeMkcNrEZH7OsSFlFpfuTi+x4zySgGmPkoJSfaxXNwEAtmoKmlRRly7zGcQO3O7XOtNvd30uaL9LZX0ACzqzQllKygpDwRPolGi81ESj9G/6QVBMDe9AarIN5WgxGeApFZQsnborhPfCxX5JpvdglEgqB30LYVDPWrFjNxWSSe9ShKn9vWxDBf20aqZxHHeienN1wVPTR2XpRU3n9I6vBYRkufCuenNRAuhl6hQ1ihBsGybgk4ZE8e+VUXAy4STxKY3U42SQQkTgJnePKRsBSVlgJIdps2i3hwUxs296VN8CoLVAKSnUZKEEE51buukk3Xie6E0SiYqfkvhUA+53lu7eb03V/KT6KD29fEiAZ1XWAl3gLmwQ+rM7af/WcFsIglXABHJBOET8xuJSdo1Z25ivxZJoySZ0YmeWZ0yJr6+TwywEly9rPVGdG6b2kFmenNG2QtKsbQ0GRqUMAHonbkB48lZPTEZa5R0ypjIK4NAmLz+k87g5SkmTqPU6QEAXdNbbn9qNHQuO8OqJ6ZSSjhpZS4EzIVH4ugcP5rezCYSAOink4m6iJBkrHcscCh+WyaCUrIrK1DFO8ADSILXXN8UpYyJSqPkRvmVAmO1oHMl1YgTZ25Tf7McQUkQWHoAlyhbQUlZyWUkQck0j5IsKNGb3nJvenly4cAZ+o/oljFRrQzM/HU0FNpHyWQ178j01t5qqAHRaOicDEA6yG0OcAFr/xEfCQ1WA7L6O10NHWmtNz9OgGYTCeC7yDca05vt/k7qp+wQT14DBCPiZ9n8luhQ6rwBhJGqJmVM/PRsWGHpR+Qk1QhprTdTjRJBBKP8O6bjopkZYBolh5StoKSs5FKyRonA9Ebho2SlUYqFYuByo3Jk9ExvKlszsYak0FFvBpMUkV+WHrJGqfMLxAwGXRINnV3Tm1pgMPqt/Cg0kKRiMLqHSPyy/OjArmA2kQC+E5RIngvHwrhZCROOy++THEGJSKOkY+b3o7bVCq9SjfACr5jyndV6kyIfdTVKsrZUFnilOQNcNlUMwxZlKygpD4Q8+LiYRwkwHiRIzCKmprdoNbmGpOBRb/qTFJFflh5Vg8WcUnwaUUGqt5czQMn9aab1sSvMkETq+dEPw4npjcQvy48O7AqWGiV/pQggMUk7FjiMyl7IKH2yT2pUp1IQ1ywaT4OOmd+P/ntWEJcZofwtNPmy7Jq0M2kx8zZA5qOk9k8KlO1U7wpl23vKAyHn/dGLkpHICkrOo96IfHX0TG9KhtUa8lWNT0xvRH5ZegRDUobubHRi7uSsNjMZaX3srshJzCJ+Nr2RCHh5/Ungl+XrCdAsIR/gP42ShQYDcKG/zaLegPz8O/GsRol4YaOjvfa1QK2DRutjFbxBO5ao9red9Vu+twGLCMZ9YpS0as5gOKN8BSWl1htBCRPKWm8AmenNEKWMyf5sGRNVKnpiDUnB0wMYFMQl8csyQjK/xaSVlJFGyQutD4lZxM+mNzuTL4lflh+1aAqKacLK9OYTjRLN/WtXGDeLegN0TG9ZjRJx8IXOoszXJlodiLKk29QoKfmyAiEEpdIweee2Gkvk35ELZv3K1FRKpjeBF38Hec5gqQEcU7aCkqbWWygmZsQ2IJtHyYbpzcCZ23QA0itjoopeINZiFMv0ZqBRMvXLMkJKERCVohPzTJkUQoFddbnd6LFiQRJyTnJ/Gvpl+VlTYCUU+KzeG5XjvV1h3OC5VOiX0yeJDiQC4m9PrAHWWZQ5zv9UYEi0Prb9HQmiGy3HdXVEp96zGQxnx/zuL1lqABcpW0FJU+vNRJsE2DO9Ga3YiTJU65Ux0fFRojK9FSITcVLfR4lIODRCinyLJXs155Kh8iOiXJGTmEX8KDQQDcoO7s+SML2VmI+SmYbZcX8Ta5T2AukkkI7Tm970CuP68NkwgyRLut2oN6LFi6VGyeLeBrS/JUsN4BplKyhpNEomjtyAuwknicPkcyPf1IKSQeqBPGS/gUwia5LwEiPTm50cSjKS6S0qnduOc7xtB0wCs4gfhQYqAc/G/enraCazUHjAdz5KVPevXYHDLOoN0IaVK3XeKDVKOj5KftS2mkF77wsUi08igdiqv6xyhAFajWmCaZTcomwFJeXGFQg0SpS13gBjNSpxcdjcMibxrL2ZeACKVov2bKAwKQLkEiYmpjdqpMK4MWkAN9KAeOEMSxOR5KfJwInfS0HC1b2EWCiQHF6LDInpzbHAQRz19iXk2mCJUIVluzRU1ovvKr9KP/rvmUGTJR3QRohaQTWWGD1XZlnnZdQaU1a+xDXKV1CSV3KCYK7KhNpHyUbCSYMVu+VKrWqw+K5olLIRDMQreo7LqsR79pM13Akp/dW8I9ObrFGSC3UaRBF6aXozzUfkQ/MCkW+VhTM3iYkgySfBC+TPREGwEgpkh1cIhXkmLKDJeWXfR8nK9JY/ucajFZprW1LVKNZ4FDJAx+cAfC5Q60A0lqj6g+aZJxLCVL6UutoqEo2SWmMalwviMo2SU8pSUErzaaQFcdUjapS8M70ZTkSWpjdjHyWqEFUpvB7tn1vv6xQD0xuRX5YRsqDU2645l3JumlpZNk1vdgSOYuLE9EakoVP9jn76vwFYTybBEFAhaz+K76dEc//aEjjUuXcsIwGzDsCJcExzbUsCAaD/SPHz/q0A/KltNYNkbA4HwghKWnqa/4tIIFbdA7raKqscYYD2t1TmjFridjL0KUtBSX2DU2mUXDS9WWuU5KSTxs7cRBN//Wjx/cBW632dopjetFlgbZUvkalqAAIhJd+VkeBJsiJP8SlkKMwtBYlI8gAi3yqD+5PGbKd3fNEhmkz8E/nmea03de4dq0jATBLoaAUAxKXniUoL3H+U+C6NNaVW6410bLajoaYxsarbosEq6zyQY0ZlPkpuUZaCkvomjBL4KEUcJJw0dJa19FEyNr1RaTFkQWl/AQQlg9U8sV+WHoEgUD0EUZ7XnEuGJoRfvT8JVA6YPhIYiAQ8B/dnMBBUooJ8NwkSTSb+cej2vNabknsnABhdI1KZXdzs/0xsV0jM00PlV9hfO9aUWq030rHZjgBIsgAJBUIIcAFNWzTQaJR69jEfJRcpS0FJeSC4IDiAPOrNxVpvxKY3VRI48cBqugGofoz4Lg2AnmIR9WbL9AYANUNEEyl0+pMiZ5De8WbQhPT6yV/HSYQNqeO9byOaqDRK/jG9eeY8r/YbNMthJvtu5QhKVIubHO21H7WtZpCOzXY0fCTn5jjOfGwn8lFSaZTi2cW137nrrrswevRoxGIxTJs2Da+99prhvsuXLwfHcXmvDz/80LP2laWgpNy0ckSYB1FvVgn9iE1vchkTu6a3/oU0vclRGS6a3gCgdqiSQd2O6U2tAbGlUSKYxGjP7SU0IedGpjerCdKPTuwA6B1eiwyN87wtgcMqClBG7pN9n4rXCoYt25WHolHaBsCf/ntmkI7Ndu59Ym2VmT+lVSkaIMdHqTRMb0888QSuvfZaLFiwABs2bMDxxx+POXPmYMeOHabHbdmyBbt27VJehx12mGdtLEtBSXkg5H/fpM4bkPVRSrqYcNJyAFKXMUknsv4/dk1vB7Z7Hw5tUGeL2C/LiJqhikbJrNabGcoAZGdwI3CKBvxjYiBKwmkw+RL3px8nQUEgDKH2j6BE4zxvq6+tkk3KyH2yXxSUEtLCgsr0pow12wBBKDnTm5f3PrEQZpbNnOS3lH/HeLtofgOKYnrr7OxER0eH8kokjPvqzjvvxA9+8AP88Ic/xPjx47Fw4UIMHz4cixcvNr1GQ0MDGhsblVcwaFxdwynlKSjJEyAkVbSHCSftaEAASGVMggAEceCRidXQrWhqhop1gfiU95FvXiScBIDaYcYaJcpVoNumNz/661AV87V5f/oyoimdAGBdu9FPpjfPa71ZlS+RkftECimPS5MO1TNbNxIAByQ7gZ59tqNNiwXtvU/zf5Ga9UwXdFZZ5wEx8adsKZEXAkUwvTU3N6O2tlZ5tbS06O6XTCaxbt06zJ49W7N99uzZWLVqlek1pk6diqamJpx88sl49dVXXWu7Hvp52vs4yk0rb/CghImjWm+AVMZkoGh62/eJuC0YAUJRuhVmICgOYPs+Fs1vcgiv2/AZIC1l/84xvRH7ZRlRM0QRlOyEswM2HTAJfatiwRi6+C7fCA00fluJTAKCICh13Ugd731pepNNE4C5YFDpI0GJIueVnF+Hql4irUZJbhdtZm4ACMfE2owdrcD+rYhGfChMm0A6NtvxGSMdS0wXIFZZ5wExTYM8bygnLbygtGnTJgwdOjTbhKh+n+7duxeZTAaDBw/WbB88eDDa2tp0j2lqasI999yDadOmIZFI4B//+AdOPvlkLF++HCeccIJ7/4SKshSUlFWcnNPLKj2AnczcTk1vgGh+69qt+A3ItmbqYpP1Y0RBaf9nwJhZZMfQop6kcgZlYr8sI1SmN6OEk6QTu62QXgLnzq5Ul2+EBppab/L+uferpXDoR9ObbHYLRk2LXPvR9EaTX4dKy0PsozRQ8yd1rTeZ/qNFQenAVsSGTADgM2HaBNKx2U6xX+IFiJk/muJ/Z+4qgn6DcgSlwvsoVVdXo6aGXEDLFf7NFgRjx47F2LFjlb9nzJiBnTt34o477vBMUCpL05umzhtAnHAylRGQ4cnq+1jV0iKy/csO3fu1ghK1v00hUgTIqx1weQ8ylXCoR+0wRKV+z40uo3bAdDmkF/Cf0EDtW6VqN6njvS8jmmgdl/2gUSJJamqVX8cMg0LVeeRolOJc/rWJqB8lvu/f6k/zrAlemt5Iz22qrSLxvwNU2echWiHCNheoBWDgwIEIBoN52qM9e/bkaZnMOOaYY/Dxxx+73TyFshSUlJtWFnoIE04C5A7djmu9AVlBSdEo1WiOJR6AChH5pq7zlrMSoBIO9agciFggnHc+gN70ZifqjVhb5ZMJgcR5PhQIIcSFNPurP3thfvAcq/IlMrL2JNEu+TUVDxLHe8v8OmbY1ShJvl7UixvVWGNH81JMvLz3XRlLSCI6Aa3Q6/OIt0gkgmnTpmHZsmWa7cuWLcPMmTOJz7NhwwY0NTW53TyFsjS9KQ+EIJnSLDVKWUEpkc6gImLtXZ+bXyd3oCNaqSkhu5KPkiwo0YYLK7mUPBSUTB5iR7XeACAQQLQqu7pIpBOokIp20tr+qeozEeYU8pu/DvGgHIoinUrrapRIo3N8qVGymkhidUAgBPBpUatUO9R8f48QBIFIgyfn1+lN99ILpjZ9lOKS1pba9KbSXqs139S+VUXAy3ufWAgz86UkyREG5AhK/s+hNG/ePFxwwQWYPn06ZsyYgXvuuQc7duzA5ZdfDgCYP38+Wltb8fDDDwMAFi5ciFGjRmHChAlIJpNYsmQJli5diqVLl3rWRs81Si0tLeA4Dtdee63XlyJGGZykbM9WN14oGEAwID7kpA7dRvl1qHIKyRqlzl3ie47pjXjQVJve9IotuoGJWtix6Q1AqHY4QjoO3dSrQBshvaUUKp/iU8hICwA7JgQvk+55DulEEghkHbqLWO8tzacVM7Kj/DpmEEe95Thzy/cQrelNR6MkQECKT9GdpwiQjs22xhLaaFLdhJOkZlSVdrAEsnKfd955WLhwIX77299iypQpWLlyJZ5//nmMHCkGHu3atUuTUymZTOK6667DpEmTcPzxx+P111/Hc889h69//euetdFTjdLbb7+Ne+65B5MmTfLyMtQoN21GLIxrudqCqFXqSWaIs3Pn5teRNSBUOYVUWhTxpNWac+dqqwypGwGAEx+0rj1ANbntlxgTQcmx6Q0AaoYi2rEdaY7T14BYDUB2HDBJnTt95K+jHmDtmBCI/bL8aHojnUgAKTKoragO3er7hej+TdgQTEk1Smq/FgAJqWg49eJGXpR17UYskw1+iWfiiAQjdOcqMLS13uxopx2NJX1UowQAV1xxBa644grd7x588EHN3zfccANuuOGGArQqi2capa6uLpx//vm499570b9/f68uYwtFC5GRVjlWqy2oUwSQRb4Z5dehyimUs8qTVwe5EUuWhKJA7XDxs1d+SiZmD0e13mRU2bnVAxSt7d9OwklHDpgFRn2v2YmwoTHb5R5bdEgnEsAXuZTkvubAIRIwFyLsJEwFoBIeLSKlgmHRJCkRlzRA1Iubiv7KecLtreAga+KL/2xYQXvve5Fw0lQ7bctHqTQEJb/jmaB05ZVX4owzzsApp5xiul8ikdBk8Ozs7PSqSdlryhNgWhKUiDRK9Ekn9VS0pH4vALKmN6URWo2S2B5S89so8d0rPyUSjZLd9ACAmCKAz0866QfTm5+EBvVgb+UT4uT+9GWtN9KJBPBFigD1vWv1W9k2dSrCI4mWTeoTLohEJqm5LhX9R4mnObDNVv6yYkGbFNJWYAhpNGmuQMzzZCVMAK3pzefO3KWCJ4LS448/jvXr1xtm41TT0tKiyeDZ3NzsRZM0KAOUXNLDarUFe7mUcm/6DJ9BmqdQaRuY3jQRS9QO3R4VxyUQlGwnnARE05tOdm5a0xtpf6X5NNKS+cGLrN9eQeM4r+cPUdK13kjDpwFfCEo0z4VtYdyO8BitJorGM0RVHLeUyph4WeuNtD8NhTA5mS9AHtUJlISPUinguqC0c+dO/OQnP8GSJUsQi1k/ZPPnz0d7e7vy2rRpk9tNykOZXGXHZhrTG6GPEpCvRlXf/ESCUkV9Nh09oFGjUqt/vU4RQGB6c6RRqtWv90Zb6410wNb8VqQrTB9MBjQTnN7kW9K13qiEguKb3miCHGzfY1TCo9gnQqzG2eKmfzZ4xE+LCCuIC9c6qPVm26yXohGUSic9QKngujP3unXrsGfPHkybNk3ZlslksHLlSixatAiJREJTvC4ajWrSm3d0dLjdpDw0CSe5oJiUywI36r3ROG8CyE9HrxaUglF0p7ptJJ0sokbJiY+SWqMkXUutoXNb66Pu15I0vRFMcHqr15Ku9UaaMwjwh0aJImO97f62ITymo9XghU7NdalQFceNVZWe6a2Ytd4MtVXy+BqqEOcFMyJVQCgGpOPMR8klXBeUTj75ZLz33nuabZdccgnGjRuHn//8555W+CVFke4FQTdBoh60ztxA/k0vXzccCFtHqsnIZUwAzeqA2k7udS4lgvQAjqLeKgcoRYzj3W0AKLU+lL4S8rkjgYjlb+Unfx0ax3m9Qbm0TW8EtbBkfFDvjaYGom1fHyoHd1F4jEerAXRqrkuFOkVArTju+EHbaoVXtd7U+bJsm95oFgEcJ/6W7TuZ6c0lXBeUqqurMXHiRM22fv36YcCAAXnbi4XG9Eay0gJQGRW7qiOeJr5OrorWlt2/qgGQ5CS1oERvehslvvfuB3oPAhV15G0gwcDRkNovywiOQywYBSAgIQmOVBFelL4SNJOYn4QGGsf53PuTxi/L16Y3Go1S1x7v2mOBLY0SrcBBkzJBCh5JxKqBFFk0ni6yRungDsSC4wGUmEaJMOEk6b2vyZdlpVEy0k6TpnmQ6TdQFJSYRskVyrKEiTIJ8jzZoAqgsUa8gdvayR/4XBWtLbu/OvJNtTqgDheOVmcnBy/8lAzKR1D7ZZkQlXNR9YjmEnnSINH60KrLaSYxPwkNtgS8nPuT5Hg/5Y5SIC1hAgD9xWR26GhV1SksLDQmadv9Lfu2kIxz488GjvgW4lMvUK5pK5t29RCxMDGfRlRyA/XDs2EGaZZ0gP630Lhc2M1PlqK4twHgKxcBQ74CjPamSGy5UZASJsuXLy/EZYhRJkFBIFtpAWiqFSfpXRSCUu5NbyufkIFjni2fhfoxok/G/q3AkKnkx5FgYHqj9ssyIRbuB6R7kOjZpzk3jemCtL/sTGJ+mAycaClo/LL85MCuQBvhVTkA6NkH7P0IGDLF06bp4eX9q0CjiagaBJx7LxIHPyVuly6BgCiI7v1IiSz2g7bVDDtZ0mkDQzhwCKtqVuphOJbQmFABYPol4ovhCuWtURIE4huvqVZ8OHa191rsmSVXjWorn5A6RYBO1BvVCtPLyDcD05stvywDopKgmIgfEN8p+tOu6Y1EuPOj6Y0oksogKpNIQ+fHgqc0kwnHAYNEsxD2bPauTSbYEWqp7jFBIM+9o8KNkkPyWBNLi/mYfHWf6ECdJR0UGqV0diyxzG1m5ItGY0JluE5ZCkp2fJQaJUHJjuktdyKybXrTc+amWdF7mUvJwOzhKB9LDtForXjOeLv4TqGho62VRZOPyFemtzS5liLXhECl4bBbe8xLaCeTBllQ8j4liR620gPQ3GOpXgCS7YvUZAM6Ac4QyU8pmso36/oRO1nSPdVO547rtBolhquUp6CUG/VGwJA690xvVAOQbHoLRsVSJBK2fBaUFAHbyI8hxcD05kqySYlYhVgKJ5Hs0JybSOtDqQGhmcT85K9D5cydc38WxLnYS2gnE1lQ+vJDb9pjgZf3L4CsNgmgEpRoBGZDZI2S1AY/aFvNsJUlnTYwxMlYQmNWZrhOWQpKGtMbpUapvTeFniRZ5JuR6Y1KpS07neYUsrWlxejvYS4lIx8lN+q8SUQr6sVzShMilZmJ0vmdZhLzk78O1aDs4P70U+4oBdrJRNEoFcf05jSVgyU0uXdUuKpRineJ5ywRjRKNv1haSCsRvabnTlOMJUbjOk3iUIbrlKWgpDG9Ea4+a2JhVEkpAki1SrkqWlsrtfoxwLn3iy8Vtlb0sumt8wttplc3MJikXKnzJhGrFLVrCT4BpOK2JhrahJM0QoMfJgOqQdng/qQ9VpAz3Bcb2slk0DjxvX0nEPc+0W0utrR/djRKlOYaVxLE9pcFJclM7ieBWgc7Wh+A7Pewc+78qDemUSomZScoacJAeXKNEpDVKu06SPbQGyWcpBYajvgGMPwo/XPTDECV9VmH8APb6dpghUHxTTdNb9GYZHrjOKCj1VPThZ1JzA+TgZNBmapOnNSfvMATraoLAu1kUlkPVDeJn7/c4k2bTPC81htNAk4Vrpje6kYA4LLO3D7Qtpphx+wMkGn4qFKNBA20VcxHqaiUnaCknihpnLkB+sg3o4STbpihbJneOM6bUiaCACRFFbuR6c0VjZIcESIJSnacYePpOJEGhGoS85G/jh3hMc+Zm6I/1ccVlUwakCreU5knZK1SERy67QQjUN1jsnM7rUbJDdNbOAbUDEFUCrn3xT1iAo1wyHEclYbajkCcd24W9VZUylpQokkPAKgFJTqNUm7Um9N8QupzUztJepEiIJMEBKm0i4HpzRUfJbk/OQ7o+IJuFSgNQAIEpPiU5f52TG9+mAyoovVyzDk092c4EAYnl5Txg6OuTcdlNDSL70XwU7KV3oJmYaRolCqo2uXagq7/aKWQtR/M0mbQCoc0429vuldzDMl5885NkziU4TplJyjJN19IetFI6LRJJ41Mb65olOzWF/NCoyT7hgCGCSddMb3JAgnHAe2f2wpnV7fJDFumN0JtlZfYirCR7k8a4ZDjOPv1x7xAFpS4gCY61BIl8q3wgpLntd5saiFcW9DVj8oWsvaBttUM2gUdjbmdZiwJcAElPYFmbKfJOs9wnbITlJQHQv7XbWmUim96s+1A7EVxXPkhDkaAoDbzrCtqfAlFOMzxUSLpT7UGhGTQpspHRKmt8hKqaD2DhJO0q2pfTIJJlVBAU3ajiJFvnqdjsOnX4lqkav/Roh8ofCJMm0C7oKMZf2n9NHU11DYShzLco+wEpWxqAGkDjY+SlEuJNOmkUS0tN0xv1LXeZLwwvZk40boqHKpNb+2tVBMNrQbEjkaJ9Nxe4iQSkHpA91Hpluw9SGdmwqCx4nvXbqBnv7ttssDzWm82I6Vci1StZ6Y39T6k59b1R7NpRmW4Q9kJSsoDIW+gkNBpfZRcqfVmgO1JSlXZGxmXopWUsOyqvK9cFQ5lQScg+ihRrwIpVuU0Ah6ttspL7JoM1e/E5gc/md7sRgVFq6UILRRcq0SVjsFO8IbN3DuuRar2H62Y3nzhx2YC7YKOxvWB1qynO7YzZ+6iUnaCkibZJGAr6o006WSuetbNnEK2HYhVlb3RvtNxOwCoBuT8vnTTL0vrzP25fVMRyeBGkY/IT/46diJs+oTpzclEotR8K2zkG1U6Bjt9bVOj5NqCTq1RSruct81laBd0NOMv7YJOdyxh6QGKStkJSsoDIdnOaVZb1ZRJJ3Md/tx0bLadDToQAPqPEj+7ZX4rkOlN6U+OA3oPIC4JaF5oQGyvAossNNCo+eU2Z4QMUnyKyi9LfY1iC4cAnE0kRfJTspOOgTQbNADbfeLagq6iP6JhUcucSHVb7FxcqLWpFOOvXbOe5tws4WRRKT9BSV7F8frh7FbQJJ00SujnikbJiX+I28VxC2R6UzQgHAcBQCJ+kOrctkxvJeavQ1XWRdVviXSCXqPko4zkjiYSOUVAgWu+2cl5pT7OEptaNlcXdDVDxHOWikbJA+007WJR1x/NIKEvozCUnaCk3LSyoES52qKJfHOl1psBjkw9SooAlzRKJqY3L/yyeI5DGkBcKo7rSUgvpVDrF9MbzSQXCUSyuZAycfsDuh/8T5zUwmoYJ77v2SQmTy0QdkxvAEV/29UoubmgqxkuntMPwrQJtiPTSDJzUy4Wdf3RUiw9QDEpO0Epa3qTNUp0AyuNQ3duPSxXcwo5MfX0d1lQMlnNu1rrTTXQxDkOCSkbuBchvXaFhmKb3mgjAdUrYxq/LPU1fDEJOtEoDTxczL/Ue0CMfisQijO3k/w6ZjiMenNlQVcnFvWO+6XMjQG2TW8U/o62FyDppOhTCjAfpSJRdoKS8kDwYmp92nBLmqSTufWwvMgpZE+jJJne3PJRUsqX5Jve3BQO1RqQRIBDQpoIvAjppV4F+sBfhxd4JHmxjAfxoBzKCnjUfll+Mr058VEKV2SfiQL5KWX4jJJzy1F+HTNs5t6hicazIiotytIQkJEXpz7ErumNypnbrhCm9u9iUW9FoewEJeWBsBH1BtCZ3nLz63iRpdpW9Xa16c0NU4PJJOWmcKjWgMQ5ztuQXtpVoA+EBk0dQ0q/LTv3p+1cXl6gaE9sTiQFdujW/FZO8uuYkbSpUXIzUnXAodnz+kGgNsBuZBqRM7fNiDqlv+TfMRACQhGiczDcpewEJU16gFCFGAVGAU3SSU1+nQy9s6wZir+OnerttcMBLgike4HONsdtITG9uTHoAlqHblpTkR3TmxfaKq9QD9p2hEfb0Tl+mABTDsOnC5wiQFNz0kl+HTNsFsV1NVJ1wGHZ88qaZx9iO+EkiUaJ0qyXN5Y4XQQwHFN2gpKyWqIsiCsja5S+OGitUdLk10nH3a31FtJqq6gIRYDaYeJnN8xvBTK9AcjRKNH1J40GhNa50w/+OnJfh7gQQoEQ0TFqp1RqvywfFQN2XAtLqflWmMg3+T4JBUIIBoJEx1AHDCTtTbBuRqoGaoYhLOdSOrDN8fm8grrWG0UCUNoFcr7pjeVQKjblJyipTW82JHRZUOqIp9GdIEg6GcyfiNwYgDT+OrZSBLhYHLdApjf1eRLRaiQ47TYrSFfkgiCUpL+OnYzKGo2STb+sYjuwA3BeC0tOEbBnc0Ei32jLWgA2AgZsTrBuLugQCCAmR1Ye+NT5+TyCdmym+S0cR9TZNKGWEnfddRdGjx6NWCyGadOm4bXXXjPdf8WKFZg2bRpisRjGjBmDu+++29P2lZ2gpDG92ZDQ1Ukn2zoIHLqlB6or1ZW3zQkafx075h43i+OaTFKua5TkQWTQ4WKGbopzk2pAnPiPFNP0ZicVg9qEYDs6xxcaJYe1sAYcAgTConbUrYz1JtgxSVP3t02NEq3Z2YooJ2rMEge3u3I+L/Dy3rdd6y3XmbuPapSeeOIJXHvttViwYAE2bNiA448/HnPmzMGOHTt099+6dStOP/10HH/88diwYQNuuukmXHPNNVi6dKlnbSw7QUnRcPCCbQm9iSLppLxCaU+0Z7e5NQA50WK4WRxXNr3pDMhu+mWpzxMfeCjikn+Z29l0Nf4jJZRw0k5fq6PeaCdIW/XHvMJpLaxgGBgo+dPs8d78Zke7TN3fSp+QC492ovGsiEppDeIFEEDtQh0YYsP0ZlsI6+MapTvvvBM/+MEP8MMf/hDjx4/HwoULMXz4cCxevFh3/7vvvhsjRozAwoULMX78ePzwhz/E97//fdxxxx2etbHsBCWtRsneoNpIk3RSuunbk6KgFOACxP4jpOd2lnSyMKY315y5ZQ1d3XBlm9sOmPIKMMgFEQ6Eyc7tA38dt0xvXhQZ9hw3amEpkW/eO3TbeS6oNMg2c+/Y0aZaoQgVHZ+7cj4voI5Mo/gtaIXivIi6Eixf0tnZiY6ODuWVSOiPEclkEuvWrcPs2bM122fPno1Vq1bpHrN69eq8/U877TSsXbsWqVTKnX8gh7ITlLQ+SvZuvCEUuZTkwUbWKEWDUXCSycgpjnxECmB6UyfZdMMvC8hO4u39BmS3xTuIjiVdBdoxi/jBX8eJ30tvutf5yreYuDGZKJFv3qcIsBNZRhUwYDP3jp1oPCui0vUTbkTYegSt4Er6W2T4jBKVbDu60UnW+SLR3NyM2tpa5dXS0qK73969e5HJZDB48GDN9sGDB6OtTf9+aWtr090/nU5j79697vwDObij2ighnEa9AWqNEoGPkjyxS4KSW6s09bltTVRyYdz4QaBnP1BZb78hBqY3Ofkh4N6gqwievPg7BgUB4db1gFRTygxSDYgd4c4PQoMtAU/6HzuTndltpWh6c2MyUSLfvBeU7ESWUZnabebesRONZ0UsUg10A/Hu3aKjvEsLRTehTgdC+FvYSgORO66XoEZp06ZNGDp0qPJ3NGr+v+cqDwRBMFUo6O2vt90tyk6jpDG92fRnGFJnw/Qma5RcsvsDDrUYkX5AVaP42amfkoHZQ62Wds0vK7c/BQHY+SbVsZbO3DbMIn4QGuw4zuf2J83xfsgdpeDGZKIISlsAj7NIO3K8J+lvm7l37GglrYhGawAACT4BdHuz4neCHb8s0uAN9VhjO5rUDbNygamurkZNTY3yMhKUBg4ciGAwmKc92rNnT57WSKaxsVF3/1AohAEDBuge45SyE5S0pjd7ETKNteRJJxUNSNIDjZJTB2K3iuMamN7kdrnpl6U4x8v9KQjA529THWvVX3bMIn7w17GTiiH3/qTxy/JD7igFNyaT/qOAUAxIxwGPc/7Ycbyn6m+TQtUk7XJLAwwAUWmcjXOce2WTXMSOXxbp2Cs/k+FAGAGObLrNW9A5DVTwMZFIBNOmTcOyZcs025ctW4aZM2fqHjNjxoy8/V9++WVMnz4d4TDZ2EVL2QlKykrOgemNJumkvELpSNBVuifBsQOxG8Vxed5w9arWzLilEpX7T+lPQQBa14vOq4THWq0CbZlFfGB6syXgObg//ZA7CoBoznEje3EgCAwaK3722E/JjuM9TcV6uxo2t30KAZWAxwXcK8TtIq6Yxwywk2ohb0FXgholGubNm4f77rsPf//737F582b89Kc/xY4dO3D55ZcDAObPn48LL7xQ2f/yyy/H9u3bMW/ePGzevBl///vfcf/99+O6667zrI3l56MkT4K8fdNbbtLJflHjbsxz5vaL6Q1wpziuPCAD+aY3l/OxqM+l9CcCQCYBtL0HDJtGdCzpKrDUTG9OBDzFh44mXN0HuaMAiBogSEkinU4mDc3ArndEQWn8mY6bZoQd0xudRskHySYl1Nn0/axRosqSTplqxI45vJSj3mg477zzsG/fPvz2t7/Frl27MHHiRDz//PMYOXIkAGDXrl2anEqjR4/G888/j5/+9Kf461//iiFDhuDPf/4zzj33XM/aWLaCkhONkpx0siuRRltHHIcMyi/dIZObHsAL05ttLYYbKQJkFT84sXaeCjuDhBWKc7zcnyHpN9z5pqWgRKoBsSPg+cFfx5aAl2N6s2VuLLZGKakS1p1OJoPGie8epwiwlfOK5nm3aa5xs86bjLKI4Dhg9weundctnESLJvkkeIE3NKs5EYizeZRKL+qNliuuuAJXXHGF7ncPPvhg3rYTTzwR69ev97hVWcrW9OYkPQBAnnQyN+rNkwHI7kQlmxna3iMyXemSUtXYyikw7IljaK4zd7Ra/OLztyyPJdWAOM1HVCycmN7s3J/Utce8Qr4HQzHRfOYEuZSJxzXf7Dje01Sst61RcrHOm4wiUHMcsHWl547ytDiJFlUfb3ZuW0lgc2u99VGNUilQdoKSVqNkX0InTTopPyBy+LUXA5BtLUbDBKByoBjeTyBo6JLUd+QGvHEMzevPCimtwU7r9pNqQGxFJPnAX8fOJOfk/pT7J82nkSnm5Oe0fIkaOfJt70f2Fw8E2HG8p9Lg2fVRsnHvW6GMU6GomI7ki42undsNnKQDAcwFV0emt0xCDHtPSXNMH/VRKgXKSlBK8SlkBHFAjwq8IwmdNOmkfNMLkg+FF0KD7ck5EAAO+ar4+ZNX7J3DJLrG7Tpv6nMp/Vk5EOCCQEcr0G6e+ZdUA+IkIqlUa73ZuT81k0UxzW9uRgXVDgMi1WJW6/3eFXG1VeuNJnjDZpFgt0sOASpNWG2TuOHT/7p2bjewY7IOBUIIcaLnitnvYUerrt43kUlkx9g+GPVWKrguKLW0tODII49EdXU1GhoacM4552DLli1uX8YWask/5sBHCSBPOpm7SvEi6s3RJCULSp/aFJRMJik7q2Yrcs8VDVcCjRPFPyy0SqQaECf5iHyhUbIRYaP8bfPYoprf3IwK4jigQfZT8i7yzVatN5rgDZv1wTzxK5Q1SlUN4gafCUp2/bJIxl8nArFyfMpFjSnDFq4LSitWrMCVV16JNWvWYNmyZUin05g9eza6u7utD/YY+YHgBCAiwJGETpp0MvcB8ZXpDcgKSrveAbq+pD++wKa3vP4MxoBhR4l/WORTItWA2MpH5AN/HSdqfuVvimMDXEDJuVTUem9u+3AoNd+8E5Qc1Xqjceam1Ch5YXpTBLyKOnHD528BiU7jAwqMXb8skvHXzqIrHAgjyAWz5zYZYxmFwXVB6cUXX8TFF1+MCRMmYPLkyXjggQewY8cOrFu3zu1LUaNMJBDAAQ41SmRJJ/MmIj+Z3gCgejAw+Ajx82fL6Y8nML25mpMlV0MXigLDjxb/sMjQTaoBsbUK9IG/jpPoHaO/rciL0CkGbkcFyQ7dHka+2ar1RhO84VCj5EmppWBQzN3Gp4Ftr7t2fqfYFQ5Jxl+7WnWNhlodMMMoCp77KLW3i9E09fX6tcQSiYSmynBnp3crDU2dN8CZRokw6aQT04YVrlWsP9SB+Y3A9Oa5Rmn4keIfu97NOj7qQKoBcWJ6A4pnfnMavQPYGNB94MTuukZJThHgYeSbk5xXRNq7lD1zpBd+hRqToWLq94/5za5wSHLv2zXraTTUfTzhZCngqaAkCALmzZuH4447DhMnTtTdp6WlRVNluLm52bP2KDct7zw5XWNO0kkjnJg2rHCtYr168JKFSFJM1MJe5GTR1YDUjQSqBgN8yjKihkQD4sT0ZnVuL3Eq4NEeqz6+qEkn3Z5IZI3S/s9MBW8nOMl5RXR/Je1pIbzwK9RoR3wsKNHe+yQBHE7NeolUL5CW7kHmzF00PBWUrrrqKrz77rt47LHHDPeZP38+2tvbldemTd6pu7N13nhxgwPnuOpYGNVSRu62DuMHJc/52AOhwfFqfsQMcUDt2g3sfp/uWBPTmxc5WXRNbxwHDJO0ShZpDrxaBfrBX8dJrTejv0mP7zNRbwBQ1QBU1AMCL6YJ8ABbSU1ptHc2tWye+BWqNd+jjxejVPd9AhzY7to1nGDX9EYy/trVqisLEFWxaqZRKh6eCUpXX301nnnmGbz66qsYNmyY4X7RaFRTZbi6utqrJmnrvAGOB9ZGgqSTuasUL8JuHWswQlFg1HHiZ9qVnskk5WVOFhmlP4dLDt2EkW9erAKL7a/jNMKG9lj18UUVlNzWKHGcyqHbG/ObK/l1zLDZJ57WeksngFhtdlHz2auuXcMJTk1vpukBHJreElINRgB5lQ8YhcN1QUkQBFx11VV48skn8d///hejR492+xK20dR5C4SAUMTR+UiSTuZplDwIu3VFg3HIyeI7bT4lgqg3T9MDyAOQ4tD9lqn5kMYBs9SEBich5zJemB88x4vMxbKg9MUG986pwpX8OmbY1LJ54leYK1AccpL4/qk/BCW7flkkrg+OTW+yoKRT+YBROFzv+SuvvBJLlizBo48+iurqarS1taGtrQ29vd7Y+mlQHgjBfkFcNSRJJw01IC7gasV62Xdgx2pV/TYCCExvXiSclFEGoKYpQCAMdO8BDmyzPJ7E9GY3UqVYQoOTkHMZR9E5xcJmckVTxswS3zc/C/C8e+eVcCW/jhkONUqeRufKY81ny31RzsRpZBpJwknb0aRSxnwW8VZcXBeUFi9ejPb2dsyaNQtNTU3K64knnnD7UtRoot5cUNOTJJ30MuGkqxXrBx4G1A4HMklg2xvkxxXY9GaoUQrHgKbJ4meTfEo0Dpi2V5jF1ihRDPjBQBChQLY2tl0tmi8STro5mRx6qpihu+Nzy/xcdrBzj+Xl1zFD0bLZzMztRa03WfMy5CtAtNY35Uzs+mWRjL+OI+qSXeIG5p9UVDwxvem9Lr74YrcvRU3WmdtZQVwZkqSThUg46YrpjePsRaSY5LDxJCeLmQZE8VMyzqdEogGx7dxZRNObIAiOBTzAvl9WcRNOysK6iz4c4Rgw7nTx8/tL3TsvxN/KbsFoYg2eiabXDC9Mb2pfSkEQgGAIGHOC+KUPot/s+mWRjL92zXqKtiolCUos4q2olJXRs1cKs3RPo2SddLIQCSddW80fKvkp0eRTMlHxe5GTJU8Doj43gUM3iQbEroBXTH+dNJ8GL0Vz2o2wcXKsLzRKbmcunniu+L7paVdNRCk+la2tRyvUkgZw2C2Ka9PsbIb6nkryUqFhH6UJcByZ5nKqEfX+CZv5sBjuUlaCklaj5IaPkngzmyWdLESttxSfcicb9OgTAC4ghkQf3El2jFIqoSrvKy9ysuSeT9OfcimT3e8DiS7TY92u+K1uSzE0SurBmlorpNqfekB30/xrFy+cuQFgzElArE5Mm7F9lWun1fxWdjVKZho8PgPIwrrNorhe5HsDVIsIWVDyQTkTx5FpLtd6A1QLOq/ubQYVZSUoKSYV3l0fJbOkk+r8OoA3YbeASxNVRX9g6HTxM6lWySSxnRc5WXLPp5loaocCNcPE/DdfrDc91u2K30Bx/XXkvubAIRKgi+bUaJTsCofFNL25XcJEJhQBxp8pfnbR/Cb3FQdOMzaQQKTBkydXgF6jZPPeNyMUCCHAiVONMk71H+WbciZ+q/UGqBd0crJJJigVk7ISlNz2UVInnTR16DbSgDjEk7IZivmNUCVOYHpzUzjMPV/eACSXMzHwU/JyFVhMfx21XxXHcVTHlrzpzctVt2x+2/wMkDHOwE+D+rmg/a2INHjyMwmO2m/Li8UNx3H6ArVPzG92TW8FqfUmC0rM9FZUylJQEn2U3Fl9ylolUz+lkIEGxCFqfx3XBCU5n9Jny8kmBgLTW8E0SoAqn5J+pJKVBiTFp5ARRDOm7RVmETVKdkwmJW9687IW1qgTgMqBQM8+YOsKV07p5Lkg0uCpBUdKQcwL0xtg4E/pE0HJdjoQmiz/tJraUI62ijlzF5WyEpQ0mbldWn021cm5lMgi3zwbgNxyIB4yVcyeG283NF9pMDG9eZGTJfd8eeeW/ZQ+1088aSXMqCcgL3wWvMJJX7theituwkmXS5ioCYaA5rPEz+8/6copnWhtiAI4bDoAO4nGs0JXqPBJOZOC1HpzWhqIaZSKSlkJSm6b3gCgqYYgl5JHpjf1+VybnIOhbLI9qyzd6aToYwAUrNZb7vnyzt14BBCKAb0HxAHY4Fij/lJPQLZrPxXB9ObEcV6THqAUa715XV1dNr99+Kx4zzvEiUmaKAWFzbxSTqLxrNAVKnxSzsTLVA3OI+qk+435KBWVshKUspm5edcG1aY6a0FJHnQigYji1OgWrtV7U3MIoZ9SSpXBW2c1XwjTW965QxFg6DTx8+ZnDY81WgWqV/t2fX2KYXpzkopBfUzJJZzMpAA+JX72ajIZMQOoahS1rC6YidwwvZlq8FL2nNudRONZYShUKOa34glKjiPTDO59QRBsC8XKgk5Op+B2oAKDirISlJRVt5saJYp6b26v0gCPtBjy4NW6VtTMGCGb3QLhvLp5aT6NtCBqmwqWHkBmyvni+1v35GkArDQgTiaxYprenGiUND5fpZZwUh3h5dVkEggCE74mfnYh+s1JriIiDZ5NjZKTaDwrDIUKue5bEcuZOM7Eb3DvKzmj4EA77fUigEFEeQlK8gPBu+fM3USRdNJtgUF9bldX9HXDgYGHi2H2n5k4sJqYPNQDudsConw+Q63PEd8AqgYDnbuAD57UPdaov5xMYsX013HD78XO8UWv9Sbfg1wQCDorcm3KxK+L71ueB1LGiyISnDhME2nwFGduuog3J9F4VhgKFUUuZ+JllnT1OGA7ea2JawOjcJSVoKQMBB5olMySTqondrfxTItxCEGWbpOIN/Ug4ZXpzfC8oShw1GXi51WLNE7dVqtAR9FjRfTXKVvTm4MILyqGHSnWQkx2AR+/7OhUTmogEmnwbOaV8spUrj5n3rNR5HImXmZJl//XABfQVBMgQfFFk7TyLOqtuJSVoOR2UVyALOmkPLi57dQMeKjFUPIpvaobPQaAKNmkJ35Zcn+ardKmf19s1+73NGHdpKtAW/4jxUw46YIztx2/rKKb3mzWNKOG41TmN2fRb05qIBJp8GzmlfIqQSxgIVQUMU2Al1nS1YKnbX9HKVUJ0ygVl7ISlLLO3O6UMAHIkk5aakAc4JkWY+SxoimjfSew92P9fUxqbHlR501G0dCZnbuyPuurtGpR3rFWq0BH/iPFSDjpQnqAUhMOAXibbDIX2fz20UuGJXJI8Nz0ZlN49CpBLGAhVBSxnIkTvyyrVA2u+KJJ9RuZj1JxKStBSZMewEUJ3SrppDzweKLS9qpifaRSjPYBgM3/0t8nKU0WOoKSV3Xe1Oe07M9jfgyAAz5ZBuz5UHOskTDjyIRVRH8dJ6kY5GM8cy72Eq/Kl+jRNEUsu5HuBT560fZpnOQqIhLGFeHRf6Y3XaGi/yig/hAx1cjGx1y/thlO/LLUY6+go3V3QyBOSGZBFvVWXMpLUFKb3ly0+VolnVScuUvJ9AYAk78tvq/6C9CzP/97k9W8l2p8Yuf4AYcA484QP68WtUqWGiUn0WNF1K44MhkGCTR0FscWPeqtECtujsvmVHJgfnPybBAFb9jMK+VEA2KFpS/ljCvE9xW3A/EO169vhBupGniBR5rPd7twQyCOy4IS0ygVlbISlJSBwKWiuDJWSSdL0vQGAJPOAwZPFPPHrPxD/vcEpjcvhENFQ0cysc+8Wnx/9wmga491egAXoseKknDSBb8XJykR4pm47qrac7xONpmLbH77ZJn4XNjAidaSKHjDZqZyr8qXAAQLuq9cBAw4FOjZC6z6s+vXN8LR864a2/QEVzcE4oSs5GKCUlGhc8UvYTJ8BikpJ4WbJUwA66STTkwbVsiD2r3v3osHP3jQ9fOjKgPEhgG7ngGW/EcbWZRJASOHAb0bgUeO0hyWkXKiFFWjBIi134ZOF3NCvXUvokdeBABoT7TjqJw2A8jeIw7U5Ts6d+ie20tSGfvtdnJ/qn/fox89mvp4x/Bp8R4UtuXdg54xaoSYOuOfJwGU0UxA9rdy0t+vt75ufI+lE2KfbH8UeOSfxOeWtSJeLuge//BxLP3YIBdVHYCqYcD2x4El//I2ilGCl3yA7CzoIoEIOHAQIODkf56c970yBjp4JjMch6NGDgNe/I7r/REJRvD6t1939Zxec+DAAVxzzTV45plnAABnnXUW/vKXv6Curs7wmIsvvhgPPfSQZtvRRx+NNWvWEF+3bAQl9QrMzfQAgHXSyYkDJiLIBTFp0CTXrikzaeAkcOCQFtJIp92pbp5HQFI86qn7AwEAvOi3odc+D/7nCQMmIBQIkZ2b44CZVwH/vBh4+z40zLgSTf2asKt7F3oN2gwAkwdNpm7XiOoRqIvW4WDioOm5vSLABTBxwETq48bWj0UkEMHkBvr/uV+4Hw6pPQSftn9alP8ZgOU96DocAC4gZgSXEwJSEuACmDiQ/rcaXz8ekUAEST5p3t+BACCkARtjghfP7MSBExHgAtbjlNlY4yGTBtL/zxzHYdKgSXjny3dMfws7564KV2FMzWh81rEVvYGAJ/2RKVKCTyd897vfxeeff44XXxR9BC+77DJccMEFePbZ/CoMav7nf/4HDzzwgPJ3JEKXc40TiqIvN+bzzz/H8OHDsXPnTgwbNsy18/ICjz0HtiJx11EYnk4jcNMXrjnIrfzoS1z497cwrrEaL157gu4+PakeVHqkPt3Xu8/bSerLj4BHvwlAAL61BGiSHvyVdwAbHgamfR847tq8w4JcEI39Gl1PXgdQ9mcmDfxlKnBwB3DGnUh85Xv4sudLw92jwSgGVQ6y1a7edC/29e6zdaxT+oX7oX+sv61je1I9qAhV2PqtUnwKu7t327quY978G7Dmr8CEc4FTfl2Yax7YBjx8lqhNuuRFoKqB+hROfqvOZCfaEyZmvycvBXa+CZzWkvXRIyQcCGNwv8G22mXFgfgBdKvLHunxxQbgnxeJguj5S0U/Q48JcAE09Wuyde+n+TTautsMvw8FQhhcOdjec9W1G7sXjhf/uHq9Le2lGRzHYWjVUFfP6dX8DQCbN29Gc3Mz1qxZg6OPFrXXa9aswYwZM/Dhhx9i7NixusddfPHFOHjwIJ5++mnb1y4bjVKAC6AxUp1dYYXostaaIWuUWg/2gucFBAL5D4VXQhIADKgY4Nm5AQDVw4Ajvg1sWAK89ifg+y+KmpoMD6QzQGWDuE8BoerPYAg45grgxRuBNXchOu0SDPOovRWhCs/O7SVO7s9wIFzE/zko3oMVAwt3D1YPAxqnieHsr94OfOfxgpiJlMtHqlEdqTbeIZUS+6RqaMGfSzP6x/pbC4djhwGHzgE+/DewajHw3ccL0zibhAIhz+79cCaFYemMWCKqdpQn1/CKzs5OdHRknfKj0SiiUWcm3dWrV6O2tlYRkgDgmGOOQW1tLVatWmUoKAHA8uXL0dDQgLq6Opx44om45ZZb0NBAvsApK2duTYLEgHv/+vD6SlTHQuiMp7H8oz2unddXnLRAFC53rskWmy1kxJFTpn5PLJWw7xNHod0Mn2Gzrplj5v5JzDP20YvAxkcKe20rCu3g7jan3CyWpPnoBWDbG8VuTfEo4d+xubkZtbW1yqulpcXxOdva2nSFm4aGBrS1GWv15syZg0ceeQT//e9/8cc//hFvv/02vvrVryKRIA+6KS9ByaOJPRYO4jtHjQAA3PfaVlfP7RtqhmQjyP7za7HYrEnUm++IVgPTLxY/r15kuiujhEgVKDN3LoObxcUDALxwo2jW9Qs28yj5hoGHAdPEoAss+6VxZYC+js3oRT+wadMmtLe3K6/58+cb7nvzzTeD4zjT19q1awFA14QpCIKpafO8887DGWecgYkTJ2Lu3Ll44YUX8NFHH+G5554j/n/KS1DyUEK/aOYoBAMcVn26Dx98YS9s2Pccew3QrwHY/xmw7gHThJO+5OjLRTv/9jeA1vXFbg3DDYqlUQLEhcPwo4FkJ/D0FQDPF74NeqRKVxOhcOKNooDQug7Y9HSxW1McSlijVF1djZqaGuVlZna76qqrsHnzZtPXxIkT0djYiN27830hv/zySwweTO5X19TUhJEjR+Ljjw0qTuhQXoKShxL60LoKnH5EEwDg/tf7qFYpWg2cJK0Mlt8GdEk3bSmY3gBRKzbxG+LnVX8pblsY7lBM828gCJyzWLz2tteAt+8tfBv0KKbw6BbVg1Ua7N+IGuxyo5RcGxwwcOBAjBs3zvQVi8UwY8YMtLe346233lKOffPNN9He3o6ZM2cSX2/fvn3YuXMnmpqaiI8pL0HJYwn9B8eNBgA8+84X2NNRpNpXXjP1QmDgWKB3P/ClWBakZDRKADDjSvH9gydF53RGaVPIEiZ6DDgEOPW34udlvwb2flKcdsgIgsocWULPpR4zrxI12Ae2AuseLHZrCk+x722fMX78ePzP//wPLr30UqxZswZr1qzBpZdeijPPPFPjyD1u3Dg89dRTAICuri5cd911WL16NbZt24bly5dj7ty5GDhwIL72ta8RX7u8BCWPJfQpw+swfWR/pDICHl693ZNrFJ1gKDsxyJTSg9w0CTjup+LnZ64RC5wyShc/rLqn/wAYM0vM4/TUj8R0FMUinRCTYQJA2L3I3qIQrQZm3Sh+XnFbQUub+IKUlPKlj2uUaHjkkUdwxBFHYPbs2Zg9ezYmTZqEf/zjH5p9tmzZgvZ20f0lGAzivffew9lnn43DDz8cF110EQ4//HCsXr0a1dUmkaM5lJegVAAJ/YfHi1qlJW9uR2+y9BJ6EXH4acCo47N/l5KgBAAn/xqY/B1AyIiJKD9fW+wWMeziBz+OQAA4+69iVGXrWmDVn4rXFllwBErSCTiPr1wIDDgM6NkHvH5nsVtTWIoVqOBj6uvrsWTJEnR0dKCjowNLlizJy8otCAIuvvhiAEBFRQVeeukl7NmzB8lkEtu3b8eDDz6I4cOHU123vASlAkjopzY3Ynh9BQ72pPDkhs89u05R4Thg9u+yf8dqi9cWO3AccNZfgENPESeWR75ZfJMJwx5+iQyqHQbMuV38/GoL0PZecdohLwaDEVH7W+oEw9lEoq//P2D1X4vbnkLSF3zN+ghlJih5L6EHAxwumSlqle5/fSt4vo+Gtg6ZKq6iT7lZnCRKjWAY+OZDwJCviP5WS74GdBrn4mD4FD9olGQmfxsYe4ZY1uSpy0UzWKHxgynSbcadCRwj+Ra+dJPo3F0OKQP64m9ZopSXoFQgCf1bRw5HdTSEz77s7rsJKAExiaPs71OKRKuA8/8J1I8R8+As+YbtivCMIuGnyYTjxESUlQOA3e+Lk3qh62n1RQdgjgNOuwU4+Vfi36/fCTx7TXF9wQpBX/wtS5TyEpQKNKhWRUP4ztF9PAFlX6HfQOB7T4rRNbvfA574XnE0AQx6eF6VM8gnk0nVIODMheLnt+8DHjoLaG8t3PX9JDi6CccBx/9MFES5ALD+YbEmXKqPRhcDffe3LEHKS1AqoISuTkC56Ysyi9YoNepHA9/7PyBSDWxdKZpN/JI8kGFMWjVJ+mkyaT4L+Pp9QKQK2P46cPexwJYXCnNtP5kivWDaxaLJPBgR68E98o2+Gw3X13/LEqK8BKUCSuhD6yowZ2IjgD6cgLIv0TQZOO8fYgHKD54EHjkX2L2p2K1imKGJ8PLZZDLpm8CPVor3Ve8B4LFvi6VOvNZW+sW53UuazwK+t1Rc2Gx7DXjwDKCrD7o4lMNvWSKUl6BUYAn9h8ePAQA8805r301A2Zc45CTga3eLwtKn/xU1Ac9cA3Tmp81n+ABZQxyKuVrk2jUGHAL8YFnWEfnNxcB9p3gbYVkuWojRJwAX/xuoHAi0vQv8/bS+l+ajXH7LEsCz0eWuu+7C6NGjEYvFMG3aNLz22mteXYqcAkvoU4bXYVpfT0DZ1zjiG8CVbwLjzxIT961/CPjzVGDF77MDF8MflIIPRygK/M+twHf/F6ioFyf1v50AbHzUm8itUugTtxgyBfjBy0DdCLH+5H0nA3+fA2x5sW+Yzsvpt/Q5nghKTzzxBK699losWLAAGzZswPHHH485c+Zgx44iV9gugoT+Q6msySN9OQFlX2PAIaIZ7vsvAUOniwL2q7cAf/kKsOGRwkcyMfRJ+syR24zDTwN+/IaYqDXVDTz9Y2DRkcDKO4CDO927TrlFSslauynni5rgHauAx84D7joGWP+P0g7MKLff0sd4Iijdeeed+MEPfoAf/vCHGD9+PBYuXIjhw4dj8eLFXlyOnCJI6LMniAkoD/Sk8K2/rcYVj6zDTU+9hzte2oL7XvsMT67/HK9+uAdb2johlENukFJixDHAD/8DfOPv4qq1cxfwryuAxccCr94K7Hiz74co+xlFQ1wiK+6aIcCF/wJO+gUQqgD2fQz893fAwonAg2eKtQedOiaXoxaiuhE45y7g2neBY38CRGuAvVuAZ64CFk4CXrsT6D1Y7FbSU46/pU9xPXVrMpnEunXrcOONN2q2z549G6tWrcrbP5FIIJHISv2dnZ1uN0nVuMJL6MEAh8uOH4Nf/usDvNfajvdajfP0DKmN4dTmwZg9oRFHja5HOOhDv4tyg+OAieeKiQTfukfUAHy5GVixGVhxu5iVfPSJwKEnA4ecDNTRpcZnOKAUfTgCQeDE64GjfwRsfgZ453HRIVl+PXcdMP5M0fTbNFkU0DmO/PxJ75Pq+paaIWIdyuOvE4vorlkMdH4BvPIbUSPcNBkYfgww/ChxEVTdWOwWm1OK93cfxXVBae/evchkMhg8eLBm++DBg9HWlp/5uKWlBb/5zW/cboY+RZLQzz96JMY21mBXey8OdCdxoCeFAz3Se3cSB3qS+PTLLnzRHsdDq7fjodXbURML4aRxDZjd3IgTxw5CVbQPlCMoZcIx4NhrxCSbW54HPvkP8OmrQPygOOFtfkbcb+BYYNiRYsqB+jHZ91Ir81IKlHJUUKxGvJemfk9Mdvru/4pC076Pgff+Kb4AsX7c4AlA40RgsPRqGG88eSplmkqwT9wiViM+q0dfDry/FFj1F2DPB0DrOvG1RiqDUjcSGH40MOJoYNB4oHYoUD0ECEWK234ZZb4q49/SJ3g2+3I5qyBBEPK2AcD8+fMxb9485e/W1lY0Nzd706gi+TQEAhyOGl1vuk88lcHrH+/Fy5va8MrmPdjXncS/Nn6Bf238ApFgAIc3VqGhOobBNVEMqo6hoTqKwTXi+8DqKMIBVd9y8lt2mwABgiD6jyqfAaXECi8I4AXxXZA+Z3hB3M4DGUH+LCDDC8gI4jky8t/SNs3fOeVb5J9ffg8GAqitCKN/ZRj9KyOoqwyjKhrSvU98Q2V9doLjM0DreuDTV4BPXhELou7dIr7yjhsA9B8tCk6VA4GK/tKrTvW5v2g2CMdE00xfqNXlJX1lxV03AjjhOjGh4hfrRYFp+yrgyy1Aol30u9mh0sZzAaDfIKCqQUyUWjVYTHRZNRjY/YG4T6n3iRuEIsCU74ilZQ7uAHa+CexYA+x8S8ycfnC7+Hrvf1UHcWI/1g4FaoaK5ZlqhgCxOiBaLQph0VrpvVp6XivotH6kpPrI/d0HcH0kHjhwIILBYJ72aM+ePXlaJgCIRqOIRqPK3x0dHiUPEwRf23xj4SBOaR6MU5oHI8ML2LDjAJZt2o2XN+3G1r3deL+1A0AfTaymIhzkUFsRQf/KMPpFQwgHOYQCAYSCHEIBDqFgAOEgh2AgoIiBsjiW6+MV4DgEOPGdU31WR5KrD5E/CxB0tmnhII6NHKIIBE4H6s9ARW0HDu3egIb4VgxIfI76ZCvqE62oTu8Xq5/37BOFKUIyCCIdiCDFRZEKRJHioshwIWS4EHguKH5GELzyHgDPBSGAg4AABHDiNukzwEHgpH9eeRe3g+OkfeT/TvU/c/Lf2e85ZTe1gK4/WYh9qBXarbBy1xMANMU/xSEA3tmdwiP/947ub2V2Hk07dI8VNNtyzy8I0hmE7LnUixHlb+XY3G2C8p38t8g3gMg3EB6axrDM5xiR/AwjUp9iePIzDEt+iurMQaBrt/gy4PF39uO1beuV/1NuV97/ndsnef9jTgdBfIZCQU58D3AIBDgEpW0cx6meDU56z18461/bpF0G7cx+L1h8DwDjAYyHMPgSRAd2Y3jPJozsfhcjet5HfXIXalN7EBaSQFeb+GpdZ9lmAODBIcOFkQ5EkebC0ucI0lwEaS4MXnpexWcxKH6W3znp2eQC4jPLic8uOA5TpISqv39lB3rC+S4pVj6tVk9ZMMDh13MnEP2P5Y7rglIkEsG0adOwbNkyfO1rX1O2L1u2DGeffbbblyMnkwQEKVopXFG8dhAQDHCYPqoe00fV48Y547B1bze27evG7o4E9nQksKczjt0dCXwpve/rTkBW3uQO7uI2IMBBfxCThQeOU33WChfBAKcIGEEuOzAGpM/yYBmStgcD4isQEK9nJMikMjwO9qRwUDJFJtI8UhkBe7sS2NtVqtEqo6VXln7oxQhuD0ZyuzGM+xL9uU7UoRu1XBfq0IU6rht1XBdq0Y1qrlc5LogMgnwvougFWKCdIRv2h/G/ez4vdjM8ogrAJOkFAAIGogODuQMYxB3EQK4dg9Cu+ZxCEHfuOAx7sKuI7S4FBgM4VXoBgIAB6EATtw9DuX1okl6N3AFUowfVXA+q0Itqrhc1ED8HOHFJEhCSCGeSrrewR4jivrf3Ign3a1BGQgEmKBHiiW5/3rx5uOCCCzB9+nTMmDED99xzD3bs2IHLL7/ci8uRM2u+6OwYqSpuOyjgOA5jBlVhzKDSabNdepMZyXcriYM9KfQkM0hneKR4AekMj3RGQIrnkeEFpDJZoUvRc3DZv+WVOi+ZCNWmRZ4XNMoPvdWu5nvpCvI2tflS/Fs8t3yd3NOpTaAAkOGAfRBfuW2HwCMkpBDiE8ormIkjLIifA3wGASEtvpBBUEgjIGQQ4NPghAwC4MGBBycI4MAjAB6QPnOSWkEQeLGHBF58E3jJNC61RfrHOEk3pSarQeE10rig0jfpkfddXh8ZHScY78dxSAeiEBrPxvXRQarfX/t7mbbL5HfW7sdpzqU+t/Idp7pWzqJE/b2yTaVtUbZL3wkQkOGBDM+L7yqzN5+z4OA4sZf2AtgnNeAKk3bl9onR/Zrbfxwn3uNyW9K5ZveM9ByoTPvQaM2EvGchv59NvrPYOfd7q/8r93/LHpf9Iw1AFsHVz7kAAQLPI5TpRSTTg6CQQpBPIiikEOKTCPFJBIWkuA0ZcAKPgCA9owIvPrPSdggZ6ZkTAPDgBOn5FTL4omYSflQznrxPLPpITShgeTRDwhNB6bzzzsO+ffvw29/+Frt27cLEiRPx/PPPY+TIkV5cjoxQFJh1o/V+jKJREQmiIlKBIXX+1vgx/MUxxW4Ag8Ho03jmLXrFFVfgiiuu8Or0DAaDwWAwGJ7DEvUwGAwGg8FgGMAEJQaDwWAwGAwDmKDEYDAYDAaDYQATlBgMBoPBYDAMYIISg8FgMBgMhgFMUGIwGAwGg8EwgAlKDAaDwWAwGAYwQYnBYDAYDAbDACYoMRgMBoPBYBjABCUGg8FgMBgMA5igxGAwGAwGg2EAE5QYDAaDwWAwDPCsKK5deJ4HAOzatavILWEwGAwGg0GKPG/L83hfwXeC0u7duwEARx11VJFbwmAwGAwGg5bdu3djxIgRxW6Ga3CCIAjFboSadDqNDRs2YPDgwQgE3LUMdnZ2orm5GZs2bUJ1dbWr5+6LsP6ih/UZHay/6GF9RgfrL3rs9hnP89i9ezemTp2KUMh3ehjb+E5Q8pKOjg7U1taivb0dNTU1xW6O72H9RQ/rMzpYf9HD+owO1l/0sD7Twpy5GQwGg8FgMAxgghKDwWAwGAyGAWUlKEWjUfz6179GNBotdlNKAtZf9LA+o4P1Fz2sz+hg/UUP6zMtZeWjxGAwGAwGg0FDWWmUGAwGg8FgMGhgghKDwWAwGAyGAUxQYjAYDAaDwTCACUoMBoPBYDAYBjBBicFgMBgMBsOAshGU7rrrLowePRqxWAzTpk3Da6+9Vuwm+YaVK1di7ty5GDJkCDiOw9NPP635XhAE3HzzzRgyZAgqKiowa9YsfPDBB8VprA9oaWnBkUceierqajQ0NOCcc87Bli1bNPuwPsuyePFiTJo0CTU1NaipqcGMGTPwwgsvKN+zvrKmpaUFHMfh2muvVbaxfsty8803g+M4zauxsVH5nvWVPq2trfje976HAQMGoLKyElOmTMG6deuU71m/iZSFoPTEE0/g2muvxYIFC7BhwwYcf/zxmDNnDnbs2FHspvmC7u5uTJ48GYsWLdL9/ve//z3uvPNOLFq0CG+//TYaGxtx6qmnorOzs8At9QcrVqzAlVdeiTVr1mDZsmVIp9OYPXs2uru7lX1Yn2UZNmwYbrvtNqxduxZr167FV7/6VZx99tnKgMv6ypy3334b99xzDyZNmqTZzvpNy4QJE7Br1y7l9d577ynfsb7K58CBAzj22GMRDofxwgsvYNOmTfjjH/+Iuro6ZR/WbxJCGXDUUUcJl19+uWbbuHHjhBtvvLFILfIvAISnnnpK+ZvneaGxsVG47bbblG3xeFyora0V7r777iK00H/s2bNHACCsWLFCEATWZyT0799fuO+++1hfWdDZ2SkcdthhwrJly4QTTzxR+MlPfiIIArvHcvn1r38tTJ48Wfc71lf6/PznPxeOO+44w+9Zv2Xp8xqlZDKJdevWYfbs2Zrts2fPxqpVq4rUqtJh69ataGtr0/RfNBrFiSeeyPpPor29HQBQX18PgPWZGZlMBo8//ji6u7sxY8YM1lcWXHnllTjjjDNwyimnaLazfsvn448/xpAhQzB69Gh8+9vfxmeffQaA9ZURzzzzDKZPn45vfvObaGhowNSpU3Hvvfcq37N+y9LnBaW9e/cik8lg8ODBmu2DBw9GW1tbkVpVOsh9xPpPH0EQMG/ePBx33HGYOHEiANZnerz33nuoqqpCNBrF5ZdfjqeeegrNzc2sr0x4/PHHsX79erS0tOR9x/pNy9FHH42HH34YL730Eu699160tbVh5syZ2LdvH+srAz777DMsXrwYhx12GF566SVcfvnluOaaa/Dwww8DYPeYmlCxG1AoOI7T/C0IQt42hjGs//S56qqr8O677+L111/P+471WZaxY8di48aNOHjwIJYuXYqLLroIK1asUL5nfaVl586d+MlPfoKXX34ZsVjMcD/WbyJz5sxRPh9xxBGYMWMGDjnkEDz00EM45phjALC+yoXneUyfPh233norAGDq1Kn44IMPsHjxYlx44YXKfqzfykCjNHDgQASDwTwJeM+ePXmSMiMfOXKE9V8+V199NZ555hm8+uqrGDZsmLKd9Vk+kUgEhx56KKZPn46WlhZMnjwZf/rTn1hfGbBu3Trs2bMH06ZNQygUQigUwooVK/DnP/8ZoVBI6RvWb/r069cPRxxxBD7++GN2jxnQ1NSE5uZmzbbx48crQU6s37L0eUEpEolg2rRpWLZsmWb7smXLMHPmzCK1qnQYPXo0GhsbNf2XTCaxYsWKsu0/QRBw1VVX4cknn8R///tfjB49WvM96zNrBEFAIpFgfWXAySefjPfeew8bN25UXtOnT8f555+PjRs3YsyYMazfTEgkEti8eTOamprYPWbAsccem5fW5KOPPsLIkSMBsHFMQ7G8yAvJ448/LoTDYeH+++8XNm3aJFx77bVCv379hG3bthW7ab6gs7NT2LBhg7BhwwYBgHDnnXcKGzZsELZv3y4IgiDcdtttQm1trfDkk08K7733nvCd73xHaGpqEjo6Oorc8uLw4x//WKitrRWWL18u7Nq1S3n19PQo+7A+yzJ//nxh5cqVwtatW4V3331XuOmmm4RAICC8/PLLgiCwviJFHfUmCKzf1PzsZz8Tli9fLnz22f9v345R1YjCMAxPQB0QLAW1sbWwcgE2tlY2loIbsXIJNjY2ugIXYCu2YiVkK18KYS7JvQMhjSF5HpjqnGL4YYaXYc73XK/XzOfzdDqd6h1vVp/dbrc0Go1st9s8n8+cTqe02+0cj8dqj7m9/BehlCS73S7D4TCtViuTyaQ6yk1yuVxSFMWna7VaJXkdE91sNun1einLMtPpNPf7/b03/UZfzaooihwOh2qPmX1Yr9fVs9ftdjObzapISszqd/0aSub2Yblcpt/vp9lsZjAYZLFY5PF4VOtm9bXz+ZzxeJyyLDMajbLf739aN7eXb0nynm9ZAAB/t3/+HyUAgD8llAAAagglAIAaQgkAoIZQAgCoIZQAAGoIJQCAGkIJAKCGUAIAqCGUAABqCCUAgBo/ADn47D5niYGSAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_treatments(data: dict, patient: int):\n",
    "    df = pd.DataFrame({'N(t)': data['cancer_volume'][patient],\n",
    "                       'C(t)': data['chemo_dosage'][patient],\n",
    "                       'd(t)': data['radio_dosage'][patient],\n",
    "                       })\n",
    "    df = df[['N(t)', \"C(t)\", \"d(t)\"]]\n",
    "    df.plot(secondary_y=['C(t)', 'd(t)'])\n",
    "    plt.xlabel(\"$t$\")\n",
    "    plt.show()\n",
    "\n",
    "plot_treatments(test_data_factuals, 130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cancer_volume', 'chemo_application', 'radio_application', 'sequence_lengths', 'patient_types'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_counterfactuals.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_treatments(data: dict, patient: int):\n",
    "    df = pd.DataFrame({'N(t)': data['cancer_volume'][patient],\n",
    "                       'C(t)': data['chemo_application'][patient],\n",
    "                       'd(t)': data['radio_application'][patient],\n",
    "                       })\n",
    "    df = df[['N(t)', \"C(t)\", \"d(t)\"]]\n",
    "    df.plot(secondary_y=['C(t)', 'd(t)'])\n",
    "    plt.xlabel(\"$t$\")\n",
    "    plt.show()\n",
    "\n",
    "plot_treatments(test_data_counterfactuals, 34000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['cancer_volume', 'chemo_dosage', 'radio_dosage', 'chemo_application', 'radio_application', 'chemo_probabilities', 'radio_probabilities', 'sequence_lengths', 'death_flags', 'recovery_flags', 'patient_types'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column that indicates the application of chemo and radio at time t-1\n",
    "\n",
    "def add_previous_treatment(data: dict):\n",
    "    data['chemo_application_prev'] = np.roll(data['chemo_application'], 1, axis=1)\n",
    "    data['radio_application_prev'] = np.roll(data['radio_application'], 1, axis=1)\n",
    "    data['chemo_application_prev'][:, 0] = 0\n",
    "    data['radio_application_prev'][:, 0] = 0\n",
    "    return data\n",
    "\n",
    "training_data = add_previous_treatment(training_data)\n",
    "validation_data = add_previous_treatment(validation_data)\n",
    "test_data_factuals = add_previous_treatment(test_data_factuals)\n",
    "test_data_counterfactuals = add_previous_treatment(test_data_counterfactuals)\n",
    "test_data_seq = add_previous_treatment(test_data_seq)\n",
    "\n",
    "def add_time_steps(data: dict): # this should be the same shape as the cancer_volume (patients, time_steps)\n",
    "    data['time_step'] = np.tile(np.arange(data['cancer_volume'].shape[1]), (data['cancer_volume'].shape[0], 1))\n",
    "    return data\n",
    "\n",
    "#sequence lengths is reported once per patient, so we tile it to match the shape of the data\n",
    "def add_sequence_lengths(data: dict):\n",
    "    data['sequence_length_tile'] = np.tile(data['sequence_lengths'][:, None], (1, data['cancer_volume'].shape[1]))\n",
    "    data['distance_from_end'] = data['sequence_length_tile'] - data['time_step']\n",
    "    #distance_from_end_scaled is a value between 0 and 1 that indicates how far we are from the end of the sequence for each patient\n",
    "    data['distance_from_end_scaled'] = data['distance_from_end'] / data['sequence_length_tile']\n",
    "    return data\n",
    "\n",
    "training_data = add_time_steps(training_data)\n",
    "validation_data = add_time_steps(validation_data)\n",
    "test_data_factuals = add_time_steps(test_data_factuals)\n",
    "test_data_counterfactuals = add_time_steps(test_data_counterfactuals)\n",
    "test_data_seq = add_time_steps(test_data_seq)\n",
    "\n",
    "training_data = add_sequence_lengths(training_data)\n",
    "validation_data = add_sequence_lengths(validation_data)\n",
    "test_data_factuals = add_sequence_lengths(test_data_factuals)\n",
    "test_data_counterfactuals = add_sequence_lengths(test_data_counterfactuals)\n",
    "test_data_seq = add_sequence_lengths(test_data_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 60)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 60)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 60)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['time_step'].shape\n",
    "training_data['sequence_length_tile'].shape\n",
    "training_data['chemo_application_prev'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_sequence_lengths = training_data['sequence_lengths']\n",
    "validation_data_sequence_lengths = validation_data['sequence_lengths']\n",
    "test_data_factuals_sequence_lengths = test_data_factuals['sequence_lengths']\n",
    "test_data_counterfactuals_sequence_lengths = test_data_counterfactuals['sequence_lengths']\n",
    "test_data_seq_sequence_lengths = test_data_seq['sequence_lengths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "        14., 15., 17., 18., 19., 21., 22., 23., 24., 25., 26., 27., 28.,\n",
       "        29., 31., 32., 33., 35., 37., 40., 42., 43., 45., 48., 50., 52.,\n",
       "        53., 57., 58., 59.]),\n",
       " array([  15,   98,   69,   37,   19,   21,   15,    9,    7,    6,    6,\n",
       "           7,    6,    2,    4,    6,    1,    2,    1,    1,    3,    1,\n",
       "           2,    1,    1,    1,    1,    1,    1,    1,    1,    2,    1,\n",
       "           1,    1,    1,    2,    1,    1,    3,    2,    1, 9638]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count of the unique values of the sequence lengths\n",
    "np.unique(training_data_sequence_lengths, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "        14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26.,\n",
       "        27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39.,\n",
       "        40., 41., 42., 43., 44., 45., 46., 47., 48., 49., 50., 51., 52.,\n",
       "        53., 54., 55., 56., 57., 58., 59.]),\n",
       " array([4000, 3964, 3948, 3936, 3912, 3904, 3904, 3888, 3880, 3876, 3876,\n",
       "        3876, 3868, 3868, 3864, 3860, 3852, 3852, 3852, 3848, 3848, 3844,\n",
       "        3844, 3836, 3820, 3820, 3816, 3816, 3804, 3804, 3804, 3800, 3800,\n",
       "        3800, 3796, 3792, 3784, 3780, 3780, 3772, 3772, 3772, 3772, 3772,\n",
       "        3772, 3772, 3772, 3772, 3764, 3764, 3764, 3760, 3752, 3752, 3752,\n",
       "        3748, 3748, 3744, 3744]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_data_counterfactuals_sequence_lengths, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_keys = [\n",
    "    'chemo_application_prev', 'radio_application_prev', 'cancer_volume'\n",
    "]\n",
    "\n",
    "training_data = {key: training_data[key] for key in needed_keys}\n",
    "validation_data = {key: validation_data[key] for key in needed_keys}\n",
    "test_data_factuals = {key: test_data_factuals[key] for key in needed_keys}\n",
    "test_data_counterfactuals = {key: test_data_counterfactuals[key] for key in needed_keys}\n",
    "test_data_seq = {key: test_data_seq[key] for key in needed_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert tensors where the first dimension is the number of patients the second dimension is time and the third is the features\n",
    "#the keys are the features\n",
    "#within the features, the first dimension is the number of patients, the second is time\n",
    "\n",
    "#convert the keys to a dimension in the tensor\n",
    "def dictionary_to_tensor(data_dict):\n",
    "    # Extract keys and values from the dictionary\n",
    "    keys = list(data_dict.keys())\n",
    "    values = [data_dict[key] for key in keys]\n",
    "    \n",
    "    # Check consistency in dimensions\n",
    "    num_patients = values[0].shape[0]\n",
    "    time_steps = values[0].shape[1]\n",
    "    \n",
    "    for table in values:\n",
    "        assert table.shape[0] == num_patients, \"Number of patients mismatch.\"\n",
    "        assert table.shape[1] == time_steps, \"Number of time steps mismatch.\"\n",
    "    \n",
    "    # Stack tables along the new feature dimension\n",
    "    tensor = np.stack(values, axis=-1)\n",
    "    tensor = torch.tensor(tensor, dtype=torch.float32)\n",
    "    \n",
    "    return tensor, keys\n",
    "    \n",
    "training_data_tensor, keys = dictionary_to_tensor(training_data)\n",
    "validation_data_tensor, keys = dictionary_to_tensor(validation_data)\n",
    "test_data_factuals_tensor, keys = dictionary_to_tensor(test_data_factuals)\n",
    "test_data_counterfactuals_tensor, keys = dictionary_to_tensor(test_data_counterfactuals)\n",
    "test_data_seq_tensor, keys = dictionary_to_tensor(test_data_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([225456, 60, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([570680, 65, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_counterfactuals_tensor.shape\n",
    "test_data_seq_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225456,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(570680,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_counterfactuals_sequence_lengths.shape\n",
    "test_data_seq_sequence_lengths.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data embedding before feeding into the model\n",
    "\n",
    "This will first one-hot encode all the categorical features and then embed them to n columns. The resulting columns will then be concatenated with the numerical features. The result will then be used to create the torch tensor for the model. The torch tensor will be shaped as (Cases, Time, Features).\n",
    "\n",
    "The input data will be a dataframe like this:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataEmbedder(nn.Module):\n",
    "    def __init__(self, categorical_indices_sizes, numerical_indices, dataset):\n",
    "        super(DataEmbedder, self).__init__()\n",
    "        self.categoricals = categorical_indices_sizes #dictionary with feature name, and a list of index and size\n",
    "        self.numerics = numerical_indices #dictionary with feature name and index\n",
    "        self.embeddings = nn.ModuleDict()\n",
    "        self.mapping_dicts = {}\n",
    "\n",
    "        # Initialize embeddings and mapping dictionaries\n",
    "        for key in self.categoricals:\n",
    "            unique_values = np.unique(dataset[:, :, self.categoricals[key][0]])\n",
    "            self.mapping_dicts[key] = {name: idx for idx, name in enumerate(unique_values)}\n",
    "            self.embeddings[key] = nn.Embedding(num_embeddings=len(unique_values), embedding_dim=self.categoricals[key][1])\n",
    "            print(f\"Feature: {key}, Categories: {len(unique_values)}, Embedding Size: {self.categoricals[key][1]}\")\n",
    "    \n",
    "    def forward(self, dataset):\n",
    "\n",
    "        # Apply embeddings to the categorical indices\n",
    "        embedded_features = []\n",
    "        for key in self.categoricals:\n",
    "            embedded_features.append(self.embeddings[key](dataset[:, :, self.categoricals[key][0]].long()))\n",
    "        \n",
    "        \n",
    "        embedded_features = torch.cat(embedded_features, dim=-1)\n",
    "\n",
    "        numeric_features = dataset[:, :, list(self.numerics.values())].float()\n",
    "\n",
    "        # Concatenate the embedded features with the numerical data\n",
    "        result = torch.cat([embedded_features, numeric_features], dim=-1)\n",
    "\n",
    "        feature_count_embedded = len(self.numerics) + sum([self.categoricals[key][1] for key in self.categoricals])\n",
    "\n",
    "        result = result.reshape(dataset.shape[0], -1, feature_count_embedded)\n",
    "\n",
    "        return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moded Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class moded_TimesSeriesAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    A module that computes multi-head attention given query, key, and value tensors for time series data of shape (b, t, f, e)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim: int, num_heads: int):\n",
    "        \"\"\"\n",
    "        Constructor.\n",
    "        \n",
    "        Inputs:\n",
    "        - input_dim: Dimension of the input query, key, and value. We assume they all have\n",
    "          the same dimensions. This is basically the dimension of the embedding.\n",
    "        - num_heads: Number of attention heads\n",
    "        \"\"\"\n",
    "        super(moded_TimesSeriesAttention, self).__init__()\n",
    "\n",
    "        assert embed_dim % num_heads == 0\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dim_per_head = embed_dim // num_heads\n",
    "\n",
    "\n",
    "        self.linear_query = nn.Linear(embed_dim, embed_dim)\n",
    "        self.linear_key = nn.Linear(embed_dim, embed_dim)\n",
    "        self.linear_value = nn.Linear(embed_dim, embed_dim)#(self.num_heads * self.dim_per_head * self.dim_per_head))\n",
    "        self.output_linear = nn.Linear(embed_dim, embed_dim)\n",
    "        self.softmax = nn.Softmax2d()\n",
    "\n",
    "\n",
    "    def forward(self, query: torch.Tensor, key: torch.Tensor, value: torch.Tensor, mask: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        Compute the attended feature representations.\n",
    "        \n",
    "        Inputs:\n",
    "        - query: Tensor of the shape BxTxFXE, where B is the batch size, T is the time dimension, F is the feature dimension, \n",
    "        and E is the embedding dimension\n",
    "        - key: Tensor of the shape BxTxFXE\n",
    "        - value: Tensor of the shape BxTxFXE\n",
    "        - mask: Tensor indicating where the attention should *not* be performed\n",
    "        \"\"\"\n",
    "        b = query.shape[0]\n",
    "        t = query.shape[1]\n",
    "        f = query.shape[2]\n",
    "        e = query.shape[3]\n",
    "        d = self.dim_per_head\n",
    "        h = self.num_heads\n",
    "\n",
    "\n",
    "        query_linear = self.linear_query(query)\n",
    "        key_linear = self.linear_key(key)\n",
    "        value_linear = self.linear_value(value)\n",
    "\n",
    "        query_reshaped = query_linear.reshape(b, t, f, self.num_heads, self.dim_per_head)\n",
    "        key_reshaped = key_linear.reshape(b, t, f, self.num_heads, self.dim_per_head)\n",
    "        value_reshaped = value_linear.reshape(b, t, f, self.num_heads, self.dim_per_head)#, self.dim_per_head)\n",
    "\n",
    "        query_reshaped = query_reshaped.permute(0, 3, 1, 2, 4) # BxHxTxFxD\n",
    "        key_reshaped = key_reshaped.permute(0, 3, 1, 2, 4) # BxHxTxFxD\n",
    "        value_reshaped = value_reshaped.permute(0, 3, 1, 2, 4)#, 5) # BxHxTxFxDxD\n",
    "\n",
    "\n",
    "        kq = torch.einsum(\"bhtfd,bhxyd->bhtfxy\", key_reshaped, query_reshaped)\n",
    "\n",
    "        dot_prod_scores = kq/math.sqrt(self.dim_per_head)\n",
    "\n",
    "\n",
    "        #softmax across last 2 features (use softmax2d)\n",
    "        dot_prod_scores = dot_prod_scores.reshape(b*h, t*f, t, f)\n",
    "        dot_prod_scores = self.softmax(dot_prod_scores)\n",
    "        dot_prod_scores = dot_prod_scores.reshape(b, h, t, f, t, f)\n",
    "\n",
    "        out = torch.einsum(\"bhtfxy,bhtfd->bhtfd\",\n",
    "                           dot_prod_scores, value_reshaped)\n",
    "        out = out.permute(0, 2, 3, 1, 4).reshape(b, t, f, e)\n",
    "        out = self.output_linear(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class moded_TransformerEncoderCell(nn.Module):\n",
    "    \"\"\"\n",
    "    A single cell (unit) for the Transformer encoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim: int, num_heads: int, ff_dim: int, dropout: float):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - embed_dim: embedding dimension for each element in the time series data\n",
    "        - num_heads: Number of attention heads in a multi-head attention module\n",
    "        - ff_dim: The hidden dimension for a feedforward network\n",
    "        - dropout: Dropout ratio for the output of the multi-head attention and feedforward\n",
    "          modules.\n",
    "        \"\"\"\n",
    "        super(moded_TransformerEncoderCell, self).__init__()\n",
    "\n",
    "        self.time_series_attention = moded_TimesSeriesAttention(embed_dim, num_heads)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(embed_dim, ff_dim)\n",
    "        self.linear2 = nn.Linear(ff_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - x: Tensor of the shape BxTxFXE, where B is the batch size, T is the time dimension, F is the feature dimension,\n",
    "        and E is the embedding dimension\n",
    "        - mask: Tensor for multi-head attention\n",
    "        \"\"\"\n",
    "\n",
    "        attention2 = self.time_series_attention(x, x, x, mask)\n",
    "        attention = x + self.dropout1(attention2)\n",
    "        attention = self.layer_norm(attention)\n",
    "\n",
    "        attention2 = self.linear2(self.dropout(\n",
    "            self.activation(self.linear1(attention))))\n",
    "        attention = attention + self.dropout2(attention2)\n",
    "        attention = self.layer_norm(attention)\n",
    "\n",
    "        return attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class moded_TransformerEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A full encoder consisting of a set of TransformerEncoderCell.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim: int, num_heads: int, ff_dim: int, num_cells: int, dropout: float = 0.1):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - embed_dim: embedding dimension for each element in the time series data\n",
    "        - num_heads: Number of attention heads in a multi-head attention module\n",
    "        - ff_dim: The hidden dimension for a feedforward network\n",
    "        - num_cells: Number of time series attention cells in the encoder\n",
    "        - dropout: Dropout ratio for the output of the multi-head attention and feedforward\n",
    "          modules.\n",
    "        \"\"\"\n",
    "        super(moded_TransformerEncoder, self).__init__()\n",
    "\n",
    "        self.norm = None\n",
    "\n",
    "        self.encoder_modules = nn.ModuleList(moded_TransformerEncoderCell(\n",
    "            embed_dim, num_heads, ff_dim, dropout) for _ in range(num_cells))\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - x: Tensor of the shape BxTxFXE, where B is the batch size, T is the time dimension, F is the feature dimension,\n",
    "        and E is the embedding dimension\n",
    "        - mask: Tensor for multi-head attention\n",
    "        \n",
    "        Return:\n",
    "        - y: Tensor of the shape BxTxFXE\n",
    "        \"\"\"\n",
    "\n",
    "        #run encoder modules and add residual connections\n",
    "        for encoder_module in self.encoder_modules:\n",
    "            x = encoder_module(x, mask)\n",
    "\n",
    "        y = x\n",
    "\n",
    "        return y\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimesSeriesAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        d_in,\n",
    "        d_out,\n",
    "        nh=8,\n",
    "        dk=0,\n",
    "        dv=0,\n",
    "        dd=0,\n",
    "        kernel_size=(3, 7),\n",
    "        stride=(1,1,1),\n",
    "        kernel_type='VplusR',  # ['V', 'R', 'VplusR']\n",
    "        feat_type='VplusR',  # ['V', 'R', 'VplusR']\n",
    "    ):\n",
    "        super(TimesSeriesAttention, self).__init__()\n",
    "\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.nh = nh\n",
    "        self.dv = dv = d_out // nh if dv == 0 else dv\n",
    "        self.dk = dk = dv if dk == 0 else dk\n",
    "        self.dd = dd = dk if dd == 0 else dd\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.kernel_type = kernel_type\n",
    "        self.feat_type = feat_type\n",
    "\n",
    "        assert self.kernel_type in [\n",
    "            'V', 'R', 'VplusR'], \"Not implemented involution type: {}\".format(self.kernel_type)\n",
    "        assert self.feat_type in [\n",
    "            'V', 'R', 'VplusR'], \"Not implemented feature type: {}\".format(self.feat_type)\n",
    "\n",
    "        # print(\"d_in: {}, d_out: {}, nh: {}, dk: {}, dv: {}, dd:{}, kernel_size: {}, kernel_type: {}, feat_type: {}\"\n",
    "        #       .format(d_in, d_out, nh, dk, dv, self.dd, kernel_size, kernel_type, feat_type))\n",
    "\n",
    "        self.ksize = ksize = kernel_size[0] * kernel_size[1]\n",
    "        self.pad = pad = tuple(k//2 for k in kernel_size)\n",
    "\n",
    "        # hidden dimension\n",
    "        d_hid = nh * dk + dv if self.kernel_type == 'V' else nh * dk + dk + dv\n",
    "\n",
    "        # Linear projection\n",
    "        #self.projection = nn.Conv2d(d_in, d_hid, 1, bias=False)\n",
    "        self.projection_linear = nn.Sequential(\n",
    "            nn.Linear(d_in, d_hid, bias=False),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Linear(d_hid, d_hid, bias=False)\n",
    "        )\n",
    "\n",
    "        # Intervolution Kernel\n",
    "        if self.kernel_type == 'V':\n",
    "            self.H2 = nn.Conv2d(1, dd, kernel_size,\n",
    "                                padding=self.pad, bias=False)\n",
    "        elif self.kernel_type == 'R':\n",
    "            self.H1 = nn.Conv2d(dk, dk*dd, kernel_size,\n",
    "                                padding=self.pad, groups=dk, bias=False)\n",
    "            self.H2 = nn.Conv2d(1, dd, kernel_size,\n",
    "                                padding=self.pad, bias=False)\n",
    "        elif self.kernel_type == 'VplusR':\n",
    "            self.P1 = nn.Parameter(torch.randn(dk, dd).unsqueeze(\n",
    "                0)*np.sqrt(1/(ksize*dd)), requires_grad=True)\n",
    "            self.H1 = nn.Conv2d(dk, dk*dd, kernel_size,\n",
    "                                padding=self.pad, groups=dk, bias=False)\n",
    "            self.H2 = nn.Conv2d(1, dd, kernel_size,\n",
    "                                padding=self.pad, bias=False)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # Feature embedding layer\n",
    "        if self.feat_type == 'V':\n",
    "            pass\n",
    "        elif self.feat_type == 'R':\n",
    "            self.G = nn.Conv2d(1, dv, kernel_size,\n",
    "                               padding=self.pad, bias=False)\n",
    "        elif self.feat_type == 'VplusR':\n",
    "            self.G = nn.Conv2d(1, dv, kernel_size,\n",
    "                               padding=self.pad, bias=False)\n",
    "            self.I = nn.Parameter(torch.eye(dk).unsqueeze(0), requires_grad=True)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # Downsampling layer\n",
    "        if max(self.stride) > 1:\n",
    "            self.avgpool = nn.AvgPool2d(kernel_size=(\n",
    "                1, 3), stride=(1, 2), padding=(0, 1))\n",
    "\n",
    "    def L2norm(self, x, d=1):\n",
    "        eps = 1e-6\n",
    "        norm = x ** 2\n",
    "        norm = norm.sum(dim=d, keepdim=True) + eps\n",
    "        norm = norm ** (0.5)\n",
    "        return (x / norm)\n",
    "\n",
    "    def forward(self, x):\n",
    "                \n",
    "        #print(x.shape)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        N, C, T, H= x.shape\n",
    "\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        \n",
    "        '''Linear projection'''\n",
    "        #x_proj = self.projection(x)\n",
    "        x_proj = self.projection_linear(x)\n",
    "        x_proj = x_proj.permute(0, 3, 1, 2)\n",
    "        #print(x_proj.shape)\n",
    "\n",
    "        if self.kernel_type != 'V':\n",
    "            q, k, v = torch.split(\n",
    "                x_proj, [self.nh * self.dk, self.dk, self.dv], dim=1)\n",
    "        else:\n",
    "            q, v = torch.split(x_proj, [self.nh * self.dk, self.dv], dim=1)\n",
    "\n",
    "        '''Normalization'''\n",
    "        q = rearrange(q, 'b (nh k) t h -> b nh k t h', k=self.dk)\n",
    "        q = self.L2norm(q, d=2)\n",
    "        q = rearrange(q, 'b nh k t h -> (b t h) nh k')\n",
    "\n",
    "        v = self.L2norm(v, d=1)\n",
    "\n",
    "        if self.kernel_type != 'V':\n",
    "            k = self.L2norm(k, d=1)\n",
    "\n",
    "        '''\n",
    "        q = (b t h) nh k\n",
    "        k = b k t h\n",
    "        v = b v t h\n",
    "        '''\n",
    "\n",
    "        #Intervolution generation\n",
    "        # Basic kernel\n",
    "        if self.kernel_type == 'V':\n",
    "            kernel = q\n",
    "        # Relational kernel\n",
    "        else:\n",
    "            K_H1 = self.H1(k)\n",
    "            K_H1 = rearrange(K_H1, 'b (k d) t h-> (b t h) k d', k=self.dk)\n",
    "\n",
    "            if self.kernel_type == 'VplusR':\n",
    "                K_H1 = K_H1 + self.P1\n",
    "\n",
    "            kernel = torch.einsum(\n",
    "                'abc,abd->acd', q.transpose(1, 2), K_H1)  # (bth, nh, d)\n",
    "\n",
    "        #feature generation\n",
    "        # Appearance feature\n",
    "        v = rearrange(v, 'b (v 1) t h-> (b v) 1 t h')\n",
    "\n",
    "        V = self.H2(v)  # (bv, d, t, h)\n",
    "        feature = rearrange(V, '(b v) d t h -> (b t h) v d', v=self.dv)\n",
    "\n",
    "        # Relational feature\n",
    "        if self.feat_type in ['R', 'VplusR']:\n",
    "            V_G = self.G(v)  # (bv, v2, t, h)\n",
    "            V_G = rearrange(V_G, '(b v) v2 t h -> (b t h) v v2', v=self.dv)\n",
    "\n",
    "            if self.feat_type == 'VplusR':\n",
    "                V_G = V_G + self.I\n",
    "\n",
    "            feature = torch.einsum('abc,abd->acd', V_G, feature)  # (bth, v2, d)\n",
    "\n",
    "        #kernel * feat\n",
    "        out = torch.einsum('abc,adc->adb', kernel, feature)  # (bth, nh, v2)\n",
    "\n",
    "        out = rearrange(out, '(b t h) nh v -> b (nh v) t h', t=T, h=H)\n",
    "\n",
    "        if max(self.stride) > 1:\n",
    "            out = self.avgpool(out)\n",
    "\n",
    "        out = out.permute(0, 2, 3, 1)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderCell(nn.Module):\n",
    "    \"\"\"\n",
    "    A single cell (unit) for the Transformer encoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim: int, num_heads: int, kernel_size, ff_dim: int, dropout: float):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - embed_dim: embedding dimension for each element in the time series data\n",
    "        - num_heads: Number of attention heads in a multi-head attention module\n",
    "        - ff_dim: The hidden dimension for a feedforward network\n",
    "        - dropout: Dropout ratio for the output of the multi-head attention and feedforward\n",
    "          modules.\n",
    "        \"\"\"\n",
    "        super(TransformerEncoderCell, self).__init__()\n",
    "\n",
    "        self.time_series_attention = TimesSeriesAttention(embed_dim, embed_dim, nh = num_heads, kernel_size=kernel_size)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(embed_dim, ff_dim)\n",
    "        self.linear2 = nn.Linear(ff_dim, embed_dim)\n",
    "\n",
    "\n",
    "    def forward(self, data: torch.Tensor,embeddings, mask: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - x: Tensor of the shape BxTxFXE, where B is the batch size, T is the time dimension, F is the feature dimension,\n",
    "        and E is the embedding dimension\n",
    "        - mask: Tensor for multi-head attention\n",
    "        \"\"\"\n",
    "\n",
    "        #attention2 = self.time_series_attention(x, x, x, mask)\n",
    "        attention2 = self.time_series_attention(data)\n",
    "        attention = data + self.dropout1(attention2)\n",
    "        attention = self.layer_norm(attention)\n",
    "\n",
    "        attention2 = self.linear2(self.dropout(self.activation(self.linear1(attention))))\n",
    "        attention = attention + self.dropout2(attention2)\n",
    "        attention = self.layer_norm(attention)\n",
    "\n",
    "        return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A full encoder consisting of a set of TransformerEncoderCell.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim: int, num_heads: int, kernel_size, ff_dim: int, num_cells: int, dropout: float=0.1):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - embed_dim: embedding dimension for each element in the time series data\n",
    "        - num_heads: Number of attention heads in a multi-head attention module\n",
    "        - ff_dim: The hidden dimension for a feedforward network\n",
    "        - num_cells: Number of time series attention cells in the encoder\n",
    "        - dropout: Dropout ratio for the output of the multi-head attention and feedforward\n",
    "          modules.\n",
    "        \"\"\"\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        \n",
    "        self.norm = None\n",
    "\n",
    "        self.encoder_modules = nn.ModuleList(TransformerEncoderCell(embed_dim, num_heads, kernel_size, ff_dim, dropout) for _ in range(num_cells))\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor=None):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "        - x: Tensor of the shape BxTxFXE, where B is the batch size, T is the time dimension, F is the feature dimension,\n",
    "        and E is the embedding dimension\n",
    "        - mask: Tensor for multi-head attention\n",
    "        \n",
    "        Return:\n",
    "        - y: Tensor of the shape BxTxFXE\n",
    "        \"\"\"\n",
    "\n",
    "        #run encoder modules and add residual connections\n",
    "        for encoder_module in self.encoder_modules:\n",
    "            x = encoder_module(x, mask)\n",
    "\n",
    "        y = x\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSDI transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_torch_trans(num_heads=8, num_cells=1, embed_dim=128, ff_dim=512, dropout=0.1):\n",
    "    encoder_layer = nn.TransformerEncoderLayer(\n",
    "        d_model=embed_dim, nhead=num_heads, dim_feedforward=ff_dim, activation=\"gelu\", dropout=dropout\n",
    "    )\n",
    "    return nn.TransformerEncoder(encoder_layer, num_layers=num_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionEmbedding(nn.Module):\n",
    "    def __init__(self, num_steps, embedding_dim, projection_dim=None):\n",
    "        super(DiffusionEmbedding, self).__init__()\n",
    "        if projection_dim is None:\n",
    "            projection_dim = embedding_dim\n",
    "        self.register_buffer(\n",
    "            \"embedding\",\n",
    "            self._build_embedding(num_steps, embedding_dim / 2),\n",
    "            persistent=False,\n",
    "        )\n",
    "        self.projection1 = nn.Linear(embedding_dim, projection_dim)\n",
    "        self.projection2 = nn.Linear(projection_dim, embedding_dim)        \n",
    "\n",
    "    def forward(self, diffusion_step, data, device=\"cpu\"):\n",
    "        x = self.embedding[diffusion_step]\n",
    "        x = self.projection1(x)\n",
    "        x = F.silu(x)\n",
    "        x = self.projection2(x)\n",
    "        x = F.silu(x)\n",
    "        x = torch.zeros(data.shape).to(device) + x.unsqueeze(1).unsqueeze(1)\n",
    "        return x\n",
    "\n",
    "    def _build_embedding(self, num_steps, dim=64):\n",
    "        steps = torch.arange(num_steps).unsqueeze(1)  # (T,1)\n",
    "        frequencies = 10.0 ** (torch.arange(dim) / (dim - 1) * 4.0).unsqueeze(0)  # (1,dim)\n",
    "        table = steps * frequencies  # (T,dim)\n",
    "        table = torch.cat([torch.sin(table), torch.cos(table)], dim=1)  # (T,dim*2)\n",
    "        return table\n",
    "    \n",
    "\n",
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim, max_len=10000.0):\n",
    "        super(TimeEmbedding, self).__init__()\n",
    "        self.max_len = max_len\n",
    "        self.learnable = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, data, device=\"cpu\"):\n",
    "\n",
    "        b, l, f, e = data.shape\n",
    "        pe = None\n",
    "        pe_row = torch.arange(l)\n",
    "\n",
    "        pe = pe_row.unsqueeze(0)\n",
    "        pe = pe.unsqueeze(2)\n",
    "\n",
    "        pe = pe.repeat((b,1,e))\n",
    "        pe = pe.float()\n",
    "\n",
    "        pe[:, :, 0::2] = torch.sin(pe[:, :, 0::2]/(self.max_len**(torch.arange(0, e, 2)/e)))\n",
    "        pe[:, :, 1::2] = torch.cos(pe[:, :, 1::2]/(self.max_len**(torch.arange(0, e, 2)/e)))\n",
    "\n",
    "        pe = pe.to(device).unsqueeze(2).repeat((1,1,f,1))\n",
    "\n",
    "        # pe = torch.arange(l).unsqueeze(0).unsqueeze(-1).unsqueeze(-1).to(device)\n",
    "        # pe = torch.zeros(data.shape).to(device) + pe\n",
    "        \n",
    "        # div_term = 1 / torch.pow(\n",
    "        #     self.max_len, torch.arange(0, f, 2) / f\n",
    "        # ).unsqueeze(-1).to(device)\n",
    "\n",
    "        # pe[:, :, 0::2] = torch.sin(pe[:, :, 0::2] * div_term)\n",
    "        # pe[:, :, 1::2] = torch.cos(pe[:, :, 1::2] * div_term)\n",
    "\n",
    "        return self.learnable(pe) \n",
    "    \n",
    "class FeatureEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim, max_len=10000.0):\n",
    "        super(FeatureEmbedding, self).__init__()\n",
    "        self.max_len = max_len\n",
    "        self.learnable = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embedding_dim, embedding_dim),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, data, device=\"cpu\"):\n",
    "        b, l, f, e = data.shape\n",
    "\n",
    "        pe = None\n",
    "        pe_row = torch.arange(f)\n",
    "\n",
    "        pe = pe_row.unsqueeze(0)\n",
    "        pe = pe.unsqueeze(2)\n",
    "\n",
    "        pe = pe.repeat((b,1,e))\n",
    "        pe = pe.float()\n",
    "\n",
    "        pe[:, :, 0::2] = torch.sin(pe[:, :, 0::2]/(self.max_len**(torch.arange(0, e, 2)/e)))\n",
    "        pe[:, :, 1::2] = torch.cos(pe[:, :, 1::2]/(self.max_len**(torch.arange(0, e, 2)/e)))\n",
    "\n",
    "        pe = pe.to(device).unsqueeze(1).repeat((1,l,1,1))\n",
    "\n",
    "        # pe = torch.arange(f).unsqueeze(0).unsqueeze(0).unsqueeze(-1).to(device)\n",
    "        # pe = torch.zeros(data.shape).to(device) + pe\n",
    "\n",
    "        # div_term = 1 / torch.pow(\n",
    "        #     self.max_len, torch.arange(0, e, 2) / e\n",
    "        # ).to(device)\n",
    "\n",
    "        # pe[:, :, :, 0::2] = torch.sin(pe[:, :, :, 0::2] * div_term)\n",
    "        # pe[:, :, :, 1::2] = torch.cos(pe[:, :, :, 1::2] * div_term)\n",
    "\n",
    "        return self.learnable(pe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv1d_with_init(in_channels, out_channels, kernel_size):\n",
    "    layer = nn.Conv1d(in_channels, out_channels, kernel_size)\n",
    "    nn.init.kaiming_normal_(layer.weight)\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, num_heads=8, num_cells=1, kernel_size=(3, 7), embed_dim=128, ff_dim=512, dropout=0.1, method = \"rsa\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.method = method\n",
    "\n",
    "        self.embedding_add = nn.Sequential(\n",
    "            nn.Linear(embed_dim*4, embed_dim*4),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embed_dim*4, embed_dim*2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(embed_dim*2, embed_dim)\n",
    "        )\n",
    "        \n",
    "\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        self.mid_projection = Conv1d_with_init(embed_dim, 2 * embed_dim, 1)\n",
    "        #nn.Linear(embed_dim, embed_dim*2)\n",
    "        self.output_projection = Conv1d_with_init(embed_dim, 2 * embed_dim, 1)\n",
    "        #self.output_projection = nn.Linear(embed_dim, embed_dim*2)\n",
    "\n",
    "        if method == \"rsa\":\n",
    "            self.feature_and_time_transformer = TransformerEncoder(embed_dim = embed_dim,\n",
    "                                              num_heads = num_heads,\n",
    "                                              kernel_size=kernel_size,\n",
    "                                              ff_dim = ff_dim,\n",
    "                                              num_cells = num_cells,\n",
    "                                              dropout = dropout)\n",
    "            self.linear_time_and_feature = nn.Linear(embed_dim, embed_dim)\n",
    "            \n",
    "        elif method == \"csdi\":\n",
    "            self.time_layer = get_torch_trans(num_heads=num_heads, num_cells=num_cells, embed_dim=embed_dim, ff_dim=ff_dim, dropout=dropout)\n",
    "            self.feature_layer = get_torch_trans(num_heads=num_heads, num_cells=num_cells, embed_dim=embed_dim, ff_dim=ff_dim, dropout=dropout)\n",
    "            self.linear_time = nn.Linear(embed_dim, embed_dim)\n",
    "            self.linear_feature = nn.Linear(embed_dim, embed_dim)\n",
    "        \n",
    "        elif method == \"csdi_moded_transformer\":\n",
    "            self.time_layer = get_torch_trans(num_heads=num_heads, num_cells=num_cells, embed_dim=embed_dim, ff_dim=ff_dim, dropout=dropout)\n",
    "            self.feature_layer = get_torch_trans(num_heads=num_heads, num_cells=num_cells, embed_dim=embed_dim, ff_dim=ff_dim, dropout=dropout)\n",
    "            self.linear_time = nn.Linear(embed_dim, embed_dim)\n",
    "            self.linear_feature = nn.Linear(embed_dim, embed_dim)\n",
    "            self.feature_and_time_transformer = moded_TransformerEncoder(embed_dim=embed_dim,\n",
    "                                                                   num_heads=num_heads,\n",
    "                                                                   ff_dim=ff_dim,\n",
    "                                                                   num_cells=num_cells,\n",
    "                                                                   dropout=dropout)\n",
    "            self.linear_time_and_feature = nn.Linear(embed_dim, embed_dim)\n",
    "        \n",
    "        elif method == \"rsa_csdi\":\n",
    "            self.time_layer = get_torch_trans(\n",
    "                num_heads=num_heads, num_cells=num_cells, embed_dim=embed_dim, ff_dim=ff_dim, dropout=dropout)\n",
    "            self.feature_layer = get_torch_trans(\n",
    "                num_heads=num_heads, num_cells=num_cells, embed_dim=embed_dim, ff_dim=ff_dim, dropout=dropout)\n",
    "            self.linear_time = nn.Linear(embed_dim, embed_dim)\n",
    "            self.linear_feature = nn.Linear(embed_dim, embed_dim)\n",
    "            self.feature_and_time_transformer = TransformerEncoder(embed_dim = embed_dim,\n",
    "                                              num_heads = num_heads,\n",
    "                                              kernel_size=kernel_size,\n",
    "                                              ff_dim = ff_dim,\n",
    "                                              num_cells = num_cells,\n",
    "                                              dropout = dropout)\n",
    "            self.linear_time_and_feature = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "        \n",
    "        elif method == \"rsa_moded_transformer\":\n",
    "            self.feature_and_time_transformer = TransformerEncoder(embed_dim = embed_dim,\n",
    "                                              num_heads = num_heads,\n",
    "                                              kernel_size=kernel_size,\n",
    "                                              ff_dim = ff_dim,\n",
    "                                              num_cells = num_cells,\n",
    "                                              dropout = dropout)\n",
    "            self.linear_time_and_feature = nn.Linear(embed_dim, embed_dim)\n",
    "            self.moded_feature_and_time_transformer = moded_TransformerEncoder(embed_dim=embed_dim,\n",
    "                                                                   num_heads=num_heads,\n",
    "                                                                   ff_dim=ff_dim,\n",
    "                                                                   num_cells=num_cells,\n",
    "                                                                   dropout=dropout)\n",
    "            self.moded_linear_time_and_feature = nn.Linear(embed_dim, embed_dim)\n",
    "        \n",
    "        elif method == \"moded_transformer_alone\":\n",
    "            self.moded_feature_and_time_transformer = moded_TransformerEncoder(embed_dim=embed_dim,\n",
    "                                                                   num_heads=num_heads,\n",
    "                                                                   ff_dim=ff_dim,\n",
    "                                                                   num_cells=num_cells,\n",
    "                                                                   dropout=dropout)\n",
    "            self.moded_linear_time_and_feature = nn.Linear(embed_dim, embed_dim)\n",
    "        \n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward_time(self, y, base_shape):\n",
    "        b, t, f, e = base_shape\n",
    "        y = y.permute(0, 2, 1, 3).reshape(b * f, t, e)\n",
    "        y = self.time_layer(y.permute(1, 0, 2)).permute(1, 0, 2)\n",
    "        y = y.reshape(b, f, t, e).permute(0, 2, 1, 3)\n",
    "        return y\n",
    "\n",
    "    def forward_feature(self, y, base_shape):\n",
    "        b, t, f, e = base_shape\n",
    "        y = y.reshape(b * t, f, e)\n",
    "        y = self.feature_layer(y.permute(1, 0, 2)).permute(1, 0, 2)\n",
    "        y = y.reshape(b, t, f, e)\n",
    "        return y        \n",
    "\n",
    "\n",
    "    def forward(self, noised_data, diffusion_emb, time_emb, feature_emb):\n",
    "\n",
    "        b, t, f, e = noised_data.shape\n",
    "        base_shape = noised_data.shape\n",
    "        \n",
    "        y = torch.stack((noised_data, diffusion_emb, time_emb, feature_emb), dim = -1)\n",
    "        y = y.reshape(b, t, f, -1)\n",
    "        y = self.embedding_add(y)\n",
    "        y_resid = y\n",
    "\n",
    "        if self.method == \"rsa\":\n",
    "            y = self.feature_and_time_transformer(y)\n",
    "            y = y.squeeze(-1)\n",
    "            y = self.linear_time_and_feature(y)\n",
    "        \n",
    "        elif self.method == \"csdi\":\n",
    "            y = self.forward_time(y, base_shape)\n",
    "            y = self.linear_time(y)\n",
    "            y = (y + y_resid) / math.sqrt(2.0)\n",
    "            y = self.layer_norm(y)\n",
    "            y = self.forward_feature(y, base_shape) \n",
    "            y = self.linear_feature(y)\n",
    "        \n",
    "        elif self.method == \"csdi_moded_transformer\":\n",
    "            y = self.forward_time(y, base_shape)\n",
    "            y = self.linear_time(y)\n",
    "            y = (y + y_resid) / math.sqrt(2.0)\n",
    "            y = self.layer_norm(y)\n",
    "            y = self.forward_feature(y, base_shape) \n",
    "            y = self.linear_feature(y)\n",
    "            y = (y + y_resid) / math.sqrt(2.0)\n",
    "            y_resid = y\n",
    "            y = self.layer_norm(y)\n",
    "            y = self.feature_and_time_transformer(y)\n",
    "            y = self.linear_time_and_feature(y)\n",
    "        \n",
    "        elif self.method == \"rsa_csdi\":\n",
    "            y = self.forward_time(y, base_shape)\n",
    "            y = self.linear_time(y)\n",
    "            y = (y + y_resid) / math.sqrt(2.0)\n",
    "            y = self.layer_norm(y)\n",
    "            y = self.forward_feature(y, base_shape) \n",
    "            y = self.linear_feature(y)\n",
    "            y = (y + y_resid) / math.sqrt(2.0)\n",
    "            y_resid = y\n",
    "            y = self.layer_norm(y)\n",
    "            y = self.feature_and_time_transformer(y)\n",
    "            y = y.squeeze(-1)\n",
    "            y = self.linear_time_and_feature(y)\n",
    "        \n",
    "        elif self.method == \"rsa_moded_transformer\":\n",
    "            y = self.feature_and_time_transformer(y)\n",
    "            y = y.squeeze(-1)\n",
    "            y = self.linear_time_and_feature(y)\n",
    "            y = (y + y_resid) / math.sqrt(2.0)\n",
    "            y = self.layer_norm(y)\n",
    "            y = self.moded_feature_and_time_transformer(y)\n",
    "            y = self.moded_linear_time_and_feature(y)\n",
    "        \n",
    "        elif self.method == \"moded_transformer_alone\":\n",
    "            y = self.moded_feature_and_time_transformer(y)\n",
    "            y = self.moded_linear_time_and_feature(y)\n",
    "\n",
    "        \n",
    "        y = (y + y_resid) / math.sqrt(2.0)\n",
    "        y = self.layer_norm(y)\n",
    "        y = y.permute(0, 3, 1, 2).reshape(b, e, t*f)\n",
    "        y = self.mid_projection(y)\n",
    "        #y = y.permute(0, 3, 2, 1).reshape(b, 2*e, t*f)\n",
    "\n",
    "        gate, filter = torch.chunk(y, 2, dim=1)\n",
    "        y = torch.sigmoid(gate) * torch.tanh(filter)  # (b,e,f*t)\n",
    "        #y = y.permute(0, 2, 1)\n",
    "        y = self.output_projection(y)\n",
    "        #y = y.permute(0, 2, 1)\n",
    "\n",
    "        residual, skip = torch.chunk(y, 2, dim=1)\n",
    "        residual = residual.permute(0, 2, 1)\n",
    "        skip = skip.permute(0, 2, 1)\n",
    "        residual = residual.reshape(base_shape)\n",
    "        skip = skip.reshape(base_shape)\n",
    "        return (noised_data + residual) / math.sqrt(2.0), skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelLoop(nn.Module):\n",
    "    def __init__(self, embed_dim=128, diffusion_steps = 1000, num_heads=8, kernel_size=(3, 7),num_cells=1, num_residual_layers = 4, ff_dim=512, dropout=0.1, method = \"rsa\", device = \"cpu\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.emb_dim = embed_dim\n",
    "\n",
    "        # self.data_embedding_linear = nn.Sequential(\n",
    "        #     nn.Linear(1, self.emb_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.emb_dim, self.emb_dim)\n",
    "        # ) \n",
    "        # self.x_embedding = nn.Sequential(\n",
    "        #     nn.Linear(1, self.emb_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.emb_dim, self.emb_dim)\n",
    "        # ) \n",
    "\n",
    "        self.data_embedding_linear = Conv1d_with_init(1, self.emb_dim, 1)\n",
    "        self.x_embedding = Conv1d_with_init(2, self.emb_dim, 1)\n",
    "        \n",
    "        self.output = Conv1d_with_init(self.emb_dim, 1, 1)\n",
    "        self.output_final = Conv1d_with_init(self.emb_dim, 1, 1)\n",
    "        \n",
    "        # self.x_add = nn.Sequential(\n",
    "        #     nn.Linear(embed_dim*num_residual_layers, embed_dim*num_residual_layers),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(embed_dim*num_residual_layers, embed_dim)\n",
    "        # )\n",
    "\n",
    "        \n",
    "        self.diffusion_embedding = DiffusionEmbedding(diffusion_steps, embed_dim)\n",
    "        self.time_embedding = TimeEmbedding(embed_dim)\n",
    "        self.feature_embedding = FeatureEmbedding(embed_dim)\n",
    "\n",
    "        self.residual_layers = nn.ModuleList(\n",
    "                ResidualBlock(\n",
    "                    num_heads=num_heads,\n",
    "                    num_cells=num_cells,\n",
    "                    kernel_size=kernel_size,\n",
    "                    embed_dim=embed_dim,\n",
    "                    ff_dim=ff_dim,\n",
    "                    dropout=dropout,\n",
    "                    method = method\n",
    "                ) for _ in range(num_residual_layers)\n",
    "        )\n",
    "    \n",
    "        # self.output = nn.Sequential(\n",
    "        #     nn.Linear(self.emb_dim, self.emb_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.emb_dim, 1)\n",
    "        # )\n",
    "\n",
    "        # self.output_final = nn.Sequential(\n",
    "        #     nn.Linear(self.emb_dim, self.emb_dim),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(self.emb_dim, 1)\n",
    "        # )\n",
    "\n",
    "\n",
    "    def forward(self, noised_data, noise_mask, diffusion_t):\n",
    "\n",
    "        b, t, f, a = noised_data.shape\n",
    "        \n",
    "        noised_data_reshaped = noised_data.permute(0, 3, 1, 2).reshape(b, 1, t*f)\n",
    "        noised_data_embedded = self.data_embedding_linear(noised_data_reshaped).permute(0, 2, 1).reshape(b, t, f, self.emb_dim)\n",
    "        diffusion_embedding = self.diffusion_embedding(diffusion_t, noised_data_embedded, device = self.device)\n",
    "        time_embedding = self.time_embedding(noised_data_embedded, device = self.device)\n",
    "        feature_embedding = self.feature_embedding(noised_data_embedded, device = self.device)\n",
    "\n",
    "        x = noised_data_embedded\n",
    "        skip = []\n",
    "        for layer in self.residual_layers:\n",
    "            x, skip_connection = layer(x, diffusion_embedding, time_embedding, feature_embedding)\n",
    "            skip.append(skip_connection)\n",
    "            x = x.permute(0, 3, 1, 2).reshape(b, self.emb_dim, t*f)\n",
    "            x = self.output(x).permute(0, 2, 1).reshape(b, t, f)\n",
    "            x = torch.stack((x, noised_data.squeeze(-1)), dim = -1)\n",
    "            #x = x * noise_mask + noised_data * (1 - noise_mask)\n",
    "            x = x.permute(0, 3, 1, 2).reshape(b, 2, t*f)\n",
    "            x = self.x_embedding(x).permute(0, 2, 1).reshape(b, t, f, self.emb_dim)\n",
    "\n",
    "        x = torch.sum(torch.stack(skip, dim = -1), dim=-1)/ math.sqrt(len(self.residual_layers))\n",
    "        # x = torch.stack(skip, dim = -1).reshape(b, t, f, -1)\n",
    "        #x = self.x_add(x)\n",
    "        x = x.permute(0, 3, 1, 2).reshape(b, self.emb_dim, t*f)\n",
    "        x = self.output_final(x).permute(0, 2, 1).reshape(b, t, f, 1).squeeze(-1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_named_beta_schedule(schedule_name, num_diffusion_timesteps):\n",
    "    \"\"\"\n",
    "    Get a pre-defined beta schedule for the given name.\n",
    "\n",
    "    The beta schedule library consists of beta schedules which remain similar\n",
    "    in the limit of num_diffusion_timesteps.\n",
    "    Beta schedules may be added, but should not be removed or changed once\n",
    "    they are committed to maintain backwards compatibility.\n",
    "    \"\"\"\n",
    "    if schedule_name == \"linear\":\n",
    "        # Linear schedule from Ho et al, extended to work for any number of\n",
    "        # diffusion steps.\n",
    "        scale = 1000 / num_diffusion_timesteps\n",
    "        beta_start = scale * 0.0001\n",
    "        beta_end = scale * 0.02\n",
    "        return torch.linspace(\n",
    "            beta_start, beta_end, num_diffusion_timesteps\n",
    "        )\n",
    "    elif schedule_name == \"cosine\":\n",
    "        return betas_for_alpha_bar(\n",
    "            num_diffusion_timesteps,\n",
    "            lambda t: math.cos((t + 0.008) / 1.008 * math.pi / 2) ** 2,\n",
    "        )\n",
    "    elif schedule_name == \"quadratic\":\n",
    "        scale = 50 / num_diffusion_timesteps\n",
    "        beta_start = scale * 0.0001\n",
    "        beta_end = scale * 0.5\n",
    "        return torch.linspace(\n",
    "            beta_start ** 0.5, beta_end ** 0.5, num_diffusion_timesteps\n",
    "        ) ** 2\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError(f\"unknown beta schedule: {schedule_name}\")\n",
    "\n",
    "def betas_for_alpha_bar(num_diffusion_timesteps, alpha_bar, max_beta=0.999):\n",
    "    \"\"\"\n",
    "    Create a beta schedule that discretizes the given alpha_t_bar function,\n",
    "    which defines the cumulative product of (1-beta) over time from t = [0,1].\n",
    "\n",
    "    :param num_diffusion_timesteps: the number of betas to produce.\n",
    "    :param alpha_bar: a lambda that takes an argument t from 0 to 1 and\n",
    "                      produces the cumulative product of (1-beta) up to that\n",
    "                      part of the diffusion process.\n",
    "    :param max_beta: the maximum beta to use; use values lower than 1 to\n",
    "                     prevent singularities.\n",
    "    \"\"\"\n",
    "    betas = []\n",
    "    for i in range(num_diffusion_timesteps):\n",
    "        t1 = i / num_diffusion_timesteps\n",
    "        t2 = (i + 1) / num_diffusion_timesteps\n",
    "        betas.append(min(1 - alpha_bar(t2) / alpha_bar(t1), max_beta))\n",
    "    return torch.tensor(betas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class diffusion_imputation(nn.Module):\n",
    "    def __init__(self, emb_dim, excluded_features = None,\n",
    "                #vocab_size,\n",
    "                #pad_idx= None,\n",
    "                strategy = \"random\",\n",
    "                num_residual_layers = 4,\n",
    "                features_to_impute = None,\n",
    "                features_to_impute_completely = None,\n",
    "                features_to_impute_after_time = None,\n",
    "                last_n_time = 1,\n",
    "                missing_prp = 0.1,\n",
    "                diffusion_steps = 1000,\n",
    "                diffusion_beta_schedule = \"quadratic\",\n",
    "                num_heads = 8,\n",
    "                kernel_size=(3, 7),\n",
    "                ff_dim = 512,\n",
    "                num_cells = 2,\n",
    "                dropout = 0.1,\n",
    "                method = \"rsa\",\n",
    "                device = \"cpu\"):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "    \n",
    "        self.device = device\n",
    "        self.emb_dim = emb_dim\n",
    "        self.strategy = strategy\n",
    "        self.features_to_impute = features_to_impute\n",
    "        self.missing_prp = missing_prp\n",
    "        self.diffusion_steps = diffusion_steps\n",
    "        self.last_n_time = last_n_time\n",
    "        self.exclude_features = excluded_features   \n",
    "        self.features_to_impute_completely = features_to_impute_completely\n",
    "        self.features_to_impute_after_time = features_to_impute_after_time\n",
    "\n",
    "        #set device to cuda if available\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = \"cuda\"\n",
    "\n",
    "        \n",
    "        self.model_loop = ModelLoop(embed_dim = self.emb_dim,\n",
    "                                    diffusion_steps = diffusion_steps,\n",
    "                                    num_heads = num_heads,\n",
    "                                    kernel_size = kernel_size,\n",
    "                                    ff_dim = ff_dim,\n",
    "                                    num_cells = num_cells,\n",
    "                                    dropout = dropout,\n",
    "                                    num_residual_layers = num_residual_layers,\n",
    "                                    method = method,\n",
    "                                    device = self.device)\n",
    "        \n",
    "        self.beta = get_named_beta_schedule(diffusion_beta_schedule, \n",
    "                                            diffusion_steps)\n",
    "        \n",
    "        #self.beta = torch.linspace(0.0001, 0.5, diffusion_steps)\n",
    "\n",
    "        # self.beta = torch.linspace(\n",
    "        #         0.0001 ** 0.5, 0.5 ** 0.5, diffusion_steps\n",
    "        #     ) ** 2\n",
    "        \n",
    "        self.alpha_hat = 1 - self.beta \n",
    "        self.alpha = torch.cumprod(self.alpha_hat, dim=0)\n",
    "        self.alpha_torch = torch.tensor(self.alpha).float()\n",
    "\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "\n",
    "    def get_mask(self, data, strategy = \"random\"):\n",
    "        \n",
    "        b = data.shape[0]\n",
    "        t = data.shape[1]\n",
    "        f = data.shape[2]\n",
    "\n",
    "        if strategy == \"forecasting\":\n",
    "            forecasted_time = torch.randint(2, t, (b, 1, 1))\n",
    "            mask = torch.zeros_like(data)\n",
    "            for i in range(b):\n",
    "                mask[i, forecasted_time[i]:, :] = 1\n",
    "\n",
    "        if strategy == \"forecasting_last_n_time\":\n",
    "            mask = torch.zeros_like(data)\n",
    "            mask[:, -self.last_n_time, :] = 1\n",
    "\n",
    "        if strategy == \"death_prediction\":\n",
    "            mask = torch.zeros_like(data)\n",
    "            #death is the last 7 columns of the data\n",
    "            mask[:,:, -1] = 1\n",
    "        \n",
    "        if strategy == \"random_features\":\n",
    "            selected_features = torch.randint(0, f, (b, 1, 1))\n",
    "            mask = torch.zeros_like(data)\n",
    "            mask[:, :, selected_features] = 1\n",
    "        \n",
    "        if strategy == \"selected_features\":\n",
    "            mask = torch.zeros_like(data)\n",
    "            mask[:, :, self.features_to_impute] = 1\n",
    "        \n",
    "        if strategy == \"selected_features_after_time\":\n",
    "            selected_time = torch.randint(1, t, (b, 1, 1))\n",
    "            mask = torch.zeros_like(data)\n",
    "            mask[:, selected_time:, self.features_to_impute] = 1\n",
    "\n",
    "        if strategy == \"selected_features_last_n_time\":\n",
    "            mask = torch.zeros_like(data)\n",
    "            mask[:, -self.last_n_time:, self.features_to_impute] = 1\n",
    "        \n",
    "        if strategy == \"random\":\n",
    "            mask = torch.rand(size=(b, t, f))\n",
    "            mask = mask < self.missing_prp\n",
    "            mask = mask.float()\n",
    "\n",
    "        if strategy == \"selected_features_and_selected_features_after_time\":\n",
    "            mask = torch.zeros_like(data)\n",
    "            mask[:, :, self.features_to_impute_completely] = 1\n",
    "            mask[:, -self.last_n_time:, self.features_to_impute_after_time] = 1\n",
    "\n",
    "        if self.exclude_features is not None:\n",
    "            mask[:, :, self.exclude_features] = 0\n",
    "\n",
    "        return mask\n",
    "    \n",
    "    def loss_func(self, predicted_noise, noise, noise_mask):\n",
    "        # noise = torch.nan_to_num(noise, nan=0.0)\n",
    "        # predicted_noise = torch.nan_to_num(predicted_noise, nan=0.0)\n",
    "        residual = noise - predicted_noise\n",
    "        num_obs = torch.sum(noise_mask)\n",
    "        loss = (residual**2).sum() / num_obs\n",
    "        return(loss)\n",
    "    \n",
    "    def forward(self, data):\n",
    "         \n",
    "        b, t, f = data.shape\n",
    "\n",
    "        noise_mask = self.get_mask(data, self.strategy).to(self.device)\n",
    "        noise = torch.randn((b, t, f)).to(self.device)\n",
    "        noise = (noise_mask * noise)\n",
    "\n",
    "        diffusion_t = torch.randint(0, self.diffusion_steps, (b,1)).squeeze(1)\n",
    "        alpha = self.alpha_torch[diffusion_t].unsqueeze(1).unsqueeze(2).to(self.device)\n",
    "\n",
    "        noised_data = data * noise_mask\n",
    "        noised_data = noised_data * (alpha**0.5) + noise * ((1 - alpha)**0.5)\n",
    "        conditional_data = data * (1 - noise_mask)\n",
    "        noised_data = noised_data + conditional_data\n",
    "        noised_data = noised_data.float()\n",
    "\n",
    "        predicted_noise = self.model_loop(noised_data.unsqueeze(3), noise_mask.unsqueeze(3), diffusion_t)\n",
    "        predicted_noise = predicted_noise * noise_mask\n",
    "\n",
    "        return (predicted_noise, noise, noise_mask)\n",
    "    \n",
    "    def eval_with_grad(self, data, scale=1):\n",
    "\n",
    "        #with torch.no_grad():\n",
    "        imputation_mask = self.get_mask(data, self.strategy).to(self.device)\n",
    "        conditional_data = data * (1 - imputation_mask)\n",
    "        random_noise = torch.randn_like(data)* imputation_mask * scale\n",
    "        data_2 = (conditional_data + random_noise).unsqueeze(3)\n",
    "\n",
    "        b, ti, f, e = data_2.shape\n",
    "        imputed_samples = torch.zeros((b, ti, f)).to(self.device)\n",
    "        x = (conditional_data + random_noise)\n",
    "\n",
    "        for t in range(self.diffusion_steps - 1, -1, -1):\n",
    "\n",
    "            x = x.unsqueeze(3).float()\n",
    "            predicted_noise = self.model_loop(x, imputation_mask.unsqueeze(3), torch.tensor([t]).to(self.device))\n",
    "            predicted_noise = predicted_noise * imputation_mask\n",
    "            \n",
    "            coeff1 = 1 / self.alpha_hat[t] ** 0.5\n",
    "            coeff2 = (1 - self.alpha_hat[t]) / (1 - self.alpha[t]) ** 0.5\n",
    "            \n",
    "            x = x.squeeze(3)\n",
    "            x = coeff1 * (x - coeff2 * predicted_noise)\n",
    "            \n",
    "            if t > 0:\n",
    "                noise = torch.randn_like(x)\n",
    "                sigma = (\n",
    "                    (1.0 - self.alpha[t - 1]) / (1.0 - self.alpha[t]) * self.beta[t]\n",
    "                ) ** 0.5\n",
    "                x += sigma * noise\n",
    "            \n",
    "            x = data_2.squeeze(3) * (1 - imputation_mask) + x * imputation_mask\n",
    "            \n",
    "            imputed_samples = x\n",
    "\n",
    "        return(imputed_samples, data, imputation_mask)\n",
    "\n",
    "    \n",
    "    def eval(self, data, imputation_mask, mean, std, scale=1 , verbose = True):\n",
    "        \n",
    "        conditional_data = data * (1 - imputation_mask)\n",
    "        random_noise = torch.randn_like(data)* imputation_mask *scale\n",
    "        data_2 = (conditional_data + random_noise).unsqueeze(3)\n",
    "\n",
    "        b, ti, f, e = data_2.shape\n",
    "        imputed_samples = torch.zeros((b, ti, f)).to(self.device)\n",
    "        x = (conditional_data + random_noise)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for t in range(self.diffusion_steps - 1, -1, -1):\n",
    "\n",
    "                x = x.unsqueeze(3).float()\n",
    "                predicted_noise = self.model_loop(x, imputation_mask.unsqueeze(3), torch.tensor([t]).to(self.device))\n",
    "                predicted_noise = predicted_noise * imputation_mask\n",
    "                \n",
    "                coeff1 = 1 / self.alpha_hat[t] ** 0.5\n",
    "                coeff2 = (1 - self.alpha_hat[t]) / (1 - self.alpha[t]) ** 0.5\n",
    "                \n",
    "                x = x.squeeze(3)\n",
    "                x = coeff1 * (x - coeff2 * predicted_noise)\n",
    "                \n",
    "                if t > 0:\n",
    "                    noise = torch.randn_like(x)\n",
    "                    sigma = (\n",
    "                        (1.0 - self.alpha[t - 1]) / (1.0 - self.alpha[t]) * self.beta[t]\n",
    "                    ) ** 0.5\n",
    "                    x += sigma * noise\n",
    "                \n",
    "                x = data_2.squeeze(3) * (1 - imputation_mask) + x * imputation_mask\n",
    "            \n",
    "\n",
    "            imputed_samples = x.detach()\n",
    "        #show the data at torch.max(torch.abs(data[imputation_mask !=0] - imputed_samples[imputation_mask !=0]))\n",
    "        # print(\"differences = \", torch.abs(data[imputation_mask !=0] - imputed_samples[imputation_mask !=0]))\n",
    "        # print(\"data = \", data[imputation_mask !=0])\n",
    "        # print(\"imputed = \", imputed_samples[imputation_mask !=0])\n",
    "        print(\"max difference = \", torch.max(torch.abs(data[imputation_mask !=0] - imputed_samples[imputation_mask !=0])).item())\n",
    "        print(\"data at max difference = \", data[imputation_mask !=0][torch.argmax(torch.abs(data[imputation_mask !=0] - imputed_samples[imputation_mask !=0]))].item())\n",
    "        print(\"imputed at max difference = \", imputed_samples[imputation_mask !=0][torch.argmax(torch.abs(data[imputation_mask !=0] - imputed_samples[imputation_mask !=0]))].item())\n",
    "        mae = torch.mean(torch.abs(data[imputation_mask !=0] - imputed_samples[imputation_mask !=0])).item()\n",
    "        #descale the data\n",
    "        imputed_samples_copy = imputed_samples.detach().clone()\n",
    "        imputed_samples_copy = imputed_samples_copy * std + mean\n",
    "        data_copy = data.detach().clone()\n",
    "        data_copy = data_copy * std + mean\n",
    "        rmse = torch.sqrt(torch.mean((data_copy[imputation_mask !=0] - imputed_samples_copy[imputation_mask !=0])**2)).item()\n",
    "        rmse = rmse / 1150 * 100\n",
    "        if verbose == True:\n",
    "            print(\"mae = \", mae)\n",
    "            print(\"rmse = \", rmse)\n",
    "        # data_to_print = data[imputation_mask !=0]\n",
    "        # imputed_samples_to_print = imputed_samples[imputation_mask !=0]\n",
    "        # print(\"data:\", data_to_print)\n",
    "        # print(\"imputed:\", imputed_samples_to_print)\n",
    "        # print(\"absolute difference in the first 100 : \", torch.abs(data_to_print - imputed_samples_to_print)[:100])\n",
    "        # print(\"mae = \", torch.mean(torch.abs(data_to_print - imputed_samples_to_print)).item())\n",
    "\n",
    "        return(imputed_samples, data, imputation_mask, mae, rmse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import statistics\n",
    "from itertools import chain\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "def train(model, data_loader, data_loader_validation, epochs, lr, loss_func, batch_embedder,\n",
    "          windowed_mode=False, window_mode=\"uniform\", min_window=50, max_window=100, neg_bin_p=0.95, train_on_all_every=4,\n",
    "          annealing_mode = False, annealing_window=5, annealing_multiplier=1.25, annealing_ratio = 0.5, annealing_minimum = 1e-6,\n",
    "          device=\"cuda\", verbose=False, plot_every=10,\n",
    "          validation_frequency=1, validation_prp=10, moving_avg_window=10):\n",
    "    \n",
    "    batch_embedder = batch_embedder.to(device)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(\n",
    "        chain(batch_embedder.parameters(), model.parameters()),\n",
    "        lr=lr\n",
    "    )\n",
    "\n",
    "    model.train()\n",
    "    batch_embedder.train()\n",
    "    loss_list = []\n",
    "    initial_value = 1.0  # Initial value for equal probability\n",
    "    window_losses = torch.ones(max_window - min_window + 1, device=device) * initial_value  # Track losses for each window length\n",
    "    window_counts = torch.zeros(max_window - min_window + 1, device=device)  # Track counts for each window length\n",
    "    loss_deques = [deque(maxlen=moving_avg_window) for _ in range(max_window - min_window + 1)]  # Deques for moving average\n",
    "    if windowed_mode and window_mode == \"biased_loss\":\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 12))\n",
    "    else:\n",
    "        fig, ax1 = plt.subplots(1, 1, figsize=(10, 6))\n",
    "    epoch_loss_list = []\n",
    "    val_loss = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Annealing for the learning rate\n",
    "        if annealing_mode and epoch > annealing_window:\n",
    "            if len(epoch_loss_list) > 0 and epoch_loss_list[-1] >= annealing_multiplier * (statistics.mean(epoch_loss_list[-annealing_window:])):\n",
    "                for g in optimizer.param_groups:\n",
    "                    if g['lr'] * annealing_ratio < annealing_minimum:\n",
    "                        g['lr'] = annealing_minimum\n",
    "                    else:\n",
    "                        g['lr'] *= annealing_ratio\n",
    "\n",
    "        start = time.time()\n",
    "        for i, batch in enumerate(data_loader):\n",
    "            \n",
    "            batch = batch.to(device)\n",
    "            batch = batch_embedder(batch)\n",
    "\n",
    "            # cut_start = 0\n",
    "            # cut_end = 0\n",
    "            batch_length = batch.shape[1]\n",
    "\n",
    "            # Windowed mode logic\n",
    "            if windowed_mode:\n",
    "                if window_mode == \"uniform\":\n",
    "                    while True:\n",
    "                        window_length = torch.randint(min_window, max_window + 1, (1,)).item()\n",
    "                        cut_start = torch.randint(0, batch_length - window_length + 1, (1,)).item()\n",
    "                        cut_end = cut_start + window_length\n",
    "                        if min_window <= (cut_end - cut_start) <= max_window:\n",
    "                            break\n",
    "                    batch = batch[:, cut_start:cut_end, :]\n",
    "\n",
    "                elif window_mode == \"negative_binomial\":\n",
    "                    total_count = 1\n",
    "                    probs = neg_bin_p\n",
    "                    distribution = torch.distributions.NegativeBinomial(total_count=total_count, probs=probs)\n",
    "                    while True:\n",
    "                        window_length = distribution.sample().item() + min_window\n",
    "                        cut_start = torch.randint(0, batch_length - window_length + 1, (1,)).item()\n",
    "                        cut_end = cut_start + window_length\n",
    "                        if min_window <= window_length <= max_window:\n",
    "                            break\n",
    "                    batch = batch[:, cut_start:cut_end, :]\n",
    "\n",
    "                elif window_mode == \"biased_loss\":\n",
    "                    if torch.min(window_counts) < 2:\n",
    "                        # Use uniform distribution until each length has been used at least twice\n",
    "                        window_probs = torch.ones_like(window_losses) / len(window_losses)\n",
    "                    elif torch.sum(window_counts) % train_on_all_every == 0:\n",
    "                        window_probs = torch.ones_like(window_losses) / len(window_losses)\n",
    "                    else:\n",
    "                        # Update probabilities based on moving average of losses\n",
    "                        avg_losses = torch.tensor([np.mean(loss_deque) if len(loss_deque) > 0 else initial_value for loss_deque in loss_deques], device=device)\n",
    "                        window_probs = avg_losses / avg_losses.sum()\n",
    "                    \n",
    "                    while True:\n",
    "                        window_length = torch.multinomial(window_probs, 1).item() + min_window\n",
    "                        cut_start = torch.randint(0, batch_length - window_length + 1, (1,)).item()\n",
    "                        cut_end = cut_start + window_length\n",
    "                        if min_window <= window_length <= max_window:\n",
    "                            break\n",
    "                    batch = batch[:, cut_start:cut_end, :]\n",
    "\n",
    "                    window_counts[window_length - min_window] += 1  # Update window counts\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            predicted_noise, noise, noise_mask = model(batch)\n",
    "            loss = loss_func(predicted_noise, noise, noise_mask)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_list.append(loss.item())\n",
    "\n",
    "            epoch_loss = sum(loss_list[-len(data_loader):]) / len(data_loader)\n",
    "            epoch_loss_list.append(epoch_loss)\n",
    "            \n",
    "            # Update window losses and moving average deque\n",
    "            if windowed_mode and window_mode == \"biased_loss\":\n",
    "                window_idx = window_length - min_window\n",
    "                window_losses[window_idx] += loss.item()\n",
    "                loss_deques[window_idx].append(loss.item())\n",
    "\n",
    "            # Dynamic plot update\n",
    "            if i % plot_every == 0:\n",
    "                ax1.clear()\n",
    "                ax1.set_ylim(0, 1)\n",
    "                ax1.plot(loss_list)\n",
    "                if len(loss_list) > 100:\n",
    "                    ax1.plot(np.convolve(loss_list, np.ones((100,))/100, mode='valid'))\n",
    "                    ax1.text(len(loss_list) - 1, np.convolve(loss_list, np.ones((100,))/100, mode='valid')[-1],\n",
    "                            str(round(np.convolve(loss_list, np.ones((100,))/100, mode='valid')[-1], 3)))\n",
    "                if len(epoch_loss_list) > 0:\n",
    "                    ax1.text(0.1, 0.9, f\"Epoch: {epoch} | Learning rate: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "                # ax1.text(0.1, 0.8, f\"Learning rate: {optimizer.param_groups[0]['lr']:.4e}\")\n",
    "                ax1.text(0.1, 0.8, f\"Loss: {epoch_loss_list[-1]:.3e} | Validation loss: {val_loss:.3e}\")\n",
    "                ax1.text(0.1, 0.7, f\"Time per step: {((time.time() - start) / (i + 1)):.2f} s | Time per epoch: {((time.time() - start) / (i + 1) * len(data_loader)):.2f} s\")\n",
    "                ax1.text(0.1, 0.6, f\"Time till finish (est.): {((time.time() - start) / (i + 1) * len(data_loader) * (epochs - epoch)) / 60:.2f} min\")\n",
    "                if windowed_mode and window_mode == \"biased_loss\":\n",
    "                    ax2.clear()\n",
    "                    ax2.bar(range(min_window, max_window + 1), window_counts.cpu().numpy())\n",
    "                    ax2.set_ylabel(\"Counts\")\n",
    "                    ax2.set_title(\"Counts of Each Window Length Used\")\n",
    "\n",
    "                    moving_avg_losses = torch.tensor([np.mean(loss_deque) if len(loss_deque) > 0 else initial_value for loss_deque in loss_deques], device=device).cpu().numpy()\n",
    "                    ax3.clear()\n",
    "                    ax3.bar(range(min_window, max_window + 1), moving_avg_losses)\n",
    "                    ax3.set_xlabel(\"Window Length\")\n",
    "                    ax3.set_ylabel(\"Moving Average Loss\")\n",
    "                    ax3.set_title(\"Moving Average Loss for Each Window Length\")\n",
    "\n",
    "                display(fig)\n",
    "                clear_output(wait=True)\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        # Validation\n",
    "        if epoch % validation_frequency == 0:\n",
    "            loss_list_validation = []\n",
    "            for i, batch in enumerate(data_loader_validation):\n",
    "                batch = batch.to(device)\n",
    "                batch = batch_embedder(batch)\n",
    "                if i % validation_prp == 0:\n",
    "                    predicted_noise, noise, noise_mask = model(batch)\n",
    "                    loss = loss_func(predicted_noise, noise, noise_mask)\n",
    "                    loss_list_validation.append(loss.item())\n",
    "\n",
    "            val_loss = np.mean(loss_list_validation)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch} completed in {end - start} seconds, Loss: {epoch_loss}\")\n",
    "            print(f\"Validation Loss: {val_loss}\")\n",
    "\n",
    "\n",
    "    return model, loss_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_indices_sizes = {\n",
    "    # 'time_step' : [0, 1],\n",
    "    'chemo_application_prev': [0, 1],\n",
    "    'radio_application_prev': [1, 1]\n",
    "}\n",
    "\n",
    "numerical_indices = {\n",
    "    'cancer_volume': 2\n",
    "}\n",
    "\n",
    "# training_data_tensor_embedded = data_embedder(training_data_tensor)\n",
    "# validation_data_tensor_embedded = data_embedder(validation_data_tensor)\n",
    "# test_data_factuals_tensor_embedded = data_embedder(test_data_factuals_tensor)\n",
    "# test_data_counterfactuals_tensor_embedded = data_embedder(test_data_counterfactuals_tensor)\n",
    "# test_data_seq_tensor_embedded = data_embedder(test_data_seq_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "#create data loader for train, val, and test \n",
    "train_loader = torch.utils.data.DataLoader(training_data_tensor, batch_size=20, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(validation_data_tensor, batch_size=20, shuffle=True)\n",
    "# test_loader = torch.utils.data.DataLoader(test_data_counterfactuals_tensor, batch_size=20, shuffle=True)\n",
    "\n",
    "#check the size of the train, val, and test sets\n",
    "print(len(train_loader))\n",
    "print(len(val_loader))\n",
    "# print(len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13268"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: chemo_application_prev, Categories: 2, Embedding Size: 1\n",
      "Feature: radio_application_prev, Categories: 2, Embedding Size: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6794/4265982885.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.alpha_torch = torch.tensor(self.alpha).float()\n"
     ]
    }
   ],
   "source": [
    "diffusion_imputer = diffusion_imputation(emb_dim = 64,\n",
    "                                        # strategy='forecasting_last_n_time',\n",
    "                                        # strategy='random',\n",
    "                                        # missing_prp= 0.1,\n",
    "                                        # strategy='selected_features',\n",
    "                                        strategy='selected_features_last_n_time',\n",
    "                                        features_to_impute = [2],\n",
    "                                        # excluded_features = [i for i in range(6)], #[2],#[0,1,2,3,5], #for the embedded stock names which we don't need to predict\n",
    "                                        # strategy='selected_features_and_selected_features_after_time',\n",
    "                                        # features_to_impute_completely=[2],\n",
    "                                        # features_to_impute_after_time=[3],\n",
    "                                        last_n_time = 1,\n",
    "                                        num_residual_layers= 8,\n",
    "                                        diffusion_steps= 100,\n",
    "                                        diffusion_beta_schedule= \"quadratic\",\n",
    "                                        num_heads= 16,\n",
    "                                        kernel_size=(2, 2),\n",
    "                                        ff_dim=4096,\n",
    "                                        num_cells = 4,\n",
    "                                        dropout=0,\n",
    "                                        method=\"csdi\",  # csdi, csdi_moded_transformer, rsa, rsa_moded_transformer, moded_transformer_alone, rsa_csdi\n",
    "                                        device=\"cuda\")\n",
    "\n",
    "data_embedder = DataEmbedder(categorical_indices_sizes, numerical_indices, training_data_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(diffusion_imputation(\n",
       "   (model_loop): ModelLoop(\n",
       "     (data_embedding_linear): Conv1d(1, 64, kernel_size=(1,), stride=(1,))\n",
       "     (x_embedding): Conv1d(2, 64, kernel_size=(1,), stride=(1,))\n",
       "     (output): Conv1d(64, 1, kernel_size=(1,), stride=(1,))\n",
       "     (output_final): Conv1d(64, 1, kernel_size=(1,), stride=(1,))\n",
       "     (diffusion_embedding): DiffusionEmbedding(\n",
       "       (projection1): Linear(in_features=64, out_features=64, bias=True)\n",
       "       (projection2): Linear(in_features=64, out_features=64, bias=True)\n",
       "     )\n",
       "     (time_embedding): TimeEmbedding(\n",
       "       (learnable): Sequential(\n",
       "         (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "         (1): SiLU()\n",
       "         (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "       )\n",
       "     )\n",
       "     (feature_embedding): FeatureEmbedding(\n",
       "       (learnable): Sequential(\n",
       "         (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "         (1): SiLU()\n",
       "         (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "       )\n",
       "     )\n",
       "     (residual_layers): ModuleList(\n",
       "       (0-7): 8 x ResidualBlock(\n",
       "         (embedding_add): Sequential(\n",
       "           (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "           (1): SiLU()\n",
       "           (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "           (3): SiLU()\n",
       "           (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "         )\n",
       "         (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "         (mid_projection): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "         (output_projection): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "         (time_layer): TransformerEncoder(\n",
       "           (layers): ModuleList(\n",
       "             (0-3): 4 x TransformerEncoderLayer(\n",
       "               (self_attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "               )\n",
       "               (linear1): Linear(in_features=64, out_features=4096, bias=True)\n",
       "               (dropout): Dropout(p=0, inplace=False)\n",
       "               (linear2): Linear(in_features=4096, out_features=64, bias=True)\n",
       "               (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "               (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout1): Dropout(p=0, inplace=False)\n",
       "               (dropout2): Dropout(p=0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (feature_layer): TransformerEncoder(\n",
       "           (layers): ModuleList(\n",
       "             (0-3): 4 x TransformerEncoderLayer(\n",
       "               (self_attn): MultiheadAttention(\n",
       "                 (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "               )\n",
       "               (linear1): Linear(in_features=64, out_features=4096, bias=True)\n",
       "               (dropout): Dropout(p=0, inplace=False)\n",
       "               (linear2): Linear(in_features=4096, out_features=64, bias=True)\n",
       "               (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "               (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout1): Dropout(p=0, inplace=False)\n",
       "               (dropout2): Dropout(p=0, inplace=False)\n",
       "             )\n",
       "           )\n",
       "         )\n",
       "         (linear_time): Linear(in_features=64, out_features=64, bias=True)\n",
       "         (linear_feature): Linear(in_features=64, out_features=64, bias=True)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " [0.9339131116867065,\n",
       "  0.9041997790336609,\n",
       "  2.1561343669891357,\n",
       "  2.875293254852295,\n",
       "  1.320068597793579,\n",
       "  1.3500659465789795,\n",
       "  0.7502924203872681,\n",
       "  0.7103622555732727,\n",
       "  0.6585103273391724,\n",
       "  0.6360592842102051,\n",
       "  1.0366696119308472,\n",
       "  1.4091908931732178,\n",
       "  1.4718968868255615,\n",
       "  0.7697752714157104,\n",
       "  0.5792005062103271,\n",
       "  0.30087974667549133,\n",
       "  0.36898308992385864,\n",
       "  0.5726904273033142,\n",
       "  0.48736029863357544,\n",
       "  0.5240362882614136,\n",
       "  0.8782097101211548,\n",
       "  0.8031201362609863,\n",
       "  0.20278076827526093,\n",
       "  0.2703282833099365,\n",
       "  0.3528922200202942,\n",
       "  0.19415414333343506,\n",
       "  0.24313127994537354,\n",
       "  0.5711849331855774,\n",
       "  0.15306571125984192,\n",
       "  1.5210022926330566,\n",
       "  0.08354318886995316,\n",
       "  0.34595152735710144,\n",
       "  0.23667064309120178,\n",
       "  0.37709230184555054,\n",
       "  0.08842829614877701,\n",
       "  0.24644319713115692,\n",
       "  0.39447933435440063,\n",
       "  0.412728488445282,\n",
       "  0.23758924007415771,\n",
       "  0.12678439915180206,\n",
       "  0.18775829672813416,\n",
       "  0.22026458382606506,\n",
       "  0.46026936173439026,\n",
       "  0.11519398540258408,\n",
       "  0.20680923759937286,\n",
       "  0.2578001022338867,\n",
       "  0.6622689962387085,\n",
       "  0.08122663199901581,\n",
       "  0.5767598152160645,\n",
       "  0.2579173147678375,\n",
       "  0.43955081701278687,\n",
       "  0.29702144861221313,\n",
       "  0.13641120493412018,\n",
       "  0.2226477563381195,\n",
       "  0.05151001736521721,\n",
       "  0.23624639213085175,\n",
       "  0.4560048580169678,\n",
       "  0.2814369201660156,\n",
       "  0.10309597104787827,\n",
       "  0.09410405158996582,\n",
       "  0.10366108268499374,\n",
       "  0.40142685174942017,\n",
       "  0.26344773173332214,\n",
       "  0.24819615483283997,\n",
       "  0.45242390036582947,\n",
       "  0.2139737904071808,\n",
       "  0.2128511369228363,\n",
       "  0.38297367095947266,\n",
       "  0.31340718269348145,\n",
       "  0.48726925253868103,\n",
       "  0.4059392511844635,\n",
       "  0.42509016394615173,\n",
       "  0.10400168597698212,\n",
       "  0.08188962191343307,\n",
       "  0.4342101216316223,\n",
       "  0.2883450388908386,\n",
       "  0.28950372338294983,\n",
       "  0.4366477429866791,\n",
       "  0.11459426581859589,\n",
       "  0.16694077849388123,\n",
       "  0.30147165060043335,\n",
       "  0.8365122675895691,\n",
       "  0.07463496923446655,\n",
       "  0.45419636368751526,\n",
       "  0.5418823957443237,\n",
       "  0.7468794584274292,\n",
       "  0.15571290254592896,\n",
       "  0.2381279021501541,\n",
       "  0.10875995457172394,\n",
       "  0.13533830642700195,\n",
       "  0.6282855868339539,\n",
       "  0.23442992568016052,\n",
       "  0.15282590687274933,\n",
       "  0.34141701459884644,\n",
       "  0.1466539055109024,\n",
       "  0.3886089026927948,\n",
       "  0.4240482449531555,\n",
       "  0.5665239691734314,\n",
       "  0.057905834168195724,\n",
       "  0.2156156301498413,\n",
       "  0.22036299109458923,\n",
       "  0.3759327828884125,\n",
       "  0.28476542234420776,\n",
       "  0.3024134039878845,\n",
       "  0.6108108758926392,\n",
       "  0.11381659656763077,\n",
       "  0.32130172848701477,\n",
       "  0.429085910320282,\n",
       "  0.1364956945180893,\n",
       "  0.1792515367269516,\n",
       "  0.565771222114563,\n",
       "  0.26982951164245605,\n",
       "  0.45253515243530273,\n",
       "  0.22577746212482452,\n",
       "  0.2032216489315033,\n",
       "  0.12750479578971863,\n",
       "  0.46106773614883423,\n",
       "  0.5222822427749634,\n",
       "  0.3684253692626953,\n",
       "  0.2269635945558548,\n",
       "  0.13859695196151733,\n",
       "  0.3719567060470581,\n",
       "  0.1435191035270691,\n",
       "  0.05872952193021774,\n",
       "  0.17857053875923157,\n",
       "  0.1897313892841339,\n",
       "  0.07366176694631577,\n",
       "  0.18923832476139069,\n",
       "  0.5506994128227234,\n",
       "  0.19934172928333282,\n",
       "  0.17484799027442932,\n",
       "  0.3024342954158783,\n",
       "  0.11157115548849106,\n",
       "  0.243727445602417,\n",
       "  0.13443729281425476,\n",
       "  0.37525564432144165,\n",
       "  0.07558900117874146,\n",
       "  0.4769248068332672,\n",
       "  0.22207915782928467,\n",
       "  0.18380963802337646,\n",
       "  0.2066979855298996,\n",
       "  0.28869324922561646,\n",
       "  0.2432672083377838,\n",
       "  0.1177174299955368,\n",
       "  0.2687603831291199,\n",
       "  0.3696393370628357,\n",
       "  0.07062484323978424,\n",
       "  0.2452257126569748,\n",
       "  0.14687266945838928,\n",
       "  0.24893729388713837,\n",
       "  0.08575250208377838,\n",
       "  0.2800842225551605,\n",
       "  0.08000480383634567,\n",
       "  0.22837574779987335,\n",
       "  0.3590950071811676,\n",
       "  0.30479344725608826,\n",
       "  0.10233404487371445,\n",
       "  0.2658918499946594,\n",
       "  0.20553627610206604,\n",
       "  0.11510570347309113,\n",
       "  0.19605329632759094,\n",
       "  0.25755611062049866,\n",
       "  0.3058857023715973,\n",
       "  0.11190947145223618,\n",
       "  0.32451075315475464,\n",
       "  0.3382636606693268,\n",
       "  0.1348574459552765,\n",
       "  0.09278132766485214,\n",
       "  0.0974162146449089,\n",
       "  0.10131888091564178,\n",
       "  0.15994122624397278,\n",
       "  0.09223999828100204,\n",
       "  0.14296413958072662,\n",
       "  0.2911129295825958,\n",
       "  0.13813742995262146,\n",
       "  0.07095211744308472,\n",
       "  0.06446007639169693,\n",
       "  0.14501003921031952,\n",
       "  0.23447716236114502,\n",
       "  0.8548765182495117,\n",
       "  0.2547455430030823,\n",
       "  0.30823683738708496,\n",
       "  0.31835517287254333,\n",
       "  0.2029964029788971,\n",
       "  0.1780426800251007,\n",
       "  0.10926711559295654,\n",
       "  0.3007660508155823,\n",
       "  0.9226444363594055,\n",
       "  0.3258991837501526,\n",
       "  0.09146466106176376,\n",
       "  0.16162772476673126,\n",
       "  0.25600212812423706,\n",
       "  0.05095934122800827,\n",
       "  0.5153228044509888,\n",
       "  0.11302008479833603,\n",
       "  0.15796437859535217,\n",
       "  0.07827746868133545,\n",
       "  0.21600386500358582,\n",
       "  0.08892625570297241,\n",
       "  0.19645559787750244,\n",
       "  0.2972707748413086,\n",
       "  0.2347976714372635,\n",
       "  0.0691162571310997,\n",
       "  0.3896622061729431,\n",
       "  0.03547213226556778,\n",
       "  0.4562741219997406,\n",
       "  0.3742941915988922,\n",
       "  0.3840528130531311,\n",
       "  0.14248599112033844,\n",
       "  0.17338153719902039,\n",
       "  0.15544886887073517,\n",
       "  0.13777272403240204,\n",
       "  0.3507247567176819,\n",
       "  0.1286347657442093,\n",
       "  0.09993588179349899,\n",
       "  0.21167047321796417,\n",
       "  0.15207061171531677,\n",
       "  0.11303527653217316,\n",
       "  0.2599382698535919,\n",
       "  0.3238455355167389,\n",
       "  0.17640388011932373,\n",
       "  0.24604949355125427,\n",
       "  0.05709855630993843,\n",
       "  0.0740317851305008,\n",
       "  0.2462785542011261,\n",
       "  0.30067312717437744,\n",
       "  0.1971563845872879,\n",
       "  0.12379735708236694,\n",
       "  0.2902824282646179,\n",
       "  0.23011402785778046,\n",
       "  0.2410205602645874,\n",
       "  0.13296639919281006,\n",
       "  0.10214383900165558,\n",
       "  0.38440749049186707,\n",
       "  0.12192685902118683,\n",
       "  0.2578657865524292,\n",
       "  0.19317208230495453,\n",
       "  0.24902033805847168,\n",
       "  0.37108904123306274,\n",
       "  0.34207287430763245,\n",
       "  0.21388459205627441,\n",
       "  0.2204306423664093,\n",
       "  0.07741130143404007,\n",
       "  0.4749343991279602,\n",
       "  0.30309706926345825,\n",
       "  0.2478218972682953,\n",
       "  0.32772865891456604,\n",
       "  0.25543567538261414,\n",
       "  0.20645789802074432,\n",
       "  0.16984763741493225,\n",
       "  0.3387693762779236,\n",
       "  0.11418157815933228,\n",
       "  0.11304441839456558,\n",
       "  0.2147195041179657,\n",
       "  0.21529901027679443,\n",
       "  0.1395263969898224,\n",
       "  0.3246840834617615,\n",
       "  0.09547816216945648,\n",
       "  0.11252300441265106,\n",
       "  0.2271428108215332,\n",
       "  0.5622802972793579,\n",
       "  0.10772087424993515,\n",
       "  0.5773881077766418,\n",
       "  0.1894938051700592,\n",
       "  0.08879655599594116,\n",
       "  0.2672995924949646,\n",
       "  0.262183278799057,\n",
       "  0.1399044692516327,\n",
       "  0.2615031599998474,\n",
       "  0.16036756336688995,\n",
       "  0.06403102725744247,\n",
       "  0.2262047529220581,\n",
       "  0.16385981440544128,\n",
       "  0.19034549593925476,\n",
       "  0.09839440882205963,\n",
       "  0.11763210594654083,\n",
       "  0.20112057030200958,\n",
       "  0.6389824748039246,\n",
       "  0.11638309806585312,\n",
       "  0.19370749592781067,\n",
       "  0.26679062843322754,\n",
       "  0.2298489809036255,\n",
       "  0.10159780830144882,\n",
       "  0.10494138300418854,\n",
       "  0.1978011280298233,\n",
       "  0.13581806421279907,\n",
       "  0.10473412275314331,\n",
       "  0.15563566982746124,\n",
       "  0.3275773823261261,\n",
       "  0.2422945499420166,\n",
       "  0.07523782551288605,\n",
       "  0.16619181632995605,\n",
       "  0.15552452206611633,\n",
       "  0.10775198042392731,\n",
       "  0.077455535531044,\n",
       "  0.26777881383895874,\n",
       "  0.4509921669960022,\n",
       "  0.07555370032787323,\n",
       "  0.06731939315795898,\n",
       "  0.09821021556854248,\n",
       "  0.10280616581439972,\n",
       "  0.237504243850708,\n",
       "  0.10198895633220673,\n",
       "  0.09214707463979721,\n",
       "  0.28526002168655396,\n",
       "  0.12470612674951553,\n",
       "  0.17373162508010864,\n",
       "  0.1642097532749176,\n",
       "  0.3412741720676422,\n",
       "  0.32605233788490295,\n",
       "  0.06496953964233398,\n",
       "  0.14862529933452606,\n",
       "  0.3169664740562439,\n",
       "  0.10267601907253265,\n",
       "  0.211886927485466,\n",
       "  0.20616476237773895,\n",
       "  0.1464945375919342,\n",
       "  0.1311103105545044,\n",
       "  0.12446935474872589,\n",
       "  0.06630434840917587,\n",
       "  0.35652703046798706,\n",
       "  0.4031691551208496,\n",
       "  0.15774932503700256,\n",
       "  0.35446590185165405,\n",
       "  0.20574936270713806,\n",
       "  0.13753175735473633,\n",
       "  0.11337889730930328,\n",
       "  0.0952906459569931,\n",
       "  0.15505850315093994,\n",
       "  0.1537749022245407,\n",
       "  0.12378866970539093,\n",
       "  0.1875048726797104,\n",
       "  0.12231133133172989,\n",
       "  0.36860668659210205,\n",
       "  0.09654200077056885,\n",
       "  0.13549788296222687,\n",
       "  0.23153558373451233,\n",
       "  0.34164243936538696,\n",
       "  0.35116007924079895,\n",
       "  0.08574499934911728,\n",
       "  0.08188782632350922,\n",
       "  0.21561244130134583,\n",
       "  0.32342973351478577,\n",
       "  0.1832161396741867,\n",
       "  0.4620983600616455,\n",
       "  0.21009807288646698,\n",
       "  0.14867503941059113,\n",
       "  0.25018832087516785,\n",
       "  0.147017702460289,\n",
       "  0.33412134647369385,\n",
       "  0.3014237582683563,\n",
       "  0.11872086673974991,\n",
       "  0.15451496839523315,\n",
       "  0.10102121531963348,\n",
       "  0.13083705306053162,\n",
       "  0.22663994133472443,\n",
       "  0.253060519695282,\n",
       "  0.1413661390542984,\n",
       "  0.08254159986972809,\n",
       "  0.05958525463938713,\n",
       "  0.21027640998363495,\n",
       "  0.43108615279197693,\n",
       "  0.03132351487874985,\n",
       "  0.059670913964509964,\n",
       "  0.17676326632499695,\n",
       "  0.05564945936203003,\n",
       "  0.11076541244983673,\n",
       "  0.10366430133581161,\n",
       "  0.16870379447937012,\n",
       "  0.2488071471452713,\n",
       "  0.20525798201560974,\n",
       "  0.3039238452911377,\n",
       "  0.3949224650859833,\n",
       "  0.2582305371761322,\n",
       "  0.3762097954750061,\n",
       "  0.13464702665805817,\n",
       "  0.44761958718299866,\n",
       "  0.0971030592918396,\n",
       "  0.16494518518447876,\n",
       "  0.12788447737693787,\n",
       "  0.13601122796535492,\n",
       "  0.06768486648797989,\n",
       "  0.15706783533096313,\n",
       "  0.12638510763645172,\n",
       "  0.09646639227867126,\n",
       "  0.10115139186382294,\n",
       "  0.07799845933914185,\n",
       "  0.2959158420562744,\n",
       "  0.07240820676088333,\n",
       "  0.14163930714130402,\n",
       "  0.12888482213020325,\n",
       "  0.20245523750782013,\n",
       "  0.13060419261455536,\n",
       "  0.23925717175006866,\n",
       "  0.20313462615013123,\n",
       "  0.13771241903305054,\n",
       "  0.37441200017929077,\n",
       "  0.10493119060993195,\n",
       "  0.2034265547990799,\n",
       "  0.11115642637014389,\n",
       "  0.13983705639839172,\n",
       "  0.16537491977214813,\n",
       "  0.25534874200820923,\n",
       "  0.226169615983963,\n",
       "  0.05802864953875542,\n",
       "  0.24545255303382874,\n",
       "  0.12110777199268341,\n",
       "  0.24624958634376526,\n",
       "  0.061268072575330734,\n",
       "  0.3258053958415985,\n",
       "  0.080804243683815,\n",
       "  0.11312107741832733,\n",
       "  0.06648413091897964,\n",
       "  0.17614878714084625,\n",
       "  0.0785408467054367,\n",
       "  0.2626273036003113,\n",
       "  0.11756595224142075,\n",
       "  0.16261467337608337,\n",
       "  0.09566961973905563,\n",
       "  0.15466523170471191,\n",
       "  0.06987911462783813,\n",
       "  0.17276433110237122,\n",
       "  0.286310613155365,\n",
       "  0.10201996564865112,\n",
       "  0.11851350963115692,\n",
       "  0.23777008056640625,\n",
       "  0.16905395686626434,\n",
       "  0.20262444019317627,\n",
       "  0.24836702644824982,\n",
       "  0.0470794215798378,\n",
       "  0.14465096592903137,\n",
       "  0.126901313662529,\n",
       "  0.15777559578418732,\n",
       "  0.3232397437095642,\n",
       "  0.10953372716903687,\n",
       "  0.09153088927268982,\n",
       "  0.25698643922805786,\n",
       "  0.2432752102613449,\n",
       "  0.07893352210521698,\n",
       "  0.2009766846895218,\n",
       "  0.08035643398761749,\n",
       "  0.06865379959344864,\n",
       "  0.13166776299476624,\n",
       "  0.16027064621448517,\n",
       "  0.28136804699897766,\n",
       "  0.08460484445095062,\n",
       "  0.2326887547969818,\n",
       "  0.16194215416908264,\n",
       "  0.06172354146838188,\n",
       "  0.3264133036136627,\n",
       "  0.09764496237039566,\n",
       "  0.1478860229253769,\n",
       "  0.0802052766084671,\n",
       "  0.3289629817008972,\n",
       "  0.1570628583431244,\n",
       "  0.13182692229747772,\n",
       "  0.2963426113128662,\n",
       "  0.208703875541687,\n",
       "  0.0783580094575882,\n",
       "  0.2191019058227539,\n",
       "  0.48988527059555054,\n",
       "  0.18529406189918518,\n",
       "  0.12490673363208771,\n",
       "  0.2439795285463333,\n",
       "  0.11294251680374146,\n",
       "  0.08305195719003677,\n",
       "  0.11885283142328262,\n",
       "  0.26436108350753784,\n",
       "  0.18212592601776123,\n",
       "  0.21666988730430603,\n",
       "  0.12329824268817902,\n",
       "  0.09695307910442352,\n",
       "  0.14267154037952423,\n",
       "  0.25882142782211304,\n",
       "  0.09463541954755783,\n",
       "  0.2708563208580017,\n",
       "  0.1294078528881073,\n",
       "  0.14597861468791962,\n",
       "  0.12679675221443176,\n",
       "  0.3369186222553253,\n",
       "  0.2880992591381073,\n",
       "  0.04440159723162651,\n",
       "  0.3095431327819824,\n",
       "  0.5016506314277649,\n",
       "  0.4503244459629059,\n",
       "  0.14845259487628937,\n",
       "  0.09924226254224777,\n",
       "  0.21725499629974365,\n",
       "  0.11694033443927765,\n",
       "  0.10637573897838593,\n",
       "  0.2626999318599701,\n",
       "  0.08218608051538467,\n",
       "  0.11912617832422256,\n",
       "  0.11057183891534805,\n",
       "  0.20505475997924805,\n",
       "  0.15988652408123016,\n",
       "  0.12564608454704285,\n",
       "  0.4663814902305603,\n",
       "  0.11601835489273071,\n",
       "  0.0844995379447937,\n",
       "  0.2500081956386566,\n",
       "  0.07530258595943451,\n",
       "  0.12946537137031555,\n",
       "  0.2498370110988617,\n",
       "  0.06686470657587051,\n",
       "  0.11042505502700806,\n",
       "  0.12230151891708374,\n",
       "  0.19430801272392273,\n",
       "  0.19446498155593872,\n",
       "  0.35080423951148987,\n",
       "  0.18942081928253174,\n",
       "  0.405993789434433,\n",
       "  0.13625775277614594,\n",
       "  0.23187296092510223,\n",
       "  0.19689440727233887,\n",
       "  0.36609870195388794,\n",
       "  0.1621716469526291,\n",
       "  0.0751076191663742,\n",
       "  0.15218722820281982,\n",
       "  0.17547914385795593,\n",
       "  0.21514251828193665,\n",
       "  0.11439643055200577,\n",
       "  0.16399066150188446,\n",
       "  0.10031405836343765,\n",
       "  0.12767663598060608,\n",
       "  0.06641275435686111,\n",
       "  0.19209197163581848,\n",
       "  0.24157050251960754,\n",
       "  0.1743042916059494,\n",
       "  0.322807252407074,\n",
       "  0.08316504955291748,\n",
       "  0.409325510263443,\n",
       "  0.12776228785514832,\n",
       "  0.19097602367401123,\n",
       "  0.12349820137023926,\n",
       "  0.08524458110332489,\n",
       "  0.1283199042081833,\n",
       "  0.26697200536727905,\n",
       "  0.23215463757514954,\n",
       "  0.12067703902721405,\n",
       "  0.29759082198143005,\n",
       "  0.1489509791135788,\n",
       "  0.300230473279953,\n",
       "  0.0848303884267807,\n",
       "  0.09224121272563934,\n",
       "  0.11020505428314209,\n",
       "  0.2116720974445343,\n",
       "  0.2839318513870239,\n",
       "  0.15036770701408386,\n",
       "  0.25613778829574585,\n",
       "  0.23662903904914856,\n",
       "  0.06908215582370758,\n",
       "  0.17876720428466797,\n",
       "  0.15322206914424896,\n",
       "  0.09378917515277863,\n",
       "  0.1546986848115921,\n",
       "  0.06027568504214287,\n",
       "  0.13325032591819763,\n",
       "  0.1473955363035202,\n",
       "  0.21439556777477264,\n",
       "  0.07975137233734131,\n",
       "  0.09400903433561325,\n",
       "  0.17467138171195984,\n",
       "  0.24833829700946808,\n",
       "  0.1530662477016449,\n",
       "  0.12219049781560898,\n",
       "  0.24663543701171875,\n",
       "  0.05397052317857742,\n",
       "  0.20276319980621338,\n",
       "  0.1793442666530609,\n",
       "  0.11521843820810318,\n",
       "  0.16196513175964355,\n",
       "  0.11942432820796967,\n",
       "  0.1228485107421875,\n",
       "  0.06519830971956253,\n",
       "  0.11808033287525177,\n",
       "  0.22528786957263947,\n",
       "  0.3359963297843933,\n",
       "  0.07322495430707932,\n",
       "  0.05254166200757027,\n",
       "  0.044652462005615234,\n",
       "  0.06472575664520264,\n",
       "  0.03168375417590141,\n",
       "  0.426464706659317,\n",
       "  0.12052075564861298,\n",
       "  0.14516912400722504,\n",
       "  0.10954637825489044,\n",
       "  0.05873940512537956,\n",
       "  0.47184377908706665,\n",
       "  0.4063033163547516,\n",
       "  0.15790727734565735,\n",
       "  0.2618868350982666,\n",
       "  0.08106803894042969,\n",
       "  0.2589462697505951,\n",
       "  0.20781469345092773,\n",
       "  0.06751170009374619,\n",
       "  0.10276226699352264,\n",
       "  0.11029626429080963,\n",
       "  0.0512806661427021,\n",
       "  0.3712851405143738,\n",
       "  0.13652151823043823,\n",
       "  0.22874712944030762,\n",
       "  0.11928434669971466,\n",
       "  0.14536407589912415,\n",
       "  0.189401313662529,\n",
       "  0.11813360452651978,\n",
       "  0.08691557496786118,\n",
       "  0.13404838740825653,\n",
       "  0.05945631116628647,\n",
       "  0.4196392893791199,\n",
       "  0.07667897641658783,\n",
       "  0.13469469547271729,\n",
       "  0.2890768349170685,\n",
       "  0.05467904359102249,\n",
       "  0.17923501133918762,\n",
       "  0.25104260444641113,\n",
       "  0.08067355304956436,\n",
       "  0.13262206315994263,\n",
       "  0.2505263686180115,\n",
       "  0.053780220448970795,\n",
       "  0.21848030388355255,\n",
       "  0.401319682598114,\n",
       "  0.20496073365211487,\n",
       "  0.2245214432477951,\n",
       "  0.19724252820014954,\n",
       "  0.12295802682638168,\n",
       "  0.4141636788845062,\n",
       "  0.04974176734685898,\n",
       "  0.06291061639785767,\n",
       "  0.1901555359363556,\n",
       "  0.17083491384983063,\n",
       "  0.16155250370502472,\n",
       "  0.35196322202682495,\n",
       "  0.27464812994003296,\n",
       "  0.2558612823486328,\n",
       "  0.09087132662534714,\n",
       "  0.12629970908164978,\n",
       "  0.32340970635414124,\n",
       "  0.16836583614349365,\n",
       "  0.16115309298038483,\n",
       "  0.11124815046787262,\n",
       "  0.11406481266021729,\n",
       "  0.055883198976516724,\n",
       "  0.18807169795036316,\n",
       "  0.27646374702453613,\n",
       "  0.17359638214111328,\n",
       "  0.07143677026033401,\n",
       "  0.30293458700180054,\n",
       "  0.14037403464317322,\n",
       "  0.12954425811767578,\n",
       "  0.12711091339588165,\n",
       "  0.13354358077049255,\n",
       "  0.16617433726787567,\n",
       "  0.2735995650291443,\n",
       "  0.42171555757522583,\n",
       "  0.39336642622947693,\n",
       "  0.28235766291618347,\n",
       "  0.08693285286426544,\n",
       "  0.24602147936820984,\n",
       "  0.18352006375789642,\n",
       "  0.12858110666275024,\n",
       "  0.2893291711807251,\n",
       "  0.12070727348327637,\n",
       "  0.22307100892066956,\n",
       "  0.32657021284103394,\n",
       "  0.09294156730175018,\n",
       "  0.09392371028661728,\n",
       "  0.19299675524234772,\n",
       "  0.07516700029373169,\n",
       "  0.07280460000038147,\n",
       "  0.06347298622131348,\n",
       "  0.12073056399822235,\n",
       "  0.3764474391937256,\n",
       "  0.1733287274837494,\n",
       "  0.07934220135211945,\n",
       "  0.3893764019012451,\n",
       "  0.26534897089004517,\n",
       "  0.13828858733177185,\n",
       "  0.16677594184875488,\n",
       "  0.15102246403694153,\n",
       "  0.21802759170532227,\n",
       "  0.055217843502759933,\n",
       "  0.1519344598054886,\n",
       "  0.30052676796913147,\n",
       "  0.32897046208381653,\n",
       "  0.12538468837738037,\n",
       "  0.15271422266960144,\n",
       "  0.29822880029678345,\n",
       "  0.1958528310060501,\n",
       "  0.07399297505617142,\n",
       "  0.0671481192111969,\n",
       "  0.24458837509155273,\n",
       "  0.07638660818338394,\n",
       "  0.08768007904291153,\n",
       "  0.250102698802948,\n",
       "  0.05600324273109436,\n",
       "  0.4224061071872711,\n",
       "  0.21380898356437683,\n",
       "  0.12241804599761963,\n",
       "  0.30670076608657837,\n",
       "  0.17799553275108337,\n",
       "  0.27148857712745667,\n",
       "  0.08673213422298431,\n",
       "  0.17742523550987244,\n",
       "  0.0556221529841423,\n",
       "  0.12542550265789032,\n",
       "  0.20236420631408691,\n",
       "  0.26380735635757446,\n",
       "  0.1260751187801361,\n",
       "  0.21331524848937988,\n",
       "  0.04914260655641556,\n",
       "  0.2440381944179535,\n",
       "  0.23901717364788055,\n",
       "  0.22193403542041779,\n",
       "  0.240277498960495,\n",
       "  0.05764596536755562,\n",
       "  0.14402981102466583,\n",
       "  0.15507349371910095,\n",
       "  0.10434003174304962,\n",
       "  0.27772265672683716,\n",
       "  0.2303246557712555,\n",
       "  0.05537066608667374,\n",
       "  0.13886341452598572,\n",
       "  0.4236830174922943,\n",
       "  0.14801785349845886,\n",
       "  0.2707403600215912,\n",
       "  0.18328239023685455,\n",
       "  0.2407582700252533,\n",
       "  0.11413183063268661,\n",
       "  0.15729866921901703,\n",
       "  0.12458334863185883,\n",
       "  0.15482959151268005,\n",
       "  0.06672702729701996,\n",
       "  0.11316947638988495,\n",
       "  0.09066550433635712,\n",
       "  0.16231997311115265,\n",
       "  0.27685970067977905,\n",
       "  0.07089845836162567,\n",
       "  0.12173118442296982,\n",
       "  0.24228760600090027,\n",
       "  0.09103342145681381,\n",
       "  0.09361854940652847,\n",
       "  0.24330362677574158,\n",
       "  0.11129341274499893,\n",
       "  0.15743772685527802,\n",
       "  0.16402676701545715,\n",
       "  0.24666795134544373,\n",
       "  0.299774169921875,\n",
       "  0.15105026960372925,\n",
       "  0.1161646619439125,\n",
       "  0.08587811142206192,\n",
       "  0.11074980348348618,\n",
       "  0.30475741624832153,\n",
       "  0.18942098319530487,\n",
       "  0.41261616349220276,\n",
       "  0.2943359911441803,\n",
       "  0.11888803541660309,\n",
       "  0.19784560799598694,\n",
       "  0.17440645396709442,\n",
       "  0.10548047721385956,\n",
       "  0.19563668966293335,\n",
       "  0.1725299209356308,\n",
       "  0.06683795154094696,\n",
       "  0.10225212574005127,\n",
       "  0.12472810596227646,\n",
       "  0.2705300748348236,\n",
       "  0.1417536735534668,\n",
       "  0.15723387897014618,\n",
       "  0.20096448063850403,\n",
       "  0.12128468602895737,\n",
       "  0.26932573318481445,\n",
       "  0.06674109399318695,\n",
       "  0.11001475155353546,\n",
       "  0.3336448073387146,\n",
       "  0.13464000821113586,\n",
       "  0.3189564347267151,\n",
       "  0.1895398199558258,\n",
       "  0.21260079741477966,\n",
       "  0.10460243374109268,\n",
       "  0.15772178769111633,\n",
       "  0.1319577395915985,\n",
       "  0.30955570936203003,\n",
       "  0.13671281933784485,\n",
       "  0.1331852376461029,\n",
       "  0.09358471632003784,\n",
       "  0.09517115354537964,\n",
       "  0.3165239095687866,\n",
       "  0.28139644861221313,\n",
       "  0.17698052525520325,\n",
       "  0.05010277032852173,\n",
       "  0.1546632945537567,\n",
       "  0.15133798122406006,\n",
       "  0.258261501789093,\n",
       "  0.13622775673866272,\n",
       "  0.3169112801551819,\n",
       "  0.49842947721481323,\n",
       "  0.12335498631000519,\n",
       "  0.05158098787069321,\n",
       "  0.046876996755599976,\n",
       "  0.1380125880241394,\n",
       "  0.07514305412769318,\n",
       "  0.24072766304016113,\n",
       "  0.13523530960083008,\n",
       "  0.03758367896080017,\n",
       "  0.11802902072668076,\n",
       "  0.3064650893211365,\n",
       "  0.4923301637172699,\n",
       "  0.21628287434577942,\n",
       "  0.21794942021369934,\n",
       "  0.03809506446123123,\n",
       "  0.16547629237174988,\n",
       "  0.07747706025838852,\n",
       "  0.2249372899532318,\n",
       "  0.10148052126169205,\n",
       "  0.19779841601848602,\n",
       "  0.08124767243862152,\n",
       "  0.1368831843137741,\n",
       "  0.2184886932373047,\n",
       "  0.3389555513858795,\n",
       "  0.08559589833021164,\n",
       "  0.17324700951576233,\n",
       "  0.06267298012971878,\n",
       "  0.11158774048089981,\n",
       "  0.08147470653057098,\n",
       "  0.1276579648256302,\n",
       "  0.7866983413696289,\n",
       "  0.1413341462612152,\n",
       "  0.13120964169502258,\n",
       "  0.11812430620193481,\n",
       "  0.15382729470729828,\n",
       "  0.15865345299243927,\n",
       "  0.1100294440984726,\n",
       "  0.07563106715679169,\n",
       "  0.12016186863183975,\n",
       "  0.15428172051906586,\n",
       "  0.19944612681865692,\n",
       "  0.2607034742832184,\n",
       "  0.2658448815345764,\n",
       "  0.22804780304431915,\n",
       "  0.3043900430202484,\n",
       "  0.3261933922767639,\n",
       "  0.17350590229034424,\n",
       "  0.10304760932922363,\n",
       "  0.1338529884815216,\n",
       "  0.13472017645835876,\n",
       "  0.13303862512111664,\n",
       "  0.1118142381310463,\n",
       "  0.2122238129377365,\n",
       "  0.08750716596841812,\n",
       "  0.1485482156276703,\n",
       "  0.1164708286523819,\n",
       "  0.2121710330247879,\n",
       "  0.2056845724582672,\n",
       "  0.09102928638458252,\n",
       "  0.11229334026575089,\n",
       "  0.46434783935546875,\n",
       "  0.12802986800670624,\n",
       "  0.06900636851787567,\n",
       "  0.15886501967906952,\n",
       "  0.04055657237768173,\n",
       "  0.5558338761329651,\n",
       "  0.6316795945167542,\n",
       "  0.3153671622276306,\n",
       "  0.08133256435394287,\n",
       "  0.08568356931209564,\n",
       "  0.16972991824150085,\n",
       "  0.14472706615924835,\n",
       "  0.1078062504529953,\n",
       "  0.229714035987854,\n",
       "  0.2188984602689743,\n",
       "  0.21364884078502655,\n",
       "  0.5388595461845398,\n",
       "  0.18059885501861572,\n",
       "  0.10180334001779556,\n",
       "  0.08000709116458893,\n",
       "  0.14611701667308807,\n",
       "  0.3467879891395569,\n",
       "  0.08770973980426788,\n",
       "  0.1574574112892151,\n",
       "  0.11219880729913712,\n",
       "  0.10827833414077759,\n",
       "  0.20462556183338165,\n",
       "  0.19799299538135529,\n",
       "  0.3614789545536041,\n",
       "  0.17330797016620636,\n",
       "  0.25880175828933716,\n",
       "  0.3603455722332001,\n",
       "  0.05970440059900284,\n",
       "  0.1493455320596695,\n",
       "  0.3835722804069519,\n",
       "  0.054933976382017136,\n",
       "  0.06331115961074829,\n",
       "  0.09467478841543198,\n",
       "  0.11657221615314484,\n",
       "  0.1327754557132721,\n",
       "  0.14548449218273163,\n",
       "  0.07033649832010269,\n",
       "  0.20705199241638184,\n",
       "  0.20277857780456543,\n",
       "  0.06403116881847382,\n",
       "  0.4533994197845459,\n",
       "  0.1133560761809349,\n",
       "  0.2637965977191925,\n",
       "  0.10875300318002701,\n",
       "  0.12086980044841766,\n",
       "  0.1546149104833603,\n",
       "  0.161981463432312,\n",
       "  0.07380746304988861,\n",
       "  0.17550399899482727,\n",
       "  0.19103257358074188,\n",
       "  0.21740858256816864,\n",
       "  0.055355411022901535,\n",
       "  0.09877939522266388,\n",
       "  0.03668846935033798,\n",
       "  0.16057303547859192,\n",
       "  0.16150911152362823,\n",
       "  0.23565275967121124,\n",
       "  0.1309039145708084,\n",
       "  0.17979924380779266,\n",
       "  0.16559679806232452,\n",
       "  0.1833634227514267,\n",
       "  0.03013148531317711,\n",
       "  0.11112678050994873,\n",
       "  0.1209222823381424,\n",
       "  0.2234574258327484,\n",
       "  0.11308252811431885,\n",
       "  0.33352941274642944,\n",
       "  0.21895961463451385,\n",
       "  0.03521279618144035,\n",
       "  0.343843936920166,\n",
       "  0.06556671857833862,\n",
       "  0.09715160727500916,\n",
       "  0.05010775476694107,\n",
       "  0.21092167496681213,\n",
       "  0.24956393241882324,\n",
       "  0.05116598680615425,\n",
       "  0.13225314021110535,\n",
       "  0.10566174983978271,\n",
       "  0.12223776429891586,\n",
       "  0.1822870969772339,\n",
       "  0.10508017241954803,\n",
       "  0.37431997060775757,\n",
       "  0.13515646755695343,\n",
       "  0.22640344500541687,\n",
       "  0.20310679078102112,\n",
       "  0.19132688641548157,\n",
       "  0.13352113962173462,\n",
       "  0.07321364432573318,\n",
       "  0.32613644003868103,\n",
       "  0.3322095572948456,\n",
       "  0.06552304327487946,\n",
       "  0.19523969292640686,\n",
       "  0.10174574702978134,\n",
       "  0.24584197998046875,\n",
       "  0.043824322521686554,\n",
       "  0.291531503200531,\n",
       "  0.3657722771167755,\n",
       "  0.24191410839557648,\n",
       "  0.08692572265863419,\n",
       "  0.28196772933006287,\n",
       "  0.22657087445259094,\n",
       "  0.11301956325769424,\n",
       "  0.28977417945861816,\n",
       "  0.19804976880550385,\n",
       "  0.06015685945749283,\n",
       "  0.09234306216239929,\n",
       "  0.37494686245918274,\n",
       "  0.13913197815418243,\n",
       "  0.04473624378442764,\n",
       "  0.23008021712303162,\n",
       "  0.10269860923290253,\n",
       "  0.07478977739810944,\n",
       "  0.11518581956624985,\n",
       "  0.2754765450954437,\n",
       "  0.36474210023880005,\n",
       "  0.02937484346330166,\n",
       "  0.21701808273792267,\n",
       "  0.3622453212738037,\n",
       "  0.0850849375128746,\n",
       "  0.10809912532567978,\n",
       "  0.35448530316352844,\n",
       "  0.28081509470939636,\n",
       "  0.12006497383117676,\n",
       "  0.3625710606575012,\n",
       "  0.14390292763710022,\n",
       "  0.07685434073209763,\n",
       "  0.40992897748947144,\n",
       "  0.14486730098724365,\n",
       "  0.12842904031276703,\n",
       "  0.19904367625713348,\n",
       "  0.15648336708545685,\n",
       "  0.2771334648132324,\n",
       "  0.10517077147960663,\n",
       "  0.30963534116744995,\n",
       "  0.3989827036857605,\n",
       "  0.5007822513580322,\n",
       "  0.13028687238693237,\n",
       "  0.24452967941761017,\n",
       "  0.21822138130664825,\n",
       "  0.21604637801647186,\n",
       "  ...])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1200 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(\n",
    "    diffusion_imputer, \n",
    "    train_loader, \n",
    "    val_loader,\n",
    "    batch_embedder = data_embedder,\n",
    "    windowed_mode = True,\n",
    "    window_mode = \"biased_loss\",\n",
    "    train_on_all_every = 3,\n",
    "    min_window = 2,\n",
    "    max_window = 60,\n",
    "    device = \"cuda\",\n",
    "    epochs = 100,\n",
    "    lr = 1e-4,\n",
    "    annealing_mode = True,\n",
    "    annealing_window = 5,\n",
    "    annealing_multiplier = 1,\n",
    "    annealing_ratio=0.75,\n",
    "    annealing_minimum=1e-6,\n",
    "    loss_func = diffusion_imputer.loss_func,\n",
    "    validation_frequency = 2, \n",
    "    validation_prp = 1,\n",
    "    verbose = False,\n",
    "    plot_every = 100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_hybrid(\n",
    "#     diffusion_imputer, \n",
    "#     hybrid_model,\n",
    "#     train_loader, \n",
    "#     val_loader,\n",
    "#     batch_embedder = embedder,\n",
    "#     epochs = 20,\n",
    "#     lr = 0.001, \n",
    "#     annealing_window = 5,\n",
    "#     annealing_multiplier = 1,\n",
    "#     loss_func = diffusion_imputer.loss_func,\n",
    "#     hybrid_loss_func = hybrid_model.loss_func,\n",
    "#     hybrid_start_epoch = 0,\n",
    "#     hybrid_every_n_epoch = 5,\n",
    "#     validation_frequency=2, \n",
    "#     validation_prp=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save the entire model for further training\n",
    "torch.save(diffusion_imputer, \"diffusion_imputer_cancer_jul8.pt\")\n",
    "torch.save(data_embedder, \"data_embedder_cancer_jul8.pt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffusion_imputer = torch.load(\"diffusion_imputer_cancer_jul5.pt\")\n",
    "# data_embedder = torch.load(\"data_embedder_cancer_jul5.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_batch_test = 82\n",
    "# data_loaders = get_dataloader(num_batch_test, \"cuda\")\n",
    "# data_loader_test = get_dataloader(num_batch_test, \"cuda\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52.43550990660676"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "7.734152322128005"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_standard_deviation = stds['cancer_volume']\n",
    "training_mean = means['cancer_volume']\n",
    "\n",
    "training_standard_deviation\n",
    "training_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([225456, 60, 3])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_data_counterfactuals_tensor\n",
    "# test_data = test_data_factuals_tensor\n",
    "# test_data = validation_data_tensor\n",
    "\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., ..., 59., 59., 59.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_counterfactuals_sequence_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "       14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26.,\n",
       "       27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39.,\n",
       "       40., 41., 42., 43., 44., 45., 46., 47., 48., 49., 50., 51., 52.,\n",
       "       53., 54., 55., 56., 57., 58., 59.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([4000, 3964, 3948, 3936, 3912, 3904, 3904, 3888, 3880, 3876, 3876,\n",
       "       3876, 3868, 3868, 3864, 3860, 3852, 3852, 3852, 3848, 3848, 3844,\n",
       "       3844, 3836, 3820, 3820, 3816, 3816, 3804, 3804, 3804, 3800, 3800,\n",
       "       3800, 3796, 3792, 3784, 3780, 3780, 3772, 3772, 3772, 3772, 3772,\n",
       "       3772, 3772, 3772, 3772, 3764, 3764, 3764, 3760, 3752, 3752, 3752,\n",
       "       3748, 3748, 3744, 3744])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4000, 60, 3])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3876, 60, 3])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4000, 2, 3])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3876, 12, 3])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#divide test data to parts based on test_data_counterfactuals_sequence_lengths (So that the stuff in each chunk is of the same length)\n",
    "#row 0 of test_data_counterfactuals_sequence_lengths tells the sequence length of the first row of test_data and so on\n",
    "#so, if rows 0, 5, and 19 of test_data_counterfactuals_sequence_lengths are the same, then the first, sixth, and twentieth rows of test_data are of the same length and should be in the same chunk\n",
    "\n",
    "#find the unique sequence lengths\n",
    "unique_sequence_lengths, counts = np.unique(test_data_counterfactuals_sequence_lengths, return_counts=True)\n",
    "# unique_sequence_lengths, counts = np.unique(test_data_factuals_sequence_lengths, return_counts=True)\n",
    "# unique_sequence_lengths, counts = np.unique(validation_data_sequence_lengths, return_counts=True)\n",
    "\n",
    "unique_sequence_lengths\n",
    "counts\n",
    "\n",
    "#find the indices of the unique sequence lengths\n",
    "indices = [np.where(test_data_counterfactuals_sequence_lengths == i)[0] for i in unique_sequence_lengths]\n",
    "# indices = [np.where(test_data_factuals_sequence_lengths == i)[0] for i in unique_sequence_lengths]\n",
    "# indices = [np.where(validation_data_sequence_lengths == i)[0] for i in unique_sequence_lengths]\n",
    "\n",
    "#divide the test data into chunks based on the unique sequence lengths\n",
    "test_data_chunks = [test_data[i] for i in indices]\n",
    "len(test_data_chunks)\n",
    "test_data_chunks[0].shape\n",
    "test_data_chunks[10].shape\n",
    "\n",
    "#cut the second dimension of each chunk to its corresponding sequence length\n",
    "# test_data_chunks = [chunk[:, :int(length)+1, :] for chunk, length in zip(test_data_chunks, unique_sequence_lengths)]\n",
    "test_data_chunks = [chunk[:, :int(length)+1, :] for chunk, length in zip(test_data_chunks, unique_sequence_lengths)]\n",
    "\n",
    "test_data_chunks[0].shape\n",
    "test_data_chunks[10].shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 1.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 1.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 1.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 1.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 1.]]], device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#copy to the gpu\n",
    "test_data_chunks = [chunk.to(\"cuda\") for chunk in test_data_chunks]\n",
    "\n",
    "#use embedder\n",
    "test_data_chunks_embedded = [data_embedder(chunk) for chunk in test_data_chunks]\n",
    "\n",
    "#create impuation masks\n",
    "imputation_masks = [diffusion_imputer.get_mask(chunk,\n",
    "                                               strategy='selected_features_last_n_time') for chunk in test_data_chunks_embedded]\n",
    "imputation_masks = [mask.to(\"cuda\") for mask in imputation_masks]\n",
    "imputation_masks[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3852, 18, 3])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputation_masks[16].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0806,  0.3321,  3.1693],\n",
       "         [ 1.0805,  0.3321,  2.8202],\n",
       "         [ 1.0805,  0.3321,  2.3144],\n",
       "         ...,\n",
       "         [ 1.0806,  0.3321, -0.1176],\n",
       "         [ 1.0805,  0.3082, -0.1388],\n",
       "         [ 1.0806,  0.3321,     nan]],\n",
       "\n",
       "        [[ 1.0806,  0.3321,  3.1693],\n",
       "         [ 1.0805,  0.3321,  2.8202],\n",
       "         [ 1.0805,  0.3321,  2.3144],\n",
       "         ...,\n",
       "         [ 1.0806,  0.3321, -0.1176],\n",
       "         [ 1.0805,  0.3082, -0.1388],\n",
       "         [ 1.0806,  0.3082,     nan]],\n",
       "\n",
       "        [[ 1.0806,  0.3321,  3.1693],\n",
       "         [ 1.0805,  0.3321,  2.8202],\n",
       "         [ 1.0805,  0.3321,  2.3144],\n",
       "         ...,\n",
       "         [ 1.0806,  0.3321, -0.1176],\n",
       "         [ 1.0805,  0.3082, -0.1388],\n",
       "         [ 1.0805,  0.3321,     nan]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 1.0806,  0.3321, -0.1348],\n",
       "         [ 1.0805,  0.3321, -0.1360],\n",
       "         [ 1.0805,  0.3321, -0.1379],\n",
       "         ...,\n",
       "         [ 1.0805,  0.3321, -0.1472],\n",
       "         [ 1.0806,  0.3321, -0.1472],\n",
       "         [ 1.0806,  0.3082,     nan]],\n",
       "\n",
       "        [[ 1.0806,  0.3321, -0.1348],\n",
       "         [ 1.0805,  0.3321, -0.1360],\n",
       "         [ 1.0805,  0.3321, -0.1379],\n",
       "         ...,\n",
       "         [ 1.0805,  0.3321, -0.1472],\n",
       "         [ 1.0806,  0.3321, -0.1472],\n",
       "         [ 1.0805,  0.3321,     nan]],\n",
       "\n",
       "        [[ 1.0806,  0.3321, -0.1348],\n",
       "         [ 1.0805,  0.3321, -0.1360],\n",
       "         [ 1.0805,  0.3321, -0.1379],\n",
       "         ...,\n",
       "         [ 1.0805,  0.3321, -0.1472],\n",
       "         [ 1.0806,  0.3321, -0.1472],\n",
       "         [ 1.0805,  0.3082,     nan]]], device='cuda:0',\n",
       "       grad_fn=<WhereBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[    nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan],\n",
       "         ...,\n",
       "         [    nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan],\n",
       "         [    nan,     nan, -0.1385]],\n",
       "\n",
       "        [[    nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan],\n",
       "         ...,\n",
       "         [    nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan],\n",
       "         [    nan,     nan, -0.1442]],\n",
       "\n",
       "        [[    nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan],\n",
       "         ...,\n",
       "         [    nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan],\n",
       "         [    nan,     nan, -0.1397]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[    nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan],\n",
       "         ...,\n",
       "         [    nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan],\n",
       "         [    nan,     nan, -0.1474]],\n",
       "\n",
       "        [[    nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan],\n",
       "         ...,\n",
       "         [    nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan],\n",
       "         [    nan,     nan, -0.1473]],\n",
       "\n",
       "        [[    nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan],\n",
       "         ...,\n",
       "         [    nan,     nan,     nan],\n",
       "         [    nan,     nan,     nan],\n",
       "         [    nan,     nan, -0.1474]]], device='cuda:0',\n",
       "       grad_fn=<WhereBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "given_points = [torch.where(mask == 0, chunk, torch.tensor(float('nan')).to(\"cuda\")) for chunk, mask in zip(test_data_chunks_embedded, imputation_masks)]\n",
    "evaluated_points = [torch.where(mask != 0, chunk, torch.tensor(float('nan')).to(\"cuda\")) for chunk, mask in zip(test_data_chunks_embedded, imputation_masks)]\n",
    "\n",
    "given_points[58]\n",
    "evaluated_points[58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max difference =  21.409988403320312\n",
      "data at max difference =  2.8340299129486084\n",
      "imputed at max difference =  24.2440185546875\n",
      "mae =  0.5998466610908508\n",
      "rmse =  11.389292841372283\n",
      "Progress: 0.00%\n",
      "0\n",
      "max difference =  43.69564437866211\n",
      "data at max difference =  2.3850014209747314\n",
      "imputed at max difference =  46.08064651489258\n",
      "mae =  0.7600550055503845\n",
      "rmse =  20.42264457370924\n",
      "Progress: 0.08%\n",
      "1\n",
      "max difference =  5.255807399749756\n",
      "data at max difference =  5.496946334838867\n",
      "imputed at max difference =  0.24113886058330536\n",
      "mae =  0.31585174798965454\n",
      "rmse =  4.106155727220618\n",
      "Progress: 0.17%\n",
      "2\n",
      "max difference =  55.33047103881836\n",
      "data at max difference =  5.049139499664307\n",
      "imputed at max difference =  60.37961196899414\n",
      "mae =  1.2920444011688232\n",
      "rmse =  31.88708761463995\n",
      "Progress: 0.25%\n",
      "3\n",
      "max difference =  88.54277801513672\n",
      "data at max difference =  12.65227222442627\n",
      "imputed at max difference =  101.19505310058594\n",
      "mae =  3.7997961044311523\n",
      "rmse =  70.00583283797555\n",
      "Progress: 0.34%\n",
      "4\n",
      "max difference =  115.24185180664062\n",
      "data at max difference =  5.5453572273254395\n",
      "imputed at max difference =  120.7872085571289\n",
      "mae =  3.03774356842041\n",
      "rmse =  72.95235542629077\n",
      "Progress: 0.42%\n",
      "5\n",
      "max difference =  73.5596694946289\n",
      "data at max difference =  -0.14749836921691895\n",
      "imputed at max difference =  73.41217041015625\n",
      "mae =  3.150958776473999\n",
      "rmse =  52.66969365658968\n",
      "Progress: 0.51%\n",
      "6\n",
      "max difference =  48.914894104003906\n",
      "data at max difference =  2.983938694000244\n",
      "imputed at max difference =  51.898834228515625\n",
      "mae =  1.6794521808624268\n",
      "rmse =  30.11705481487772\n",
      "Progress: 0.59%\n",
      "7\n",
      "max difference =  154.73388671875\n",
      "data at max difference =  3.7007248401641846\n",
      "imputed at max difference =  158.4346160888672\n",
      "mae =  2.3547139167785645\n",
      "rmse =  72.75863514775816\n",
      "Progress: 0.68%\n",
      "8\n",
      "max difference =  57.037967681884766\n",
      "data at max difference =  2.2002665996551514\n",
      "imputed at max difference =  59.23823547363281\n",
      "mae =  1.0235164165496826\n",
      "rmse =  27.336667268172555\n",
      "Progress: 0.76%\n",
      "9\n",
      "max difference =  44.40150451660156\n",
      "data at max difference =  2.8465027809143066\n",
      "imputed at max difference =  47.248008728027344\n",
      "mae =  1.291215181350708\n",
      "rmse =  28.02496868631114\n",
      "Progress: 0.85%\n",
      "10\n",
      "max difference =  119.60468292236328\n",
      "data at max difference =  3.192647933959961\n",
      "imputed at max difference =  122.79733276367188\n",
      "mae =  2.0127651691436768\n",
      "rmse =  59.08307680876359\n",
      "Progress: 0.93%\n",
      "11\n",
      "max difference =  29.234729766845703\n",
      "data at max difference =  3.4434592723846436\n",
      "imputed at max difference =  32.67818832397461\n",
      "mae =  0.6252071261405945\n",
      "rmse =  14.950013533882473\n",
      "Progress: 1.02%\n",
      "12\n",
      "max difference =  41.8532600402832\n",
      "data at max difference =  2.9304683208465576\n",
      "imputed at max difference =  44.783729553222656\n",
      "mae =  1.017710566520691\n",
      "rmse =  25.125777534816574\n",
      "Progress: 1.10%\n",
      "13\n",
      "max difference =  2.9546926021575928\n",
      "data at max difference =  3.078768014907837\n",
      "imputed at max difference =  6.03346061706543\n",
      "mae =  0.14922097325325012\n",
      "rmse =  1.9851575105086616\n",
      "Progress: 1.19%\n",
      "14\n",
      "max difference =  25.148906707763672\n",
      "data at max difference =  4.049773693084717\n",
      "imputed at max difference =  29.198680877685547\n",
      "mae =  0.4917338788509369\n",
      "rmse =  13.09579202403193\n",
      "Progress: 1.27%\n",
      "15\n",
      "max difference =  4.617419242858887\n",
      "data at max difference =  3.25317645072937\n",
      "imputed at max difference =  7.870595455169678\n",
      "mae =  0.1864844113588333\n",
      "rmse =  3.081187040909477\n",
      "Progress: 1.36%\n",
      "16\n",
      "max difference =  22.178579330444336\n",
      "data at max difference =  4.297800540924072\n",
      "imputed at max difference =  26.47637939453125\n",
      "mae =  0.7099527716636658\n",
      "rmse =  15.409397291100543\n",
      "Progress: 1.44%\n",
      "17\n",
      "max difference =  39.770904541015625\n",
      "data at max difference =  4.372129440307617\n",
      "imputed at max difference =  44.14303207397461\n",
      "mae =  0.9206217527389526\n",
      "rmse =  22.988015879755437\n",
      "Progress: 1.53%\n",
      "18\n",
      "max difference =  27.61996841430664\n",
      "data at max difference =  3.2883851528167725\n",
      "imputed at max difference =  30.908353805541992\n",
      "mae =  0.5946409702301025\n",
      "rmse =  15.828520401664402\n",
      "Progress: 1.61%\n",
      "19\n",
      "max difference =  77.78041076660156\n",
      "data at max difference =  3.578327178955078\n",
      "imputed at max difference =  81.3587417602539\n",
      "mae =  1.6368250846862793\n",
      "rmse =  46.41428541100544\n",
      "Progress: 1.69%\n",
      "20\n",
      "max difference =  12.670109748840332\n",
      "data at max difference =  2.80688738822937\n",
      "imputed at max difference =  15.476997375488281\n",
      "mae =  0.3323063552379608\n",
      "rmse =  7.586586330247962\n",
      "Progress: 1.78%\n",
      "21\n",
      "max difference =  33.14198303222656\n",
      "data at max difference =  2.794804811477661\n",
      "imputed at max difference =  35.93678665161133\n",
      "mae =  0.7579548954963684\n",
      "rmse =  20.17149419369905\n",
      "Progress: 1.86%\n",
      "22\n",
      "max difference =  73.51962280273438\n",
      "data at max difference =  3.1619231700897217\n",
      "imputed at max difference =  76.68154907226562\n",
      "mae =  1.4143837690353394\n",
      "rmse =  40.47010338824728\n",
      "Progress: 1.95%\n",
      "23\n",
      "max difference =  28.539945602416992\n",
      "data at max difference =  2.7374680042266846\n",
      "imputed at max difference =  31.277414321899414\n",
      "mae =  0.8042951226234436\n",
      "rmse =  19.36252627165421\n",
      "Progress: 2.03%\n",
      "24\n",
      "max difference =  18.586814880371094\n",
      "data at max difference =  3.0082943439483643\n",
      "imputed at max difference =  21.595109939575195\n",
      "mae =  0.41014403104782104\n",
      "rmse =  10.111983589504076\n",
      "Progress: 2.12%\n",
      "25\n",
      "max difference =  73.75577545166016\n",
      "data at max difference =  3.3274190425872803\n",
      "imputed at max difference =  77.08319091796875\n",
      "mae =  1.584532380104065\n",
      "rmse =  38.6849073327106\n",
      "Progress: 2.20%\n",
      "26\n",
      "max difference =  53.12177276611328\n",
      "data at max difference =  2.4062821865081787\n",
      "imputed at max difference =  55.528053283691406\n",
      "mae =  1.206371784210205\n",
      "rmse =  31.450691554857336\n",
      "Progress: 2.29%\n",
      "27\n",
      "max difference =  25.215391159057617\n",
      "data at max difference =  3.0260767936706543\n",
      "imputed at max difference =  28.24146842956543\n",
      "mae =  0.47646474838256836\n",
      "rmse =  12.395188041355299\n",
      "Progress: 2.37%\n",
      "28\n",
      "max difference =  17.447397232055664\n",
      "data at max difference =  2.9589877128601074\n",
      "imputed at max difference =  20.40638542175293\n",
      "mae =  0.4667762517929077\n",
      "rmse =  10.112463909646738\n",
      "Progress: 2.46%\n",
      "29\n",
      "max difference =  65.80979919433594\n",
      "data at max difference =  3.688014030456543\n",
      "imputed at max difference =  69.49781036376953\n",
      "mae =  1.870627999305725\n",
      "rmse =  39.24556566321332\n",
      "Progress: 2.54%\n",
      "30\n",
      "max difference =  45.025146484375\n",
      "data at max difference =  3.1269123554229736\n",
      "imputed at max difference =  48.15205764770508\n",
      "mae =  1.4530532360076904\n",
      "rmse =  31.334138289741848\n",
      "Progress: 2.63%\n",
      "31\n",
      "max difference =  110.21525573730469\n",
      "data at max difference =  2.5404391288757324\n",
      "imputed at max difference =  112.75569152832031\n",
      "mae =  1.8962980508804321\n",
      "rmse =  53.13272758152174\n",
      "Progress: 2.71%\n",
      "32\n",
      "max difference =  56.28342056274414\n",
      "data at max difference =  3.129429817199707\n",
      "imputed at max difference =  59.41284942626953\n",
      "mae =  0.6964862942695618\n",
      "rmse =  25.856543499490485\n",
      "Progress: 2.80%\n",
      "33\n",
      "max difference =  95.61548614501953\n",
      "data at max difference =  2.9661622047424316\n",
      "imputed at max difference =  98.58164978027344\n",
      "mae =  1.2075201272964478\n",
      "rmse =  43.97815472146739\n",
      "Progress: 2.88%\n",
      "34\n",
      "max difference =  79.4560775756836\n",
      "data at max difference =  2.986680746078491\n",
      "imputed at max difference =  82.44275665283203\n",
      "mae =  1.8756120204925537\n",
      "rmse =  43.4559326171875\n",
      "Progress: 2.97%\n",
      "35\n",
      "max difference =  79.35858154296875\n",
      "data at max difference =  3.6970813274383545\n",
      "imputed at max difference =  83.0556640625\n",
      "mae =  1.2269750833511353\n",
      "rmse =  38.018246858016305\n",
      "Progress: 3.05%\n",
      "36\n",
      "max difference =  59.80616760253906\n",
      "data at max difference =  3.6129720211029053\n",
      "imputed at max difference =  63.41913986206055\n",
      "mae =  1.3238325119018555\n",
      "rmse =  35.58812945822011\n",
      "Progress: 3.14%\n",
      "37\n",
      "max difference =  18.350412368774414\n",
      "data at max difference =  3.030712366104126\n",
      "imputed at max difference =  21.38112449645996\n",
      "mae =  0.47393056750297546\n",
      "rmse =  10.518490335215693\n",
      "Progress: 3.22%\n",
      "38\n",
      "max difference =  44.86400604248047\n",
      "data at max difference =  3.2595252990722656\n",
      "imputed at max difference =  48.123531341552734\n",
      "mae =  0.620823860168457\n",
      "rmse =  20.796234130859375\n",
      "Progress: 3.31%\n",
      "39\n",
      "max difference =  12.770049095153809\n",
      "data at max difference =  3.023979425430298\n",
      "imputed at max difference =  15.794028282165527\n",
      "mae =  0.22185243666172028\n",
      "rmse =  5.9295541514521055\n",
      "Progress: 3.39%\n",
      "40\n",
      "max difference =  15.389985084533691\n",
      "data at max difference =  2.844825029373169\n",
      "imputed at max difference =  18.23480987548828\n",
      "mae =  0.4361678957939148\n",
      "rmse =  9.016215448794156\n",
      "Progress: 3.47%\n",
      "41\n",
      "max difference =  3.991170883178711\n",
      "data at max difference =  2.1045942306518555\n",
      "imputed at max difference =  6.095765113830566\n",
      "mae =  0.16162167489528656\n",
      "rmse =  3.06193675165591\n",
      "Progress: 3.56%\n",
      "42\n",
      "max difference =  49.69900894165039\n",
      "data at max difference =  2.1207797527313232\n",
      "imputed at max difference =  51.81978988647461\n",
      "mae =  0.9912211298942566\n",
      "rmse =  29.475246263586957\n",
      "Progress: 3.64%\n",
      "43\n",
      "max difference =  5.765689849853516\n",
      "data at max difference =  2.022857904434204\n",
      "imputed at max difference =  7.788547992706299\n",
      "mae =  0.1370164155960083\n",
      "rmse =  2.8098569123641304\n",
      "Progress: 3.73%\n",
      "44\n",
      "max difference =  1.8398244380950928\n",
      "data at max difference =  4.07535982131958\n",
      "imputed at max difference =  2.2355353832244873\n",
      "mae =  0.09369209408760071\n",
      "rmse =  1.1907703565514607\n",
      "Progress: 3.81%\n",
      "45\n",
      "max difference =  13.17258071899414\n",
      "data at max difference =  1.7150543928146362\n",
      "imputed at max difference =  14.887635231018066\n",
      "mae =  0.22653308510780334\n",
      "rmse =  6.154426906419837\n",
      "Progress: 3.90%\n",
      "46\n",
      "max difference =  13.690712928771973\n",
      "data at max difference =  3.3105075359344482\n",
      "imputed at max difference =  17.001220703125\n",
      "mae =  0.22333809733390808\n",
      "rmse =  6.35100853961447\n",
      "Progress: 3.98%\n",
      "47\n",
      "max difference =  5.967013835906982\n",
      "data at max difference =  3.8365588188171387\n",
      "imputed at max difference =  9.803572654724121\n",
      "mae =  0.13918805122375488\n",
      "rmse =  2.976519045622452\n",
      "Progress: 4.07%\n",
      "48\n",
      "max difference =  20.355268478393555\n",
      "data at max difference =  3.6271133422851562\n",
      "imputed at max difference =  23.98238182067871\n",
      "mae =  0.4512752890586853\n",
      "rmse =  11.687473462975543\n",
      "Progress: 4.15%\n",
      "49\n",
      "max difference =  2.216744899749756\n",
      "data at max difference =  4.738558769226074\n",
      "imputed at max difference =  2.5218138694763184\n",
      "mae =  0.07948707044124603\n",
      "rmse =  1.3181293321692424\n",
      "Progress: 4.24%\n",
      "50\n",
      "max difference =  4.827827453613281\n",
      "data at max difference =  4.473196029663086\n",
      "imputed at max difference =  9.301023483276367\n",
      "mae =  0.12193666398525238\n",
      "rmse =  2.5183992800505264\n",
      "Progress: 4.32%\n",
      "51\n",
      "max difference =  14.627638816833496\n",
      "data at max difference =  4.618027687072754\n",
      "imputed at max difference =  19.24566650390625\n",
      "mae =  0.20243366062641144\n",
      "rmse =  6.766563083814538\n",
      "Progress: 4.41%\n",
      "52\n",
      "max difference =  74.94363403320312\n",
      "data at max difference =  4.122889995574951\n",
      "imputed at max difference =  79.06652069091797\n",
      "mae =  1.0443133115768433\n",
      "rmse =  35.11621624490489\n",
      "Progress: 4.49%\n",
      "53\n",
      "max difference =  1.3589192628860474\n",
      "data at max difference =  3.171074867248535\n",
      "imputed at max difference =  1.8121556043624878\n",
      "mae =  0.0368489995598793\n",
      "rmse =  0.6726860378099524\n",
      "Progress: 4.58%\n",
      "54\n",
      "max difference =  52.595298767089844\n",
      "data at max difference =  3.536703109741211\n",
      "imputed at max difference =  56.13200378417969\n",
      "mae =  0.7084168195724487\n",
      "rmse =  24.571137801460598\n",
      "Progress: 4.66%\n",
      "55\n",
      "max difference =  76.3271255493164\n",
      "data at max difference =  3.2829904556274414\n",
      "imputed at max difference =  79.61011505126953\n",
      "mae =  0.8996316194534302\n",
      "rmse =  35.050494650135875\n",
      "Progress: 4.75%\n",
      "56\n",
      "max difference =  9.626307487487793\n",
      "data at max difference =  3.0583953857421875\n",
      "imputed at max difference =  12.68470287322998\n",
      "mae =  0.17892003059387207\n",
      "rmse =  4.880510744841202\n",
      "Progress: 4.83%\n",
      "57\n",
      "max difference =  17.845914840698242\n",
      "data at max difference =  3.733560085296631\n",
      "imputed at max difference =  21.57947540283203\n",
      "mae =  0.389816552400589\n",
      "rmse =  9.625132021696672\n",
      "Progress: 4.92%\n",
      "58\n",
      "max difference =  4.554954528808594\n",
      "data at max difference =  5.34846830368042\n",
      "imputed at max difference =  0.7935139536857605\n",
      "mae =  0.2604127526283264\n",
      "rmse =  3.4675525167713994\n",
      "Progress: 5.00%\n",
      "0\n",
      "max difference =  114.05531311035156\n",
      "data at max difference =  2.3850014209747314\n",
      "imputed at max difference =  116.44031524658203\n",
      "mae =  1.5755044221878052\n",
      "rmse =  52.535076638926625\n",
      "Progress: 5.08%\n",
      "1\n",
      "max difference =  12.994390487670898\n",
      "data at max difference =  5.496946334838867\n",
      "imputed at max difference =  18.491336822509766\n",
      "mae =  0.4189988374710083\n",
      "rmse =  6.933741030485733\n",
      "Progress: 5.17%\n",
      "2\n",
      "max difference =  59.491241455078125\n",
      "data at max difference =  5.610413074493408\n",
      "imputed at max difference =  65.10165405273438\n",
      "mae =  1.8656554222106934\n",
      "rmse =  37.042416779891305\n",
      "Progress: 5.25%\n",
      "3\n",
      "max difference =  183.3082733154297\n",
      "data at max difference =  1.3048335313796997\n",
      "imputed at max difference =  184.6131134033203\n",
      "mae =  4.1278252601623535\n",
      "rmse =  97.27430791440217\n",
      "Progress: 5.34%\n",
      "4\n",
      "max difference =  149.17723083496094\n",
      "data at max difference =  1.5234109163284302\n",
      "imputed at max difference =  150.7006378173828\n",
      "mae =  2.3178811073303223\n",
      "rmse =  69.5322265625\n",
      "Progress: 5.42%\n",
      "5\n",
      "max difference =  142.6654815673828\n",
      "data at max difference =  4.73240327835083\n",
      "imputed at max difference =  147.39788818359375\n",
      "mae =  2.188616991043091\n",
      "rmse =  65.8801959493886\n",
      "Progress: 5.51%\n",
      "6\n",
      "max difference =  100.49305725097656\n",
      "data at max difference =  5.106971740722656\n",
      "imputed at max difference =  105.60002899169922\n",
      "mae =  2.956374406814575\n",
      "rmse =  60.15511952275815\n",
      "Progress: 5.59%\n",
      "7\n",
      "max difference =  18.76034927368164\n",
      "data at max difference =  1.7896761894226074\n",
      "imputed at max difference =  20.550025939941406\n",
      "mae =  0.9640288949012756\n",
      "rmse =  15.111963686735733\n",
      "Progress: 5.68%\n",
      "8\n",
      "max difference =  162.0183868408203\n",
      "data at max difference =  4.5931077003479\n",
      "imputed at max difference =  166.6114959716797\n",
      "mae =  2.4485385417938232\n",
      "rmse =  75.76968516474184\n",
      "Progress: 5.76%\n",
      "9\n",
      "max difference =  154.92465209960938\n",
      "data at max difference =  3.422072172164917\n",
      "imputed at max difference =  158.3467254638672\n",
      "mae =  2.3408424854278564\n",
      "rmse =  73.30130668308425\n",
      "Progress: 5.85%\n",
      "10\n",
      "max difference =  4.031744003295898\n",
      "data at max difference =  3.435976505279541\n",
      "imputed at max difference =  7.4677205085754395\n",
      "mae =  0.18764983117580414\n",
      "rmse =  2.6182229415230127\n",
      "Progress: 5.93%\n",
      "11\n",
      "max difference =  74.78224182128906\n",
      "data at max difference =  3.75504207611084\n",
      "imputed at max difference =  78.53728485107422\n",
      "mae =  1.5071728229522705\n",
      "rmse =  41.043149201766305\n",
      "Progress: 6.02%\n",
      "12\n",
      "max difference =  26.593616485595703\n",
      "data at max difference =  3.242663860321045\n",
      "imputed at max difference =  29.836280822753906\n",
      "mae =  0.41820865869522095\n",
      "rmse =  12.27013762100883\n",
      "Progress: 6.10%\n",
      "13\n",
      "max difference =  37.66301345825195\n",
      "data at max difference =  3.078768014907837\n",
      "imputed at max difference =  40.741783142089844\n",
      "mae =  1.0545490980148315\n",
      "rmse =  24.38683551290761\n",
      "Progress: 6.19%\n",
      "14\n",
      "max difference =  51.97016143798828\n",
      "data at max difference =  4.049773693084717\n",
      "imputed at max difference =  56.019935607910156\n",
      "mae =  0.8741022348403931\n",
      "rmse =  26.360319718070652\n",
      "Progress: 6.27%\n",
      "15\n",
      "max difference =  24.355539321899414\n",
      "data at max difference =  3.5889499187469482\n",
      "imputed at max difference =  27.944488525390625\n",
      "mae =  0.5955822467803955\n",
      "rmse =  14.608751379925272\n",
      "Progress: 6.36%\n",
      "16\n",
      "max difference =  66.20936584472656\n",
      "data at max difference =  4.297800540924072\n",
      "imputed at max difference =  70.50716400146484\n",
      "mae =  1.3886399269104004\n",
      "rmse =  36.686735733695656\n",
      "Progress: 6.44%\n",
      "17\n",
      "max difference =  42.624847412109375\n",
      "data at max difference =  3.383026599884033\n",
      "imputed at max difference =  46.00787353515625\n",
      "mae =  1.2102290391921997\n",
      "rmse =  29.37687882133152\n",
      "Progress: 6.53%\n",
      "18\n",
      "max difference =  33.605560302734375\n",
      "data at max difference =  3.599268674850464\n",
      "imputed at max difference =  37.204830169677734\n",
      "mae =  0.5327355265617371\n",
      "rmse =  15.848923392917799\n",
      "Progress: 6.61%\n",
      "19\n",
      "max difference =  49.55601119995117\n",
      "data at max difference =  3.578327178955078\n",
      "imputed at max difference =  53.13433837890625\n",
      "mae =  0.7790672183036804\n",
      "rmse =  23.437545112941578\n",
      "Progress: 6.69%\n",
      "20\n",
      "max difference =  30.054594039916992\n",
      "data at max difference =  3.635903835296631\n",
      "imputed at max difference =  33.69049835205078\n",
      "mae =  0.7026253342628479\n",
      "rmse =  17.548491104789402\n",
      "Progress: 6.78%\n",
      "21\n",
      "max difference =  21.074670791625977\n",
      "data at max difference =  3.333967447280884\n",
      "imputed at max difference =  24.40863800048828\n",
      "mae =  0.40920543670654297\n",
      "rmse =  11.072088490361754\n",
      "Progress: 6.86%\n",
      "22\n",
      "max difference =  26.130462646484375\n",
      "data at max difference =  2.8592002391815186\n",
      "imputed at max difference =  28.989662170410156\n",
      "mae =  0.5987611413002014\n",
      "rmse =  14.9533227008322\n",
      "Progress: 6.95%\n",
      "23\n",
      "max difference =  65.40142822265625\n",
      "data at max difference =  3.0022151470184326\n",
      "imputed at max difference =  68.40364074707031\n",
      "mae =  0.9643567204475403\n",
      "rmse =  30.595151154891305\n",
      "Progress: 7.03%\n",
      "24\n",
      "max difference =  3.7134852409362793\n",
      "data at max difference =  2.3074660301208496\n",
      "imputed at max difference =  6.020951271057129\n",
      "mae =  0.18026328086853027\n",
      "rmse =  2.7122203992760703\n",
      "Progress: 7.12%\n",
      "25\n",
      "max difference =  87.99678039550781\n",
      "data at max difference =  3.3274190425872803\n",
      "imputed at max difference =  91.3241958618164\n",
      "mae =  1.8716940879821777\n",
      "rmse =  46.61537767493206\n",
      "Progress: 7.20%\n",
      "26\n",
      "max difference =  38.93265914916992\n",
      "data at max difference =  2.975456476211548\n",
      "imputed at max difference =  41.90811538696289\n",
      "mae =  0.8855199813842773\n",
      "rmse =  20.27262546705163\n",
      "Progress: 7.29%\n",
      "27\n",
      "max difference =  46.76467514038086\n",
      "data at max difference =  2.310703754425049\n",
      "imputed at max difference =  49.07537841796875\n",
      "mae =  1.338301658630371\n",
      "rmse =  30.337402343749996\n",
      "Progress: 7.37%\n",
      "28\n",
      "max difference =  78.33063507080078\n",
      "data at max difference =  3.531285285949707\n",
      "imputed at max difference =  81.86192321777344\n",
      "mae =  1.9815372228622437\n",
      "rmse =  47.74790357506794\n",
      "Progress: 7.46%\n",
      "29\n",
      "max difference =  25.391878128051758\n",
      "data at max difference =  3.1065943241119385\n",
      "imputed at max difference =  28.498472213745117\n",
      "mae =  0.6082990765571594\n",
      "rmse =  13.469895072605297\n",
      "Progress: 7.54%\n",
      "30\n",
      "max difference =  19.463075637817383\n",
      "data at max difference =  3.594463348388672\n",
      "imputed at max difference =  23.057538986206055\n",
      "mae =  0.6771865487098694\n",
      "rmse =  13.886515741762908\n",
      "Progress: 7.63%\n",
      "31\n",
      "max difference =  65.44577026367188\n",
      "data at max difference =  3.6001527309417725\n",
      "imputed at max difference =  69.0459213256836\n",
      "mae =  1.3456600904464722\n",
      "rmse =  34.29762865149456\n",
      "Progress: 7.71%\n",
      "32\n",
      "max difference =  58.48784255981445\n",
      "data at max difference =  3.586270332336426\n",
      "imputed at max difference =  62.07411193847656\n",
      "mae =  1.8416879177093506\n",
      "rmse =  39.318359375\n",
      "Progress: 7.80%\n",
      "33\n",
      "max difference =  35.867393493652344\n",
      "data at max difference =  3.5381031036376953\n",
      "imputed at max difference =  39.40549850463867\n",
      "mae =  0.9131929278373718\n",
      "rmse =  22.175891378651492\n",
      "Progress: 7.88%\n",
      "34\n",
      "max difference =  43.629146575927734\n",
      "data at max difference =  3.5691335201263428\n",
      "imputed at max difference =  47.198280334472656\n",
      "mae =  0.7860748171806335\n",
      "rmse =  21.370653235394023\n",
      "Progress: 7.97%\n",
      "35\n",
      "max difference =  111.14027404785156\n",
      "data at max difference =  3.109546422958374\n",
      "imputed at max difference =  114.24981689453125\n",
      "mae =  2.9016969203948975\n",
      "rmse =  74.12552543308423\n",
      "Progress: 8.05%\n",
      "36\n",
      "max difference =  38.90477752685547\n",
      "data at max difference =  3.144315719604492\n",
      "imputed at max difference =  42.049095153808594\n",
      "mae =  1.088951587677002\n",
      "rmse =  25.048315960427992\n",
      "Progress: 8.14%\n",
      "37\n",
      "max difference =  221.90357971191406\n",
      "data at max difference =  3.625164747238159\n",
      "imputed at max difference =  225.52874755859375\n",
      "mae =  3.60103702545166\n",
      "rmse =  109.47255010190217\n",
      "Progress: 8.22%\n",
      "38\n",
      "max difference =  8.962519645690918\n",
      "data at max difference =  3.179063081741333\n",
      "imputed at max difference =  12.141582489013672\n",
      "mae =  0.21377989649772644\n",
      "rmse =  4.707650557808254\n",
      "Progress: 8.31%\n",
      "39\n",
      "max difference =  11.885934829711914\n",
      "data at max difference =  2.502089738845825\n",
      "imputed at max difference =  14.38802433013916\n",
      "mae =  0.46742239594459534\n",
      "rmse =  8.809252531632133\n",
      "Progress: 8.39%\n",
      "40\n",
      "max difference =  58.19659423828125\n",
      "data at max difference =  2.7489545345306396\n",
      "imputed at max difference =  60.94554901123047\n",
      "mae =  1.243173360824585\n",
      "rmse =  34.33440100628397\n",
      "Progress: 8.47%\n",
      "41\n",
      "max difference =  12.953753471374512\n",
      "data at max difference =  3.2627665996551514\n",
      "imputed at max difference =  16.216520309448242\n",
      "mae =  0.3245033919811249\n",
      "rmse =  6.961141171662703\n",
      "Progress: 8.56%\n",
      "42\n",
      "max difference =  26.459381103515625\n",
      "data at max difference =  3.536712169647217\n",
      "imputed at max difference =  29.99609375\n",
      "mae =  0.42837420105934143\n",
      "rmse =  12.458241338315219\n",
      "Progress: 8.64%\n",
      "43\n",
      "max difference =  4.6812825202941895\n",
      "data at max difference =  1.7463536262512207\n",
      "imputed at max difference =  6.42763614654541\n",
      "mae =  0.14324301481246948\n",
      "rmse =  2.6511610279912534\n",
      "Progress: 8.73%\n",
      "44\n",
      "max difference =  28.581497192382812\n",
      "data at max difference =  3.745873212814331\n",
      "imputed at max difference =  32.327369689941406\n",
      "mae =  0.4161607325077057\n",
      "rmse =  13.300184166949727\n",
      "Progress: 8.81%\n",
      "45\n",
      "max difference =  4.180997371673584\n",
      "data at max difference =  3.8894925117492676\n",
      "imputed at max difference =  8.070489883422852\n",
      "mae =  0.13177670538425446\n",
      "rmse =  2.3354122327721636\n",
      "Progress: 8.90%\n",
      "46\n",
      "max difference =  56.709754943847656\n",
      "data at max difference =  3.933950424194336\n",
      "imputed at max difference =  60.643707275390625\n",
      "mae =  0.7335981726646423\n",
      "rmse =  26.006416652513586\n",
      "Progress: 8.98%\n",
      "47\n",
      "max difference =  18.5927734375\n",
      "data at max difference =  3.482053518295288\n",
      "imputed at max difference =  22.074827194213867\n",
      "mae =  0.40980616211891174\n",
      "rmse =  10.338014685589334\n",
      "Progress: 9.07%\n",
      "48\n",
      "max difference =  13.008855819702148\n",
      "data at max difference =  3.996349573135376\n",
      "imputed at max difference =  17.005205154418945\n",
      "mae =  0.22726790606975555\n",
      "rmse =  6.100705354110055\n",
      "Progress: 9.15%\n",
      "49\n",
      "max difference =  2.3716487884521484\n",
      "data at max difference =  4.738558769226074\n",
      "imputed at max difference =  7.110207557678223\n",
      "mae =  0.11817019432783127\n",
      "rmse =  1.838665837826936\n",
      "Progress: 9.24%\n",
      "50\n",
      "max difference =  22.471590042114258\n",
      "data at max difference =  3.7768969535827637\n",
      "imputed at max difference =  26.24848747253418\n",
      "mae =  0.44632643461227417\n",
      "rmse =  12.978952159052309\n",
      "Progress: 9.32%\n",
      "51\n",
      "max difference =  41.726402282714844\n",
      "data at max difference =  4.304757595062256\n",
      "imputed at max difference =  46.031158447265625\n",
      "mae =  0.48418962955474854\n",
      "rmse =  19.070145316745922\n",
      "Progress: 9.41%\n",
      "52\n",
      "max difference =  92.84180450439453\n",
      "data at max difference =  3.1322391033172607\n",
      "imputed at max difference =  95.97404479980469\n",
      "mae =  1.253793716430664\n",
      "rmse =  43.61758024796195\n",
      "Progress: 9.49%\n",
      "53\n",
      "max difference =  9.469284057617188\n",
      "data at max difference =  3.7796366214752197\n",
      "imputed at max difference =  13.248920440673828\n",
      "mae =  0.14035342633724213\n",
      "rmse =  4.38583639393682\n",
      "Progress: 9.58%\n",
      "54\n",
      "max difference =  67.78614044189453\n",
      "data at max difference =  3.1952109336853027\n",
      "imputed at max difference =  70.98135375976562\n",
      "mae =  1.0118731260299683\n",
      "rmse =  32.53718633237093\n",
      "Progress: 9.66%\n",
      "55\n",
      "max difference =  18.548776626586914\n",
      "data at max difference =  3.6263844966888428\n",
      "imputed at max difference =  22.175161361694336\n",
      "mae =  0.28850722312927246\n",
      "rmse =  9.045902418053668\n",
      "Progress: 9.75%\n",
      "56\n",
      "max difference =  79.09477233886719\n",
      "data at max difference =  3.957808017730713\n",
      "imputed at max difference =  83.05258178710938\n",
      "mae =  1.3843159675598145\n",
      "rmse =  39.20823868461277\n",
      "Progress: 9.83%\n",
      "57\n",
      "max difference =  48.193267822265625\n",
      "data at max difference =  4.061976432800293\n",
      "imputed at max difference =  52.255245208740234\n",
      "mae =  1.0583547353744507\n",
      "rmse =  29.787523352581523\n",
      "Progress: 9.92%\n",
      "58\n",
      "max difference =  117.6114730834961\n",
      "data at max difference =  5.34846830368042\n",
      "imputed at max difference =  122.9599380493164\n",
      "mae =  1.3381136655807495\n",
      "rmse =  53.66806428328804\n",
      "Progress: 10.00%\n",
      "0\n",
      "max difference =  20.255573272705078\n",
      "data at max difference =  2.3850014209747314\n",
      "imputed at max difference =  22.640575408935547\n",
      "mae =  0.5263546109199524\n",
      "rmse =  10.542031329611074\n",
      "Progress: 10.08%\n",
      "1\n",
      "max difference =  55.158416748046875\n",
      "data at max difference =  5.496946334838867\n",
      "imputed at max difference =  60.65536117553711\n",
      "mae =  0.9246826767921448\n",
      "rmse =  26.56732177734375\n",
      "Progress: 10.17%\n",
      "2\n",
      "max difference =  53.8056755065918\n",
      "data at max difference =  5.610413074493408\n",
      "imputed at max difference =  59.41608810424805\n",
      "mae =  1.0678389072418213\n",
      "rmse =  26.050810440726902\n",
      "Progress: 10.25%\n",
      "3\n",
      "max difference =  95.52173614501953\n",
      "data at max difference =  1.3048335313796997\n",
      "imputed at max difference =  96.82656860351562\n",
      "mae =  3.218736410140991\n",
      "rmse =  66.13041886039403\n",
      "Progress: 10.34%\n",
      "4\n",
      "max difference =  216.2783660888672\n",
      "data at max difference =  4.6376261711120605\n",
      "imputed at max difference =  220.91598510742188\n",
      "mae =  5.711883544921875\n",
      "rmse =  116.17741593070652\n",
      "Progress: 10.42%\n",
      "5\n",
      "max difference =  142.45179748535156\n",
      "data at max difference =  15.96798324584961\n",
      "imputed at max difference =  158.41978454589844\n",
      "mae =  4.077132225036621\n",
      "rmse =  84.5621868631114\n",
      "Progress: 10.51%\n",
      "6\n",
      "max difference =  36.04642105102539\n",
      "data at max difference =  4.360837459564209\n",
      "imputed at max difference =  40.407257080078125\n",
      "mae =  1.1979883909225464\n",
      "rmse =  22.53545611837636\n",
      "Progress: 10.59%\n",
      "7\n",
      "max difference =  75.27920532226562\n",
      "data at max difference =  3.7007248401641846\n",
      "imputed at max difference =  78.97992706298828\n",
      "mae =  2.251127243041992\n",
      "rmse =  48.57651154891304\n",
      "Progress: 10.68%\n",
      "8\n",
      "max difference =  47.291019439697266\n",
      "data at max difference =  4.2853007316589355\n",
      "imputed at max difference =  51.57632064819336\n",
      "mae =  1.2436038255691528\n",
      "rmse =  25.46539306640625\n",
      "Progress: 10.76%\n",
      "9\n",
      "max difference =  75.94110107421875\n",
      "data at max difference =  3.7451744079589844\n",
      "imputed at max difference =  79.686279296875\n",
      "mae =  1.025154948234558\n",
      "rmse =  34.883263629415765\n",
      "Progress: 10.85%\n",
      "10\n",
      "max difference =  18.544078826904297\n",
      "data at max difference =  2.881241798400879\n",
      "imputed at max difference =  21.425321578979492\n",
      "mae =  0.4832583963871002\n",
      "rmse =  11.315750785495924\n",
      "Progress: 10.93%\n",
      "11\n",
      "max difference =  16.942852020263672\n",
      "data at max difference =  2.8884100914001465\n",
      "imputed at max difference =  19.831262588500977\n",
      "mae =  0.48350009322166443\n",
      "rmse =  9.913722826086957\n",
      "Progress: 11.02%\n",
      "12\n",
      "max difference =  138.5990447998047\n",
      "data at max difference =  3.242663860321045\n",
      "imputed at max difference =  141.84170532226562\n",
      "mae =  1.8843940496444702\n",
      "rmse =  64.70340098505434\n",
      "Progress: 11.10%\n",
      "13\n",
      "max difference =  88.31547546386719\n",
      "data at max difference =  3.078768014907837\n",
      "imputed at max difference =  91.39424133300781\n",
      "mae =  1.0593054294586182\n",
      "rmse =  40.38740871263587\n",
      "Progress: 11.19%\n",
      "14\n",
      "max difference =  27.829124450683594\n",
      "data at max difference =  3.7214345932006836\n",
      "imputed at max difference =  31.55055809020996\n",
      "mae =  0.5015361905097961\n",
      "rmse =  13.787660018257473\n",
      "Progress: 11.27%\n",
      "15\n",
      "max difference =  82.39228820800781\n",
      "data at max difference =  4.187092304229736\n",
      "imputed at max difference =  86.57938385009766\n",
      "mae =  2.601257801055908\n",
      "rmse =  59.72858462126359\n",
      "Progress: 11.36%\n",
      "16\n",
      "max difference =  46.32028579711914\n",
      "data at max difference =  3.6800894737243652\n",
      "imputed at max difference =  50.00037384033203\n",
      "mae =  0.6013954877853394\n",
      "rmse =  21.29586526621943\n",
      "Progress: 11.44%\n",
      "17\n",
      "max difference =  65.66394805908203\n",
      "data at max difference =  4.372129440307617\n",
      "imputed at max difference =  70.03607940673828\n",
      "mae =  0.8160298466682434\n",
      "rmse =  30.09878672724185\n",
      "Progress: 11.53%\n",
      "18\n",
      "max difference =  46.88114929199219\n",
      "data at max difference =  3.599268674850464\n",
      "imputed at max difference =  50.48041915893555\n",
      "mae =  1.0238810777664185\n",
      "rmse =  27.62254001783288\n",
      "Progress: 11.61%\n",
      "19\n",
      "max difference =  156.86155700683594\n",
      "data at max difference =  3.578327178955078\n",
      "imputed at max difference =  160.43988037109375\n",
      "mae =  2.414907693862915\n",
      "rmse =  76.56943147078805\n",
      "Progress: 11.69%\n",
      "20\n",
      "max difference =  22.243824005126953\n",
      "data at max difference =  3.3378450870513916\n",
      "imputed at max difference =  25.581668853759766\n",
      "mae =  0.6442601084709167\n",
      "rmse =  14.836875583814537\n",
      "Progress: 11.78%\n",
      "21\n",
      "max difference =  19.020788192749023\n",
      "data at max difference =  2.794804811477661\n",
      "imputed at max difference =  21.815593719482422\n",
      "mae =  0.28965044021606445\n",
      "rmse =  8.835256161897078\n",
      "Progress: 11.86%\n",
      "22\n",
      "max difference =  33.13969802856445\n",
      "data at max difference =  3.7011895179748535\n",
      "imputed at max difference =  36.84088897705078\n",
      "mae =  0.6008689999580383\n",
      "rmse =  16.511466648267664\n",
      "Progress: 11.95%\n",
      "23\n",
      "max difference =  19.31048583984375\n",
      "data at max difference =  2.2658510208129883\n",
      "imputed at max difference =  21.576335906982422\n",
      "mae =  0.5008852481842041\n",
      "rmse =  11.922618036684783\n",
      "Progress: 12.03%\n",
      "24\n",
      "max difference =  41.69839096069336\n",
      "data at max difference =  2.3074660301208496\n",
      "imputed at max difference =  44.005855560302734\n",
      "mae =  0.7453551292419434\n",
      "rmse =  20.680317754330844\n",
      "Progress: 12.12%\n",
      "25\n",
      "max difference =  62.22404098510742\n",
      "data at max difference =  2.7550079822540283\n",
      "imputed at max difference =  64.97904968261719\n",
      "mae =  1.410564661026001\n",
      "rmse =  32.998482082201086\n",
      "Progress: 12.20%\n",
      "26\n",
      "max difference =  39.76816177368164\n",
      "data at max difference =  3.524782419204712\n",
      "imputed at max difference =  43.292945861816406\n",
      "mae =  1.330936074256897\n",
      "rmse =  28.04164455247962\n",
      "Progress: 12.29%\n",
      "27\n",
      "max difference =  25.729480743408203\n",
      "data at max difference =  2.911207675933838\n",
      "imputed at max difference =  28.640687942504883\n",
      "mae =  0.5628569722175598\n",
      "rmse =  13.342846414317256\n",
      "Progress: 12.37%\n",
      "28\n",
      "max difference =  51.581504821777344\n",
      "data at max difference =  2.9589877128601074\n",
      "imputed at max difference =  54.54049301147461\n",
      "mae =  1.1299991607666016\n",
      "rmse =  27.851668648097828\n",
      "Progress: 12.46%\n",
      "29\n",
      "max difference =  15.001932144165039\n",
      "data at max difference =  3.5692858695983887\n",
      "imputed at max difference =  18.571218490600586\n",
      "mae =  0.45955103635787964\n",
      "rmse =  10.227133709451426\n",
      "Progress: 12.54%\n",
      "30\n",
      "max difference =  19.017574310302734\n",
      "data at max difference =  3.1269123554229736\n",
      "imputed at max difference =  22.144487380981445\n",
      "mae =  0.4747358560562134\n",
      "rmse =  11.8675537109375\n",
      "Progress: 12.63%\n",
      "31\n",
      "max difference =  57.550132751464844\n",
      "data at max difference =  3.720954418182373\n",
      "imputed at max difference =  61.271087646484375\n",
      "mae =  1.2302236557006836\n",
      "rmse =  32.24394425101902\n",
      "Progress: 12.71%\n",
      "32\n",
      "max difference =  103.552978515625\n",
      "data at max difference =  3.586270332336426\n",
      "imputed at max difference =  107.13925170898438\n",
      "mae =  1.7312616109848022\n",
      "rmse =  50.69146463145381\n",
      "Progress: 12.80%\n",
      "33\n",
      "max difference =  20.321090698242188\n",
      "data at max difference =  2.9661622047424316\n",
      "imputed at max difference =  23.28725242614746\n",
      "mae =  0.6683140397071838\n",
      "rmse =  13.558491582455842\n",
      "Progress: 12.88%\n",
      "34\n",
      "max difference =  36.368343353271484\n",
      "data at max difference =  3.5691335201263428\n",
      "imputed at max difference =  39.937477111816406\n",
      "mae =  0.8889807462692261\n",
      "rmse =  19.571956468665082\n",
      "Progress: 12.97%\n",
      "35\n",
      "max difference =  86.9175033569336\n",
      "data at max difference =  2.425321340560913\n",
      "imputed at max difference =  89.34282684326172\n",
      "mae =  1.7990516424179077\n",
      "rmse =  45.42799443783967\n",
      "Progress: 13.05%\n",
      "36\n",
      "max difference =  34.14910125732422\n",
      "data at max difference =  3.024057149887085\n",
      "imputed at max difference =  37.17315673828125\n",
      "mae =  0.42587199807167053\n",
      "rmse =  15.613688593325408\n",
      "Progress: 13.14%\n",
      "37\n",
      "max difference =  50.98908996582031\n",
      "data at max difference =  3.152101755142212\n",
      "imputed at max difference =  54.14119338989258\n",
      "mae =  0.9215592741966248\n",
      "rmse =  25.040928052819293\n",
      "Progress: 13.22%\n",
      "38\n",
      "max difference =  77.92459106445312\n",
      "data at max difference =  2.96101450920105\n",
      "imputed at max difference =  80.88560485839844\n",
      "mae =  2.193396806716919\n",
      "rmse =  52.76930833899457\n",
      "Progress: 13.31%\n",
      "39\n",
      "max difference =  73.58248901367188\n",
      "data at max difference =  2.502089738845825\n",
      "imputed at max difference =  76.08457946777344\n",
      "mae =  1.098775863647461\n",
      "rmse =  34.73005211871603\n",
      "Progress: 13.39%\n",
      "40\n",
      "max difference =  28.753232955932617\n",
      "data at max difference =  2.3753409385681152\n",
      "imputed at max difference =  31.12857437133789\n",
      "mae =  0.6923731565475464\n",
      "rmse =  16.95683885657269\n",
      "Progress: 13.47%\n",
      "41\n",
      "max difference =  23.147449493408203\n",
      "data at max difference =  1.7181442975997925\n",
      "imputed at max difference =  24.86559295654297\n",
      "mae =  0.5837808847427368\n",
      "rmse =  13.025062892747963\n",
      "Progress: 13.56%\n",
      "42\n",
      "max difference =  56.71489334106445\n",
      "data at max difference =  1.7637147903442383\n",
      "imputed at max difference =  58.478607177734375\n",
      "mae =  0.8329408168792725\n",
      "rmse =  26.44923201851223\n",
      "Progress: 13.64%\n",
      "43\n",
      "max difference =  12.743565559387207\n",
      "data at max difference =  1.6754016876220703\n",
      "imputed at max difference =  14.418967247009277\n",
      "mae =  0.2148798257112503\n",
      "rmse =  5.913928488026494\n",
      "Progress: 13.73%\n",
      "44\n",
      "max difference =  17.164695739746094\n",
      "data at max difference =  4.07535982131958\n",
      "imputed at max difference =  21.240055084228516\n",
      "mae =  0.26119059324264526\n",
      "rmse =  7.928183514138927\n",
      "Progress: 13.81%\n",
      "45\n",
      "max difference =  9.957611083984375\n",
      "data at max difference =  4.227313041687012\n",
      "imputed at max difference =  14.184924125671387\n",
      "mae =  0.21315230429172516\n",
      "rmse =  4.922065403150476\n",
      "Progress: 13.90%\n",
      "46\n",
      "max difference =  17.67561149597168\n",
      "data at max difference =  3.6604838371276855\n",
      "imputed at max difference =  21.336095809936523\n",
      "mae =  0.2905231714248657\n",
      "rmse =  8.388983685037363\n",
      "Progress: 13.98%\n",
      "47\n",
      "max difference =  1.5789597034454346\n",
      "data at max difference =  4.113564491271973\n",
      "imputed at max difference =  2.534604787826538\n",
      "mae =  0.08232443779706955\n",
      "rmse =  1.1363442462423574\n",
      "Progress: 14.07%\n",
      "48\n",
      "max difference =  13.709867477416992\n",
      "data at max difference =  3.996349573135376\n",
      "imputed at max difference =  17.70621681213379\n",
      "mae =  0.21419478952884674\n",
      "rmse =  6.339027073072351\n",
      "Progress: 14.15%\n",
      "49\n",
      "max difference =  8.400834083557129\n",
      "data at max difference =  4.054295539855957\n",
      "imputed at max difference =  12.455129623413086\n",
      "mae =  0.15165498852729797\n",
      "rmse =  3.9629699043605635\n",
      "Progress: 14.24%\n",
      "50\n",
      "max difference =  4.241673469543457\n",
      "data at max difference =  4.473196029663086\n",
      "imputed at max difference =  8.714869499206543\n",
      "mae =  0.10428717732429504\n",
      "rmse =  2.162681413733441\n",
      "Progress: 14.32%\n",
      "51\n",
      "max difference =  36.8276481628418\n",
      "data at max difference =  4.304757595062256\n",
      "imputed at max difference =  41.13240432739258\n",
      "mae =  0.45276618003845215\n",
      "rmse =  16.860119363536004\n",
      "Progress: 14.41%\n",
      "52\n",
      "max difference =  11.854011535644531\n",
      "data at max difference =  3.7667183876037598\n",
      "imputed at max difference =  15.620729446411133\n",
      "mae =  0.20290429890155792\n",
      "rmse =  5.709296848462976\n",
      "Progress: 14.49%\n",
      "53\n",
      "max difference =  17.094135284423828\n",
      "data at max difference =  3.171074867248535\n",
      "imputed at max difference =  20.26521110534668\n",
      "mae =  0.22410550713539124\n",
      "rmse =  7.863899562669836\n",
      "Progress: 14.58%\n",
      "54\n",
      "max difference =  5.585245132446289\n",
      "data at max difference =  3.536703109741211\n",
      "imputed at max difference =  9.1219482421875\n",
      "mae =  0.13259842991828918\n",
      "rmse =  2.9064533399498984\n",
      "Progress: 14.66%\n",
      "55\n",
      "max difference =  8.352253913879395\n",
      "data at max difference =  3.6263844966888428\n",
      "imputed at max difference =  11.978638648986816\n",
      "mae =  0.16734722256660461\n",
      "rmse =  4.184557707413383\n",
      "Progress: 14.75%\n",
      "56\n",
      "max difference =  14.289865493774414\n",
      "data at max difference =  3.634439468383789\n",
      "imputed at max difference =  17.924304962158203\n",
      "mae =  0.18321619927883148\n",
      "rmse =  6.552088198454483\n",
      "Progress: 14.83%\n",
      "57\n",
      "max difference =  18.227767944335938\n",
      "data at max difference =  4.061976432800293\n",
      "imputed at max difference =  22.289745330810547\n",
      "mae =  0.4084390103816986\n",
      "rmse =  11.430922798488451\n",
      "Progress: 14.92%\n",
      "58\n",
      "max difference =  71.04190826416016\n",
      "data at max difference =  1.963033676147461\n",
      "imputed at max difference =  73.00494384765625\n",
      "mae =  1.050825595855713\n",
      "rmse =  32.95774774966033\n",
      "Progress: 15.00%\n",
      "0\n",
      "max difference =  142.1200714111328\n",
      "data at max difference =  4.60740852355957\n",
      "imputed at max difference =  146.72747802734375\n",
      "mae =  1.9453545808792114\n",
      "rmse =  65.72592030400816\n",
      "Progress: 15.08%\n",
      "1\n",
      "max difference =  84.60942077636719\n",
      "data at max difference =  5.496946334838867\n",
      "imputed at max difference =  90.10636901855469\n",
      "mae =  1.5523970127105713\n",
      "rmse =  45.13827912703805\n",
      "Progress: 15.17%\n",
      "2\n",
      "max difference =  106.08060455322266\n",
      "data at max difference =  6.752999305725098\n",
      "imputed at max difference =  112.83360290527344\n",
      "mae =  2.888195037841797\n",
      "rmse =  60.75107209578804\n",
      "Progress: 15.25%\n",
      "3\n",
      "max difference =  95.9782943725586\n",
      "data at max difference =  4.429995536804199\n",
      "imputed at max difference =  100.40828704833984\n",
      "mae =  2.9004199504852295\n",
      "rmse =  64.38983419667119\n",
      "Progress: 15.34%\n",
      "4\n",
      "max difference =  62.906776428222656\n",
      "data at max difference =  15.242568016052246\n",
      "imputed at max difference =  78.14934539794922\n",
      "mae =  3.1005961894989014\n",
      "rmse =  51.92662512737771\n",
      "Progress: 15.42%\n",
      "5\n",
      "max difference =  130.7764129638672\n",
      "data at max difference =  13.818947792053223\n",
      "imputed at max difference =  144.59536743164062\n",
      "mae =  5.391595840454102\n",
      "rmse =  93.14712126358695\n",
      "Progress: 15.51%\n",
      "6\n",
      "max difference =  149.68292236328125\n",
      "data at max difference =  4.688121318817139\n",
      "imputed at max difference =  154.3710479736328\n",
      "mae =  3.3858468532562256\n",
      "rmse =  80.6096881368886\n",
      "Progress: 15.59%\n",
      "7\n",
      "max difference =  113.3950424194336\n",
      "data at max difference =  4.087564945220947\n",
      "imputed at max difference =  117.48260498046875\n",
      "mae =  1.8339306116104126\n",
      "rmse =  55.26889966881794\n",
      "Progress: 15.68%\n",
      "8\n",
      "max difference =  56.504554748535156\n",
      "data at max difference =  4.987031936645508\n",
      "imputed at max difference =  61.49158477783203\n",
      "mae =  1.2828929424285889\n",
      "rmse =  29.77807086447011\n",
      "Progress: 15.76%\n",
      "9\n",
      "max difference =  77.25151062011719\n",
      "data at max difference =  3.169604778289795\n",
      "imputed at max difference =  80.42111206054688\n",
      "mae =  1.8838250637054443\n",
      "rmse =  44.77820354959239\n",
      "Progress: 15.85%\n",
      "10\n",
      "max difference =  61.11411666870117\n",
      "data at max difference =  2.881241798400879\n",
      "imputed at max difference =  63.995357513427734\n",
      "mae =  1.211924433708191\n",
      "rmse =  30.396701978600543\n",
      "Progress: 15.93%\n",
      "11\n",
      "max difference =  60.72565460205078\n",
      "data at max difference =  3.1999928951263428\n",
      "imputed at max difference =  63.9256477355957\n",
      "mae =  1.2278426885604858\n",
      "rmse =  32.05831511124321\n",
      "Progress: 16.02%\n",
      "12\n",
      "max difference =  26.209257125854492\n",
      "data at max difference =  3.242663860321045\n",
      "imputed at max difference =  29.451921463012695\n",
      "mae =  0.6820510625839233\n",
      "rmse =  16.65553084663723\n",
      "Progress: 16.10%\n",
      "13\n",
      "max difference =  137.38258361816406\n",
      "data at max difference =  3.9568417072296143\n",
      "imputed at max difference =  141.3394317626953\n",
      "mae =  1.94325590133667\n",
      "rmse =  64.09412151834239\n",
      "Progress: 16.19%\n",
      "14\n",
      "max difference =  41.679901123046875\n",
      "data at max difference =  4.049773693084717\n",
      "imputed at max difference =  45.72967529296875\n",
      "mae =  1.0238879919052124\n",
      "rmse =  25.412353515625004\n",
      "Progress: 16.27%\n",
      "15\n",
      "max difference =  14.536568641662598\n",
      "data at max difference =  3.5889499187469482\n",
      "imputed at max difference =  18.125518798828125\n",
      "mae =  0.40615954995155334\n",
      "rmse =  8.798657624617867\n",
      "Progress: 16.36%\n",
      "16\n",
      "max difference =  66.7285385131836\n",
      "data at max difference =  3.6800894737243652\n",
      "imputed at max difference =  70.40863037109375\n",
      "mae =  0.8902348279953003\n",
      "rmse =  30.752186650815215\n",
      "Progress: 16.44%\n",
      "17\n",
      "max difference =  26.636943817138672\n",
      "data at max difference =  4.016514301300049\n",
      "imputed at max difference =  30.653457641601562\n",
      "mae =  0.624072790145874\n",
      "rmse =  14.407867431640625\n",
      "Progress: 16.53%\n",
      "18\n",
      "max difference =  21.206268310546875\n",
      "data at max difference =  2.734581470489502\n",
      "imputed at max difference =  23.94084930419922\n",
      "mae =  0.4847189486026764\n",
      "rmse =  11.387338389521059\n",
      "Progress: 16.61%\n",
      "19\n",
      "max difference =  22.852445602416992\n",
      "data at max difference =  3.0443854331970215\n",
      "imputed at max difference =  25.896831512451172\n",
      "mae =  0.4471321105957031\n",
      "rmse =  11.50434278405231\n",
      "Progress: 16.69%\n",
      "20\n",
      "max difference =  76.8003158569336\n",
      "data at max difference =  1.079750657081604\n",
      "imputed at max difference =  77.88006591796875\n",
      "mae =  2.670652389526367\n",
      "rmse =  59.23230511209239\n",
      "Progress: 16.78%\n",
      "21\n",
      "max difference =  46.33426284790039\n",
      "data at max difference =  3.0974695682525635\n",
      "imputed at max difference =  49.431732177734375\n",
      "mae =  0.5605301856994629\n",
      "rmse =  21.16896786897079\n",
      "Progress: 16.86%\n",
      "22\n",
      "max difference =  18.55124282836914\n",
      "data at max difference =  3.7011895179748535\n",
      "imputed at max difference =  22.252431869506836\n",
      "mae =  0.2585740089416504\n",
      "rmse =  8.514909827190898\n",
      "Progress: 16.95%\n",
      "23\n",
      "max difference =  15.454668998718262\n",
      "data at max difference =  2.7374680042266846\n",
      "imputed at max difference =  18.192136764526367\n",
      "mae =  0.37345266342163086\n",
      "rmse =  8.485627547554348\n",
      "Progress: 17.03%\n",
      "24\n",
      "max difference =  32.63221740722656\n",
      "data at max difference =  2.3074660301208496\n",
      "imputed at max difference =  34.93968200683594\n",
      "mae =  0.5410155653953552\n",
      "rmse =  15.977797798488453\n",
      "Progress: 17.12%\n",
      "25\n",
      "max difference =  44.47791290283203\n",
      "data at max difference =  2.7827811241149902\n",
      "imputed at max difference =  47.26069259643555\n",
      "mae =  1.1758091449737549\n",
      "rmse =  26.24787438434103\n",
      "Progress: 17.20%\n",
      "26\n",
      "max difference =  122.21452331542969\n",
      "data at max difference =  2.8632819652557373\n",
      "imputed at max difference =  125.07780456542969\n",
      "mae =  2.350714921951294\n",
      "rmse =  63.57066809612771\n",
      "Progress: 17.29%\n",
      "27\n",
      "max difference =  24.387405395507812\n",
      "data at max difference =  3.0260767936706543\n",
      "imputed at max difference =  27.413482666015625\n",
      "mae =  0.5950216054916382\n",
      "rmse =  13.297937807829483\n",
      "Progress: 17.37%\n",
      "28\n",
      "max difference =  193.43630981445312\n",
      "data at max difference =  3.648150682449341\n",
      "imputed at max difference =  197.08445739746094\n",
      "mae =  2.9251904487609863\n",
      "rmse =  94.72730553668478\n",
      "Progress: 17.46%\n",
      "29\n",
      "max difference =  41.13357925415039\n",
      "data at max difference =  3.5692858695983887\n",
      "imputed at max difference =  44.70286560058594\n",
      "mae =  1.3314238786697388\n",
      "rmse =  28.96501889436141\n",
      "Progress: 17.54%\n",
      "30\n",
      "max difference =  14.077990531921387\n",
      "data at max difference =  3.1269123554229736\n",
      "imputed at max difference =  17.20490264892578\n",
      "mae =  0.3809942305088043\n",
      "rmse =  8.16440084706182\n",
      "Progress: 17.63%\n",
      "31\n",
      "max difference =  27.49816131591797\n",
      "data at max difference =  3.720954418182373\n",
      "imputed at max difference =  31.2191162109375\n",
      "mae =  0.948174774646759\n",
      "rmse =  20.49586951214334\n",
      "Progress: 17.71%\n",
      "32\n",
      "max difference =  37.75373840332031\n",
      "data at max difference =  3.129429817199707\n",
      "imputed at max difference =  40.8831672668457\n",
      "mae =  0.8395596742630005\n",
      "rmse =  21.142322042713996\n",
      "Progress: 17.80%\n",
      "33\n",
      "max difference =  63.50693893432617\n",
      "data at max difference =  2.4541218280792236\n",
      "imputed at max difference =  65.9610595703125\n",
      "mae =  0.9080643057823181\n",
      "rmse =  29.80657162873641\n",
      "Progress: 17.88%\n",
      "34\n",
      "max difference =  68.26062774658203\n",
      "data at max difference =  3.688072681427002\n",
      "imputed at max difference =  71.94869995117188\n",
      "mae =  1.746610403060913\n",
      "rmse =  40.75867229959239\n",
      "Progress: 17.97%\n",
      "35\n",
      "max difference =  57.906585693359375\n",
      "data at max difference =  2.9895694255828857\n",
      "imputed at max difference =  60.896156311035156\n",
      "mae =  1.186127781867981\n",
      "rmse =  32.49794603430706\n",
      "Progress: 18.05%\n",
      "36\n",
      "max difference =  39.448551177978516\n",
      "data at max difference =  3.024057149887085\n",
      "imputed at max difference =  42.47260665893555\n",
      "mae =  0.9342681169509888\n",
      "rmse =  22.60206935716712\n",
      "Progress: 18.14%\n",
      "37\n",
      "max difference =  24.03960609436035\n",
      "data at max difference =  3.625164747238159\n",
      "imputed at max difference =  27.664770126342773\n",
      "mae =  0.8938524723052979\n",
      "rmse =  19.246502420176633\n",
      "Progress: 18.22%\n",
      "38\n",
      "max difference =  24.478837966918945\n",
      "data at max difference =  3.179063081741333\n",
      "imputed at max difference =  27.657901763916016\n",
      "mae =  0.8072630167007446\n",
      "rmse =  17.466490372367527\n",
      "Progress: 18.31%\n",
      "39\n",
      "max difference =  62.49580764770508\n",
      "data at max difference =  2.917407751083374\n",
      "imputed at max difference =  65.41321563720703\n",
      "mae =  1.0988198518753052\n",
      "rmse =  31.314986519191578\n",
      "Progress: 18.39%\n",
      "40\n",
      "max difference =  26.652807235717773\n",
      "data at max difference =  2.7489545345306396\n",
      "imputed at max difference =  29.401762008666992\n",
      "mae =  0.9676284790039062\n",
      "rmse =  20.996142843495242\n",
      "Progress: 18.47%\n",
      "41\n",
      "max difference =  14.723248481750488\n",
      "data at max difference =  2.1045942306518555\n",
      "imputed at max difference =  16.827842712402344\n",
      "mae =  0.23971758782863617\n",
      "rmse =  6.899257494055706\n",
      "Progress: 18.56%\n",
      "42\n",
      "max difference =  44.377864837646484\n",
      "data at max difference =  1.6908007860183716\n",
      "imputed at max difference =  46.06866455078125\n",
      "mae =  0.7518567442893982\n",
      "rmse =  22.543098781419836\n",
      "Progress: 18.64%\n",
      "43\n",
      "max difference =  28.071517944335938\n",
      "data at max difference =  3.6511685848236084\n",
      "imputed at max difference =  31.722686767578125\n",
      "mae =  0.36230161786079407\n",
      "rmse =  12.842133895210598\n",
      "Progress: 18.73%\n",
      "44\n",
      "max difference =  12.353103637695312\n",
      "data at max difference =  4.07535982131958\n",
      "imputed at max difference =  16.428462982177734\n",
      "mae =  0.21423111855983734\n",
      "rmse =  5.786280756411346\n",
      "Progress: 18.81%\n",
      "45\n",
      "max difference =  18.290098190307617\n",
      "data at max difference =  3.8894925117492676\n",
      "imputed at max difference =  22.179590225219727\n",
      "mae =  0.2623353898525238\n",
      "rmse =  8.399181200110393\n",
      "Progress: 18.90%\n",
      "46\n",
      "max difference =  14.979455947875977\n",
      "data at max difference =  3.933950424194336\n",
      "imputed at max difference =  18.913406372070312\n",
      "mae =  0.32287847995758057\n",
      "rmse =  7.773095172384512\n",
      "Progress: 18.98%\n",
      "47\n",
      "max difference =  1.9269700050354004\n",
      "data at max difference =  3.8365588188171387\n",
      "imputed at max difference =  5.763528823852539\n",
      "mae =  0.09682770818471909\n",
      "rmse =  1.4127878935440727\n",
      "Progress: 19.07%\n",
      "48\n",
      "max difference =  32.60810470581055\n",
      "data at max difference =  4.654101848602295\n",
      "imputed at max difference =  37.26220703125\n",
      "mae =  0.964119553565979\n",
      "rmse =  23.079008682914402\n",
      "Progress: 19.15%\n",
      "49\n",
      "max difference =  21.752574920654297\n",
      "data at max difference =  4.054295539855957\n",
      "imputed at max difference =  25.80687141418457\n",
      "mae =  0.48606494069099426\n",
      "rmse =  11.893988567849863\n",
      "Progress: 19.24%\n",
      "50\n",
      "max difference =  4.5537824630737305\n",
      "data at max difference =  1.0856837034225464\n",
      "imputed at max difference =  5.639466285705566\n",
      "mae =  0.1402420550584793\n",
      "rmse =  2.747275974439538\n",
      "Progress: 19.32%\n",
      "51\n",
      "max difference =  12.692794799804688\n",
      "data at max difference =  5.0189433097839355\n",
      "imputed at max difference =  17.71173858642578\n",
      "mae =  0.30359184741973877\n",
      "rmse =  7.594022667926291\n",
      "Progress: 19.41%\n",
      "52\n",
      "max difference =  60.663177490234375\n",
      "data at max difference =  3.488410711288452\n",
      "imputed at max difference =  64.1515884399414\n",
      "mae =  0.6508727669715881\n",
      "rmse =  27.669929836107336\n",
      "Progress: 19.49%\n",
      "53\n",
      "max difference =  3.5904901027679443\n",
      "data at max difference =  3.512697458267212\n",
      "imputed at max difference =  7.103187561035156\n",
      "mae =  0.09037467837333679\n",
      "rmse =  1.8944733661154043\n",
      "Progress: 19.58%\n",
      "54\n",
      "max difference =  14.54904556274414\n",
      "data at max difference =  4.1450324058532715\n",
      "imputed at max difference =  18.69407844543457\n",
      "mae =  0.3846392035484314\n",
      "rmse =  9.595110022503397\n",
      "Progress: 19.66%\n",
      "55\n",
      "max difference =  8.363541603088379\n",
      "data at max difference =  3.6263844966888428\n",
      "imputed at max difference =  11.9899263381958\n",
      "mae =  0.17346599698066711\n",
      "rmse =  4.264586407205333\n",
      "Progress: 19.75%\n",
      "56\n",
      "max difference =  57.243560791015625\n",
      "data at max difference =  3.0583953857421875\n",
      "imputed at max difference =  60.30195617675781\n",
      "mae =  0.6139551997184753\n",
      "rmse =  26.110208262567937\n",
      "Progress: 19.83%\n",
      "57\n",
      "max difference =  66.12865447998047\n",
      "data at max difference =  4.061976432800293\n",
      "imputed at max difference =  70.19062805175781\n",
      "mae =  0.8210686445236206\n",
      "rmse =  30.57579504925272\n",
      "Progress: 19.92%\n",
      "58\n",
      "max difference =  92.09349060058594\n",
      "data at max difference =  4.55797004699707\n",
      "imputed at max difference =  96.65145874023438\n",
      "mae =  1.6388659477233887\n",
      "rmse =  46.51209026834239\n",
      "Progress: 20.00%\n",
      "0\n",
      "max difference =  112.55198669433594\n",
      "data at max difference =  2.3850014209747314\n",
      "imputed at max difference =  114.9369888305664\n",
      "mae =  1.497664451599121\n",
      "rmse =  52.21835725203804\n",
      "Progress: 20.08%\n",
      "1\n",
      "max difference =  53.91270446777344\n",
      "data at max difference =  5.496946334838867\n",
      "imputed at max difference =  59.40964889526367\n",
      "mae =  0.796271562576294\n",
      "rmse =  25.007260529891305\n",
      "Progress: 20.17%\n",
      "2\n",
      "max difference =  76.1263656616211\n",
      "data at max difference =  5.049139499664307\n",
      "imputed at max difference =  81.17550659179688\n",
      "mae =  1.556330680847168\n",
      "rmse =  37.069649074388586\n",
      "Progress: 20.25%\n",
      "3\n",
      "max difference =  49.97296905517578\n",
      "data at max difference =  3.835675001144409\n",
      "imputed at max difference =  53.80864334106445\n",
      "mae =  3.4028124809265137\n",
      "rmse =  49.63187839673913\n",
      "Progress: 20.34%\n",
      "4\n",
      "max difference =  117.15353393554688\n",
      "data at max difference =  15.242568016052246\n",
      "imputed at max difference =  132.39610290527344\n",
      "mae =  3.3472044467926025\n",
      "rmse =  69.32047172214673\n",
      "Progress: 20.42%\n",
      "5\n",
      "max difference =  118.89421081542969\n",
      "data at max difference =  5.54367733001709\n",
      "imputed at max difference =  124.4378890991211\n",
      "mae =  4.2154645919799805\n",
      "rmse =  83.13862941576087\n",
      "Progress: 20.51%\n",
      "6\n",
      "max difference =  100.0257568359375\n",
      "data at max difference =  4.360837459564209\n",
      "imputed at max difference =  104.3865966796875\n",
      "mae =  1.4008570909500122\n",
      "rmse =  45.83994459069293\n",
      "Progress: 20.59%\n",
      "7\n",
      "max difference =  31.972076416015625\n",
      "data at max difference =  4.389836311340332\n",
      "imputed at max difference =  36.36191177368164\n",
      "mae =  1.1166753768920898\n",
      "rmse =  22.34863811990489\n",
      "Progress: 20.68%\n",
      "8\n",
      "max difference =  46.37409973144531\n",
      "data at max difference =  4.5931077003479\n",
      "imputed at max difference =  50.96720886230469\n",
      "mae =  1.6569116115570068\n",
      "rmse =  29.250968601392664\n",
      "Progress: 20.76%\n",
      "9\n",
      "max difference =  145.3660888671875\n",
      "data at max difference =  3.422072172164917\n",
      "imputed at max difference =  148.7881622314453\n",
      "mae =  2.379725933074951\n",
      "rmse =  71.19408648947011\n",
      "Progress: 20.85%\n",
      "10\n",
      "max difference =  65.4990005493164\n",
      "data at max difference =  2.881241798400879\n",
      "imputed at max difference =  68.38024139404297\n",
      "mae =  1.1196304559707642\n",
      "rmse =  33.2356248938519\n",
      "Progress: 20.93%\n",
      "11\n",
      "max difference =  103.66251373291016\n",
      "data at max difference =  3.75504207611084\n",
      "imputed at max difference =  107.41755676269531\n",
      "mae =  1.766675353050232\n",
      "rmse =  50.22117017663044\n",
      "Progress: 21.02%\n",
      "12\n",
      "max difference =  59.56133270263672\n",
      "data at max difference =  2.9304683208465576\n",
      "imputed at max difference =  62.49180221557617\n",
      "mae =  1.4425742626190186\n",
      "rmse =  37.121563455332875\n",
      "Progress: 21.10%\n",
      "13\n",
      "max difference =  48.441036224365234\n",
      "data at max difference =  3.078768014907837\n",
      "imputed at max difference =  51.519805908203125\n",
      "mae =  0.6986242532730103\n",
      "rmse =  22.662212869395383\n",
      "Progress: 21.19%\n",
      "14\n",
      "max difference =  48.98618698120117\n",
      "data at max difference =  3.7214345932006836\n",
      "imputed at max difference =  52.70762252807617\n",
      "mae =  0.7414892315864563\n",
      "rmse =  23.19368843410326\n",
      "Progress: 21.27%\n",
      "15\n",
      "max difference =  13.410774230957031\n",
      "data at max difference =  4.187092304229736\n",
      "imputed at max difference =  17.59786605834961\n",
      "mae =  0.23076345026493073\n",
      "rmse =  6.250218267026154\n",
      "Progress: 21.36%\n",
      "16\n",
      "max difference =  31.16926383972168\n",
      "data at max difference =  4.297800540924072\n",
      "imputed at max difference =  35.467063903808594\n",
      "mae =  0.8461460471153259\n",
      "rmse =  19.429802936056387\n",
      "Progress: 21.44%\n",
      "17\n",
      "max difference =  10.743243217468262\n",
      "data at max difference =  3.7386417388916016\n",
      "imputed at max difference =  14.481884956359863\n",
      "mae =  0.3721814751625061\n",
      "rmse =  7.365174003269362\n",
      "Progress: 21.53%\n",
      "18\n",
      "max difference =  21.017488479614258\n",
      "data at max difference =  3.2883851528167725\n",
      "imputed at max difference =  24.30587387084961\n",
      "mae =  0.46288153529167175\n",
      "rmse =  11.957057787024457\n",
      "Progress: 21.61%\n",
      "19\n",
      "max difference =  46.69169235229492\n",
      "data at max difference =  3.2785933017730713\n",
      "imputed at max difference =  49.97028732299805\n",
      "mae =  0.8490195870399475\n",
      "rmse =  24.151608674422555\n",
      "Progress: 21.69%\n",
      "20\n",
      "max difference =  37.09718704223633\n",
      "data at max difference =  2.80688738822937\n",
      "imputed at max difference =  39.904075622558594\n",
      "mae =  0.5409274101257324\n",
      "rmse =  17.19059421705163\n",
      "Progress: 21.78%\n",
      "21\n",
      "max difference =  40.488914489746094\n",
      "data at max difference =  3.333967447280884\n",
      "imputed at max difference =  43.82288360595703\n",
      "mae =  0.5487388968467712\n",
      "rmse =  18.670719312584918\n",
      "Progress: 21.86%\n",
      "22\n",
      "max difference =  13.345609664916992\n",
      "data at max difference =  3.7011895179748535\n",
      "imputed at max difference =  17.046798706054688\n",
      "mae =  0.301887184381485\n",
      "rmse =  7.209691586701767\n",
      "Progress: 21.95%\n",
      "23\n",
      "max difference =  41.834415435791016\n",
      "data at max difference =  2.7374680042266846\n",
      "imputed at max difference =  44.57188415527344\n",
      "mae =  0.8466303944587708\n",
      "rmse =  24.11482570482337\n",
      "Progress: 22.03%\n",
      "24\n",
      "max difference =  6.657741546630859\n",
      "data at max difference =  2.7563235759735107\n",
      "imputed at max difference =  9.41406536102295\n",
      "mae =  0.14358560740947723\n",
      "rmse =  3.1779397052267324\n",
      "Progress: 22.12%\n",
      "25\n",
      "max difference =  39.96241760253906\n",
      "data at max difference =  3.007465124130249\n",
      "imputed at max difference =  42.96988296508789\n",
      "mae =  1.1734544038772583\n",
      "rmse =  25.508884595788047\n",
      "Progress: 22.20%\n",
      "26\n",
      "max difference =  36.37456512451172\n",
      "data at max difference =  3.524782419204712\n",
      "imputed at max difference =  39.899349212646484\n",
      "mae =  1.4976345300674438\n",
      "rmse =  27.63329547384511\n",
      "Progress: 22.29%\n",
      "27\n",
      "max difference =  41.52994918823242\n",
      "data at max difference =  2.911207675933838\n",
      "imputed at max difference =  44.441158294677734\n",
      "mae =  0.839442253112793\n",
      "rmse =  21.101770815641984\n",
      "Progress: 22.37%\n",
      "28\n",
      "max difference =  78.80741882324219\n",
      "data at max difference =  2.9589877128601074\n",
      "imputed at max difference =  81.76640319824219\n",
      "mae =  1.8555080890655518\n",
      "rmse =  43.90910007642663\n",
      "Progress: 22.46%\n",
      "29\n",
      "max difference =  15.907608032226562\n",
      "data at max difference =  3.5692858695983887\n",
      "imputed at max difference =  19.47689437866211\n",
      "mae =  0.4563068151473999\n",
      "rmse =  10.201302569845447\n",
      "Progress: 22.54%\n",
      "30\n",
      "max difference =  99.1927490234375\n",
      "data at max difference =  3.0069375038146973\n",
      "imputed at max difference =  102.1996841430664\n",
      "mae =  1.9514707326889038\n",
      "rmse =  54.99764351222826\n",
      "Progress: 22.63%\n",
      "31\n",
      "max difference =  113.42220306396484\n",
      "data at max difference =  3.129380702972412\n",
      "imputed at max difference =  116.55158233642578\n",
      "mae =  2.3867335319519043\n",
      "rmse =  68.36713442595108\n",
      "Progress: 22.71%\n",
      "32\n",
      "max difference =  38.03980255126953\n",
      "data at max difference =  3.129429817199707\n",
      "imputed at max difference =  41.16923141479492\n",
      "mae =  0.7365654110908508\n",
      "rmse =  19.540667989979617\n",
      "Progress: 22.80%\n",
      "33\n",
      "max difference =  154.51522827148438\n",
      "data at max difference =  3.654895544052124\n",
      "imputed at max difference =  158.1701202392578\n",
      "mae =  2.1649720668792725\n",
      "rmse =  72.11874256963316\n",
      "Progress: 22.88%\n",
      "34\n",
      "max difference =  72.19387817382812\n",
      "data at max difference =  3.1056199073791504\n",
      "imputed at max difference =  75.29949951171875\n",
      "mae =  1.9987828731536865\n",
      "rmse =  44.101254670516305\n",
      "Progress: 22.97%\n",
      "35\n",
      "max difference =  23.3485107421875\n",
      "data at max difference =  3.6970813274383545\n",
      "imputed at max difference =  27.045591354370117\n",
      "mae =  0.5299571752548218\n",
      "rmse =  13.236618705417799\n",
      "Progress: 23.05%\n",
      "36\n",
      "max difference =  68.00730895996094\n",
      "data at max difference =  3.144315719604492\n",
      "imputed at max difference =  71.15162658691406\n",
      "mae =  1.0704907178878784\n",
      "rmse =  32.48302161175272\n",
      "Progress: 23.14%\n",
      "37\n",
      "max difference =  30.4215145111084\n",
      "data at max difference =  3.152101755142212\n",
      "imputed at max difference =  33.57361602783203\n",
      "mae =  0.5603718757629395\n",
      "rmse =  14.711563773777172\n",
      "Progress: 23.22%\n",
      "38\n",
      "max difference =  67.07008361816406\n",
      "data at max difference =  3.2595252990722656\n",
      "imputed at max difference =  70.3296127319336\n",
      "mae =  0.8541592359542847\n",
      "rmse =  31.062070100203805\n",
      "Progress: 23.31%\n",
      "39\n",
      "max difference =  23.002607345581055\n",
      "data at max difference =  2.3955178260803223\n",
      "imputed at max difference =  25.39812469482422\n",
      "mae =  0.4623221158981323\n",
      "rmse =  12.546795388926629\n",
      "Progress: 23.39%\n",
      "40\n",
      "max difference =  77.04222106933594\n",
      "data at max difference =  2.279470682144165\n",
      "imputed at max difference =  79.32169342041016\n",
      "mae =  0.9922167658805847\n",
      "rmse =  35.533988620923914\n",
      "Progress: 23.47%\n",
      "41\n",
      "max difference =  16.40741729736328\n",
      "data at max difference =  1.7970588207244873\n",
      "imputed at max difference =  18.20447540283203\n",
      "mae =  0.40869882702827454\n",
      "rmse =  9.180686618970787\n",
      "Progress: 23.56%\n",
      "42\n",
      "max difference =  9.587287902832031\n",
      "data at max difference =  2.047865867614746\n",
      "imputed at max difference =  11.635153770446777\n",
      "mae =  0.19337356090545654\n",
      "rmse =  4.534689530082371\n",
      "Progress: 23.64%\n",
      "43\n",
      "max difference =  10.968936920166016\n",
      "data at max difference =  3.971184253692627\n",
      "imputed at max difference =  14.9401216506958\n",
      "mae =  0.2525572180747986\n",
      "rmse =  5.867734162703804\n",
      "Progress: 23.73%\n",
      "44\n",
      "max difference =  60.32025146484375\n",
      "data at max difference =  3.745873212814331\n",
      "imputed at max difference =  64.06612396240234\n",
      "mae =  0.7661070823669434\n",
      "rmse =  27.75787884256114\n",
      "Progress: 23.81%\n",
      "45\n",
      "max difference =  6.099574089050293\n",
      "data at max difference =  3.6255245208740234\n",
      "imputed at max difference =  9.725098609924316\n",
      "mae =  0.17349304258823395\n",
      "rmse =  3.338516898777174\n",
      "Progress: 23.90%\n",
      "46\n",
      "max difference =  12.901782989501953\n",
      "data at max difference =  3.933950424194336\n",
      "imputed at max difference =  16.83573341369629\n",
      "mae =  0.2977895736694336\n",
      "rmse =  7.434539131496264\n",
      "Progress: 23.98%\n",
      "47\n",
      "max difference =  42.89964294433594\n",
      "data at max difference =  4.468069553375244\n",
      "imputed at max difference =  47.367713928222656\n",
      "mae =  0.5191260576248169\n",
      "rmse =  19.601541270380434\n",
      "Progress: 24.07%\n",
      "48\n",
      "max difference =  2.681824207305908\n",
      "data at max difference =  3.6271133422851562\n",
      "imputed at max difference =  6.3089375495910645\n",
      "mae =  0.11735109984874725\n",
      "rmse =  1.9764218537703806\n",
      "Progress: 24.15%\n",
      "49\n",
      "max difference =  10.19488525390625\n",
      "data at max difference =  4.354440212249756\n",
      "imputed at max difference =  14.549325942993164\n",
      "mae =  0.16832439601421356\n",
      "rmse =  4.735477613366169\n",
      "Progress: 24.24%\n",
      "50\n",
      "max difference =  65.24156188964844\n",
      "data at max difference =  4.167771816253662\n",
      "imputed at max difference =  69.40933227539062\n",
      "mae =  0.7548739314079285\n",
      "rmse =  29.860651430876356\n",
      "Progress: 24.32%\n",
      "51\n",
      "max difference =  33.17118453979492\n",
      "data at max difference =  5.0189433097839355\n",
      "imputed at max difference =  38.190128326416016\n",
      "mae =  0.7260482907295227\n",
      "rmse =  18.99021579908288\n",
      "Progress: 24.41%\n",
      "52\n",
      "max difference =  3.663566827774048\n",
      "data at max difference =  3.1322391033172607\n",
      "imputed at max difference =  6.795805931091309\n",
      "mae =  0.10382118821144104\n",
      "rmse =  2.062336299730384\n",
      "Progress: 24.49%\n",
      "53\n",
      "max difference =  16.19091033935547\n",
      "data at max difference =  3.7796366214752197\n",
      "imputed at max difference =  19.97054672241211\n",
      "mae =  0.21382476389408112\n",
      "rmse =  7.436597077742866\n",
      "Progress: 24.58%\n",
      "54\n",
      "max difference =  12.179401397705078\n",
      "data at max difference =  3.8035402297973633\n",
      "imputed at max difference =  15.982941627502441\n",
      "mae =  0.24171607196331024\n",
      "rmse =  6.581487240998642\n",
      "Progress: 24.66%\n",
      "55\n",
      "max difference =  16.142032623291016\n",
      "data at max difference =  3.2829904556274414\n",
      "imputed at max difference =  19.425024032592773\n",
      "mae =  0.29782846570014954\n",
      "rmse =  8.21478669539742\n",
      "Progress: 24.75%\n",
      "56\n",
      "max difference =  1.6919093132019043\n",
      "data at max difference =  3.957808017730713\n",
      "imputed at max difference =  2.2658987045288086\n",
      "mae =  0.06781193614006042\n",
      "rmse =  1.049904035485309\n",
      "Progress: 24.83%\n",
      "57\n",
      "max difference =  83.79158020019531\n",
      "data at max difference =  3.733560085296631\n",
      "imputed at max difference =  87.52513885498047\n",
      "mae =  1.0537694692611694\n",
      "rmse =  38.935549528702445\n",
      "Progress: 24.92%\n",
      "58\n",
      "max difference =  35.75733947753906\n",
      "data at max difference =  3.1417088508605957\n",
      "imputed at max difference =  38.8990478515625\n",
      "mae =  0.9365875720977783\n",
      "rmse =  21.755121645720106\n",
      "Progress: 25.00%\n",
      "0\n",
      "max difference =  69.87178039550781\n",
      "data at max difference =  1.2311043739318848\n",
      "imputed at max difference =  71.1028823852539\n",
      "mae =  0.9330777525901794\n",
      "rmse =  32.035408351732336\n",
      "Progress: 25.08%\n",
      "1\n",
      "max difference =  9.779364585876465\n",
      "data at max difference =  2.448204755783081\n",
      "imputed at max difference =  12.227569580078125\n",
      "mae =  0.34074580669403076\n",
      "rmse =  5.283471480659816\n",
      "Progress: 25.17%\n",
      "2\n",
      "max difference =  128.1614990234375\n",
      "data at max difference =  4.079436302185059\n",
      "imputed at max difference =  132.24093627929688\n",
      "mae =  3.7279698848724365\n",
      "rmse =  86.43623683763587\n",
      "Progress: 25.25%\n",
      "3\n",
      "max difference =  171.70265197753906\n",
      "data at max difference =  14.66715145111084\n",
      "imputed at max difference =  186.3697967529297\n",
      "mae =  7.20319938659668\n",
      "rmse =  126.55908203124999\n",
      "Progress: 25.34%\n",
      "4\n",
      "max difference =  70.4527587890625\n",
      "data at max difference =  13.173881530761719\n",
      "imputed at max difference =  83.62664031982422\n",
      "mae =  3.896409273147583\n",
      "rmse =  62.75084918478261\n",
      "Progress: 25.42%\n",
      "5\n",
      "max difference =  107.96275329589844\n",
      "data at max difference =  -0.14749836921691895\n",
      "imputed at max difference =  107.81525421142578\n",
      "mae =  3.155815601348877\n",
      "rmse =  64.18807850713316\n",
      "Progress: 25.51%\n",
      "6\n",
      "max difference =  158.9835205078125\n",
      "data at max difference =  4.360837459564209\n",
      "imputed at max difference =  163.3443603515625\n",
      "mae =  3.667388439178467\n",
      "rmse =  87.40147333559783\n",
      "Progress: 25.59%\n",
      "7\n",
      "max difference =  67.55000305175781\n",
      "data at max difference =  4.389836311340332\n",
      "imputed at max difference =  71.9398422241211\n",
      "mae =  1.5363714694976807\n",
      "rmse =  35.27333135190218\n",
      "Progress: 25.68%\n",
      "8\n",
      "max difference =  26.643394470214844\n",
      "data at max difference =  2.2317087650299072\n",
      "imputed at max difference =  28.875102996826172\n",
      "mae =  0.9735534191131592\n",
      "rmse =  18.309623386548914\n",
      "Progress: 25.76%\n",
      "9\n",
      "max difference =  28.70722770690918\n",
      "data at max difference =  2.5638339519500732\n",
      "imputed at max difference =  31.271060943603516\n",
      "mae =  0.6246147751808167\n",
      "rmse =  14.904847518257473\n",
      "Progress: 25.85%\n",
      "10\n",
      "max difference =  58.47705841064453\n",
      "data at max difference =  3.192647933959961\n",
      "imputed at max difference =  61.66970443725586\n",
      "mae =  1.1115442514419556\n",
      "rmse =  29.230649201766308\n",
      "Progress: 25.93%\n",
      "11\n",
      "max difference =  28.125423431396484\n",
      "data at max difference =  3.75504207611084\n",
      "imputed at max difference =  31.88046646118164\n",
      "mae =  0.4191097915172577\n",
      "rmse =  12.895591404127039\n",
      "Progress: 26.02%\n",
      "12\n",
      "max difference =  147.867919921875\n",
      "data at max difference =  3.4866089820861816\n",
      "imputed at max difference =  151.35452270507812\n",
      "mae =  2.038844347000122\n",
      "rmse =  68.83116083559783\n",
      "Progress: 26.10%\n",
      "13\n",
      "max difference =  57.14812469482422\n",
      "data at max difference =  3.078768014907837\n",
      "imputed at max difference =  60.22689437866211\n",
      "mae =  0.7974101305007935\n",
      "rmse =  26.361322817595106\n",
      "Progress: 26.19%\n",
      "14\n",
      "max difference =  6.137950897216797\n",
      "data at max difference =  3.4648749828338623\n",
      "imputed at max difference =  9.602826118469238\n",
      "mae =  0.18544761836528778\n",
      "rmse =  3.4616692584493887\n",
      "Progress: 26.27%\n",
      "15\n",
      "max difference =  51.298458099365234\n",
      "data at max difference =  4.187092304229736\n",
      "imputed at max difference =  55.48554992675781\n",
      "mae =  0.9520890116691589\n",
      "rmse =  26.582986582880437\n",
      "Progress: 26.36%\n",
      "16\n",
      "max difference =  56.30427551269531\n",
      "data at max difference =  3.9510416984558105\n",
      "imputed at max difference =  60.25531768798828\n",
      "mae =  1.1024421453475952\n",
      "rmse =  28.70356286090353\n",
      "Progress: 26.44%\n",
      "17\n",
      "max difference =  17.16954803466797\n",
      "data at max difference =  3.383026599884033\n",
      "imputed at max difference =  20.552574157714844\n",
      "mae =  0.33196020126342773\n",
      "rmse =  8.17849466075068\n",
      "Progress: 26.53%\n",
      "18\n",
      "max difference =  59.209957122802734\n",
      "data at max difference =  3.2883851528167725\n",
      "imputed at max difference =  62.49834060668945\n",
      "mae =  1.4784754514694214\n",
      "rmse =  37.79639733355978\n",
      "Progress: 26.61%\n",
      "19\n",
      "max difference =  133.3794708251953\n",
      "data at max difference =  3.2785933017730713\n",
      "imputed at max difference =  136.65806579589844\n",
      "mae =  2.2430012226104736\n",
      "rmse =  69.7734905740489\n",
      "Progress: 26.69%\n",
      "20\n",
      "max difference =  18.500568389892578\n",
      "data at max difference =  3.3378450870513916\n",
      "imputed at max difference =  21.83841323852539\n",
      "mae =  0.3308718800544739\n",
      "rmse =  8.880837481954822\n",
      "Progress: 26.78%\n",
      "21\n",
      "max difference =  23.198532104492188\n",
      "data at max difference =  3.0974695682525635\n",
      "imputed at max difference =  26.296001434326172\n",
      "mae =  0.36453962326049805\n",
      "rmse =  10.731142126995584\n",
      "Progress: 26.86%\n",
      "22\n",
      "max difference =  34.287227630615234\n",
      "data at max difference =  3.7011895179748535\n",
      "imputed at max difference =  37.98841857910156\n",
      "mae =  0.721725583076477\n",
      "rmse =  17.999532948369566\n",
      "Progress: 26.95%\n",
      "23\n",
      "max difference =  40.377685546875\n",
      "data at max difference =  2.2658510208129883\n",
      "imputed at max difference =  42.64353561401367\n",
      "mae =  0.7507784366607666\n",
      "rmse =  19.877945609714672\n",
      "Progress: 27.03%\n",
      "24\n",
      "max difference =  25.635759353637695\n",
      "data at max difference =  3.0082943439483643\n",
      "imputed at max difference =  28.644054412841797\n",
      "mae =  0.381580114364624\n",
      "rmse =  11.813684878141984\n",
      "Progress: 27.12%\n",
      "25\n",
      "max difference =  64.97331237792969\n",
      "data at max difference =  3.3274190425872803\n",
      "imputed at max difference =  68.30072784423828\n",
      "mae =  1.6817355155944824\n",
      "rmse =  37.88331404976223\n",
      "Progress: 27.20%\n",
      "26\n",
      "max difference =  27.428813934326172\n",
      "data at max difference =  2.8632819652557373\n",
      "imputed at max difference =  30.292095184326172\n",
      "mae =  1.2756744623184204\n",
      "rmse =  23.049390709918477\n",
      "Progress: 27.29%\n",
      "27\n",
      "max difference =  66.73127746582031\n",
      "data at max difference =  3.0260767936706543\n",
      "imputed at max difference =  69.75735473632812\n",
      "mae =  1.0483274459838867\n",
      "rmse =  31.9312744140625\n",
      "Progress: 27.37%\n",
      "28\n",
      "max difference =  8.359376907348633\n",
      "data at max difference =  3.075853109359741\n",
      "imputed at max difference =  11.435230255126953\n",
      "mae =  0.3057938814163208\n",
      "rmse =  5.559392514436142\n",
      "Progress: 27.46%\n",
      "29\n",
      "max difference =  25.653804779052734\n",
      "data at max difference =  3.688014030456543\n",
      "imputed at max difference =  29.341819763183594\n",
      "mae =  0.44300058484077454\n",
      "rmse =  12.289134149966033\n",
      "Progress: 27.54%\n",
      "30\n",
      "max difference =  23.278976440429688\n",
      "data at max difference =  2.433009624481201\n",
      "imputed at max difference =  25.711986541748047\n",
      "mae =  0.9068350195884705\n",
      "rmse =  17.581694229789402\n",
      "Progress: 27.63%\n",
      "31\n",
      "max difference =  74.11012268066406\n",
      "data at max difference =  3.129380702972412\n",
      "imputed at max difference =  77.239501953125\n",
      "mae =  1.2360026836395264\n",
      "rmse =  35.66628630264946\n",
      "Progress: 27.71%\n",
      "32\n",
      "max difference =  17.531166076660156\n",
      "data at max difference =  3.586270332336426\n",
      "imputed at max difference =  21.117435455322266\n",
      "mae =  0.4382075369358063\n",
      "rmse =  10.013292395550272\n",
      "Progress: 27.80%\n",
      "33\n",
      "max difference =  71.16410064697266\n",
      "data at max difference =  3.5381031036376953\n",
      "imputed at max difference =  74.70220184326172\n",
      "mae =  1.4819444417953491\n",
      "rmse =  37.315233313519016\n",
      "Progress: 27.88%\n",
      "34\n",
      "max difference =  93.12908172607422\n",
      "data at max difference =  3.5691335201263428\n",
      "imputed at max difference =  96.69821166992188\n",
      "mae =  1.9212048053741455\n",
      "rmse =  48.63072668987772\n",
      "Progress: 27.97%\n",
      "35\n",
      "max difference =  113.56058502197266\n",
      "data at max difference =  3.6970813274383545\n",
      "imputed at max difference =  117.2576675415039\n",
      "mae =  1.6612927913665771\n",
      "rmse =  55.25934634001358\n",
      "Progress: 28.05%\n",
      "36\n",
      "max difference =  142.397705078125\n",
      "data at max difference =  3.7332305908203125\n",
      "imputed at max difference =  146.1309356689453\n",
      "mae =  1.7873215675354004\n",
      "rmse =  65.87211807914403\n",
      "Progress: 28.14%\n",
      "37\n",
      "max difference =  16.077320098876953\n",
      "data at max difference =  3.030712366104126\n",
      "imputed at max difference =  19.1080322265625\n",
      "mae =  0.24795091152191162\n",
      "rmse =  7.480470076851223\n",
      "Progress: 28.22%\n",
      "38\n",
      "max difference =  6.829524040222168\n",
      "data at max difference =  3.2595252990722656\n",
      "imputed at max difference =  10.089049339294434\n",
      "mae =  0.2259860634803772\n",
      "rmse =  4.194611590841542\n",
      "Progress: 28.31%\n",
      "39\n",
      "max difference =  46.83187484741211\n",
      "data at max difference =  2.3955178260803223\n",
      "imputed at max difference =  49.227394104003906\n",
      "mae =  0.7200949192047119\n",
      "rmse =  21.966449239979617\n",
      "Progress: 28.39%\n",
      "40\n",
      "max difference =  112.42395782470703\n",
      "data at max difference =  2.844825029373169\n",
      "imputed at max difference =  115.26878356933594\n",
      "mae =  2.944035053253174\n",
      "rmse =  72.9860149881114\n",
      "Progress: 28.47%\n",
      "41\n",
      "max difference =  18.288753509521484\n",
      "data at max difference =  2.1835086345672607\n",
      "imputed at max difference =  20.472261428833008\n",
      "mae =  0.4059528112411499\n",
      "rmse =  9.59588623046875\n",
      "Progress: 28.56%\n",
      "42\n",
      "max difference =  13.90794849395752\n",
      "data at max difference =  3.852797746658325\n",
      "imputed at max difference =  17.760746002197266\n",
      "mae =  0.2590638995170593\n",
      "rmse =  6.717265253481658\n",
      "Progress: 28.64%\n",
      "43\n",
      "max difference =  52.04619598388672\n",
      "data at max difference =  3.971184253692627\n",
      "imputed at max difference =  56.01737976074219\n",
      "mae =  1.0540566444396973\n",
      "rmse =  32.123283054517664\n",
      "Progress: 28.73%\n",
      "44\n",
      "max difference =  1.1139179468154907\n",
      "data at max difference =  1.6781197786331177\n",
      "imputed at max difference =  2.7920377254486084\n",
      "mae =  0.0837179645895958\n",
      "rmse =  0.9639211737591287\n",
      "Progress: 28.81%\n",
      "45\n",
      "max difference =  28.868682861328125\n",
      "data at max difference =  3.2877042293548584\n",
      "imputed at max difference =  32.15638732910156\n",
      "mae =  0.6588058471679688\n",
      "rmse =  17.668621560801633\n",
      "Progress: 28.90%\n",
      "46\n",
      "max difference =  7.930760860443115\n",
      "data at max difference =  1.541601538658142\n",
      "imputed at max difference =  9.472362518310547\n",
      "mae =  0.1727808713912964\n",
      "rmse =  3.8064313142195996\n",
      "Progress: 28.98%\n",
      "47\n",
      "max difference =  60.23469161987305\n",
      "data at max difference =  3.8365588188171387\n",
      "imputed at max difference =  64.07125091552734\n",
      "mae =  0.8174968361854553\n",
      "rmse =  27.880365786345106\n",
      "Progress: 29.07%\n",
      "48\n",
      "max difference =  7.353724479675293\n",
      "data at max difference =  3.6271133422851562\n",
      "imputed at max difference =  10.98083782196045\n",
      "mae =  0.21902015805244446\n",
      "rmse =  4.47046595034392\n",
      "Progress: 29.15%\n",
      "49\n",
      "max difference =  12.309489250183105\n",
      "data at max difference =  4.054295539855957\n",
      "imputed at max difference =  16.363784790039062\n",
      "mae =  0.20229853689670563\n",
      "rmse =  5.716731859290081\n",
      "Progress: 29.24%\n",
      "50\n",
      "max difference =  72.11032104492188\n",
      "data at max difference =  4.473196029663086\n",
      "imputed at max difference =  76.5835189819336\n",
      "mae =  0.8131029605865479\n",
      "rmse =  32.92258088485055\n",
      "Progress: 29.32%\n",
      "51\n",
      "max difference =  31.466461181640625\n",
      "data at max difference =  3.903841972351074\n",
      "imputed at max difference =  35.370304107666016\n",
      "mae =  0.3722803294658661\n",
      "rmse =  14.399546747622283\n",
      "Progress: 29.41%\n",
      "52\n",
      "max difference =  4.62957239151001\n",
      "data at max difference =  4.122889995574951\n",
      "imputed at max difference =  8.752462387084961\n",
      "mae =  0.1284116953611374\n",
      "rmse =  2.6893864507260528\n",
      "Progress: 29.49%\n",
      "53\n",
      "max difference =  24.53485870361328\n",
      "data at max difference =  3.7796366214752197\n",
      "imputed at max difference =  28.314495086669922\n",
      "mae =  0.44091641902923584\n",
      "rmse =  13.322630509086277\n",
      "Progress: 29.58%\n",
      "54\n",
      "max difference =  59.53364181518555\n",
      "data at max difference =  3.1952109336853027\n",
      "imputed at max difference =  62.728851318359375\n",
      "mae =  0.6689058542251587\n",
      "rmse =  27.19657035495924\n",
      "Progress: 29.66%\n",
      "55\n",
      "max difference =  12.697751998901367\n",
      "data at max difference =  3.2829904556274414\n",
      "imputed at max difference =  15.980742454528809\n",
      "mae =  0.24453163146972656\n",
      "rmse =  6.556208071501358\n",
      "Progress: 29.75%\n",
      "56\n",
      "max difference =  8.249245643615723\n",
      "data at max difference =  3.634439468383789\n",
      "imputed at max difference =  11.883685111999512\n",
      "mae =  0.18512701988220215\n",
      "rmse =  4.422763326893682\n",
      "Progress: 29.83%\n",
      "57\n",
      "max difference =  45.1218147277832\n",
      "data at max difference =  3.476940155029297\n",
      "imputed at max difference =  48.5987548828125\n",
      "mae =  0.6128952503204346\n",
      "rmse =  20.939390762992527\n",
      "Progress: 29.92%\n",
      "58\n",
      "max difference =  17.192508697509766\n",
      "data at max difference =  1.5294126272201538\n",
      "imputed at max difference =  18.721921920776367\n",
      "mae =  0.502494215965271\n",
      "rmse =  9.38016941236413\n",
      "Progress: 30.00%\n",
      "0\n",
      "max difference =  126.51195526123047\n",
      "data at max difference =  5.403512001037598\n",
      "imputed at max difference =  131.91546630859375\n",
      "mae =  1.838055968284607\n",
      "rmse =  58.50106678838315\n",
      "Progress: 30.08%\n",
      "1\n",
      "max difference =  12.026006698608398\n",
      "data at max difference =  3.252281427383423\n",
      "imputed at max difference =  15.278287887573242\n",
      "mae =  0.40899962186813354\n",
      "rmse =  7.096705561098846\n",
      "Progress: 30.17%\n",
      "2\n",
      "max difference =  110.46808624267578\n",
      "data at max difference =  4.079436302185059\n",
      "imputed at max difference =  114.54752349853516\n",
      "mae =  3.232372283935547\n",
      "rmse =  72.6174847146739\n",
      "Progress: 30.25%\n",
      "3\n",
      "max difference =  94.29659271240234\n",
      "data at max difference =  4.429995536804199\n",
      "imputed at max difference =  98.7265853881836\n",
      "mae =  4.221810340881348\n",
      "rmse =  75.55010720957881\n",
      "Progress: 30.34%\n",
      "4\n",
      "max difference =  87.28168487548828\n",
      "data at max difference =  15.242568016052246\n",
      "imputed at max difference =  102.52425384521484\n",
      "mae =  2.5216124057769775\n",
      "rmse =  50.04990552819294\n",
      "Progress: 30.42%\n",
      "5\n",
      "max difference =  82.14521026611328\n",
      "data at max difference =  5.54367733001709\n",
      "imputed at max difference =  87.68888854980469\n",
      "mae =  3.530731201171875\n",
      "rmse =  60.39126188858695\n",
      "Progress: 30.51%\n",
      "6\n",
      "max difference =  122.24764251708984\n",
      "data at max difference =  2.983938694000244\n",
      "imputed at max difference =  125.23158264160156\n",
      "mae =  2.5732152462005615\n",
      "rmse =  62.88557235054347\n",
      "Progress: 30.59%\n",
      "7\n",
      "max difference =  26.749103546142578\n",
      "data at max difference =  4.776676654815674\n",
      "imputed at max difference =  31.525779724121094\n",
      "mae =  1.0902405977249146\n",
      "rmse =  18.59006002674932\n",
      "Progress: 30.68%\n",
      "8\n",
      "max difference =  77.57404327392578\n",
      "data at max difference =  2.540346622467041\n",
      "imputed at max difference =  80.11438751220703\n",
      "mae =  2.4824533462524414\n",
      "rmse =  48.40056046195652\n",
      "Progress: 30.76%\n",
      "9\n",
      "max difference =  69.3115463256836\n",
      "data at max difference =  3.169604778289795\n",
      "imputed at max difference =  72.48114776611328\n",
      "mae =  1.8235116004943848\n",
      "rmse =  38.47579027258832\n",
      "Progress: 30.85%\n",
      "10\n",
      "max difference =  116.61050415039062\n",
      "data at max difference =  2.881241798400879\n",
      "imputed at max difference =  119.49174499511719\n",
      "mae =  2.880340576171875\n",
      "rmse =  67.65333623471467\n",
      "Progress: 30.93%\n",
      "11\n",
      "max difference =  30.33694076538086\n",
      "data at max difference =  3.1999928951263428\n",
      "imputed at max difference =  33.53693389892578\n",
      "mae =  0.6972941160202026\n",
      "rmse =  16.545507016389266\n",
      "Progress: 31.02%\n",
      "12\n",
      "max difference =  87.97260284423828\n",
      "data at max difference =  3.242663860321045\n",
      "imputed at max difference =  91.21526336669922\n",
      "mae =  1.2245538234710693\n",
      "rmse =  41.226814601732336\n",
      "Progress: 31.10%\n",
      "13\n",
      "max difference =  43.578277587890625\n",
      "data at max difference =  3.3944644927978516\n",
      "imputed at max difference =  46.97274398803711\n",
      "mae =  1.1279642581939697\n",
      "rmse =  27.526361880095106\n",
      "Progress: 31.19%\n",
      "14\n",
      "max difference =  20.068126678466797\n",
      "data at max difference =  3.4648749828338623\n",
      "imputed at max difference =  23.533000946044922\n",
      "mae =  0.5221929550170898\n",
      "rmse =  12.743820853855297\n",
      "Progress: 31.27%\n",
      "15\n",
      "max difference =  172.6206512451172\n",
      "data at max difference =  3.851318597793579\n",
      "imputed at max difference =  176.4719696044922\n",
      "mae =  2.4604110717773438\n",
      "rmse =  81.13827381963316\n",
      "Progress: 31.36%\n",
      "16\n",
      "max difference =  74.45690155029297\n",
      "data at max difference =  3.3333306312561035\n",
      "imputed at max difference =  77.79022979736328\n",
      "mae =  1.6484078168869019\n",
      "rmse =  44.32777205757473\n",
      "Progress: 31.44%\n",
      "17\n",
      "max difference =  29.428709030151367\n",
      "data at max difference =  4.372129440307617\n",
      "imputed at max difference =  33.800838470458984\n",
      "mae =  0.49938878417015076\n",
      "rmse =  14.116163170855977\n",
      "Progress: 31.53%\n",
      "18\n",
      "max difference =  47.16107940673828\n",
      "data at max difference =  3.2883851528167725\n",
      "imputed at max difference =  50.449462890625\n",
      "mae =  0.6501081585884094\n",
      "rmse =  21.928389839504074\n",
      "Progress: 31.61%\n",
      "19\n",
      "max difference =  65.51126098632812\n",
      "data at max difference =  3.2785933017730713\n",
      "imputed at max difference =  68.78985595703125\n",
      "mae =  1.6089797019958496\n",
      "rmse =  39.37228791610055\n",
      "Progress: 31.69%\n",
      "20\n",
      "max difference =  11.220699310302734\n",
      "data at max difference =  3.3378450870513916\n",
      "imputed at max difference =  14.558544158935547\n",
      "mae =  0.178293839097023\n",
      "rmse =  5.187687417735224\n",
      "Progress: 31.78%\n",
      "21\n",
      "max difference =  71.2868881225586\n",
      "data at max difference =  3.333967447280884\n",
      "imputed at max difference =  74.62085723876953\n",
      "mae =  0.8414733409881592\n",
      "rmse =  32.6588479746943\n",
      "Progress: 31.86%\n",
      "22\n",
      "max difference =  29.1346435546875\n",
      "data at max difference =  3.1619231700897217\n",
      "imputed at max difference =  32.296566009521484\n",
      "mae =  0.749835193157196\n",
      "rmse =  18.75654004967731\n",
      "Progress: 31.95%\n",
      "23\n",
      "max difference =  5.167717456817627\n",
      "data at max difference =  2.2658510208129883\n",
      "imputed at max difference =  7.433568477630615\n",
      "mae =  0.17630544304847717\n",
      "rmse =  2.8207450534986416\n",
      "Progress: 32.03%\n",
      "24\n",
      "max difference =  44.304874420166016\n",
      "data at max difference =  2.3074660301208496\n",
      "imputed at max difference =  46.61233901977539\n",
      "mae =  0.9173981547355652\n",
      "rmse =  26.874312691066578\n",
      "Progress: 32.12%\n",
      "25\n",
      "max difference =  206.9253387451172\n",
      "data at max difference =  3.438636064529419\n",
      "imputed at max difference =  210.3639678955078\n",
      "mae =  3.4491069316864014\n",
      "rmse =  98.7451171875\n",
      "Progress: 32.20%\n",
      "26\n",
      "max difference =  38.71588134765625\n",
      "data at max difference =  3.524782419204712\n",
      "imputed at max difference =  42.240665435791016\n",
      "mae =  0.9285755753517151\n",
      "rmse =  22.599489958389945\n",
      "Progress: 32.29%\n",
      "27\n",
      "max difference =  16.605173110961914\n",
      "data at max difference =  2.911207675933838\n",
      "imputed at max difference =  19.516380310058594\n",
      "mae =  0.462094247341156\n",
      "rmse =  10.02628691300102\n",
      "Progress: 32.37%\n",
      "28\n",
      "max difference =  71.52195739746094\n",
      "data at max difference =  3.648150682449341\n",
      "imputed at max difference =  75.17010498046875\n",
      "mae =  1.369124174118042\n",
      "rmse =  35.86223038383152\n",
      "Progress: 32.46%\n",
      "29\n",
      "max difference =  37.58416748046875\n",
      "data at max difference =  2.9878664016723633\n",
      "imputed at max difference =  40.5720329284668\n",
      "mae =  1.5747888088226318\n",
      "rmse =  29.985221531080164\n",
      "Progress: 32.54%\n",
      "30\n",
      "max difference =  67.35966491699219\n",
      "data at max difference =  3.594463348388672\n",
      "imputed at max difference =  70.95413208007812\n",
      "mae =  1.0347837209701538\n",
      "rmse =  32.292910368546195\n",
      "Progress: 32.63%\n",
      "31\n",
      "max difference =  45.57451629638672\n",
      "data at max difference =  3.129380702972412\n",
      "imputed at max difference =  48.703895568847656\n",
      "mae =  1.51176118850708\n",
      "rmse =  32.35765009341033\n",
      "Progress: 32.71%\n",
      "32\n",
      "max difference =  32.710655212402344\n",
      "data at max difference =  3.0122029781341553\n",
      "imputed at max difference =  35.72285842895508\n",
      "mae =  0.5590375065803528\n",
      "rmse =  15.611033564028531\n",
      "Progress: 32.80%\n",
      "33\n",
      "max difference =  12.4525146484375\n",
      "data at max difference =  2.9661622047424316\n",
      "imputed at max difference =  15.418676376342773\n",
      "mae =  0.3267248570919037\n",
      "rmse =  6.803706956946332\n",
      "Progress: 32.88%\n",
      "34\n",
      "max difference =  28.60647964477539\n",
      "data at max difference =  3.688072681427002\n",
      "imputed at max difference =  32.294551849365234\n",
      "mae =  0.46952781081199646\n",
      "rmse =  13.975532863451088\n",
      "Progress: 32.97%\n",
      "35\n",
      "max difference =  50.02420425415039\n",
      "data at max difference =  3.577104330062866\n",
      "imputed at max difference =  53.6013069152832\n",
      "mae =  0.8681246042251587\n",
      "rmse =  25.217964504076086\n",
      "Progress: 33.05%\n",
      "36\n",
      "max difference =  78.30036926269531\n",
      "data at max difference =  3.6129720211029053\n",
      "imputed at max difference =  81.91333770751953\n",
      "mae =  1.3915956020355225\n",
      "rmse =  38.68017578125\n",
      "Progress: 33.14%\n",
      "37\n",
      "max difference =  45.90384292602539\n",
      "data at max difference =  3.746554136276245\n",
      "imputed at max difference =  49.65039825439453\n",
      "mae =  1.507090449333191\n",
      "rmse =  31.2864698327106\n",
      "Progress: 33.22%\n",
      "38\n",
      "max difference =  17.30177116394043\n",
      "data at max difference =  3.7342121601104736\n",
      "imputed at max difference =  21.03598403930664\n",
      "mae =  0.4131212830543518\n",
      "rmse =  9.644435053286344\n",
      "Progress: 33.31%\n",
      "39\n",
      "max difference =  13.706497192382812\n",
      "data at max difference =  2.3955178260803223\n",
      "imputed at max difference =  16.102014541625977\n",
      "mae =  0.2911088466644287\n",
      "rmse =  7.8044911260190215\n",
      "Progress: 33.39%\n",
      "40\n",
      "max difference =  8.463701248168945\n",
      "data at max difference =  2.3753409385681152\n",
      "imputed at max difference =  10.839042663574219\n",
      "mae =  0.29663175344467163\n",
      "rmse =  5.797882743503736\n",
      "Progress: 33.47%\n",
      "41\n",
      "max difference =  18.160526275634766\n",
      "data at max difference =  2.1045942306518555\n",
      "imputed at max difference =  20.265121459960938\n",
      "mae =  0.33435097336769104\n",
      "rmse =  8.83159471594769\n",
      "Progress: 33.56%\n",
      "42\n",
      "max difference =  14.764348030090332\n",
      "data at max difference =  3.2897274494171143\n",
      "imputed at max difference =  18.054075241088867\n",
      "mae =  0.36076170206069946\n",
      "rmse =  8.417474497919496\n",
      "Progress: 33.64%\n",
      "43\n",
      "max difference =  24.448772430419922\n",
      "data at max difference =  1.6754016876220703\n",
      "imputed at max difference =  26.124174118041992\n",
      "mae =  0.6455040574073792\n",
      "rmse =  15.786881156589674\n",
      "Progress: 33.73%\n",
      "44\n",
      "max difference =  24.77552032470703\n",
      "data at max difference =  3.745873212814331\n",
      "imputed at max difference =  28.521392822265625\n",
      "mae =  0.7031395435333252\n",
      "rmse =  16.00847327190897\n",
      "Progress: 33.81%\n",
      "45\n",
      "max difference =  38.73524475097656\n",
      "data at max difference =  4.227313041687012\n",
      "imputed at max difference =  42.96255874633789\n",
      "mae =  0.6482590436935425\n",
      "rmse =  19.7666015625\n",
      "Progress: 33.90%\n",
      "46\n",
      "max difference =  22.431354522705078\n",
      "data at max difference =  3.933950424194336\n",
      "imputed at max difference =  26.365304946899414\n",
      "mae =  0.4896954596042633\n",
      "rmse =  12.382915994395379\n",
      "Progress: 33.98%\n",
      "47\n",
      "max difference =  2.5274648666381836\n",
      "data at max difference =  4.468069553375244\n",
      "imputed at max difference =  1.940604567527771\n",
      "mae =  0.08276166021823883\n",
      "rmse =  1.340179858000382\n",
      "Progress: 34.07%\n",
      "48\n",
      "max difference =  2.645629405975342\n",
      "data at max difference =  4.284865856170654\n",
      "imputed at max difference =  6.930495262145996\n",
      "mae =  0.10594163835048676\n",
      "rmse =  1.6311300526494563\n",
      "Progress: 34.15%\n",
      "49\n",
      "max difference =  7.921430587768555\n",
      "data at max difference =  4.738558769226074\n",
      "imputed at max difference =  12.659989356994629\n",
      "mae =  0.15384703874588013\n",
      "rmse =  3.77525462274966\n",
      "Progress: 34.24%\n",
      "50\n",
      "max difference =  24.74087142944336\n",
      "data at max difference =  4.167771816253662\n",
      "imputed at max difference =  28.90864372253418\n",
      "mae =  0.32281455397605896\n",
      "rmse =  11.38919730808424\n",
      "Progress: 34.32%\n",
      "51\n",
      "max difference =  4.330657482147217\n",
      "data at max difference =  4.304757595062256\n",
      "imputed at max difference =  8.635415077209473\n",
      "mae =  0.08813801407814026\n",
      "rmse =  2.1539084393045176\n",
      "Progress: 34.41%\n",
      "52\n",
      "max difference =  5.7865309715271\n",
      "data at max difference =  4.122889995574951\n",
      "imputed at max difference =  9.90942096710205\n",
      "mae =  0.09700387716293335\n",
      "rmse =  2.694667152736498\n",
      "Progress: 34.49%\n",
      "53\n",
      "max difference =  33.01403045654297\n",
      "data at max difference =  3.7796366214752197\n",
      "imputed at max difference =  36.79366683959961\n",
      "mae =  0.7114050388336182\n",
      "rmse =  19.025276515794836\n",
      "Progress: 34.58%\n",
      "54\n",
      "max difference =  83.9173355102539\n",
      "data at max difference =  4.1450324058532715\n",
      "imputed at max difference =  88.06237030029297\n",
      "mae =  1.1205253601074219\n",
      "rmse =  39.14350426715353\n",
      "Progress: 34.66%\n",
      "55\n",
      "max difference =  71.6689224243164\n",
      "data at max difference =  3.6263844966888428\n",
      "imputed at max difference =  75.29530334472656\n",
      "mae =  1.1642478704452515\n",
      "rmse =  36.792976711107336\n",
      "Progress: 34.75%\n",
      "56\n",
      "max difference =  117.45110321044922\n",
      "data at max difference =  3.634439468383789\n",
      "imputed at max difference =  121.08554077148438\n",
      "mae =  1.2492932081222534\n",
      "rmse =  53.568168308423914\n",
      "Progress: 34.83%\n",
      "57\n",
      "max difference =  19.506654739379883\n",
      "data at max difference =  3.1485235691070557\n",
      "imputed at max difference =  22.65517807006836\n",
      "mae =  0.3765034079551697\n",
      "rmse =  11.144502059273098\n",
      "Progress: 34.92%\n",
      "58\n",
      "max difference =  4.47960090637207\n",
      "data at max difference =  4.55797004699707\n",
      "imputed at max difference =  0.07836924493312836\n",
      "mae =  0.28967443108558655\n",
      "rmse =  4.033628712529722\n",
      "Progress: 35.00%\n",
      "0\n",
      "max difference =  122.95172882080078\n",
      "data at max difference =  2.3850014209747314\n",
      "imputed at max difference =  125.33673095703125\n",
      "mae =  1.4836738109588623\n",
      "rmse =  56.206001613451086\n",
      "Progress: 35.08%\n",
      "1\n",
      "max difference =  14.083763122558594\n",
      "data at max difference =  3.252281427383423\n",
      "imputed at max difference =  17.336044311523438\n",
      "mae =  0.3995915949344635\n",
      "rmse =  7.483912592348845\n",
      "Progress: 35.17%\n",
      "2\n",
      "max difference =  104.66351318359375\n",
      "data at max difference =  4.792801856994629\n",
      "imputed at max difference =  109.45631408691406\n",
      "mae =  1.478087306022644\n",
      "rmse =  48.21131432574728\n",
      "Progress: 35.25%\n",
      "3\n",
      "max difference =  88.10826110839844\n",
      "data at max difference =  3.0506722927093506\n",
      "imputed at max difference =  91.158935546875\n",
      "mae =  3.581472158432007\n",
      "rmse =  61.37766962466033\n",
      "Progress: 35.34%\n",
      "4\n",
      "max difference =  39.94794845581055\n",
      "data at max difference =  3.644343614578247\n",
      "imputed at max difference =  43.59229278564453\n",
      "mae =  1.8758736848831177\n",
      "rmse =  31.944404933763586\n",
      "Progress: 35.42%\n",
      "5\n",
      "max difference =  44.77053451538086\n",
      "data at max difference =  5.088260173797607\n",
      "imputed at max difference =  49.858795166015625\n",
      "mae =  1.848732352256775\n",
      "rmse =  31.64518406080163\n",
      "Progress: 35.51%\n",
      "6\n",
      "max difference =  142.76315307617188\n",
      "data at max difference =  4.688121318817139\n",
      "imputed at max difference =  147.45127868652344\n",
      "mae =  2.4360861778259277\n",
      "rmse =  67.82091223675272\n",
      "Progress: 35.59%\n",
      "7\n",
      "max difference =  53.37266159057617\n",
      "data at max difference =  4.087564945220947\n",
      "imputed at max difference =  57.460227966308594\n",
      "mae =  1.0562005043029785\n",
      "rmse =  26.480543053668477\n",
      "Progress: 35.68%\n",
      "8\n",
      "max difference =  81.05525970458984\n",
      "data at max difference =  4.987031936645508\n",
      "imputed at max difference =  86.04228973388672\n",
      "mae =  1.35563325881958\n",
      "rmse =  38.17678169582201\n",
      "Progress: 35.76%\n",
      "9\n",
      "max difference =  42.887752532958984\n",
      "data at max difference =  3.169604778289795\n",
      "imputed at max difference =  46.05735778808594\n",
      "mae =  0.9145876169204712\n",
      "rmse =  22.698138693104617\n",
      "Progress: 35.85%\n",
      "10\n",
      "max difference =  51.715232849121094\n",
      "data at max difference =  2.881241798400879\n",
      "imputed at max difference =  54.596473693847656\n",
      "mae =  1.0204583406448364\n",
      "rmse =  26.27443263841712\n",
      "Progress: 35.93%\n",
      "11\n",
      "max difference =  19.86758041381836\n",
      "data at max difference =  3.4434592723846436\n",
      "imputed at max difference =  23.311038970947266\n",
      "mae =  0.6150151491165161\n",
      "rmse =  13.120528511379076\n",
      "Progress: 36.02%\n",
      "12\n",
      "max difference =  18.03687286376953\n",
      "data at max difference =  3.798804521560669\n",
      "imputed at max difference =  21.835678100585938\n",
      "mae =  0.42310672998428345\n",
      "rmse =  9.472818125849185\n",
      "Progress: 36.10%\n",
      "13\n",
      "max difference =  37.20469665527344\n",
      "data at max difference =  3.078768014907837\n",
      "imputed at max difference =  40.28346633911133\n",
      "mae =  0.8594969511032104\n",
      "rmse =  20.272476859714676\n",
      "Progress: 36.19%\n",
      "14\n",
      "max difference =  29.087108612060547\n",
      "data at max difference =  3.4648749828338623\n",
      "imputed at max difference =  32.55198287963867\n",
      "mae =  0.4276629090309143\n",
      "rmse =  13.409547225288723\n",
      "Progress: 36.27%\n",
      "15\n",
      "max difference =  20.19298553466797\n",
      "data at max difference =  4.187092304229736\n",
      "imputed at max difference =  24.380077362060547\n",
      "mae =  0.4617347717285156\n",
      "rmse =  10.391771399456522\n",
      "Progress: 36.36%\n",
      "16\n",
      "max difference =  39.250423431396484\n",
      "data at max difference =  3.6800894737243652\n",
      "imputed at max difference =  42.930511474609375\n",
      "mae =  0.8004286289215088\n",
      "rmse =  20.132332179857336\n",
      "Progress: 36.44%\n",
      "17\n",
      "max difference =  29.546297073364258\n",
      "data at max difference =  4.372129440307617\n",
      "imputed at max difference =  33.918426513671875\n",
      "mae =  0.6285601258277893\n",
      "rmse =  16.63104778787364\n",
      "Progress: 36.53%\n",
      "18\n",
      "max difference =  9.347297668457031\n",
      "data at max difference =  3.0454649925231934\n",
      "imputed at max difference =  12.392763137817383\n",
      "mae =  0.23958468437194824\n",
      "rmse =  4.928489021632982\n",
      "Progress: 36.61%\n",
      "19\n",
      "max difference =  33.624610900878906\n",
      "data at max difference =  2.7446513175964355\n",
      "imputed at max difference =  36.3692626953125\n",
      "mae =  0.7758122682571411\n",
      "rmse =  19.056956415591035\n",
      "Progress: 36.69%\n",
      "20\n",
      "max difference =  70.36054992675781\n",
      "data at max difference =  3.1049461364746094\n",
      "imputed at max difference =  73.46549224853516\n",
      "mae =  1.1184624433517456\n",
      "rmse =  34.88405443274456\n",
      "Progress: 36.78%\n",
      "21\n",
      "max difference =  50.615806579589844\n",
      "data at max difference =  3.0974695682525635\n",
      "imputed at max difference =  53.71327590942383\n",
      "mae =  0.6964417695999146\n",
      "rmse =  23.407722804857336\n",
      "Progress: 36.86%\n",
      "22\n",
      "max difference =  27.72632598876953\n",
      "data at max difference =  3.3984665870666504\n",
      "imputed at max difference =  31.124792098999023\n",
      "mae =  0.4378542900085449\n",
      "rmse =  12.941320004670517\n",
      "Progress: 36.95%\n",
      "23\n",
      "max difference =  98.53739166259766\n",
      "data at max difference =  2.2658510208129883\n",
      "imputed at max difference =  100.8032455444336\n",
      "mae =  2.669299840927124\n",
      "rmse =  68.16053838315217\n",
      "Progress: 37.03%\n",
      "24\n",
      "max difference =  97.8310775756836\n",
      "data at max difference =  2.3074660301208496\n",
      "imputed at max difference =  100.13854217529297\n",
      "mae =  1.834236979484558\n",
      "rmse =  51.12939983865489\n",
      "Progress: 37.12%\n",
      "25\n",
      "max difference =  51.221214294433594\n",
      "data at max difference =  2.893998146057129\n",
      "imputed at max difference =  54.115211486816406\n",
      "mae =  0.8788577318191528\n",
      "rmse =  24.853913680366848\n",
      "Progress: 37.20%\n",
      "26\n",
      "max difference =  48.12746047973633\n",
      "data at max difference =  2.8632819652557373\n",
      "imputed at max difference =  50.99074172973633\n",
      "mae =  0.9245753884315491\n",
      "rmse =  24.062850288722824\n",
      "Progress: 37.29%\n",
      "27\n",
      "max difference =  85.11101531982422\n",
      "data at max difference =  3.4737296104431152\n",
      "imputed at max difference =  88.58474731445312\n",
      "mae =  1.552910327911377\n",
      "rmse =  43.214607570482336\n",
      "Progress: 37.37%\n",
      "28\n",
      "max difference =  45.063636779785156\n",
      "data at max difference =  3.075853109359741\n",
      "imputed at max difference =  48.139488220214844\n",
      "mae =  1.431959629058838\n",
      "rmse =  34.98728876528532\n",
      "Progress: 37.46%\n",
      "29\n",
      "max difference =  26.699462890625\n",
      "data at max difference =  3.5692858695983887\n",
      "imputed at max difference =  30.268749237060547\n",
      "mae =  0.5847407579421997\n",
      "rmse =  14.712160856827447\n",
      "Progress: 37.54%\n",
      "30\n",
      "max difference =  61.38100814819336\n",
      "data at max difference =  2.8946356773376465\n",
      "imputed at max difference =  64.27564239501953\n",
      "mae =  1.2826411724090576\n",
      "rmse =  33.93808912194293\n",
      "Progress: 37.63%\n",
      "31\n",
      "max difference =  43.505252838134766\n",
      "data at max difference =  3.720954418182373\n",
      "imputed at max difference =  47.2262077331543\n",
      "mae =  1.015542984008789\n",
      "rmse =  24.27170463230299\n",
      "Progress: 37.71%\n",
      "32\n",
      "max difference =  23.54552459716797\n",
      "data at max difference =  3.586270332336426\n",
      "imputed at max difference =  27.131793975830078\n",
      "mae =  0.9729042053222656\n",
      "rmse =  18.378842561141305\n",
      "Progress: 37.80%\n",
      "33\n",
      "max difference =  135.84237670898438\n",
      "data at max difference =  2.9661622047424316\n",
      "imputed at max difference =  138.80853271484375\n",
      "mae =  1.7232180833816528\n",
      "rmse =  62.48543117357337\n",
      "Progress: 37.88%\n",
      "34\n",
      "max difference =  46.287872314453125\n",
      "data at max difference =  3.5691335201263428\n",
      "imputed at max difference =  49.85700607299805\n",
      "mae =  0.9927375316619873\n",
      "rmse =  26.70804231063179\n",
      "Progress: 37.97%\n",
      "35\n",
      "max difference =  14.799873352050781\n",
      "data at max difference =  2.425321340560913\n",
      "imputed at max difference =  17.225194931030273\n",
      "mae =  0.48416632413864136\n",
      "rmse =  10.213408096976902\n",
      "Progress: 38.05%\n",
      "36\n",
      "max difference =  26.716659545898438\n",
      "data at max difference =  3.7332305908203125\n",
      "imputed at max difference =  30.44989013671875\n",
      "mae =  0.6712162494659424\n",
      "rmse =  15.897117283033287\n",
      "Progress: 38.14%\n",
      "37\n",
      "max difference =  6.539177894592285\n",
      "data at max difference =  2.5965993404388428\n",
      "imputed at max difference =  9.135777473449707\n",
      "mae =  0.20615145564079285\n",
      "rmse =  4.06294117803159\n",
      "Progress: 38.22%\n",
      "38\n",
      "max difference =  31.763065338134766\n",
      "data at max difference =  2.96101450920105\n",
      "imputed at max difference =  34.72407913208008\n",
      "mae =  0.5710166096687317\n",
      "rmse =  16.055953316066578\n",
      "Progress: 38.31%\n",
      "39\n",
      "max difference =  9.577095985412598\n",
      "data at max difference =  2.7609822750091553\n",
      "imputed at max difference =  12.338078498840332\n",
      "mae =  0.2960973381996155\n",
      "rmse =  6.088833352793818\n",
      "Progress: 38.39%\n",
      "40\n",
      "max difference =  12.7680025100708\n",
      "data at max difference =  3.11929988861084\n",
      "imputed at max difference =  15.88730239868164\n",
      "mae =  0.3522282838821411\n",
      "rmse =  7.335266776706861\n",
      "Progress: 38.47%\n",
      "41\n",
      "max difference =  4.631490707397461\n",
      "data at max difference =  1.7970588207244873\n",
      "imputed at max difference =  6.428549289703369\n",
      "mae =  0.17997023463249207\n",
      "rmse =  3.1535044131071674\n",
      "Progress: 38.56%\n",
      "42\n",
      "max difference =  20.646581649780273\n",
      "data at max difference =  2.973641872406006\n",
      "imputed at max difference =  23.620223999023438\n",
      "mae =  0.4811159074306488\n",
      "rmse =  11.196229354194973\n",
      "Progress: 38.64%\n",
      "43\n",
      "max difference =  23.239017486572266\n",
      "data at max difference =  1.7463536262512207\n",
      "imputed at max difference =  24.985370635986328\n",
      "mae =  0.6128571033477783\n",
      "rmse =  15.09432718028193\n",
      "Progress: 38.73%\n",
      "44\n",
      "max difference =  82.81307220458984\n",
      "data at max difference =  3.158930540084839\n",
      "imputed at max difference =  85.97200012207031\n",
      "mae =  1.1010006666183472\n",
      "rmse =  38.37166164232337\n",
      "Progress: 38.81%\n",
      "45\n",
      "max difference =  13.340721130371094\n",
      "data at max difference =  3.2877042293548584\n",
      "imputed at max difference =  16.62842559814453\n",
      "mae =  0.2531363070011139\n",
      "rmse =  6.322592030400815\n",
      "Progress: 38.90%\n",
      "46\n",
      "max difference =  88.20695495605469\n",
      "data at max difference =  4.283926486968994\n",
      "imputed at max difference =  92.49088287353516\n",
      "mae =  1.0522152185440063\n",
      "rmse =  40.5506936778193\n",
      "Progress: 38.98%\n",
      "47\n",
      "max difference =  72.92045593261719\n",
      "data at max difference =  4.468069553375244\n",
      "imputed at max difference =  77.3885269165039\n",
      "mae =  0.9844921827316284\n",
      "rmse =  34.162533967391305\n",
      "Progress: 39.07%\n",
      "48\n",
      "max difference =  19.143014907836914\n",
      "data at max difference =  4.654101848602295\n",
      "imputed at max difference =  23.797117233276367\n",
      "mae =  0.2722463011741638\n",
      "rmse =  8.79605832307235\n",
      "Progress: 39.15%\n",
      "49\n",
      "max difference =  34.567264556884766\n",
      "data at max difference =  3.6701767444610596\n",
      "imputed at max difference =  38.23744201660156\n",
      "mae =  0.4120253622531891\n",
      "rmse =  15.795455269191578\n",
      "Progress: 39.24%\n",
      "50\n",
      "max difference =  15.392499923706055\n",
      "data at max difference =  4.473196029663086\n",
      "imputed at max difference =  19.86569595336914\n",
      "mae =  0.38452160358428955\n",
      "rmse =  9.456038101859715\n",
      "Progress: 39.32%\n",
      "51\n",
      "max difference =  20.428298950195312\n",
      "data at max difference =  5.0189433097839355\n",
      "imputed at max difference =  25.447242736816406\n",
      "mae =  0.294719934463501\n",
      "rmse =  9.528178339419158\n",
      "Progress: 39.41%\n",
      "52\n",
      "max difference =  34.49039840698242\n",
      "data at max difference =  3.1322391033172607\n",
      "imputed at max difference =  37.62263870239258\n",
      "mae =  0.3941059708595276\n",
      "rmse =  15.74901016898777\n",
      "Progress: 39.49%\n",
      "53\n",
      "max difference =  10.217535972595215\n",
      "data at max difference =  3.7796366214752197\n",
      "imputed at max difference =  13.997172355651855\n",
      "mae =  0.2443138062953949\n",
      "rmse =  6.55313309379246\n",
      "Progress: 39.58%\n",
      "54\n",
      "max difference =  13.722259521484375\n",
      "data at max difference =  4.1450324058532715\n",
      "imputed at max difference =  17.867292404174805\n",
      "mae =  0.21977001428604126\n",
      "rmse =  6.52908988620924\n",
      "Progress: 39.66%\n",
      "55\n",
      "max difference =  64.22561645507812\n",
      "data at max difference =  4.238101482391357\n",
      "imputed at max difference =  68.46371459960938\n",
      "mae =  1.0518348217010498\n",
      "rmse =  33.85381549337636\n",
      "Progress: 39.75%\n",
      "56\n",
      "max difference =  25.844341278076172\n",
      "data at max difference =  3.3817639350891113\n",
      "imputed at max difference =  29.226104736328125\n",
      "mae =  0.3102569580078125\n",
      "rmse =  11.816698157269022\n",
      "Progress: 39.83%\n",
      "57\n",
      "max difference =  31.41607666015625\n",
      "data at max difference =  4.061976432800293\n",
      "imputed at max difference =  35.47805404663086\n",
      "mae =  0.38455820083618164\n",
      "rmse =  14.413440206776496\n",
      "Progress: 39.92%\n",
      "58\n",
      "max difference =  116.18888854980469\n",
      "data at max difference =  1.5294126272201538\n",
      "imputed at max difference =  117.71829986572266\n",
      "mae =  2.143549919128418\n",
      "rmse =  59.44334876019022\n",
      "Progress: 40.00%\n",
      "0\n",
      "max difference =  56.5604362487793\n",
      "data at max difference =  5.403512001037598\n",
      "imputed at max difference =  61.96394729614258\n",
      "mae =  0.9941569566726685\n",
      "rmse =  27.23687213400136\n",
      "Progress: 40.08%\n",
      "1\n",
      "max difference =  4.051923751831055\n",
      "data at max difference =  5.496946334838867\n",
      "imputed at max difference =  9.548870086669922\n",
      "mae =  0.2511443495750427\n",
      "rmse =  3.20100270146909\n",
      "Progress: 40.17%\n",
      "2\n",
      "max difference =  63.977195739746094\n",
      "data at max difference =  3.3279659748077393\n",
      "imputed at max difference =  67.30516052246094\n",
      "mae =  2.9349467754364014\n",
      "rmse =  51.41771930197011\n",
      "Progress: 40.25%\n",
      "3\n",
      "max difference =  94.93766021728516\n",
      "data at max difference =  14.66715145111084\n",
      "imputed at max difference =  109.60481262207031\n",
      "mae =  3.13242769241333\n",
      "rmse =  58.56394892153533\n",
      "Progress: 40.34%\n",
      "4\n",
      "max difference =  288.70355224609375\n",
      "data at max difference =  1.5234109163284302\n",
      "imputed at max difference =  290.2269592285156\n",
      "mae =  7.142707824707031\n",
      "rmse =  170.63046662703806\n",
      "Progress: 40.42%\n",
      "5\n",
      "max difference =  67.25916290283203\n",
      "data at max difference =  1.715961217880249\n",
      "imputed at max difference =  68.9751205444336\n",
      "mae =  3.1341514587402344\n",
      "rmse =  53.425001061480984\n",
      "Progress: 40.51%\n",
      "6\n",
      "max difference =  70.80307006835938\n",
      "data at max difference =  4.688121318817139\n",
      "imputed at max difference =  75.4911880493164\n",
      "mae =  1.5545098781585693\n",
      "rmse =  36.0752828846807\n",
      "Progress: 40.59%\n",
      "7\n",
      "max difference =  139.28427124023438\n",
      "data at max difference =  2.932432174682617\n",
      "imputed at max difference =  142.21670532226562\n",
      "mae =  2.807053804397583\n",
      "rmse =  71.7234523607337\n",
      "Progress: 40.68%\n",
      "8\n",
      "max difference =  89.26119232177734\n",
      "data at max difference =  4.987031936645508\n",
      "imputed at max difference =  94.24822235107422\n",
      "mae =  1.5360009670257568\n",
      "rmse =  42.55115542204484\n",
      "Progress: 40.76%\n",
      "9\n",
      "max difference =  72.80751037597656\n",
      "data at max difference =  3.422072172164917\n",
      "imputed at max difference =  76.22958374023438\n",
      "mae =  1.5306987762451172\n",
      "rmse =  37.23579207710598\n",
      "Progress: 40.85%\n",
      "10\n",
      "max difference =  33.53252410888672\n",
      "data at max difference =  2.881241798400879\n",
      "imputed at max difference =  36.41376495361328\n",
      "mae =  0.8183844089508057\n",
      "rmse =  19.417420760444973\n",
      "Progress: 40.93%\n",
      "11\n",
      "max difference =  40.884521484375\n",
      "data at max difference =  3.1999928951263428\n",
      "imputed at max difference =  44.08451461791992\n",
      "mae =  1.0660237073898315\n",
      "rmse =  26.677423891813856\n",
      "Progress: 41.02%\n",
      "12\n",
      "max difference =  29.213274002075195\n",
      "data at max difference =  3.4866089820861816\n",
      "imputed at max difference =  32.69988250732422\n",
      "mae =  0.6597061157226562\n",
      "rmse =  15.671078889266305\n",
      "Progress: 41.10%\n",
      "13\n",
      "max difference =  36.1825065612793\n",
      "data at max difference =  3.6411452293395996\n",
      "imputed at max difference =  39.82365036010742\n",
      "mae =  0.6767917275428772\n",
      "rmse =  18.10871422809103\n",
      "Progress: 41.19%\n",
      "14\n",
      "max difference =  1.6084513664245605\n",
      "data at max difference =  4.049773693084717\n",
      "imputed at max difference =  5.658225059509277\n",
      "mae =  0.1283465474843979\n",
      "rmse =  1.4400079146675442\n",
      "Progress: 41.27%\n",
      "15\n",
      "max difference =  45.02248001098633\n",
      "data at max difference =  4.187092304229736\n",
      "imputed at max difference =  49.209571838378906\n",
      "mae =  0.8638726472854614\n",
      "rmse =  23.135017726732336\n",
      "Progress: 41.36%\n",
      "16\n",
      "max difference =  30.800893783569336\n",
      "data at max difference =  3.3333306312561035\n",
      "imputed at max difference =  34.13422393798828\n",
      "mae =  0.9312684535980225\n",
      "rmse =  20.811130689538043\n",
      "Progress: 41.44%\n",
      "17\n",
      "max difference =  98.4798355102539\n",
      "data at max difference =  3.7386417388916016\n",
      "imputed at max difference =  102.21847534179688\n",
      "mae =  1.1765629053115845\n",
      "rmse =  45.072233780570656\n",
      "Progress: 41.53%\n",
      "18\n",
      "max difference =  24.78986930847168\n",
      "data at max difference =  3.599268674850464\n",
      "imputed at max difference =  28.389137268066406\n",
      "mae =  0.6450666785240173\n",
      "rmse =  14.932414179262906\n",
      "Progress: 41.61%\n",
      "19\n",
      "max difference =  66.88600158691406\n",
      "data at max difference =  2.7446513175964355\n",
      "imputed at max difference =  69.63065338134766\n",
      "mae =  1.2070045471191406\n",
      "rmse =  36.19929570737093\n",
      "Progress: 41.69%\n",
      "20\n",
      "max difference =  18.085609436035156\n",
      "data at max difference =  3.1049461364746094\n",
      "imputed at max difference =  21.190555572509766\n",
      "mae =  0.3237658739089966\n",
      "rmse =  8.790179045304008\n",
      "Progress: 41.78%\n",
      "21\n",
      "max difference =  82.30074310302734\n",
      "data at max difference =  2.794804811477661\n",
      "imputed at max difference =  85.09555053710938\n",
      "mae =  1.709520697593689\n",
      "rmse =  52.19578485903532\n",
      "Progress: 41.86%\n",
      "22\n",
      "max difference =  94.95657348632812\n",
      "data at max difference =  3.7011895179748535\n",
      "imputed at max difference =  98.65776062011719\n",
      "mae =  1.6060541868209839\n",
      "rmse =  50.12801991338315\n",
      "Progress: 41.95%\n",
      "23\n",
      "max difference =  62.17911148071289\n",
      "data at max difference =  2.7374680042266846\n",
      "imputed at max difference =  64.91658020019531\n",
      "mae =  1.1279313564300537\n",
      "rmse =  31.837004288383152\n",
      "Progress: 42.03%\n",
      "24\n",
      "max difference =  25.8492374420166\n",
      "data at max difference =  2.5594370365142822\n",
      "imputed at max difference =  28.408674240112305\n",
      "mae =  0.5352630615234375\n",
      "rmse =  13.254750127377719\n",
      "Progress: 42.12%\n",
      "25\n",
      "max difference =  46.133174896240234\n",
      "data at max difference =  3.3274190425872803\n",
      "imputed at max difference =  49.460594177246094\n",
      "mae =  1.6285614967346191\n",
      "rmse =  34.719368312669836\n",
      "Progress: 42.20%\n",
      "26\n",
      "max difference =  37.1973991394043\n",
      "data at max difference =  2.8632819652557373\n",
      "imputed at max difference =  40.0606803894043\n",
      "mae =  1.5562571287155151\n",
      "rmse =  28.53579048488451\n",
      "Progress: 42.29%\n",
      "27\n",
      "max difference =  26.85030174255371\n",
      "data at max difference =  3.5885987281799316\n",
      "imputed at max difference =  30.438899993896484\n",
      "mae =  0.8904239535331726\n",
      "rmse =  17.76619819972826\n",
      "Progress: 42.37%\n",
      "28\n",
      "max difference =  26.620426177978516\n",
      "data at max difference =  2.3798646926879883\n",
      "imputed at max difference =  29.00029182434082\n",
      "mae =  0.45178931951522827\n",
      "rmse =  12.646045187245244\n",
      "Progress: 42.46%\n",
      "29\n",
      "max difference =  108.39960479736328\n",
      "data at max difference =  3.688014030456543\n",
      "imputed at max difference =  112.08761596679688\n",
      "mae =  2.0753653049468994\n",
      "rmse =  54.413330078125\n",
      "Progress: 42.54%\n",
      "30\n",
      "max difference =  18.75391387939453\n",
      "data at max difference =  3.7144384384155273\n",
      "imputed at max difference =  22.468353271484375\n",
      "mae =  0.38772958517074585\n",
      "rmse =  9.796149212381113\n",
      "Progress: 42.63%\n",
      "31\n",
      "max difference =  37.987483978271484\n",
      "data at max difference =  3.6001527309417725\n",
      "imputed at max difference =  41.5876350402832\n",
      "mae =  0.5692725777626038\n",
      "rmse =  17.831771187160324\n",
      "Progress: 42.71%\n",
      "32\n",
      "max difference =  102.42777252197266\n",
      "data at max difference =  3.7034971714019775\n",
      "imputed at max difference =  106.13127136230469\n",
      "mae =  1.4140671491622925\n",
      "rmse =  48.304496433423914\n",
      "Progress: 42.80%\n",
      "33\n",
      "max difference =  21.862546920776367\n",
      "data at max difference =  3.5381031036376953\n",
      "imputed at max difference =  25.400650024414062\n",
      "mae =  0.41511741280555725\n",
      "rmse =  11.345234746518344\n",
      "Progress: 42.88%\n",
      "34\n",
      "max difference =  29.011486053466797\n",
      "data at max difference =  3.688072681427002\n",
      "imputed at max difference =  32.69955825805664\n",
      "mae =  0.8099047541618347\n",
      "rmse =  19.10847672172215\n",
      "Progress: 42.97%\n",
      "35\n",
      "max difference =  20.150541305541992\n",
      "data at max difference =  3.577104330062866\n",
      "imputed at max difference =  23.727645874023438\n",
      "mae =  0.29053831100463867\n",
      "rmse =  9.290244724439537\n",
      "Progress: 43.05%\n",
      "36\n",
      "max difference =  13.323389053344727\n",
      "data at max difference =  3.024057149887085\n",
      "imputed at max difference =  16.34744644165039\n",
      "mae =  0.3101046681404114\n",
      "rmse =  6.895844169284987\n",
      "Progress: 43.14%\n",
      "37\n",
      "max difference =  23.721094131469727\n",
      "data at max difference =  3.746554136276245\n",
      "imputed at max difference =  27.467647552490234\n",
      "mae =  0.5640890002250671\n",
      "rmse =  13.199216096297553\n",
      "Progress: 43.22%\n",
      "38\n",
      "max difference =  14.290253639221191\n",
      "data at max difference =  3.7342121601104736\n",
      "imputed at max difference =  18.024465560913086\n",
      "mae =  0.3604455888271332\n",
      "rmse =  7.908822101095449\n",
      "Progress: 43.31%\n",
      "39\n",
      "max difference =  13.11526107788086\n",
      "data at max difference =  2.917407751083374\n",
      "imputed at max difference =  16.032669067382812\n",
      "mae =  0.3229144215583801\n",
      "rmse =  7.24101854407269\n",
      "Progress: 43.39%\n",
      "40\n",
      "max difference =  30.856786727905273\n",
      "data at max difference =  2.3753409385681152\n",
      "imputed at max difference =  33.23212814331055\n",
      "mae =  0.4019593596458435\n",
      "rmse =  14.134735107421875\n",
      "Progress: 43.47%\n",
      "41\n",
      "max difference =  43.755313873291016\n",
      "data at max difference =  3.80366849899292\n",
      "imputed at max difference =  47.558982849121094\n",
      "mae =  0.9395979046821594\n",
      "rmse =  22.839137865149457\n",
      "Progress: 43.56%\n",
      "42\n",
      "max difference =  11.265581130981445\n",
      "data at max difference =  3.2897274494171143\n",
      "imputed at max difference =  14.55530834197998\n",
      "mae =  0.1962234526872635\n",
      "rmse =  5.259806757387907\n",
      "Progress: 43.64%\n",
      "43\n",
      "max difference =  9.872390747070312\n",
      "data at max difference =  3.971184253692627\n",
      "imputed at max difference =  13.843575477600098\n",
      "mae =  0.2548312842845917\n",
      "rmse =  5.4349507870881455\n",
      "Progress: 43.73%\n",
      "44\n",
      "max difference =  108.7019271850586\n",
      "data at max difference =  3.745873212814331\n",
      "imputed at max difference =  112.44779968261719\n",
      "mae =  1.3210735321044922\n",
      "rmse =  50.02324112601902\n",
      "Progress: 43.81%\n",
      "45\n",
      "max difference =  12.480365753173828\n",
      "data at max difference =  3.6255245208740234\n",
      "imputed at max difference =  16.10589027404785\n",
      "mae =  0.33395206928253174\n",
      "rmse =  7.54334889287534\n",
      "Progress: 43.90%\n",
      "46\n",
      "max difference =  23.66543197631836\n",
      "data at max difference =  3.933950424194336\n",
      "imputed at max difference =  27.599382400512695\n",
      "mae =  0.3774472773075104\n",
      "rmse =  11.23681640625\n",
      "Progress: 43.98%\n",
      "47\n",
      "max difference =  1.9767370223999023\n",
      "data at max difference =  4.468069553375244\n",
      "imputed at max difference =  2.491332530975342\n",
      "mae =  0.0857287123799324\n",
      "rmse =  1.2435282831606658\n",
      "Progress: 44.07%\n",
      "48\n",
      "max difference =  8.364530563354492\n",
      "data at max difference =  4.654101848602295\n",
      "imputed at max difference =  13.018632888793945\n",
      "mae =  0.16820308566093445\n",
      "rmse =  4.007746489151664\n",
      "Progress: 44.15%\n",
      "49\n",
      "max difference =  7.8134565353393555\n",
      "data at max difference =  4.738558769226074\n",
      "imputed at max difference =  12.55201530456543\n",
      "mae =  0.18023337423801422\n",
      "rmse =  4.168056322180706\n",
      "Progress: 44.24%\n",
      "50\n",
      "max difference =  24.898366928100586\n",
      "data at max difference =  3.7768969535827637\n",
      "imputed at max difference =  28.675264358520508\n",
      "mae =  0.32874971628189087\n",
      "rmse =  11.435954218325408\n",
      "Progress: 44.32%\n",
      "51\n",
      "max difference =  31.78470230102539\n",
      "data at max difference =  4.618027687072754\n",
      "imputed at max difference =  36.40272903442383\n",
      "mae =  0.5273544192314148\n",
      "rmse =  16.070309846297555\n",
      "Progress: 44.41%\n",
      "52\n",
      "max difference =  3.772097587585449\n",
      "data at max difference =  3.7667183876037598\n",
      "imputed at max difference =  7.538815975189209\n",
      "mae =  0.08070626854896545\n",
      "rmse =  1.8365655981976055\n",
      "Progress: 44.49%\n",
      "53\n",
      "max difference =  30.07257843017578\n",
      "data at max difference =  3.171074867248535\n",
      "imputed at max difference =  33.24365234375\n",
      "mae =  0.47090452909469604\n",
      "rmse =  14.967151144276494\n",
      "Progress: 44.58%\n",
      "54\n",
      "max difference =  22.613407135009766\n",
      "data at max difference =  4.1450324058532715\n",
      "imputed at max difference =  26.758440017700195\n",
      "mae =  0.4603884518146515\n",
      "rmse =  12.71444038722826\n",
      "Progress: 44.66%\n",
      "55\n",
      "max difference =  80.0263442993164\n",
      "data at max difference =  4.238101482391357\n",
      "imputed at max difference =  84.26444244384766\n",
      "mae =  1.1157292127609253\n",
      "rmse =  37.6339987049932\n",
      "Progress: 44.75%\n",
      "56\n",
      "max difference =  22.934925079345703\n",
      "data at max difference =  3.634439468383789\n",
      "imputed at max difference =  26.569364547729492\n",
      "mae =  0.429411917924881\n",
      "rmse =  12.93339206861413\n",
      "Progress: 44.83%\n",
      "57\n",
      "max difference =  25.364709854125977\n",
      "data at max difference =  3.1485235691070557\n",
      "imputed at max difference =  28.513233184814453\n",
      "mae =  0.29947149753570557\n",
      "rmse =  11.5784912109375\n",
      "Progress: 44.92%\n",
      "58\n",
      "max difference =  7.888185024261475\n",
      "data at max difference =  3.1417088508605957\n",
      "imputed at max difference =  11.02989387512207\n",
      "mae =  0.3039502501487732\n",
      "rmse =  4.738070944081182\n",
      "Progress: 45.00%\n",
      "0\n",
      "max difference =  36.156463623046875\n",
      "data at max difference =  1.2311043739318848\n",
      "imputed at max difference =  37.387569427490234\n",
      "mae =  0.6147956252098083\n",
      "rmse =  17.329975957455844\n",
      "Progress: 45.08%\n",
      "1\n",
      "max difference =  50.75505065917969\n",
      "data at max difference =  5.496946334838867\n",
      "imputed at max difference =  56.25199508666992\n",
      "mae =  0.7565844655036926\n",
      "rmse =  23.42999267578125\n",
      "Progress: 45.17%\n",
      "2\n",
      "max difference =  67.66426849365234\n",
      "data at max difference =  2.510354995727539\n",
      "imputed at max difference =  70.17462158203125\n",
      "mae =  2.6557087898254395\n",
      "rmse =  50.21328337296196\n",
      "Progress: 45.25%\n",
      "3\n",
      "max difference =  65.70329284667969\n",
      "data at max difference =  14.66715145111084\n",
      "imputed at max difference =  80.37044525146484\n",
      "mae =  2.844313383102417\n",
      "rmse =  49.26835300611413\n",
      "Progress: 45.34%\n",
      "4\n",
      "max difference =  98.67434692382812\n",
      "data at max difference =  6.054922103881836\n",
      "imputed at max difference =  104.7292709350586\n",
      "mae =  2.9947848320007324\n",
      "rmse =  62.239294964334235\n",
      "Progress: 45.42%\n",
      "5\n",
      "max difference =  124.16780090332031\n",
      "data at max difference =  3.154200792312622\n",
      "imputed at max difference =  127.3219985961914\n",
      "mae =  5.6940202713012695\n",
      "rmse =  94.06970745584239\n",
      "Progress: 45.51%\n",
      "6\n",
      "max difference =  64.02068328857422\n",
      "data at max difference =  2.983938694000244\n",
      "imputed at max difference =  67.00462341308594\n",
      "mae =  1.6559996604919434\n",
      "rmse =  35.97019892153532\n",
      "Progress: 45.59%\n",
      "7\n",
      "max difference =  113.12928009033203\n",
      "data at max difference =  4.087564945220947\n",
      "imputed at max difference =  117.21684265136719\n",
      "mae =  2.1475489139556885\n",
      "rmse =  56.63460109544837\n",
      "Progress: 45.68%\n",
      "8\n",
      "max difference =  83.731689453125\n",
      "data at max difference =  3.891376495361328\n",
      "imputed at max difference =  87.62306213378906\n",
      "mae =  1.9676569700241089\n",
      "rmse =  46.27651048743206\n",
      "Progress: 45.76%\n",
      "9\n",
      "max difference =  74.64642333984375\n",
      "data at max difference =  3.422072172164917\n",
      "imputed at max difference =  78.06849670410156\n",
      "mae =  1.1103532314300537\n",
      "rmse =  34.552121369735055\n",
      "Progress: 45.85%\n",
      "10\n",
      "max difference =  52.23455810546875\n",
      "data at max difference =  3.747382640838623\n",
      "imputed at max difference =  55.98194122314453\n",
      "mae =  1.13401460647583\n",
      "rmse =  28.34658150050951\n",
      "Progress: 45.93%\n",
      "11\n",
      "max difference =  41.53935241699219\n",
      "data at max difference =  3.75504207611084\n",
      "imputed at max difference =  45.294395446777344\n",
      "mae =  1.1149177551269531\n",
      "rmse =  25.212200662364133\n",
      "Progress: 46.02%\n",
      "12\n",
      "max difference =  36.2458381652832\n",
      "data at max difference =  2.9304683208465576\n",
      "imputed at max difference =  39.176307678222656\n",
      "mae =  0.551779568195343\n",
      "rmse =  17.09059076723845\n",
      "Progress: 46.10%\n",
      "13\n",
      "max difference =  26.979589462280273\n",
      "data at max difference =  3.9568417072296143\n",
      "imputed at max difference =  30.936431884765625\n",
      "mae =  0.8988279700279236\n",
      "rmse =  20.39257281759511\n",
      "Progress: 46.19%\n",
      "14\n",
      "max difference =  33.94509506225586\n",
      "data at max difference =  3.7214345932006836\n",
      "imputed at max difference =  37.66653060913086\n",
      "mae =  0.7169538140296936\n",
      "rmse =  18.197239087975543\n",
      "Progress: 46.27%\n",
      "15\n",
      "max difference =  18.59208869934082\n",
      "data at max difference =  3.5889499187469482\n",
      "imputed at max difference =  22.18103790283203\n",
      "mae =  0.4171130359172821\n",
      "rmse =  10.833689150602922\n",
      "Progress: 46.36%\n",
      "16\n",
      "max difference =  43.673194885253906\n",
      "data at max difference =  3.3333306312561035\n",
      "imputed at max difference =  47.006526947021484\n",
      "mae =  1.4817537069320679\n",
      "rmse =  33.118018108865485\n",
      "Progress: 46.44%\n",
      "17\n",
      "max difference =  113.29369354248047\n",
      "data at max difference =  3.7386417388916016\n",
      "imputed at max difference =  117.03233337402344\n",
      "mae =  1.3172721862792969\n",
      "rmse =  51.775942595108695\n",
      "Progress: 46.53%\n",
      "18\n",
      "max difference =  84.39764404296875\n",
      "data at max difference =  3.2883851528167725\n",
      "imputed at max difference =  87.68602752685547\n",
      "mae =  1.7525438070297241\n",
      "rmse =  52.29794709578805\n",
      "Progress: 46.61%\n",
      "19\n",
      "max difference =  30.015195846557617\n",
      "data at max difference =  3.2785933017730713\n",
      "imputed at max difference =  33.29378890991211\n",
      "mae =  0.46723657846450806\n",
      "rmse =  14.26534768809443\n",
      "Progress: 46.69%\n",
      "20\n",
      "max difference =  134.54254150390625\n",
      "data at max difference =  3.3378450870513916\n",
      "imputed at max difference =  137.88038635253906\n",
      "mae =  1.8857783079147339\n",
      "rmse =  63.52645210597826\n",
      "Progress: 46.78%\n",
      "21\n",
      "max difference =  20.199865341186523\n",
      "data at max difference =  3.636632204055786\n",
      "imputed at max difference =  23.836498260498047\n",
      "mae =  0.30900830030441284\n",
      "rmse =  9.46104563837466\n",
      "Progress: 46.86%\n",
      "22\n",
      "max difference =  11.695699691772461\n",
      "data at max difference =  3.3984665870666504\n",
      "imputed at max difference =  15.09416675567627\n",
      "mae =  0.3467099666595459\n",
      "rmse =  7.446834398352581\n",
      "Progress: 46.95%\n",
      "23\n",
      "max difference =  86.19689178466797\n",
      "data at max difference =  3.0022151470184326\n",
      "imputed at max difference =  89.19910430908203\n",
      "mae =  1.2109286785125732\n",
      "rmse =  40.40157682999321\n",
      "Progress: 47.03%\n",
      "24\n",
      "max difference =  84.32334899902344\n",
      "data at max difference =  2.3074660301208496\n",
      "imputed at max difference =  86.63081359863281\n",
      "mae =  1.1628400087356567\n",
      "rmse =  39.150703761888586\n",
      "Progress: 47.12%\n",
      "25\n",
      "max difference =  50.557003021240234\n",
      "data at max difference =  3.007465124130249\n",
      "imputed at max difference =  53.56446838378906\n",
      "mae =  0.9865497946739197\n",
      "rmse =  25.319816257642664\n",
      "Progress: 47.20%\n",
      "26\n",
      "max difference =  86.24960327148438\n",
      "data at max difference =  3.524782419204712\n",
      "imputed at max difference =  89.77438354492188\n",
      "mae =  2.7140514850616455\n",
      "rmse =  59.425956394361414\n",
      "Progress: 47.29%\n",
      "27\n",
      "max difference =  91.65643310546875\n",
      "data at max difference =  3.5885987281799316\n",
      "imputed at max difference =  95.24503326416016\n",
      "mae =  1.986171841621399\n",
      "rmse =  50.58464249320652\n",
      "Progress: 47.37%\n",
      "28\n",
      "max difference =  38.28998947143555\n",
      "data at max difference =  3.075853109359741\n",
      "imputed at max difference =  41.365840911865234\n",
      "mae =  0.9216801524162292\n",
      "rmse =  23.359059209408965\n",
      "Progress: 47.46%\n",
      "29\n",
      "max difference =  137.97500610351562\n",
      "data at max difference =  3.5692858695983887\n",
      "imputed at max difference =  141.54429626464844\n",
      "mae =  3.6429154872894287\n",
      "rmse =  94.54503863790761\n",
      "Progress: 47.54%\n",
      "30\n",
      "max difference =  42.19330978393555\n",
      "data at max difference =  3.7144384384155273\n",
      "imputed at max difference =  45.90774917602539\n",
      "mae =  0.5365467071533203\n",
      "rmse =  19.301473866338313\n",
      "Progress: 47.63%\n",
      "31\n",
      "max difference =  116.73319244384766\n",
      "data at max difference =  2.7306010723114014\n",
      "imputed at max difference =  119.46379089355469\n",
      "mae =  2.5475761890411377\n",
      "rmse =  61.9010009765625\n",
      "Progress: 47.71%\n",
      "32\n",
      "max difference =  11.423972129821777\n",
      "data at max difference =  3.129429817199707\n",
      "imputed at max difference =  14.553401947021484\n",
      "mae =  0.1898355782032013\n",
      "rmse =  5.3225250244140625\n",
      "Progress: 47.80%\n",
      "33\n",
      "max difference =  160.50173950195312\n",
      "data at max difference =  3.654895544052124\n",
      "imputed at max difference =  164.15663146972656\n",
      "mae =  1.8941826820373535\n",
      "rmse =  73.38440472146739\n",
      "Progress: 47.88%\n",
      "34\n",
      "max difference =  36.92639923095703\n",
      "data at max difference =  3.688072681427002\n",
      "imputed at max difference =  40.614471435546875\n",
      "mae =  1.299567699432373\n",
      "rmse =  26.216788913892664\n",
      "Progress: 47.97%\n",
      "35\n",
      "max difference =  41.96017837524414\n",
      "data at max difference =  3.6970813274383545\n",
      "imputed at max difference =  45.65726089477539\n",
      "mae =  1.0617945194244385\n",
      "rmse =  27.6056492017663\n",
      "Progress: 48.05%\n",
      "36\n",
      "max difference =  10.150906562805176\n",
      "data at max difference =  3.144315719604492\n",
      "imputed at max difference =  13.295222282409668\n",
      "mae =  0.3311282992362976\n",
      "rmse =  7.052134638247283\n",
      "Progress: 48.14%\n",
      "37\n",
      "max difference =  13.54603385925293\n",
      "data at max difference =  3.3407578468322754\n",
      "imputed at max difference =  16.886791229248047\n",
      "mae =  0.4333827793598175\n",
      "rmse =  8.962351923403533\n",
      "Progress: 48.22%\n",
      "38\n",
      "max difference =  21.949277877807617\n",
      "data at max difference =  3.856018304824829\n",
      "imputed at max difference =  25.805295944213867\n",
      "mae =  0.8008076548576355\n",
      "rmse =  15.486740775730299\n",
      "Progress: 48.31%\n",
      "39\n",
      "max difference =  37.58404541015625\n",
      "data at max difference =  3.274808883666992\n",
      "imputed at max difference =  40.85885238647461\n",
      "mae =  1.2272285223007202\n",
      "rmse =  27.08477783203125\n",
      "Progress: 48.39%\n",
      "40\n",
      "max difference =  39.783607482910156\n",
      "data at max difference =  2.7489545345306396\n",
      "imputed at max difference =  42.532562255859375\n",
      "mae =  0.5941511988639832\n",
      "rmse =  18.626856264860734\n",
      "Progress: 48.47%\n",
      "41\n",
      "max difference =  16.71485137939453\n",
      "data at max difference =  2.1045942306518555\n",
      "imputed at max difference =  18.819446563720703\n",
      "mae =  0.41384780406951904\n",
      "rmse =  9.43487548828125\n",
      "Progress: 48.56%\n",
      "42\n",
      "max difference =  66.71238708496094\n",
      "data at max difference =  2.973641872406006\n",
      "imputed at max difference =  69.68602752685547\n",
      "mae =  0.739678680896759\n",
      "rmse =  30.433084239130437\n",
      "Progress: 48.64%\n",
      "43\n",
      "max difference =  23.36856460571289\n",
      "data at max difference =  3.4011125564575195\n",
      "imputed at max difference =  26.769678115844727\n",
      "mae =  0.39965546131134033\n",
      "rmse =  11.08380657693614\n",
      "Progress: 48.73%\n",
      "44\n",
      "max difference =  21.16228485107422\n",
      "data at max difference =  3.745873212814331\n",
      "imputed at max difference =  24.908157348632812\n",
      "mae =  0.3744659721851349\n",
      "rmse =  10.19770680303159\n",
      "Progress: 48.81%\n",
      "45\n",
      "max difference =  12.109647750854492\n",
      "data at max difference =  3.6255245208740234\n",
      "imputed at max difference =  15.735172271728516\n",
      "mae =  0.21687272191047668\n",
      "rmse =  5.649485049040421\n",
      "Progress: 48.90%\n",
      "46\n",
      "max difference =  56.26036834716797\n",
      "data at max difference =  4.283926486968994\n",
      "imputed at max difference =  60.54429626464844\n",
      "mae =  0.9603029489517212\n",
      "rmse =  28.766033670176633\n",
      "Progress: 48.98%\n",
      "47\n",
      "max difference =  2.0040695667266846\n",
      "data at max difference =  4.113564491271973\n",
      "imputed at max difference =  2.109494924545288\n",
      "mae =  0.09886205196380615\n",
      "rmse =  1.4099091239597488\n",
      "Progress: 49.07%\n",
      "48\n",
      "max difference =  38.807098388671875\n",
      "data at max difference =  3.996349573135376\n",
      "imputed at max difference =  42.80344772338867\n",
      "mae =  0.651610255241394\n",
      "rmse =  19.0852807086447\n",
      "Progress: 49.15%\n",
      "49\n",
      "max difference =  2.80607008934021\n",
      "data at max difference =  3.6701767444610596\n",
      "imputed at max difference =  6.4762468338012695\n",
      "mae =  0.0930076390504837\n",
      "rmse =  1.5132857612941575\n",
      "Progress: 49.24%\n",
      "50\n",
      "max difference =  100.51638793945312\n",
      "data at max difference =  4.167771816253662\n",
      "imputed at max difference =  104.68415832519531\n",
      "mae =  1.2718721628189087\n",
      "rmse =  46.83506177819293\n",
      "Progress: 49.32%\n",
      "51\n",
      "max difference =  103.89385986328125\n",
      "data at max difference =  3.903841972351074\n",
      "imputed at max difference =  107.79769897460938\n",
      "mae =  1.3614120483398438\n",
      "rmse =  49.07585343070652\n",
      "Progress: 49.41%\n",
      "52\n",
      "max difference =  2.7216920852661133\n",
      "data at max difference =  4.122889995574951\n",
      "imputed at max difference =  1.401197910308838\n",
      "mae =  0.07936995476484299\n",
      "rmse =  1.480398758597996\n",
      "Progress: 49.49%\n",
      "53\n",
      "max difference =  6.580904006958008\n",
      "data at max difference =  3.171074867248535\n",
      "imputed at max difference =  9.751978874206543\n",
      "mae =  0.14763855934143066\n",
      "rmse =  3.57196741518767\n",
      "Progress: 49.58%\n",
      "54\n",
      "max difference =  2.2375051975250244\n",
      "data at max difference =  3.8035402297973633\n",
      "imputed at max difference =  1.5660350322723389\n",
      "mae =  0.07506959140300751\n",
      "rmse =  1.4147486479386038\n",
      "Progress: 49.66%\n",
      "55\n",
      "max difference =  1.2649869918823242\n",
      "data at max difference =  3.894707679748535\n",
      "imputed at max difference =  5.159694671630859\n",
      "mae =  0.05571529269218445\n",
      "rmse =  0.852348576421323\n",
      "Progress: 49.75%\n",
      "56\n",
      "max difference =  15.992992401123047\n",
      "data at max difference =  3.957808017730713\n",
      "imputed at max difference =  19.9507999420166\n",
      "mae =  0.22422479093074799\n",
      "rmse =  7.412593675696331\n",
      "Progress: 49.83%\n",
      "57\n",
      "max difference =  14.19284725189209\n",
      "data at max difference =  4.061976432800293\n",
      "imputed at max difference =  18.254823684692383\n",
      "mae =  0.19587381184101105\n",
      "rmse =  6.5241871709408965\n",
      "Progress: 49.92%\n",
      "58\n",
      "max difference =  68.17818450927734\n",
      "data at max difference =  4.55797004699707\n",
      "imputed at max difference =  72.73615264892578\n",
      "mae =  2.2192447185516357\n",
      "rmse =  48.50827955163044\n",
      "Progress: 50.00%\n",
      "0\n",
      "max difference =  29.038719177246094\n",
      "data at max difference =  2.3850014209747314\n",
      "imputed at max difference =  31.423721313476562\n",
      "mae =  0.652836263179779\n",
      "rmse =  14.970715066661006\n",
      "Progress: 50.08%\n",
      "1\n",
      "max difference =  103.61150360107422\n",
      "data at max difference =  5.496946334838867\n",
      "imputed at max difference =  109.10845184326172\n",
      "mae =  1.8290146589279175\n",
      "rmse =  54.46550186820652\n",
      "Progress: 50.17%\n",
      "2\n",
      "max difference =  48.00264358520508\n",
      "data at max difference =  4.079436302185059\n",
      "imputed at max difference =  52.08208084106445\n",
      "mae =  1.2348679304122925\n",
      "rmse =  25.786095660665758\n",
      "Progress: 50.25%\n",
      "3\n",
      "max difference =  152.04623413085938\n",
      "data at max difference =  14.66715145111084\n",
      "imputed at max difference =  166.71337890625\n",
      "mae =  4.990711212158203\n",
      "rmse =  95.68464461616848\n",
      "Progress: 50.34%\n",
      "4\n",
      "max difference =  90.99198150634766\n",
      "data at max difference =  3.644343614578247\n",
      "imputed at max difference =  94.63632202148438\n",
      "mae =  5.181208610534668\n",
      "rmse =  80.73835555366847\n",
      "Progress: 50.42%\n",
      "5\n",
      "max difference =  127.07695770263672\n",
      "data at max difference =  5.54367733001709\n",
      "imputed at max difference =  132.62063598632812\n",
      "mae =  3.2956809997558594\n",
      "rmse =  70.38890540081522\n",
      "Progress: 50.51%\n",
      "6\n",
      "max difference =  91.69380187988281\n",
      "data at max difference =  4.360837459564209\n",
      "imputed at max difference =  96.05464172363281\n",
      "mae =  1.6679272651672363\n",
      "rmse =  44.010123874830164\n",
      "Progress: 50.59%\n",
      "7\n",
      "max difference =  81.11942291259766\n",
      "data at max difference =  3.7007248401641846\n",
      "imputed at max difference =  84.82014465332031\n",
      "mae =  2.087991237640381\n",
      "rmse =  45.69106126868206\n",
      "Progress: 50.68%\n",
      "8\n",
      "max difference =  32.04570007324219\n",
      "data at max difference =  2.2002665996551514\n",
      "imputed at max difference =  34.245967864990234\n",
      "mae =  0.9574517011642456\n",
      "rmse =  20.916876751443613\n",
      "Progress: 50.76%\n",
      "9\n",
      "max difference =  60.3632926940918\n",
      "data at max difference =  3.422072172164917\n",
      "imputed at max difference =  63.78536605834961\n",
      "mae =  0.7988049387931824\n",
      "rmse =  27.663250467051633\n",
      "Progress: 50.85%\n",
      "10\n",
      "max difference =  68.794677734375\n",
      "data at max difference =  3.435976505279541\n",
      "imputed at max difference =  72.23065185546875\n",
      "mae =  1.8683364391326904\n",
      "rmse =  40.53795855978261\n",
      "Progress: 50.93%\n",
      "11\n",
      "max difference =  40.926490783691406\n",
      "data at max difference =  3.4434592723846436\n",
      "imputed at max difference =  44.36994934082031\n",
      "mae =  0.9557191133499146\n",
      "rmse =  23.924043074898098\n",
      "Progress: 51.02%\n",
      "12\n",
      "max difference =  50.385189056396484\n",
      "data at max difference =  3.242663860321045\n",
      "imputed at max difference =  53.62785339355469\n",
      "mae =  0.8263278007507324\n",
      "rmse =  23.87902301290761\n",
      "Progress: 51.10%\n",
      "13\n",
      "max difference =  42.093902587890625\n",
      "data at max difference =  3.3944644927978516\n",
      "imputed at max difference =  45.48836898803711\n",
      "mae =  0.8530917763710022\n",
      "rmse =  23.902882451596465\n",
      "Progress: 51.19%\n",
      "14\n",
      "max difference =  37.49276351928711\n",
      "data at max difference =  4.049773693084717\n",
      "imputed at max difference =  41.542537689208984\n",
      "mae =  0.7248908281326294\n",
      "rmse =  20.486659837805707\n",
      "Progress: 51.27%\n",
      "15\n",
      "max difference =  30.571626663208008\n",
      "data at max difference =  3.5889499187469482\n",
      "imputed at max difference =  34.16057586669922\n",
      "mae =  0.5822150707244873\n",
      "rmse =  15.589502749235734\n",
      "Progress: 51.36%\n",
      "16\n",
      "max difference =  99.56436157226562\n",
      "data at max difference =  4.297800540924072\n",
      "imputed at max difference =  103.8621597290039\n",
      "mae =  2.1944491863250732\n",
      "rmse =  58.12193231997283\n",
      "Progress: 51.44%\n",
      "17\n",
      "max difference =  89.04983520507812\n",
      "data at max difference =  4.016514301300049\n",
      "imputed at max difference =  93.06635284423828\n",
      "mae =  1.0230010747909546\n",
      "rmse =  40.661613132642664\n",
      "Progress: 51.53%\n",
      "18\n",
      "max difference =  27.14103889465332\n",
      "data at max difference =  1.9070957899093628\n",
      "imputed at max difference =  29.048133850097656\n",
      "mae =  0.5285522937774658\n",
      "rmse =  13.814592444378397\n",
      "Progress: 51.61%\n",
      "19\n",
      "max difference =  38.113040924072266\n",
      "data at max difference =  3.2785933017730713\n",
      "imputed at max difference =  41.39163589477539\n",
      "mae =  0.658781886100769\n",
      "rmse =  18.98751167629076\n",
      "Progress: 51.69%\n",
      "20\n",
      "max difference =  61.73805618286133\n",
      "data at max difference =  3.1049461364746094\n",
      "imputed at max difference =  64.84300231933594\n",
      "mae =  1.5209920406341553\n",
      "rmse =  36.78529954993206\n",
      "Progress: 51.78%\n",
      "21\n",
      "max difference =  29.026994705200195\n",
      "data at max difference =  2.794804811477661\n",
      "imputed at max difference =  31.821800231933594\n",
      "mae =  0.5479671359062195\n",
      "rmse =  15.269291089928668\n",
      "Progress: 51.86%\n",
      "22\n",
      "max difference =  5.085992813110352\n",
      "data at max difference =  2.8592002391815186\n",
      "imputed at max difference =  7.945193290710449\n",
      "mae =  0.18260616064071655\n",
      "rmse =  3.0398125026537026\n",
      "Progress: 51.95%\n",
      "23\n",
      "max difference =  6.712778091430664\n",
      "data at max difference =  2.2658510208129883\n",
      "imputed at max difference =  8.978629112243652\n",
      "mae =  0.2191183865070343\n",
      "rmse =  4.02669790516729\n",
      "Progress: 52.03%\n",
      "24\n",
      "max difference =  6.359264373779297\n",
      "data at max difference =  2.5594370365142822\n",
      "imputed at max difference =  8.918701171875\n",
      "mae =  0.24468612670898438\n",
      "rmse =  4.198600105617357\n",
      "Progress: 52.12%\n",
      "25\n",
      "max difference =  35.904232025146484\n",
      "data at max difference =  3.438636064529419\n",
      "imputed at max difference =  39.34286880493164\n",
      "mae =  0.8254490494728088\n",
      "rmse =  19.27198725161345\n",
      "Progress: 52.20%\n",
      "26\n",
      "max difference =  135.84898376464844\n",
      "data at max difference =  3.4126079082489014\n",
      "imputed at max difference =  139.2615966796875\n",
      "mae =  1.700706124305725\n",
      "rmse =  62.372675356657616\n",
      "Progress: 52.29%\n",
      "27\n",
      "max difference =  80.11006927490234\n",
      "data at max difference =  3.5885987281799316\n",
      "imputed at max difference =  83.69866943359375\n",
      "mae =  1.1364315748214722\n",
      "rmse =  38.01570461107337\n",
      "Progress: 52.37%\n",
      "28\n",
      "max difference =  27.995281219482422\n",
      "data at max difference =  3.648150682449341\n",
      "imputed at max difference =  31.6434326171875\n",
      "mae =  0.8474255204200745\n",
      "rmse =  17.589141845703125\n",
      "Progress: 52.46%\n",
      "29\n",
      "max difference =  103.16162872314453\n",
      "data at max difference =  3.688014030456543\n",
      "imputed at max difference =  106.84963989257812\n",
      "mae =  1.4698433876037598\n",
      "rmse =  48.375191066576086\n",
      "Progress: 52.54%\n",
      "30\n",
      "max difference =  76.21932220458984\n",
      "data at max difference =  3.0069375038146973\n",
      "imputed at max difference =  79.22625732421875\n",
      "mae =  1.931555151939392\n",
      "rmse =  44.590056046195656\n",
      "Progress: 52.63%\n",
      "31\n",
      "max difference =  67.94422149658203\n",
      "data at max difference =  3.720954418182373\n",
      "imputed at max difference =  71.66517639160156\n",
      "mae =  1.3719428777694702\n",
      "rmse =  35.121497112771735\n",
      "Progress: 52.71%\n",
      "32\n",
      "max difference =  23.528160095214844\n",
      "data at max difference =  3.586270332336426\n",
      "imputed at max difference =  27.114431381225586\n",
      "mae =  0.48493635654449463\n",
      "rmse =  11.65972369650136\n",
      "Progress: 52.80%\n",
      "33\n",
      "max difference =  32.73239517211914\n",
      "data at max difference =  2.9661622047424316\n",
      "imputed at max difference =  35.69855880737305\n",
      "mae =  1.1715874671936035\n",
      "rmse =  23.95748237941576\n",
      "Progress: 52.88%\n",
      "34\n",
      "max difference =  78.75137329101562\n",
      "data at max difference =  2.333279848098755\n",
      "imputed at max difference =  81.08465576171875\n",
      "mae =  1.3361012935638428\n",
      "rmse =  39.01643172554348\n",
      "Progress: 52.97%\n",
      "35\n",
      "max difference =  15.012419700622559\n",
      "data at max difference =  3.6970813274383545\n",
      "imputed at max difference =  18.709501266479492\n",
      "mae =  0.5642369985580444\n",
      "rmse =  11.303323496942935\n",
      "Progress: 53.05%\n",
      "36\n",
      "max difference =  79.13677215576172\n",
      "data at max difference =  3.024057149887085\n",
      "imputed at max difference =  82.16082763671875\n",
      "mae =  1.3471295833587646\n",
      "rmse =  37.98660411005435\n",
      "Progress: 53.14%\n",
      "37\n",
      "max difference =  18.30225372314453\n",
      "data at max difference =  3.746554136276245\n",
      "imputed at max difference =  22.04880714416504\n",
      "mae =  0.696226179599762\n",
      "rmse =  13.581420898437498\n",
      "Progress: 53.22%\n",
      "38\n",
      "max difference =  45.204429626464844\n",
      "data at max difference =  3.7342121601104736\n",
      "imputed at max difference =  48.93864059448242\n",
      "mae =  0.6229230165481567\n",
      "rmse =  20.88440870202106\n",
      "Progress: 53.31%\n",
      "39\n",
      "max difference =  48.172630310058594\n",
      "data at max difference =  2.3955178260803223\n",
      "imputed at max difference =  50.56814956665039\n",
      "mae =  1.009401559829712\n",
      "rmse =  27.103865913722824\n",
      "Progress: 53.39%\n",
      "40\n",
      "max difference =  15.949481964111328\n",
      "data at max difference =  2.279470682144165\n",
      "imputed at max difference =  18.228952407836914\n",
      "mae =  0.28043535351753235\n",
      "rmse =  7.5032441512398105\n",
      "Progress: 53.47%\n",
      "41\n",
      "max difference =  74.38304138183594\n",
      "data at max difference =  2.1835086345672607\n",
      "imputed at max difference =  76.5665512084961\n",
      "mae =  1.277176022529602\n",
      "rmse =  36.591982634171195\n",
      "Progress: 53.56%\n",
      "42\n",
      "max difference =  11.258377075195312\n",
      "data at max difference =  1.7637147903442383\n",
      "imputed at max difference =  13.02209186553955\n",
      "mae =  0.19743426144123077\n",
      "rmse =  5.247733074685802\n",
      "Progress: 53.64%\n",
      "43\n",
      "max difference =  53.951541900634766\n",
      "data at max difference =  3.4011125564575195\n",
      "imputed at max difference =  57.35265350341797\n",
      "mae =  0.7784011960029602\n",
      "rmse =  25.636233122452445\n",
      "Progress: 53.73%\n",
      "44\n",
      "max difference =  17.99199104309082\n",
      "data at max difference =  3.488417148590088\n",
      "imputed at max difference =  21.48040771484375\n",
      "mae =  0.3000541925430298\n",
      "rmse =  8.438448035198709\n",
      "Progress: 53.81%\n",
      "45\n",
      "max difference =  12.082502365112305\n",
      "data at max difference =  3.8894925117492676\n",
      "imputed at max difference =  15.97199535369873\n",
      "mae =  0.22151130437850952\n",
      "rmse =  5.7863066300101895\n",
      "Progress: 53.90%\n",
      "46\n",
      "max difference =  1.9000556468963623\n",
      "data at max difference =  4.283926486968994\n",
      "imputed at max difference =  2.383870840072632\n",
      "mae =  0.09236422181129456\n",
      "rmse =  1.21869418932044\n",
      "Progress: 53.98%\n",
      "47\n",
      "max difference =  1.8166394233703613\n",
      "data at max difference =  4.468069553375244\n",
      "imputed at max difference =  2.651430130004883\n",
      "mae =  0.10468605160713196\n",
      "rmse =  1.3927446448284646\n",
      "Progress: 54.07%\n",
      "48\n",
      "max difference =  3.520021915435791\n",
      "data at max difference =  4.654101848602295\n",
      "imputed at max difference =  8.174123764038086\n",
      "mae =  0.1285357028245926\n",
      "rmse =  2.143255482549253\n",
      "Progress: 54.15%\n",
      "49\n",
      "max difference =  1.7664563655853271\n",
      "data at max difference =  4.354440212249756\n",
      "imputed at max difference =  2.5879838466644287\n",
      "mae =  0.09482475370168686\n",
      "rmse =  1.3963787244713823\n",
      "Progress: 54.24%\n",
      "50\n",
      "max difference =  14.868724822998047\n",
      "data at max difference =  4.473196029663086\n",
      "imputed at max difference =  19.341920852661133\n",
      "mae =  0.19594533741474152\n",
      "rmse =  6.82544409710428\n",
      "Progress: 54.32%\n",
      "51\n",
      "max difference =  19.63136100769043\n",
      "data at max difference =  5.0189433097839355\n",
      "imputed at max difference =  24.650304794311523\n",
      "mae =  0.37080320715904236\n",
      "rmse =  10.747142625891644\n",
      "Progress: 54.41%\n",
      "52\n",
      "max difference =  36.093833923339844\n",
      "data at max difference =  3.1322391033172607\n",
      "imputed at max difference =  39.22607421875\n",
      "mae =  0.4257358908653259\n",
      "rmse =  16.494195025900137\n",
      "Progress: 54.49%\n",
      "53\n",
      "max difference =  4.464646339416504\n",
      "data at max difference =  3.512697458267212\n",
      "imputed at max difference =  7.977344036102295\n",
      "mae =  0.1131620928645134\n",
      "rmse =  2.706226514733356\n",
      "Progress: 54.58%\n",
      "54\n",
      "max difference =  38.52960968017578\n",
      "data at max difference =  3.536703109741211\n",
      "imputed at max difference =  42.066314697265625\n",
      "mae =  0.4831407070159912\n",
      "rmse =  17.77747510827106\n",
      "Progress: 54.66%\n",
      "55\n",
      "max difference =  53.97060775756836\n",
      "data at max difference =  3.2829904556274414\n",
      "imputed at max difference =  57.253597259521484\n",
      "mae =  0.8111156821250916\n",
      "rmse =  26.539847995923914\n",
      "Progress: 54.75%\n",
      "56\n",
      "max difference =  9.231863975524902\n",
      "data at max difference =  3.0583953857421875\n",
      "imputed at max difference =  12.29025936126709\n",
      "mae =  0.2115003913640976\n",
      "rmse =  5.151669709578805\n",
      "Progress: 54.83%\n",
      "57\n",
      "max difference =  14.389252662658691\n",
      "data at max difference =  4.061976432800293\n",
      "imputed at max difference =  18.451229095458984\n",
      "mae =  0.3008517622947693\n",
      "rmse =  8.065164980681045\n",
      "Progress: 54.92%\n",
      "58\n",
      "max difference =  28.973804473876953\n",
      "data at max difference =  2.503105878829956\n",
      "imputed at max difference =  31.476909637451172\n",
      "mae =  0.7772080898284912\n",
      "rmse =  18.016754150390625\n",
      "Progress: 55.00%\n",
      "0\n",
      "max difference =  33.371788024902344\n",
      "data at max difference =  4.60740852355957\n",
      "imputed at max difference =  37.97919845581055\n",
      "mae =  0.5826108455657959\n",
      "rmse =  15.630762514860733\n",
      "Progress: 55.08%\n",
      "1\n",
      "max difference =  13.127487182617188\n",
      "data at max difference =  3.252281427383423\n",
      "imputed at max difference =  16.37976837158203\n",
      "mae =  0.4950702488422394\n",
      "rmse =  8.84372213612432\n",
      "Progress: 55.17%\n",
      "2\n",
      "max difference =  12.49531364440918\n",
      "data at max difference =  5.049139499664307\n",
      "imputed at max difference =  17.544452667236328\n",
      "mae =  0.5838286280632019\n",
      "rmse =  8.15841940174932\n",
      "Progress: 55.25%\n",
      "3\n",
      "max difference =  115.69711303710938\n",
      "data at max difference =  1.3048335313796997\n",
      "imputed at max difference =  117.00194549560547\n",
      "mae =  4.485864162445068\n",
      "rmse =  78.7177044412364\n",
      "Progress: 55.34%\n",
      "4\n",
      "max difference =  77.01068878173828\n",
      "data at max difference =  1.5234109163284302\n",
      "imputed at max difference =  78.53410339355469\n",
      "mae =  3.061250925064087\n",
      "rmse =  54.53928010360054\n",
      "Progress: 55.42%\n",
      "5\n",
      "max difference =  92.05125427246094\n",
      "data at max difference =  15.96798324584961\n",
      "imputed at max difference =  108.01924133300781\n",
      "mae =  2.1496191024780273\n",
      "rmse =  46.21701978600544\n",
      "Progress: 55.51%\n",
      "6\n",
      "max difference =  27.05963897705078\n",
      "data at max difference =  4.360837459564209\n",
      "imputed at max difference =  31.42047691345215\n",
      "mae =  1.0430457592010498\n",
      "rmse =  17.699456256368887\n",
      "Progress: 55.59%\n",
      "7\n",
      "max difference =  93.28253936767578\n",
      "data at max difference =  2.517953634262085\n",
      "imputed at max difference =  95.80049133300781\n",
      "mae =  1.670609951019287\n",
      "rmse =  44.71700386379076\n",
      "Progress: 55.68%\n",
      "8\n",
      "max difference =  131.59889221191406\n",
      "data at max difference =  3.891376495361328\n",
      "imputed at max difference =  135.49026489257812\n",
      "mae =  2.4040591716766357\n",
      "rmse =  63.912417204483695\n",
      "Progress: 55.76%\n",
      "9\n",
      "max difference =  61.786155700683594\n",
      "data at max difference =  2.8465027809143066\n",
      "imputed at max difference =  64.63265991210938\n",
      "mae =  1.3520312309265137\n",
      "rmse =  33.30410368546195\n",
      "Progress: 55.85%\n",
      "10\n",
      "max difference =  114.43213653564453\n",
      "data at max difference =  3.747382640838623\n",
      "imputed at max difference =  118.17951965332031\n",
      "mae =  1.6426527500152588\n",
      "rmse =  53.434867527173914\n",
      "Progress: 55.93%\n",
      "11\n",
      "max difference =  17.06734275817871\n",
      "data at max difference =  2.8884100914001465\n",
      "imputed at max difference =  19.955753326416016\n",
      "mae =  0.5304165482521057\n",
      "rmse =  11.22158548106318\n",
      "Progress: 56.02%\n",
      "12\n",
      "max difference =  76.2723159790039\n",
      "data at max difference =  2.9304683208465576\n",
      "imputed at max difference =  79.2027816772461\n",
      "mae =  1.5351829528808594\n",
      "rmse =  45.26681916610054\n",
      "Progress: 56.10%\n",
      "13\n",
      "max difference =  34.98242950439453\n",
      "data at max difference =  3.6411452293395996\n",
      "imputed at max difference =  38.623573303222656\n",
      "mae =  0.7079794406890869\n",
      "rmse =  18.34762307871943\n",
      "Progress: 56.19%\n",
      "14\n",
      "max difference =  176.2666015625\n",
      "data at max difference =  3.136535882949829\n",
      "imputed at max difference =  179.40313720703125\n",
      "mae =  2.1209726333618164\n",
      "rmse =  81.022216796875\n",
      "Progress: 56.27%\n",
      "15\n",
      "max difference =  86.64708709716797\n",
      "data at max difference =  3.25317645072937\n",
      "imputed at max difference =  89.90026092529297\n",
      "mae =  1.5254772901535034\n",
      "rmse =  46.037167756453805\n",
      "Progress: 56.36%\n",
      "16\n",
      "max difference =  69.51895904541016\n",
      "data at max difference =  3.9510416984558105\n",
      "imputed at max difference =  73.47000122070312\n",
      "mae =  1.2572952508926392\n",
      "rmse =  37.624259617017664\n",
      "Progress: 56.44%\n",
      "17\n",
      "max difference =  20.580692291259766\n",
      "data at max difference =  4.372129440307617\n",
      "imputed at max difference =  24.952821731567383\n",
      "mae =  0.4172884225845337\n",
      "rmse =  10.384129399838656\n",
      "Progress: 56.53%\n",
      "18\n",
      "max difference =  53.1676139831543\n",
      "data at max difference =  2.734581470489502\n",
      "imputed at max difference =  55.90219497680664\n",
      "mae =  1.12997567653656\n",
      "rmse =  33.659065578294836\n",
      "Progress: 56.61%\n",
      "19\n",
      "max difference =  48.07889175415039\n",
      "data at max difference =  3.2785933017730713\n",
      "imputed at max difference =  51.357486724853516\n",
      "mae =  0.5962117314338684\n",
      "rmse =  22.037959886633832\n",
      "Progress: 56.69%\n",
      "20\n",
      "max difference =  40.285614013671875\n",
      "data at max difference =  3.3378450870513916\n",
      "imputed at max difference =  43.62345886230469\n",
      "mae =  0.8662295937538147\n",
      "rmse =  22.14636761209239\n",
      "Progress: 56.78%\n",
      "21\n",
      "max difference =  90.52517700195312\n",
      "data at max difference =  3.636632204055786\n",
      "imputed at max difference =  94.16181182861328\n",
      "mae =  1.0902291536331177\n",
      "rmse =  41.48111890709919\n",
      "Progress: 56.86%\n",
      "22\n",
      "max difference =  53.675411224365234\n",
      "data at max difference =  3.7011895179748535\n",
      "imputed at max difference =  57.37660217285156\n",
      "mae =  0.8978923559188843\n",
      "rmse =  27.160142981487773\n",
      "Progress: 56.95%\n",
      "23\n",
      "max difference =  47.30611801147461\n",
      "data at max difference =  3.0022151470184326\n",
      "imputed at max difference =  50.30833435058594\n",
      "mae =  0.7111405730247498\n",
      "rmse =  22.57433551290761\n",
      "Progress: 57.03%\n",
      "24\n",
      "max difference =  17.628767013549805\n",
      "data at max difference =  3.0082943439483643\n",
      "imputed at max difference =  20.637062072753906\n",
      "mae =  0.6158574819564819\n",
      "rmse =  13.06094094981318\n",
      "Progress: 57.12%\n",
      "25\n",
      "max difference =  51.208744049072266\n",
      "data at max difference =  3.3274190425872803\n",
      "imputed at max difference =  54.536163330078125\n",
      "mae =  1.721519112586975\n",
      "rmse =  34.41976265285326\n",
      "Progress: 57.20%\n",
      "26\n",
      "max difference =  36.948848724365234\n",
      "data at max difference =  2.4062821865081787\n",
      "imputed at max difference =  39.35512924194336\n",
      "mae =  1.0361160039901733\n",
      "rmse =  23.893846594769023\n",
      "Progress: 57.29%\n",
      "27\n",
      "max difference =  83.43882751464844\n",
      "data at max difference =  2.911207675933838\n",
      "imputed at max difference =  86.35003662109375\n",
      "mae =  1.4217537641525269\n",
      "rmse =  40.72340990149457\n",
      "Progress: 57.37%\n",
      "28\n",
      "max difference =  135.8084259033203\n",
      "data at max difference =  3.075853109359741\n",
      "imputed at max difference =  138.88427734375\n",
      "mae =  1.9043195247650146\n",
      "rmse =  63.660320779551625\n",
      "Progress: 57.46%\n",
      "29\n",
      "max difference =  61.376956939697266\n",
      "data at max difference =  3.091815233230591\n",
      "imputed at max difference =  64.4687728881836\n",
      "mae =  0.8243476748466492\n",
      "rmse =  28.302163828974187\n",
      "Progress: 57.54%\n",
      "30\n",
      "max difference =  38.02635192871094\n",
      "data at max difference =  3.1269123554229736\n",
      "imputed at max difference =  41.153263092041016\n",
      "mae =  0.8457239270210266\n",
      "rmse =  24.34310249660326\n",
      "Progress: 57.63%\n",
      "31\n",
      "max difference =  66.9214859008789\n",
      "data at max difference =  3.0085790157318115\n",
      "imputed at max difference =  69.93006134033203\n",
      "mae =  1.1741955280303955\n",
      "rmse =  32.93951416015625\n",
      "Progress: 57.71%\n",
      "32\n",
      "max difference =  16.47772979736328\n",
      "data at max difference =  3.129429817199707\n",
      "imputed at max difference =  19.607158660888672\n",
      "mae =  0.3176378905773163\n",
      "rmse =  8.272249304729959\n",
      "Progress: 57.80%\n",
      "33\n",
      "max difference =  41.00148391723633\n",
      "data at max difference =  2.9661622047424316\n",
      "imputed at max difference =  43.967647552490234\n",
      "mae =  0.6265739798545837\n",
      "rmse =  19.31778750212296\n",
      "Progress: 57.88%\n",
      "34\n",
      "max difference =  52.68644714355469\n",
      "data at max difference =  2.986680746078491\n",
      "imputed at max difference =  55.673126220703125\n",
      "mae =  1.4337291717529297\n",
      "rmse =  34.193401834239125\n",
      "Progress: 57.97%\n",
      "35\n",
      "max difference =  38.33821487426758\n",
      "data at max difference =  3.109546422958374\n",
      "imputed at max difference =  41.44776153564453\n",
      "mae =  0.6291066408157349\n",
      "rmse =  19.115124246348504\n",
      "Progress: 58.05%\n",
      "36\n",
      "max difference =  42.52055740356445\n",
      "data at max difference =  3.7332305908203125\n",
      "imputed at max difference =  46.253787994384766\n",
      "mae =  1.138228416442871\n",
      "rmse =  27.190201469089676\n",
      "Progress: 58.14%\n",
      "37\n",
      "max difference =  188.70809936523438\n",
      "data at max difference =  3.625164747238159\n",
      "imputed at max difference =  192.33326721191406\n",
      "mae =  2.37713623046875\n",
      "rmse =  87.2980373216712\n",
      "Progress: 58.22%\n",
      "38\n",
      "max difference =  20.81212615966797\n",
      "data at max difference =  3.13771915435791\n",
      "imputed at max difference =  23.949844360351562\n",
      "mae =  0.3481292724609375\n",
      "rmse =  10.083147795304008\n",
      "Progress: 58.31%\n",
      "39\n",
      "max difference =  64.2134017944336\n",
      "data at max difference =  3.023979425430298\n",
      "imputed at max difference =  67.23738098144531\n",
      "mae =  1.5406173467636108\n",
      "rmse =  36.628059718919836\n",
      "Progress: 58.39%\n",
      "40\n",
      "max difference =  83.19261932373047\n",
      "data at max difference =  2.3753409385681152\n",
      "imputed at max difference =  85.56796264648438\n",
      "mae =  0.9519523978233337\n",
      "rmse =  38.01956840183424\n",
      "Progress: 58.47%\n",
      "41\n",
      "max difference =  20.058727264404297\n",
      "data at max difference =  3.2627665996551514\n",
      "imputed at max difference =  23.32149314880371\n",
      "mae =  0.5691608190536499\n",
      "rmse =  11.992750084918478\n",
      "Progress: 58.56%\n",
      "42\n",
      "max difference =  4.247204780578613\n",
      "data at max difference =  2.1207797527313232\n",
      "imputed at max difference =  6.367984294891357\n",
      "mae =  0.14732389152050018\n",
      "rmse =  2.4029310475225034\n",
      "Progress: 58.64%\n",
      "43\n",
      "max difference =  15.677894592285156\n",
      "data at max difference =  2.0938096046447754\n",
      "imputed at max difference =  17.771703720092773\n",
      "mae =  0.27611997723579407\n",
      "rmse =  7.388825126316237\n",
      "Progress: 58.73%\n",
      "44\n",
      "max difference =  14.902572631835938\n",
      "data at max difference =  3.488417148590088\n",
      "imputed at max difference =  18.390989303588867\n",
      "mae =  0.2309243530035019\n",
      "rmse =  6.900914067807405\n",
      "Progress: 58.81%\n",
      "45\n",
      "max difference =  36.0552864074707\n",
      "data at max difference =  3.8894925117492676\n",
      "imputed at max difference =  39.94477844238281\n",
      "mae =  0.8785865306854248\n",
      "rmse =  22.19597327190897\n",
      "Progress: 58.90%\n",
      "46\n",
      "max difference =  10.758183479309082\n",
      "data at max difference =  3.3105075359344482\n",
      "imputed at max difference =  14.06869125366211\n",
      "mae =  0.25515928864479065\n",
      "rmse =  5.757194850755774\n",
      "Progress: 58.98%\n",
      "47\n",
      "max difference =  9.294702529907227\n",
      "data at max difference =  4.113564491271973\n",
      "imputed at max difference =  13.4082670211792\n",
      "mae =  0.2407374083995819\n",
      "rmse =  5.224789826766305\n",
      "Progress: 59.07%\n",
      "48\n",
      "max difference =  4.147122383117676\n",
      "data at max difference =  3.996349573135376\n",
      "imputed at max difference =  8.143471717834473\n",
      "mae =  0.14104901254177094\n",
      "rmse =  2.5330707715905234\n",
      "Progress: 59.15%\n",
      "49\n",
      "max difference =  2.2991600036621094\n",
      "data at max difference =  4.738558769226074\n",
      "imputed at max difference =  7.037718772888184\n",
      "mae =  0.09059733897447586\n",
      "rmse =  1.3773110431173574\n",
      "Progress: 59.24%\n",
      "50\n",
      "max difference =  2.732279062271118\n",
      "data at max difference =  4.864070892333984\n",
      "imputed at max difference =  2.131791830062866\n",
      "mae =  0.07700638473033905\n",
      "rmse =  1.4464141182277515\n",
      "Progress: 59.32%\n",
      "51\n",
      "max difference =  23.90379524230957\n",
      "data at max difference =  5.0189433097839355\n",
      "imputed at max difference =  28.922739028930664\n",
      "mae =  0.3050413727760315\n",
      "rmse =  10.96482517408288\n",
      "Progress: 59.41%\n",
      "52\n",
      "max difference =  7.253477096557617\n",
      "data at max difference =  3.1322391033172607\n",
      "imputed at max difference =  10.385716438293457\n",
      "mae =  0.11262961477041245\n",
      "rmse =  3.355300903320312\n",
      "Progress: 59.49%\n",
      "53\n",
      "max difference =  20.253923416137695\n",
      "data at max difference =  4.1212592124938965\n",
      "imputed at max difference =  24.37518310546875\n",
      "mae =  0.24553582072257996\n",
      "rmse =  9.266251937202785\n",
      "Progress: 59.58%\n",
      "54\n",
      "max difference =  33.855384826660156\n",
      "data at max difference =  3.1952109336853027\n",
      "imputed at max difference =  37.050594329833984\n",
      "mae =  0.48030203580856323\n",
      "rmse =  15.94617097274117\n",
      "Progress: 59.66%\n",
      "55\n",
      "max difference =  5.552301406860352\n",
      "data at max difference =  3.894707679748535\n",
      "imputed at max difference =  9.447009086608887\n",
      "mae =  0.13144083321094513\n",
      "rmse =  3.038232554560122\n",
      "Progress: 59.75%\n",
      "56\n",
      "max difference =  52.593101501464844\n",
      "data at max difference =  3.634439468383789\n",
      "imputed at max difference =  56.227542877197266\n",
      "mae =  0.7930569052696228\n",
      "rmse =  25.66993514351223\n",
      "Progress: 59.83%\n",
      "57\n",
      "max difference =  10.374683380126953\n",
      "data at max difference =  4.061976432800293\n",
      "imputed at max difference =  14.436659812927246\n",
      "mae =  0.2094937264919281\n",
      "rmse =  5.644804581351901\n",
      "Progress: 59.92%\n",
      "58\n",
      "max difference =  10.000228881835938\n",
      "data at max difference =  3.1417088508605957\n",
      "imputed at max difference =  13.141937255859375\n",
      "mae =  0.33441513776779175\n",
      "rmse =  5.631204356317935\n",
      "Progress: 60.00%\n",
      "0\n",
      "max difference =  177.69021606445312\n",
      "data at max difference =  4.60740852355957\n",
      "imputed at max difference =  182.29762268066406\n",
      "mae =  2.0029802322387695\n",
      "rmse =  81.10098930027175\n",
      "Progress: 60.08%\n",
      "1\n",
      "max difference =  14.680957794189453\n",
      "data at max difference =  3.252281427383423\n",
      "imputed at max difference =  17.933238983154297\n",
      "mae =  0.46273329854011536\n",
      "rmse =  8.186215608016305\n",
      "Progress: 60.17%\n",
      "2\n",
      "max difference =  69.27632141113281\n",
      "data at max difference =  5.78329610824585\n",
      "imputed at max difference =  75.05961608886719\n",
      "mae =  1.843827724456787\n",
      "rmse =  44.27970819887908\n",
      "Progress: 60.25%\n",
      "3\n",
      "max difference =  92.3917465209961\n",
      "data at max difference =  3.0506722927093506\n",
      "imputed at max difference =  95.44242095947266\n",
      "mae =  4.538578510284424\n",
      "rmse =  80.6346966287364\n",
      "Progress: 60.34%\n",
      "4\n",
      "max difference =  42.135284423828125\n",
      "data at max difference =  13.173881530761719\n",
      "imputed at max difference =  55.309165954589844\n",
      "mae =  1.5970959663391113\n",
      "rmse =  27.045349121093746\n",
      "Progress: 60.42%\n",
      "5\n",
      "max difference =  106.15641021728516\n",
      "data at max difference =  1.715961217880249\n",
      "imputed at max difference =  107.87236785888672\n",
      "mae =  3.109337091445923\n",
      "rmse =  62.151282269021735\n",
      "Progress: 60.51%\n",
      "6\n",
      "max difference =  92.5828857421875\n",
      "data at max difference =  5.106971740722656\n",
      "imputed at max difference =  97.68985748291016\n",
      "mae =  2.713529109954834\n",
      "rmse =  60.48085088315217\n",
      "Progress: 60.59%\n",
      "7\n",
      "max difference =  50.41843795776367\n",
      "data at max difference =  1.7896761894226074\n",
      "imputed at max difference =  52.20811462402344\n",
      "mae =  0.9965730905532837\n",
      "rmse =  24.359117590862773\n",
      "Progress: 60.68%\n",
      "8\n",
      "max difference =  37.27204132080078\n",
      "data at max difference =  2.2317087650299072\n",
      "imputed at max difference =  39.50374984741211\n",
      "mae =  1.1800267696380615\n",
      "rmse =  25.614523182744563\n",
      "Progress: 60.76%\n",
      "9\n",
      "max difference =  58.54124069213867\n",
      "data at max difference =  3.422072172164917\n",
      "imputed at max difference =  61.963314056396484\n",
      "mae =  1.3526592254638672\n",
      "rmse =  32.351310398267664\n",
      "Progress: 60.85%\n",
      "10\n",
      "max difference =  55.98760223388672\n",
      "data at max difference =  3.435976505279541\n",
      "imputed at max difference =  59.423580169677734\n",
      "mae =  1.081515908241272\n",
      "rmse =  28.580890157948367\n",
      "Progress: 60.93%\n",
      "11\n",
      "max difference =  62.995052337646484\n",
      "data at max difference =  3.1999928951263428\n",
      "imputed at max difference =  66.1950454711914\n",
      "mae =  1.2472137212753296\n",
      "rmse =  31.930260699728265\n",
      "Progress: 61.02%\n",
      "12\n",
      "max difference =  34.93679428100586\n",
      "data at max difference =  2.9304683208465576\n",
      "imputed at max difference =  37.86726379394531\n",
      "mae =  0.542833685874939\n",
      "rmse =  16.258121656334918\n",
      "Progress: 61.10%\n",
      "13\n",
      "max difference =  59.3504524230957\n",
      "data at max difference =  3.6411452293395996\n",
      "imputed at max difference =  62.99159622192383\n",
      "mae =  1.2968610525131226\n",
      "rmse =  34.72438115658967\n",
      "Progress: 61.19%\n",
      "14\n",
      "max difference =  78.74063873291016\n",
      "data at max difference =  3.7214345932006836\n",
      "imputed at max difference =  82.46207427978516\n",
      "mae =  1.0434095859527588\n",
      "rmse =  36.388430388077445\n",
      "Progress: 61.27%\n",
      "15\n",
      "max difference =  34.34480285644531\n",
      "data at max difference =  3.25317645072937\n",
      "imputed at max difference =  37.59798049926758\n",
      "mae =  0.9073750972747803\n",
      "rmse =  21.280946151069973\n",
      "Progress: 61.36%\n",
      "16\n",
      "max difference =  38.190486907958984\n",
      "data at max difference =  3.9510416984558105\n",
      "imputed at max difference =  42.14152908325195\n",
      "mae =  0.7283722758293152\n",
      "rmse =  19.086447010869563\n",
      "Progress: 61.44%\n",
      "17\n",
      "max difference =  22.036943435668945\n",
      "data at max difference =  4.016514301300049\n",
      "imputed at max difference =  26.053457260131836\n",
      "mae =  0.3573058545589447\n",
      "rmse =  10.30371491805367\n",
      "Progress: 61.53%\n",
      "18\n",
      "max difference =  16.562931060791016\n",
      "data at max difference =  3.2883851528167725\n",
      "imputed at max difference =  19.851316452026367\n",
      "mae =  0.5152368545532227\n",
      "rmse =  11.108057436735734\n",
      "Progress: 61.61%\n",
      "19\n",
      "max difference =  21.348709106445312\n",
      "data at max difference =  2.7446513175964355\n",
      "imputed at max difference =  24.093360900878906\n",
      "mae =  0.5019611120223999\n",
      "rmse =  12.320508873980978\n",
      "Progress: 61.69%\n",
      "20\n",
      "max difference =  22.865127563476562\n",
      "data at max difference =  3.1049461364746094\n",
      "imputed at max difference =  25.970073699951172\n",
      "mae =  0.604894757270813\n",
      "rmse =  15.024654222571332\n",
      "Progress: 61.78%\n",
      "21\n",
      "max difference =  19.241100311279297\n",
      "data at max difference =  3.0974695682525635\n",
      "imputed at max difference =  22.33856964111328\n",
      "mae =  0.36924421787261963\n",
      "rmse =  9.837591420049254\n",
      "Progress: 61.86%\n",
      "22\n",
      "max difference =  10.421449661254883\n",
      "data at max difference =  3.3984665870666504\n",
      "imputed at max difference =  13.819916725158691\n",
      "mae =  0.3146098554134369\n",
      "rmse =  6.895328687584919\n",
      "Progress: 61.95%\n",
      "23\n",
      "max difference =  62.44730758666992\n",
      "data at max difference =  2.2658510208129883\n",
      "imputed at max difference =  64.7131576538086\n",
      "mae =  1.4845489263534546\n",
      "rmse =  39.25263512652853\n",
      "Progress: 62.03%\n",
      "24\n",
      "max difference =  10.378179550170898\n",
      "data at max difference =  2.5594370365142822\n",
      "imputed at max difference =  12.937616348266602\n",
      "mae =  0.29899418354034424\n",
      "rmse =  6.658500339673913\n",
      "Progress: 62.12%\n",
      "25\n",
      "max difference =  31.12343978881836\n",
      "data at max difference =  3.007465124130249\n",
      "imputed at max difference =  34.13090515136719\n",
      "mae =  1.45759916305542\n",
      "rmse =  28.48849885360054\n",
      "Progress: 62.20%\n",
      "26\n",
      "max difference =  58.293373107910156\n",
      "data at max difference =  3.524782419204712\n",
      "imputed at max difference =  61.81815719604492\n",
      "mae =  1.3243849277496338\n",
      "rmse =  34.91645348590353\n",
      "Progress: 62.29%\n",
      "27\n",
      "max difference =  77.08535766601562\n",
      "data at max difference =  2.978973388671875\n",
      "imputed at max difference =  80.0643310546875\n",
      "mae =  1.099043607711792\n",
      "rmse =  36.26932426120924\n",
      "Progress: 62.37%\n",
      "28\n",
      "max difference =  88.78002166748047\n",
      "data at max difference =  3.075853109359741\n",
      "imputed at max difference =  91.85587310791016\n",
      "mae =  2.176722764968872\n",
      "rmse =  50.152280061141305\n",
      "Progress: 62.46%\n",
      "29\n",
      "max difference =  58.38665008544922\n",
      "data at max difference =  3.5692858695983887\n",
      "imputed at max difference =  61.955936431884766\n",
      "mae =  1.2395216226577759\n",
      "rmse =  31.92717179008152\n",
      "Progress: 62.54%\n",
      "30\n",
      "max difference =  46.146846771240234\n",
      "data at max difference =  3.594463348388672\n",
      "imputed at max difference =  49.741310119628906\n",
      "mae =  0.7262189388275146\n",
      "rmse =  21.785173499065895\n",
      "Progress: 62.63%\n",
      "31\n",
      "max difference =  63.950096130371094\n",
      "data at max difference =  3.129380702972412\n",
      "imputed at max difference =  67.07947540283203\n",
      "mae =  1.6113195419311523\n",
      "rmse =  37.49004065472147\n",
      "Progress: 62.71%\n",
      "32\n",
      "max difference =  162.79298400878906\n",
      "data at max difference =  3.0122029781341553\n",
      "imputed at max difference =  165.80519104003906\n",
      "mae =  1.9476451873779297\n",
      "rmse =  74.71812372622283\n",
      "Progress: 62.80%\n",
      "33\n",
      "max difference =  57.14231872558594\n",
      "data at max difference =  3.5381031036376953\n",
      "imputed at max difference =  60.680423736572266\n",
      "mae =  1.3832240104675293\n",
      "rmse =  32.1444436778193\n",
      "Progress: 62.88%\n",
      "34\n",
      "max difference =  104.4388656616211\n",
      "data at max difference =  2.769944906234741\n",
      "imputed at max difference =  107.20880889892578\n",
      "mae =  1.4493649005889893\n",
      "rmse =  48.64772100033967\n",
      "Progress: 62.97%\n",
      "35\n",
      "max difference =  83.59849548339844\n",
      "data at max difference =  3.6970813274383545\n",
      "imputed at max difference =  87.29557800292969\n",
      "mae =  1.185752034187317\n",
      "rmse =  38.8921774159307\n",
      "Progress: 63.05%\n",
      "36\n",
      "max difference =  19.019554138183594\n",
      "data at max difference =  3.6129720211029053\n",
      "imputed at max difference =  22.632526397705078\n",
      "mae =  0.43829625844955444\n",
      "rmse =  11.207542087720789\n",
      "Progress: 63.14%\n",
      "37\n",
      "max difference =  25.662166595458984\n",
      "data at max difference =  3.746554136276245\n",
      "imputed at max difference =  29.408720016479492\n",
      "mae =  0.37223994731903076\n",
      "rmse =  11.83829000721807\n",
      "Progress: 63.22%\n",
      "38\n",
      "max difference =  61.420936584472656\n",
      "data at max difference =  3.856018304824829\n",
      "imputed at max difference =  65.2769546508789\n",
      "mae =  0.8510857224464417\n",
      "rmse =  28.529875382133152\n",
      "Progress: 63.31%\n",
      "39\n",
      "max difference =  16.735082626342773\n",
      "data at max difference =  2.502089738845825\n",
      "imputed at max difference =  19.237173080444336\n",
      "mae =  0.5268893837928772\n",
      "rmse =  11.344264818274457\n",
      "Progress: 63.39%\n",
      "40\n",
      "max difference =  45.150596618652344\n",
      "data at max difference =  2.279470682144165\n",
      "imputed at max difference =  47.43006896972656\n",
      "mae =  0.8221509456634521\n",
      "rmse =  22.18412581734035\n",
      "Progress: 63.47%\n",
      "41\n",
      "max difference =  17.616525650024414\n",
      "data at max difference =  2.1835086345672607\n",
      "imputed at max difference =  19.800033569335938\n",
      "mae =  0.4896761178970337\n",
      "rmse =  11.543094800866168\n",
      "Progress: 63.56%\n",
      "42\n",
      "max difference =  63.09703826904297\n",
      "data at max difference =  3.852797746658325\n",
      "imputed at max difference =  66.94983673095703\n",
      "mae =  0.7662931680679321\n",
      "rmse =  28.856052564538043\n",
      "Progress: 63.64%\n",
      "43\n",
      "max difference =  15.410276412963867\n",
      "data at max difference =  3.081096887588501\n",
      "imputed at max difference =  18.49137306213379\n",
      "mae =  0.26765695214271545\n",
      "rmse =  7.253839244013248\n",
      "Progress: 63.73%\n",
      "44\n",
      "max difference =  2.523630380630493\n",
      "data at max difference =  2.010576009750366\n",
      "imputed at max difference =  4.534206390380859\n",
      "mae =  0.12592288851737976\n",
      "rmse =  1.747964444367782\n",
      "Progress: 63.81%\n",
      "45\n",
      "max difference =  5.076759338378906\n",
      "data at max difference =  3.2877042293548584\n",
      "imputed at max difference =  8.364463806152344\n",
      "mae =  0.13932806253433228\n",
      "rmse =  2.699213276738706\n",
      "Progress: 63.90%\n",
      "46\n",
      "max difference =  81.87415313720703\n",
      "data at max difference =  4.283926486968994\n",
      "imputed at max difference =  86.1580810546875\n",
      "mae =  0.934127926826477\n",
      "rmse =  37.40085236922555\n",
      "Progress: 63.98%\n",
      "47\n",
      "max difference =  22.695363998413086\n",
      "data at max difference =  3.8365588188171387\n",
      "imputed at max difference =  26.531923294067383\n",
      "mae =  0.3436431884765625\n",
      "rmse =  10.52686940068784\n",
      "Progress: 64.07%\n",
      "48\n",
      "max difference =  28.444923400878906\n",
      "data at max difference =  3.6271133422851562\n",
      "imputed at max difference =  32.07203674316406\n",
      "mae =  0.37988048791885376\n",
      "rmse =  13.040341584578805\n",
      "Progress: 64.15%\n",
      "49\n",
      "max difference =  58.65795135498047\n",
      "data at max difference =  4.054295539855957\n",
      "imputed at max difference =  62.71224594116211\n",
      "mae =  0.8122929930686951\n",
      "rmse =  27.59301227072011\n",
      "Progress: 64.24%\n",
      "50\n",
      "max difference =  15.25053596496582\n",
      "data at max difference =  4.473196029663086\n",
      "imputed at max difference =  19.723731994628906\n",
      "mae =  0.35894423723220825\n",
      "rmse =  9.220796668011209\n",
      "Progress: 64.32%\n",
      "51\n",
      "max difference =  13.260952949523926\n",
      "data at max difference =  4.618027687072754\n",
      "imputed at max difference =  17.87898063659668\n",
      "mae =  0.2099396288394928\n",
      "rmse =  6.314397397248642\n",
      "Progress: 64.41%\n",
      "52\n",
      "max difference =  13.583255767822266\n",
      "data at max difference =  4.122889995574951\n",
      "imputed at max difference =  17.706146240234375\n",
      "mae =  0.18727125227451324\n",
      "rmse =  6.240889839504076\n",
      "Progress: 64.49%\n",
      "53\n",
      "max difference =  16.45977020263672\n",
      "data at max difference =  4.1212592124938965\n",
      "imputed at max difference =  20.581029891967773\n",
      "mae =  0.45618724822998047\n",
      "rmse =  10.514163473378058\n",
      "Progress: 64.58%\n",
      "54\n",
      "max difference =  23.602510452270508\n",
      "data at max difference =  3.1952109336853027\n",
      "imputed at max difference =  26.79772186279297\n",
      "mae =  0.323946475982666\n",
      "rmse =  10.907290914784307\n",
      "Progress: 64.66%\n",
      "55\n",
      "max difference =  31.380874633789062\n",
      "data at max difference =  4.238101482391357\n",
      "imputed at max difference =  35.61897659301758\n",
      "mae =  0.4151879847049713\n",
      "rmse =  14.510618790336277\n",
      "Progress: 64.75%\n",
      "56\n",
      "max difference =  22.380477905273438\n",
      "data at max difference =  3.0583953857421875\n",
      "imputed at max difference =  25.438873291015625\n",
      "mae =  0.33834272623062134\n",
      "rmse =  10.70423358419667\n",
      "Progress: 64.83%\n",
      "57\n",
      "max difference =  5.816582679748535\n",
      "data at max difference =  3.1485235691070557\n",
      "imputed at max difference =  8.965106010437012\n",
      "mae =  0.1701498180627823\n",
      "rmse =  3.8511067266049595\n",
      "Progress: 64.92%\n",
      "58\n",
      "max difference =  37.37798309326172\n",
      "data at max difference =  2.351210355758667\n",
      "imputed at max difference =  39.72919464111328\n",
      "mae =  1.1005234718322754\n",
      "rmse =  24.238400666610055\n",
      "Progress: 65.00%\n",
      "0\n",
      "max difference =  53.379032135009766\n",
      "data at max difference =  1.2311043739318848\n",
      "imputed at max difference =  54.610137939453125\n",
      "mae =  0.8339323997497559\n",
      "rmse =  24.65222698709239\n",
      "Progress: 65.08%\n",
      "1\n",
      "max difference =  55.15371322631836\n",
      "data at max difference =  1.7717119455337524\n",
      "imputed at max difference =  56.9254264831543\n",
      "mae =  1.353303074836731\n",
      "rmse =  30.003086255944293\n",
      "Progress: 65.17%\n",
      "2\n",
      "max difference =  156.70924377441406\n",
      "data at max difference =  5.78329610824585\n",
      "imputed at max difference =  162.49253845214844\n",
      "mae =  3.2310917377471924\n",
      "rmse =  82.82667607846467\n",
      "Progress: 65.25%\n",
      "3\n",
      "max difference =  140.64752197265625\n",
      "data at max difference =  5.214998245239258\n",
      "imputed at max difference =  145.86251831054688\n",
      "mae =  4.454411029815674\n",
      "rmse =  87.32006305197011\n",
      "Progress: 65.34%\n",
      "4\n",
      "max difference =  250.86505126953125\n",
      "data at max difference =  3.644343614578247\n",
      "imputed at max difference =  254.5093994140625\n",
      "mae =  6.208046913146973\n",
      "rmse =  131.22690217391303\n",
      "Progress: 65.42%\n",
      "5\n",
      "max difference =  104.88566589355469\n",
      "data at max difference =  15.96798324584961\n",
      "imputed at max difference =  120.85364532470703\n",
      "mae =  2.136523723602295\n",
      "rmse =  52.02976392663044\n",
      "Progress: 65.51%\n",
      "6\n",
      "max difference =  141.59690856933594\n",
      "data at max difference =  4.688121318817139\n",
      "imputed at max difference =  146.2850341796875\n",
      "mae =  2.2213640213012695\n",
      "rmse =  66.61190663213316\n",
      "Progress: 65.59%\n",
      "7\n",
      "max difference =  82.47525024414062\n",
      "data at max difference =  3.7007248401641846\n",
      "imputed at max difference =  86.17597198486328\n",
      "mae =  2.272732734680176\n",
      "rmse =  47.18819527004076\n",
      "Progress: 65.68%\n",
      "8\n",
      "max difference =  55.45204162597656\n",
      "data at max difference =  2.540346622467041\n",
      "imputed at max difference =  57.99238967895508\n",
      "mae =  1.8419568538665771\n",
      "rmse =  35.43465788468071\n",
      "Progress: 65.76%\n",
      "9\n",
      "max difference =  125.02342224121094\n",
      "data at max difference =  3.169604778289795\n",
      "imputed at max difference =  128.19302368164062\n",
      "mae =  1.9129579067230225\n",
      "rmse =  58.358101222826086\n",
      "Progress: 65.85%\n",
      "10\n",
      "max difference =  88.28826904296875\n",
      "data at max difference =  3.747382640838623\n",
      "imputed at max difference =  92.03565216064453\n",
      "mae =  1.8778220415115356\n",
      "rmse =  52.59499193274456\n",
      "Progress: 65.93%\n",
      "11\n",
      "max difference =  49.612754821777344\n",
      "data at max difference =  2.8884100914001465\n",
      "imputed at max difference =  52.501163482666016\n",
      "mae =  1.0690288543701172\n",
      "rmse =  26.719877823539402\n",
      "Progress: 66.02%\n",
      "12\n",
      "max difference =  20.657190322875977\n",
      "data at max difference =  3.4866089820861816\n",
      "imputed at max difference =  24.143798828125\n",
      "mae =  0.5489355325698853\n",
      "rmse =  11.54799220872962\n",
      "Progress: 66.10%\n",
      "13\n",
      "max difference =  50.21687316894531\n",
      "data at max difference =  3.078768014907837\n",
      "imputed at max difference =  53.2956428527832\n",
      "mae =  1.2092411518096924\n",
      "rmse =  29.985285219938856\n",
      "Progress: 66.19%\n",
      "14\n",
      "max difference =  31.69342041015625\n",
      "data at max difference =  3.136535882949829\n",
      "imputed at max difference =  34.8299560546875\n",
      "mae =  0.5335220694541931\n",
      "rmse =  15.326029901919158\n",
      "Progress: 66.27%\n",
      "15\n",
      "max difference =  15.937076568603516\n",
      "data at max difference =  3.851318597793579\n",
      "imputed at max difference =  19.788394927978516\n",
      "mae =  0.37646225094795227\n",
      "rmse =  9.127806953761889\n",
      "Progress: 66.36%\n",
      "16\n",
      "max difference =  35.78443908691406\n",
      "data at max difference =  4.297800540924072\n",
      "imputed at max difference =  40.08224105834961\n",
      "mae =  0.6833997964859009\n",
      "rmse =  18.214968474014945\n",
      "Progress: 66.44%\n",
      "17\n",
      "max difference =  23.53542709350586\n",
      "data at max difference =  4.016514301300049\n",
      "imputed at max difference =  27.55194091796875\n",
      "mae =  0.6007242798805237\n",
      "rmse =  13.888313625169838\n",
      "Progress: 66.53%\n",
      "18\n",
      "max difference =  39.11311721801758\n",
      "data at max difference =  2.734581470489502\n",
      "imputed at max difference =  41.84769821166992\n",
      "mae =  1.0974586009979248\n",
      "rmse =  25.728804878566574\n",
      "Progress: 66.61%\n",
      "19\n",
      "max difference =  33.631736755371094\n",
      "data at max difference =  2.7446513175964355\n",
      "imputed at max difference =  36.37638854980469\n",
      "mae =  0.6159429550170898\n",
      "rmse =  17.542946193529215\n",
      "Progress: 66.69%\n",
      "20\n",
      "max difference =  36.36008834838867\n",
      "data at max difference =  3.635903835296631\n",
      "imputed at max difference =  39.99599075317383\n",
      "mae =  1.1889088153839111\n",
      "rmse =  26.56470522673234\n",
      "Progress: 66.78%\n",
      "21\n",
      "max difference =  63.9652214050293\n",
      "data at max difference =  3.0974695682525635\n",
      "imputed at max difference =  67.06269073486328\n",
      "mae =  1.1856117248535156\n",
      "rmse =  31.759510869565215\n",
      "Progress: 66.86%\n",
      "22\n",
      "max difference =  10.02786922454834\n",
      "data at max difference =  2.8592002391815186\n",
      "imputed at max difference =  12.887069702148438\n",
      "mae =  0.26488733291625977\n",
      "rmse =  5.395451421323029\n",
      "Progress: 66.95%\n",
      "23\n",
      "max difference =  33.79924011230469\n",
      "data at max difference =  2.5305981636047363\n",
      "imputed at max difference =  36.329837799072266\n",
      "mae =  0.5718929767608643\n",
      "rmse =  16.308837890625\n",
      "Progress: 67.03%\n",
      "24\n",
      "max difference =  26.264263153076172\n",
      "data at max difference =  3.0082943439483643\n",
      "imputed at max difference =  29.272558212280273\n",
      "mae =  0.7191051244735718\n",
      "rmse =  16.80727485988451\n",
      "Progress: 67.12%\n",
      "25\n",
      "max difference =  22.307228088378906\n",
      "data at max difference =  2.7827811241149902\n",
      "imputed at max difference =  25.090009689331055\n",
      "mae =  0.7745934724807739\n",
      "rmse =  15.887071692425273\n",
      "Progress: 67.20%\n",
      "26\n",
      "max difference =  24.275753021240234\n",
      "data at max difference =  2.6586732864379883\n",
      "imputed at max difference =  26.93442726135254\n",
      "mae =  1.2775156497955322\n",
      "rmse =  22.608122452445652\n",
      "Progress: 67.29%\n",
      "27\n",
      "max difference =  62.46678161621094\n",
      "data at max difference =  3.0260767936706543\n",
      "imputed at max difference =  65.49285888671875\n",
      "mae =  1.2833406925201416\n",
      "rmse =  33.50717561141304\n",
      "Progress: 67.37%\n",
      "28\n",
      "max difference =  35.93341064453125\n",
      "data at max difference =  3.075521469116211\n",
      "imputed at max difference =  39.008934020996094\n",
      "mae =  0.7767249345779419\n",
      "rmse =  18.9322337274966\n",
      "Progress: 67.46%\n",
      "29\n",
      "max difference =  56.041175842285156\n",
      "data at max difference =  2.374675750732422\n",
      "imputed at max difference =  58.41585159301758\n",
      "mae =  1.23854398727417\n",
      "rmse =  32.32332445227581\n",
      "Progress: 67.54%\n",
      "30\n",
      "max difference =  46.315799713134766\n",
      "data at max difference =  3.0069375038146973\n",
      "imputed at max difference =  49.32273864746094\n",
      "mae =  0.9798794984817505\n",
      "rmse =  24.564028532608695\n",
      "Progress: 67.63%\n",
      "31\n",
      "max difference =  79.63249206542969\n",
      "data at max difference =  3.129380702972412\n",
      "imputed at max difference =  82.76187133789062\n",
      "mae =  1.1267430782318115\n",
      "rmse =  37.2428854237432\n",
      "Progress: 67.71%\n",
      "32\n",
      "max difference =  106.3279800415039\n",
      "data at max difference =  3.0122029781341553\n",
      "imputed at max difference =  109.34017944335938\n",
      "mae =  1.4271432161331177\n",
      "rmse =  49.55826999830163\n",
      "Progress: 67.80%\n",
      "33\n",
      "max difference =  35.717262268066406\n",
      "data at max difference =  3.5381031036376953\n",
      "imputed at max difference =  39.25536346435547\n",
      "mae =  0.7245898842811584\n",
      "rmse =  20.882005774456523\n",
      "Progress: 67.88%\n",
      "34\n",
      "max difference =  23.372346878051758\n",
      "data at max difference =  3.5691335201263428\n",
      "imputed at max difference =  26.94148063659668\n",
      "mae =  0.7313348054885864\n",
      "rmse =  17.040861710258152\n",
      "Progress: 67.97%\n",
      "35\n",
      "max difference =  42.92031478881836\n",
      "data at max difference =  2.425321340560913\n",
      "imputed at max difference =  45.34563446044922\n",
      "mae =  0.9119824171066284\n",
      "rmse =  23.200925080672555\n",
      "Progress: 68.05%\n",
      "36\n",
      "max difference =  90.69905853271484\n",
      "data at max difference =  3.144315719604492\n",
      "imputed at max difference =  93.84337615966797\n",
      "mae =  1.049133062362671\n",
      "rmse =  41.457155974014945\n",
      "Progress: 68.14%\n",
      "37\n",
      "max difference =  13.35534954071045\n",
      "data at max difference =  3.625164747238159\n",
      "imputed at max difference =  16.980514526367188\n",
      "mae =  0.3867119252681732\n",
      "rmse =  7.783730548361073\n",
      "Progress: 68.22%\n",
      "38\n",
      "max difference =  34.97812271118164\n",
      "data at max difference =  3.856018304824829\n",
      "imputed at max difference =  38.83414077758789\n",
      "mae =  1.1985207796096802\n",
      "rmse =  25.667037300441574\n",
      "Progress: 68.31%\n",
      "39\n",
      "max difference =  157.90264892578125\n",
      "data at max difference =  3.023979425430298\n",
      "imputed at max difference =  160.9266357421875\n",
      "mae =  2.3655714988708496\n",
      "rmse =  76.36681598165761\n",
      "Progress: 68.39%\n",
      "40\n",
      "max difference =  44.88615417480469\n",
      "data at max difference =  2.3753409385681152\n",
      "imputed at max difference =  47.26149368286133\n",
      "mae =  0.7768015265464783\n",
      "rmse =  21.429633099099867\n",
      "Progress: 68.47%\n",
      "41\n",
      "max difference =  60.55088424682617\n",
      "data at max difference =  3.80366849899292\n",
      "imputed at max difference =  64.35455322265625\n",
      "mae =  0.8790133595466614\n",
      "rmse =  28.149299953294836\n",
      "Progress: 68.56%\n",
      "42\n",
      "max difference =  14.958036422729492\n",
      "data at max difference =  3.536712169647217\n",
      "imputed at max difference =  18.494749069213867\n",
      "mae =  0.3135341703891754\n",
      "rmse =  7.7716236943783965\n",
      "Progress: 68.64%\n",
      "43\n",
      "max difference =  1.4207916259765625\n",
      "data at max difference =  1.6754016876220703\n",
      "imputed at max difference =  3.096193313598633\n",
      "mae =  0.09125546365976334\n",
      "rmse =  1.1665355018947436\n",
      "Progress: 68.73%\n",
      "44\n",
      "max difference =  68.38741302490234\n",
      "data at max difference =  3.488417148590088\n",
      "imputed at max difference =  71.8758316040039\n",
      "mae =  1.3413010835647583\n",
      "rmse =  38.380713421365485\n",
      "Progress: 68.81%\n",
      "45\n",
      "max difference =  2.2023229598999023\n",
      "data at max difference =  4.227313041687012\n",
      "imputed at max difference =  6.429636001586914\n",
      "mae =  0.10719121992588043\n",
      "rmse =  1.4587422246518342\n",
      "Progress: 68.90%\n",
      "46\n",
      "max difference =  2.880951166152954\n",
      "data at max difference =  3.3105075359344482\n",
      "imputed at max difference =  6.191458702087402\n",
      "mae =  0.1230073869228363\n",
      "rmse =  1.9039722940196162\n",
      "Progress: 68.98%\n",
      "47\n",
      "max difference =  11.117717742919922\n",
      "data at max difference =  3.8365588188171387\n",
      "imputed at max difference =  14.954276084899902\n",
      "mae =  0.18616192042827606\n",
      "rmse =  5.157828952955163\n",
      "Progress: 69.07%\n",
      "48\n",
      "max difference =  20.44539451599121\n",
      "data at max difference =  3.996349573135376\n",
      "imputed at max difference =  24.441743850708008\n",
      "mae =  0.33360549807548523\n",
      "rmse =  9.64710401452106\n",
      "Progress: 69.15%\n",
      "49\n",
      "max difference =  9.171911239624023\n",
      "data at max difference =  3.6701767444610596\n",
      "imputed at max difference =  12.842087745666504\n",
      "mae =  0.22326520085334778\n",
      "rmse =  5.582653543223506\n",
      "Progress: 69.24%\n",
      "50\n",
      "max difference =  19.374080657958984\n",
      "data at max difference =  4.864070892333984\n",
      "imputed at max difference =  24.23815155029297\n",
      "mae =  0.37186121940612793\n",
      "rmse =  9.974663112474524\n",
      "Progress: 69.32%\n",
      "51\n",
      "max difference =  18.960620880126953\n",
      "data at max difference =  4.618027687072754\n",
      "imputed at max difference =  23.578649520874023\n",
      "mae =  0.47530338168144226\n",
      "rmse =  11.245927893597147\n",
      "Progress: 69.41%\n",
      "52\n",
      "max difference =  12.631223678588867\n",
      "data at max difference =  3.7667183876037598\n",
      "imputed at max difference =  16.39794158935547\n",
      "mae =  0.1596762090921402\n",
      "rmse =  5.776635874872622\n",
      "Progress: 69.49%\n",
      "53\n",
      "max difference =  42.1827392578125\n",
      "data at max difference =  4.1212592124938965\n",
      "imputed at max difference =  46.30399703979492\n",
      "mae =  0.46730247139930725\n",
      "rmse =  19.25068067467731\n",
      "Progress: 69.58%\n",
      "54\n",
      "max difference =  17.903579711914062\n",
      "data at max difference =  3.536703109741211\n",
      "imputed at max difference =  21.440282821655273\n",
      "mae =  0.24992796778678894\n",
      "rmse =  8.27061595087466\n",
      "Progress: 69.66%\n",
      "55\n",
      "max difference =  1.26222825050354\n",
      "data at max difference =  3.6263844966888428\n",
      "imputed at max difference =  2.3641562461853027\n",
      "mae =  0.06375711411237717\n",
      "rmse =  0.9878899947456691\n",
      "Progress: 69.75%\n",
      "56\n",
      "max difference =  52.37029266357422\n",
      "data at max difference =  3.3817639350891113\n",
      "imputed at max difference =  55.75205612182617\n",
      "mae =  0.8864302635192871\n",
      "rmse =  27.695259425951086\n",
      "Progress: 69.83%\n",
      "57\n",
      "max difference =  3.938735008239746\n",
      "data at max difference =  3.476940155029297\n",
      "imputed at max difference =  7.415675163269043\n",
      "mae =  0.11281276494264603\n",
      "rmse =  2.208961818529212\n",
      "Progress: 69.92%\n",
      "58\n",
      "max difference =  12.230430603027344\n",
      "data at max difference =  3.1417088508605957\n",
      "imputed at max difference =  15.372139930725098\n",
      "mae =  0.42835986614227295\n",
      "rmse =  7.4254362686820645\n",
      "Progress: 70.00%\n",
      "0\n",
      "max difference =  45.394535064697266\n",
      "data at max difference =  3.181105136871338\n",
      "imputed at max difference =  48.57564163208008\n",
      "mae =  0.7311655282974243\n",
      "rmse =  21.30160257090693\n",
      "Progress: 70.08%\n",
      "1\n",
      "max difference =  49.98505783081055\n",
      "data at max difference =  2.448204755783081\n",
      "imputed at max difference =  52.43326187133789\n",
      "mae =  1.0784167051315308\n",
      "rmse =  24.68281886888587\n",
      "Progress: 70.17%\n",
      "2\n",
      "max difference =  72.0744857788086\n",
      "data at max difference =  5.049139499664307\n",
      "imputed at max difference =  77.12362670898438\n",
      "mae =  2.4163780212402344\n",
      "rmse =  49.26099694293478\n",
      "Progress: 70.25%\n",
      "3\n",
      "max difference =  62.56281280517578\n",
      "data at max difference =  -0.7100453972816467\n",
      "imputed at max difference =  61.85276794433594\n",
      "mae =  1.8048949241638184\n",
      "rmse =  34.18253492272419\n",
      "Progress: 70.34%\n",
      "4\n",
      "max difference =  134.42919921875\n",
      "data at max difference =  1.5234109163284302\n",
      "imputed at max difference =  135.95260620117188\n",
      "mae =  6.857532024383545\n",
      "rmse =  114.23611582880436\n",
      "Progress: 70.42%\n",
      "5\n",
      "max difference =  63.42763137817383\n",
      "data at max difference =  1.715961217880249\n",
      "imputed at max difference =  65.14359283447266\n",
      "mae =  3.2851598262786865\n",
      "rmse =  52.20272694463315\n",
      "Progress: 70.51%\n",
      "6\n",
      "max difference =  48.234615325927734\n",
      "data at max difference =  2.546924114227295\n",
      "imputed at max difference =  50.78153991699219\n",
      "mae =  1.9811134338378906\n",
      "rmse =  38.05485999065897\n",
      "Progress: 70.59%\n",
      "7\n",
      "max difference =  40.167545318603516\n",
      "data at max difference =  3.7007248401641846\n",
      "imputed at max difference =  43.86827087402344\n",
      "mae =  1.2031877040863037\n",
      "rmse =  26.075534986413047\n",
      "Progress: 70.68%\n",
      "8\n",
      "max difference =  57.824462890625\n",
      "data at max difference =  4.5931077003479\n",
      "imputed at max difference =  62.417572021484375\n",
      "mae =  1.182373285293579\n",
      "rmse =  30.163181470788043\n",
      "Progress: 70.76%\n",
      "9\n",
      "max difference =  61.863895416259766\n",
      "data at max difference =  3.169604778289795\n",
      "imputed at max difference =  65.03350067138672\n",
      "mae =  1.3117060661315918\n",
      "rmse =  31.261474609375\n",
      "Progress: 70.85%\n",
      "10\n",
      "max difference =  20.732322692871094\n",
      "data at max difference =  2.881241798400879\n",
      "imputed at max difference =  23.613563537597656\n",
      "mae =  0.4502975046634674\n",
      "rmse =  10.42001077403193\n",
      "Progress: 70.93%\n",
      "11\n",
      "max difference =  18.200580596923828\n",
      "data at max difference =  2.8884100914001465\n",
      "imputed at max difference =  21.088991165161133\n",
      "mae =  0.3282923400402069\n",
      "rmse =  8.455214790675951\n",
      "Progress: 71.02%\n",
      "12\n",
      "max difference =  51.21714782714844\n",
      "data at max difference =  3.4866089820861816\n",
      "imputed at max difference =  54.703758239746094\n",
      "mae =  1.004988193511963\n",
      "rmse =  27.2544237219769\n",
      "Progress: 71.10%\n",
      "13\n",
      "max difference =  94.56877136230469\n",
      "data at max difference =  3.9568417072296143\n",
      "imputed at max difference =  98.5256118774414\n",
      "mae =  1.3259528875350952\n",
      "rmse =  44.63976520040761\n",
      "Progress: 71.19%\n",
      "14\n",
      "max difference =  39.09439468383789\n",
      "data at max difference =  4.049773693084717\n",
      "imputed at max difference =  43.144168853759766\n",
      "mae =  0.9540049433708191\n",
      "rmse =  23.568595554517664\n",
      "Progress: 71.27%\n",
      "15\n",
      "max difference =  30.6656551361084\n",
      "data at max difference =  3.5889499187469482\n",
      "imputed at max difference =  34.25460433959961\n",
      "mae =  0.6946084499359131\n",
      "rmse =  16.454964015794836\n",
      "Progress: 71.36%\n",
      "16\n",
      "max difference =  62.12776184082031\n",
      "data at max difference =  3.9510416984558105\n",
      "imputed at max difference =  66.07880401611328\n",
      "mae =  0.9467670917510986\n",
      "rmse =  29.427100140115485\n",
      "Progress: 71.44%\n",
      "17\n",
      "max difference =  9.641488075256348\n",
      "data at max difference =  4.372129440307617\n",
      "imputed at max difference =  14.013617515563965\n",
      "mae =  0.2899647355079651\n",
      "rmse =  5.938819553541101\n",
      "Progress: 71.53%\n",
      "18\n",
      "max difference =  83.64998626708984\n",
      "data at max difference =  3.2883851528167725\n",
      "imputed at max difference =  86.93836975097656\n",
      "mae =  1.718566656112671\n",
      "rmse =  45.07384192425272\n",
      "Progress: 71.61%\n",
      "19\n",
      "max difference =  47.69882583618164\n",
      "data at max difference =  3.2785933017730713\n",
      "imputed at max difference =  50.977420806884766\n",
      "mae =  0.6876813173294067\n",
      "rmse =  22.135167660920516\n",
      "Progress: 71.69%\n",
      "20\n",
      "max difference =  10.056966781616211\n",
      "data at max difference =  3.3378450870513916\n",
      "imputed at max difference =  13.394811630249023\n",
      "mae =  0.32951462268829346\n",
      "rmse =  6.756414662236752\n",
      "Progress: 71.78%\n",
      "21\n",
      "max difference =  6.906469345092773\n",
      "data at max difference =  3.636632204055786\n",
      "imputed at max difference =  10.54310131072998\n",
      "mae =  0.1519632637500763\n",
      "rmse =  3.330197541610054\n",
      "Progress: 71.86%\n",
      "22\n",
      "max difference =  12.134589195251465\n",
      "data at max difference =  3.1619231700897217\n",
      "imputed at max difference =  15.296512603759766\n",
      "mae =  0.32580259442329407\n",
      "rmse =  7.367373922596807\n",
      "Progress: 71.95%\n",
      "23\n",
      "max difference =  9.027812004089355\n",
      "data at max difference =  3.0022151470184326\n",
      "imputed at max difference =  12.030027389526367\n",
      "mae =  0.27532559633255005\n",
      "rmse =  5.2004497362219775\n",
      "Progress: 72.03%\n",
      "24\n",
      "max difference =  22.892066955566406\n",
      "data at max difference =  2.3074660301208496\n",
      "imputed at max difference =  25.199533462524414\n",
      "mae =  0.5449960231781006\n",
      "rmse =  14.472185217815897\n",
      "Progress: 72.12%\n",
      "25\n",
      "max difference =  46.718360900878906\n",
      "data at max difference =  3.007465124130249\n",
      "imputed at max difference =  49.725826263427734\n",
      "mae =  1.514701247215271\n",
      "rmse =  32.53368079144022\n",
      "Progress: 72.20%\n",
      "26\n",
      "max difference =  55.532020568847656\n",
      "data at max difference =  2.975456476211548\n",
      "imputed at max difference =  58.507476806640625\n",
      "mae =  1.7627445459365845\n",
      "rmse =  37.74491815981658\n",
      "Progress: 72.29%\n",
      "27\n",
      "max difference =  75.54812622070312\n",
      "data at max difference =  2.978973388671875\n",
      "imputed at max difference =  78.527099609375\n",
      "mae =  2.3266005516052246\n",
      "rmse =  52.499580715013586\n",
      "Progress: 72.37%\n",
      "28\n",
      "max difference =  124.26317596435547\n",
      "data at max difference =  3.648150682449341\n",
      "imputed at max difference =  127.91132354736328\n",
      "mae =  2.075521945953369\n",
      "rmse =  60.824776027513586\n",
      "Progress: 72.46%\n",
      "29\n",
      "max difference =  22.17012596130371\n",
      "data at max difference =  2.374675750732422\n",
      "imputed at max difference =  24.544801712036133\n",
      "mae =  0.6210204362869263\n",
      "rmse =  13.395583443019701\n",
      "Progress: 72.54%\n",
      "30\n",
      "max difference =  107.27597045898438\n",
      "data at max difference =  3.594463348388672\n",
      "imputed at max difference =  110.87043762207031\n",
      "mae =  2.1033449172973633\n",
      "rmse =  55.77501379925272\n",
      "Progress: 72.63%\n",
      "31\n",
      "max difference =  33.18325424194336\n",
      "data at max difference =  3.0085790157318115\n",
      "imputed at max difference =  36.19183349609375\n",
      "mae =  0.7157562971115112\n",
      "rmse =  18.132137132727582\n",
      "Progress: 72.71%\n",
      "32\n",
      "max difference =  53.3404426574707\n",
      "data at max difference =  3.586270332336426\n",
      "imputed at max difference =  56.92671203613281\n",
      "mae =  0.8741706609725952\n",
      "rmse =  25.243490467900813\n",
      "Progress: 72.80%\n",
      "33\n",
      "max difference =  65.5657730102539\n",
      "data at max difference =  2.9166598320007324\n",
      "imputed at max difference =  68.48242950439453\n",
      "mae =  2.203904867172241\n",
      "rmse =  41.96477210003396\n",
      "Progress: 72.88%\n",
      "34\n",
      "max difference =  48.16929626464844\n",
      "data at max difference =  3.5691335201263428\n",
      "imputed at max difference =  51.73843002319336\n",
      "mae =  0.9583430290222168\n",
      "rmse =  26.51058296535326\n",
      "Progress: 72.97%\n",
      "35\n",
      "max difference =  51.05363082885742\n",
      "data at max difference =  3.109546422958374\n",
      "imputed at max difference =  54.163177490234375\n",
      "mae =  0.587263286113739\n",
      "rmse =  23.298177967900816\n",
      "Progress: 73.05%\n",
      "36\n",
      "max difference =  82.43077087402344\n",
      "data at max difference =  3.024057149887085\n",
      "imputed at max difference =  85.45482635498047\n",
      "mae =  1.904579997062683\n",
      "rmse =  46.55834430197011\n",
      "Progress: 73.14%\n",
      "37\n",
      "max difference =  29.284364700317383\n",
      "data at max difference =  3.152101755142212\n",
      "imputed at max difference =  32.436466217041016\n",
      "mae =  0.7219828367233276\n",
      "rmse =  16.74844625721807\n",
      "Progress: 73.22%\n",
      "38\n",
      "max difference =  22.73520851135254\n",
      "data at max difference =  3.179063081741333\n",
      "imputed at max difference =  25.91427230834961\n",
      "mae =  0.49100562930107117\n",
      "rmse =  12.483730150305707\n",
      "Progress: 73.31%\n",
      "39\n",
      "max difference =  18.285524368286133\n",
      "data at max difference =  2.7609822750091553\n",
      "imputed at max difference =  21.046506881713867\n",
      "mae =  0.6814790368080139\n",
      "rmse =  13.728234332540762\n",
      "Progress: 73.39%\n",
      "40\n",
      "max difference =  14.970041275024414\n",
      "data at max difference =  2.279470682144165\n",
      "imputed at max difference =  17.24951171875\n",
      "mae =  0.3448057770729065\n",
      "rmse =  8.16288359268852\n",
      "Progress: 73.47%\n",
      "41\n",
      "max difference =  12.273426055908203\n",
      "data at max difference =  2.959125518798828\n",
      "imputed at max difference =  15.232551574707031\n",
      "mae =  0.32454073429107666\n",
      "rmse =  6.685087784476902\n",
      "Progress: 73.56%\n",
      "42\n",
      "max difference =  50.980892181396484\n",
      "data at max difference =  3.852797746658325\n",
      "imputed at max difference =  54.83369064331055\n",
      "mae =  1.2017475366592407\n",
      "rmse =  31.724763289741848\n",
      "Progress: 73.64%\n",
      "43\n",
      "max difference =  73.86203002929688\n",
      "data at max difference =  3.971184253692627\n",
      "imputed at max difference =  77.83321380615234\n",
      "mae =  0.8925929069519043\n",
      "rmse =  33.84748641304348\n",
      "Progress: 73.73%\n",
      "44\n",
      "max difference =  15.28581428527832\n",
      "data at max difference =  1.6781197786331177\n",
      "imputed at max difference =  16.96393394470215\n",
      "mae =  0.26164349913597107\n",
      "rmse =  7.114194787066916\n",
      "Progress: 73.81%\n",
      "45\n",
      "max difference =  32.06501770019531\n",
      "data at max difference =  1.978124737739563\n",
      "imputed at max difference =  34.04314422607422\n",
      "mae =  0.423016220331192\n",
      "rmse =  14.697150188943613\n",
      "Progress: 73.90%\n",
      "46\n",
      "max difference =  17.55937957763672\n",
      "data at max difference =  3.933950424194336\n",
      "imputed at max difference =  21.493330001831055\n",
      "mae =  0.28243643045425415\n",
      "rmse =  8.182519663935123\n",
      "Progress: 73.98%\n",
      "47\n",
      "max difference =  24.978822708129883\n",
      "data at max difference =  4.468069553375244\n",
      "imputed at max difference =  29.44689178466797\n",
      "mae =  0.5451681613922119\n",
      "rmse =  14.172083315641984\n",
      "Progress: 74.07%\n",
      "48\n",
      "max difference =  16.2437686920166\n",
      "data at max difference =  4.654101848602295\n",
      "imputed at max difference =  20.897871017456055\n",
      "mae =  0.2510077953338623\n",
      "rmse =  7.490423451299252\n",
      "Progress: 74.15%\n",
      "49\n",
      "max difference =  15.47147274017334\n",
      "data at max difference =  3.6701767444610596\n",
      "imputed at max difference =  19.14164924621582\n",
      "mae =  0.23001885414123535\n",
      "rmse =  7.136748604152514\n",
      "Progress: 74.24%\n",
      "50\n",
      "max difference =  1.3023629188537598\n",
      "data at max difference =  4.473196029663086\n",
      "imputed at max difference =  3.170833110809326\n",
      "mae =  0.06405208259820938\n",
      "rmse =  0.9695170858631964\n",
      "Progress: 74.32%\n",
      "51\n",
      "max difference =  10.577454566955566\n",
      "data at max difference =  3.903841972351074\n",
      "imputed at max difference =  14.48129653930664\n",
      "mae =  0.2439582198858261\n",
      "rmse =  6.692689315132474\n",
      "Progress: 74.41%\n",
      "52\n",
      "max difference =  7.263913631439209\n",
      "data at max difference =  4.122889995574951\n",
      "imputed at max difference =  11.38680362701416\n",
      "mae =  0.12743830680847168\n",
      "rmse =  3.4798182611880093\n",
      "Progress: 74.49%\n",
      "53\n",
      "max difference =  57.98691940307617\n",
      "data at max difference =  4.1212592124938965\n",
      "imputed at max difference =  62.108177185058594\n",
      "mae =  1.2711119651794434\n",
      "rmse =  33.74836001188859\n",
      "Progress: 74.58%\n",
      "54\n",
      "max difference =  1.4012641906738281\n",
      "data at max difference =  3.536703109741211\n",
      "imputed at max difference =  2.135438919067383\n",
      "mae =  0.06479449570178986\n",
      "rmse =  1.0170320427936057\n",
      "Progress: 74.66%\n",
      "55\n",
      "max difference =  2.257345199584961\n",
      "data at max difference =  4.238101482391357\n",
      "imputed at max difference =  1.980756402015686\n",
      "mae =  0.06766477227210999\n",
      "rmse =  1.1700588723887568\n",
      "Progress: 74.75%\n",
      "56\n",
      "max difference =  56.14838409423828\n",
      "data at max difference =  3.957808017730713\n",
      "imputed at max difference =  60.10619354248047\n",
      "mae =  0.6241446733474731\n",
      "rmse =  25.6322658372962\n",
      "Progress: 74.83%\n",
      "57\n",
      "max difference =  1.6285009384155273\n",
      "data at max difference =  4.061976432800293\n",
      "imputed at max difference =  2.4334754943847656\n",
      "mae =  0.06841061264276505\n",
      "rmse =  1.1259634598441746\n",
      "Progress: 74.92%\n",
      "58\n",
      "max difference =  11.582712173461914\n",
      "data at max difference =  2.936537981033325\n",
      "imputed at max difference =  14.51924991607666\n",
      "mae =  0.30542945861816406\n",
      "rmse =  5.888452944548233\n",
      "Progress: 75.00%\n",
      "0\n",
      "max difference =  6.230764389038086\n",
      "data at max difference =  2.9782025814056396\n",
      "imputed at max difference =  9.208967208862305\n",
      "mae =  0.3408583104610443\n",
      "rmse =  4.972577302352242\n",
      "Progress: 75.08%\n",
      "1\n",
      "max difference =  88.73824310302734\n",
      "data at max difference =  3.252281427383423\n",
      "imputed at max difference =  91.99052429199219\n",
      "mae =  1.1295169591903687\n",
      "rmse =  40.55705194887908\n",
      "Progress: 75.17%\n",
      "2\n",
      "max difference =  21.288654327392578\n",
      "data at max difference =  4.079436302185059\n",
      "imputed at max difference =  25.36808967590332\n",
      "mae =  0.7794825434684753\n",
      "rmse =  13.352562945822012\n",
      "Progress: 75.25%\n",
      "3\n",
      "max difference =  61.521095275878906\n",
      "data at max difference =  -0.7100453972816467\n",
      "imputed at max difference =  60.81105041503906\n",
      "mae =  3.1353273391723633\n",
      "rmse =  51.711107336956516\n",
      "Progress: 75.34%\n",
      "4\n",
      "max difference =  161.91111755371094\n",
      "data at max difference =  5.147191047668457\n",
      "imputed at max difference =  167.0583038330078\n",
      "mae =  6.203535079956055\n",
      "rmse =  112.62124235733695\n",
      "Progress: 75.42%\n",
      "5\n",
      "max difference =  157.830078125\n",
      "data at max difference =  3.154200792312622\n",
      "imputed at max difference =  160.98428344726562\n",
      "mae =  6.428504467010498\n",
      "rmse =  113.57366677989131\n",
      "Progress: 75.51%\n",
      "6\n",
      "max difference =  100.04582977294922\n",
      "data at max difference =  2.983938694000244\n",
      "imputed at max difference =  103.02976989746094\n",
      "mae =  2.1912267208099365\n",
      "rmse =  55.18648097826087\n",
      "Progress: 75.59%\n",
      "7\n",
      "max difference =  54.45787048339844\n",
      "data at max difference =  4.087564945220947\n",
      "imputed at max difference =  58.54543685913086\n",
      "mae =  1.842932105064392\n",
      "rmse =  37.33160400390625\n",
      "Progress: 75.68%\n",
      "8\n",
      "max difference =  153.92982482910156\n",
      "data at max difference =  4.082543849945068\n",
      "imputed at max difference =  158.0123748779297\n",
      "mae =  2.259702682495117\n",
      "rmse =  72.00437860903533\n",
      "Progress: 75.76%\n",
      "9\n",
      "max difference =  148.869384765625\n",
      "data at max difference =  3.169604778289795\n",
      "imputed at max difference =  152.0389862060547\n",
      "mae =  2.6913702487945557\n",
      "rmse =  74.54448136039402\n",
      "Progress: 75.85%\n",
      "10\n",
      "max difference =  73.83906555175781\n",
      "data at max difference =  3.747382640838623\n",
      "imputed at max difference =  77.5864486694336\n",
      "mae =  1.562364935874939\n",
      "rmse =  43.71725861922554\n",
      "Progress: 75.93%\n",
      "11\n",
      "max difference =  72.62387084960938\n",
      "data at max difference =  3.1999928951263428\n",
      "imputed at max difference =  75.82386016845703\n",
      "mae =  1.5956143140792847\n",
      "rmse =  41.296522057574734\n",
      "Progress: 76.02%\n",
      "12\n",
      "max difference =  17.87723159790039\n",
      "data at max difference =  2.9304683208465576\n",
      "imputed at max difference =  20.80769920349121\n",
      "mae =  0.3548095226287842\n",
      "rmse =  8.723879606827447\n",
      "Progress: 76.10%\n",
      "13\n",
      "max difference =  251.1810760498047\n",
      "data at max difference =  3.3944644927978516\n",
      "imputed at max difference =  254.57554626464844\n",
      "mae =  4.139423847198486\n",
      "rmse =  127.33302904211956\n",
      "Progress: 76.19%\n",
      "14\n",
      "max difference =  86.47867584228516\n",
      "data at max difference =  3.136535882949829\n",
      "imputed at max difference =  89.6152114868164\n",
      "mae =  1.8448039293289185\n",
      "rmse =  46.71825641134511\n",
      "Progress: 76.27%\n",
      "15\n",
      "max difference =  122.64830780029297\n",
      "data at max difference =  3.25317645072937\n",
      "imputed at max difference =  125.90148162841797\n",
      "mae =  2.246769905090332\n",
      "rmse =  62.07414444633152\n",
      "Progress: 76.36%\n",
      "16\n",
      "max difference =  18.7103271484375\n",
      "data at max difference =  4.297800540924072\n",
      "imputed at max difference =  23.008127212524414\n",
      "mae =  0.4811033010482788\n",
      "rmse =  11.917844025985055\n",
      "Progress: 76.44%\n",
      "17\n",
      "max difference =  14.183134078979492\n",
      "data at max difference =  3.7386417388916016\n",
      "imputed at max difference =  17.921775817871094\n",
      "mae =  0.3789738118648529\n",
      "rmse =  8.441605277683424\n",
      "Progress: 76.53%\n",
      "18\n",
      "max difference =  20.343589782714844\n",
      "data at max difference =  3.0454649925231934\n",
      "imputed at max difference =  23.389055252075195\n",
      "mae =  0.4758385121822357\n",
      "rmse =  10.980934474779213\n",
      "Progress: 76.61%\n",
      "19\n",
      "max difference =  13.677961349487305\n",
      "data at max difference =  3.2785933017730713\n",
      "imputed at max difference =  16.956554412841797\n",
      "mae =  0.28493356704711914\n",
      "rmse =  6.997881682022758\n",
      "Progress: 76.69%\n",
      "20\n",
      "max difference =  20.634531021118164\n",
      "data at max difference =  2.80688738822937\n",
      "imputed at max difference =  23.441417694091797\n",
      "mae =  0.4454694986343384\n",
      "rmse =  12.615572722061822\n",
      "Progress: 76.78%\n",
      "21\n",
      "max difference =  80.98346710205078\n",
      "data at max difference =  3.333967447280884\n",
      "imputed at max difference =  84.31743621826172\n",
      "mae =  1.8965296745300293\n",
      "rmse =  49.49081818953805\n",
      "Progress: 76.86%\n",
      "22\n",
      "max difference =  58.110538482666016\n",
      "data at max difference =  3.7011895179748535\n",
      "imputed at max difference =  61.811729431152344\n",
      "mae =  0.7403474450111389\n",
      "rmse =  26.630838145380437\n",
      "Progress: 76.95%\n",
      "23\n",
      "max difference =  9.892772674560547\n",
      "data at max difference =  2.7374680042266846\n",
      "imputed at max difference =  12.630240440368652\n",
      "mae =  0.3271431624889374\n",
      "rmse =  6.277972677479619\n",
      "Progress: 77.03%\n",
      "24\n",
      "max difference =  62.308319091796875\n",
      "data at max difference =  2.3074660301208496\n",
      "imputed at max difference =  64.61578369140625\n",
      "mae =  1.18727707862854\n",
      "rmse =  32.399538786514945\n",
      "Progress: 77.12%\n",
      "25\n",
      "max difference =  49.867130279541016\n",
      "data at max difference =  3.438636064529419\n",
      "imputed at max difference =  53.30576705932617\n",
      "mae =  1.3890796899795532\n",
      "rmse =  32.658932893172555\n",
      "Progress: 77.20%\n",
      "26\n",
      "max difference =  38.2761344909668\n",
      "data at max difference =  2.975456476211548\n",
      "imputed at max difference =  41.251590728759766\n",
      "mae =  0.8954297304153442\n",
      "rmse =  22.011076554008152\n",
      "Progress: 77.29%\n",
      "27\n",
      "max difference =  24.708871841430664\n",
      "data at max difference =  2.978973388671875\n",
      "imputed at max difference =  27.68784523010254\n",
      "mae =  0.5996739268302917\n",
      "rmse =  13.750111455502717\n",
      "Progress: 77.37%\n",
      "28\n",
      "max difference =  39.94752883911133\n",
      "data at max difference =  2.9589877128601074\n",
      "imputed at max difference =  42.906517028808594\n",
      "mae =  1.027040719985962\n",
      "rmse =  22.36303180197011\n",
      "Progress: 77.46%\n",
      "29\n",
      "max difference =  115.9532470703125\n",
      "data at max difference =  3.1065943241119385\n",
      "imputed at max difference =  119.05984497070312\n",
      "mae =  1.5508959293365479\n",
      "rmse =  53.68552564538044\n",
      "Progress: 77.54%\n",
      "30\n",
      "max difference =  32.468467712402344\n",
      "data at max difference =  3.7144384384155273\n",
      "imputed at max difference =  36.18290710449219\n",
      "mae =  0.7259635925292969\n",
      "rmse =  17.883946957795516\n",
      "Progress: 77.63%\n",
      "31\n",
      "max difference =  48.961395263671875\n",
      "data at max difference =  3.6001527309417725\n",
      "imputed at max difference =  52.561546325683594\n",
      "mae =  1.1065236330032349\n",
      "rmse =  27.488594386888586\n",
      "Progress: 77.71%\n",
      "32\n",
      "max difference =  86.78195190429688\n",
      "data at max difference =  3.586270332336426\n",
      "imputed at max difference =  90.36822509765625\n",
      "mae =  1.6808898448944092\n",
      "rmse =  47.189516813858695\n",
      "Progress: 77.80%\n",
      "33\n",
      "max difference =  33.07209396362305\n",
      "data at max difference =  3.654895544052124\n",
      "imputed at max difference =  36.72698974609375\n",
      "mae =  0.9625536203384399\n",
      "rmse =  21.75614066745924\n",
      "Progress: 77.88%\n",
      "34\n",
      "max difference =  48.35337829589844\n",
      "data at max difference =  3.1056199073791504\n",
      "imputed at max difference =  51.45899963378906\n",
      "mae =  1.422493577003479\n",
      "rmse =  33.651038128396735\n",
      "Progress: 77.97%\n",
      "35\n",
      "max difference =  42.51802062988281\n",
      "data at max difference =  3.6970813274383545\n",
      "imputed at max difference =  46.21510314941406\n",
      "mae =  0.8562877178192139\n",
      "rmse =  22.246743907099184\n",
      "Progress: 78.05%\n",
      "36\n",
      "max difference =  102.75850677490234\n",
      "data at max difference =  3.7332305908203125\n",
      "imputed at max difference =  106.49173736572266\n",
      "mae =  1.9786837100982666\n",
      "rmse =  56.04711383322011\n",
      "Progress: 78.14%\n",
      "37\n",
      "max difference =  12.800159454345703\n",
      "data at max difference =  3.152101755142212\n",
      "imputed at max difference =  15.952260971069336\n",
      "mae =  0.22564387321472168\n",
      "rmse =  6.053442250127378\n",
      "Progress: 78.22%\n",
      "38\n",
      "max difference =  82.13224029541016\n",
      "data at max difference =  3.7342121601104736\n",
      "imputed at max difference =  85.866455078125\n",
      "mae =  1.0238968133926392\n",
      "rmse =  37.80520762567935\n",
      "Progress: 78.31%\n",
      "39\n",
      "max difference =  81.85628509521484\n",
      "data at max difference =  2.917407751083374\n",
      "imputed at max difference =  84.77368927001953\n",
      "mae =  1.1981487274169922\n",
      "rmse =  38.56659466287364\n",
      "Progress: 78.39%\n",
      "40\n",
      "max difference =  68.18230438232422\n",
      "data at max difference =  2.7489545345306396\n",
      "imputed at max difference =  70.93125915527344\n",
      "mae =  1.3130279779434204\n",
      "rmse =  34.84865934952446\n",
      "Progress: 78.47%\n",
      "41\n",
      "max difference =  23.077070236206055\n",
      "data at max difference =  1.7970588207244873\n",
      "imputed at max difference =  24.874128341674805\n",
      "mae =  0.47109195590019226\n",
      "rmse =  12.005176046620244\n",
      "Progress: 78.56%\n",
      "42\n",
      "max difference =  19.84911346435547\n",
      "data at max difference =  1.7637147903442383\n",
      "imputed at max difference =  21.61282730102539\n",
      "mae =  0.30949854850769043\n",
      "rmse =  9.237183280613111\n",
      "Progress: 78.64%\n",
      "43\n",
      "max difference =  30.428604125976562\n",
      "data at max difference =  3.081096887588501\n",
      "imputed at max difference =  33.509700775146484\n",
      "mae =  0.4644485414028168\n",
      "rmse =  14.342070206351904\n",
      "Progress: 78.73%\n",
      "44\n",
      "max difference =  30.944120407104492\n",
      "data at max difference =  3.158930540084839\n",
      "imputed at max difference =  34.103050231933594\n",
      "mae =  0.5809389352798462\n",
      "rmse =  16.225413446841035\n",
      "Progress: 78.81%\n",
      "45\n",
      "max difference =  7.7181501388549805\n",
      "data at max difference =  3.6255245208740234\n",
      "imputed at max difference =  11.343674659729004\n",
      "mae =  0.18068572878837585\n",
      "rmse =  3.9352330746858017\n",
      "Progress: 78.90%\n",
      "46\n",
      "max difference =  5.955035209655762\n",
      "data at max difference =  3.3105075359344482\n",
      "imputed at max difference =  9.265542984008789\n",
      "mae =  0.1612846851348877\n",
      "rmse =  3.135003131368886\n",
      "Progress: 78.98%\n",
      "47\n",
      "max difference =  29.32487678527832\n",
      "data at max difference =  3.482053518295288\n",
      "imputed at max difference =  32.80693054199219\n",
      "mae =  0.36214128136634827\n",
      "rmse =  13.3990186608356\n",
      "Progress: 79.07%\n",
      "48\n",
      "max difference =  36.83085250854492\n",
      "data at max difference =  4.654101848602295\n",
      "imputed at max difference =  41.484954833984375\n",
      "mae =  0.44875025749206543\n",
      "rmse =  16.823394775390625\n",
      "Progress: 79.15%\n",
      "49\n",
      "max difference =  22.35521697998047\n",
      "data at max difference =  4.354440212249756\n",
      "imputed at max difference =  26.709657669067383\n",
      "mae =  0.4048285186290741\n",
      "rmse =  11.411342454993207\n",
      "Progress: 79.24%\n",
      "50\n",
      "max difference =  14.606121063232422\n",
      "data at max difference =  4.473196029663086\n",
      "imputed at max difference =  19.079317092895508\n",
      "mae =  0.2027686983346939\n",
      "rmse =  6.71440721594769\n",
      "Progress: 79.32%\n",
      "51\n",
      "max difference =  8.093268394470215\n",
      "data at max difference =  3.903841972351074\n",
      "imputed at max difference =  11.997110366821289\n",
      "mae =  0.1682068258523941\n",
      "rmse =  4.0523681640625\n",
      "Progress: 79.41%\n",
      "52\n",
      "max difference =  2.177609920501709\n",
      "data at max difference =  4.122889995574951\n",
      "imputed at max difference =  1.9452799558639526\n",
      "mae =  0.05159159377217293\n",
      "rmse =  1.116097989289657\n",
      "Progress: 79.49%\n",
      "53\n",
      "max difference =  41.260799407958984\n",
      "data at max difference =  3.171074867248535\n",
      "imputed at max difference =  44.4318733215332\n",
      "mae =  0.5683634281158447\n",
      "rmse =  19.341213060461957\n",
      "Progress: 79.58%\n",
      "54\n",
      "max difference =  85.46807861328125\n",
      "data at max difference =  3.1952109336853027\n",
      "imputed at max difference =  88.66329193115234\n",
      "mae =  1.1926405429840088\n",
      "rmse =  40.18792724609375\n",
      "Progress: 79.66%\n",
      "55\n",
      "max difference =  31.378387451171875\n",
      "data at max difference =  3.6263844966888428\n",
      "imputed at max difference =  35.0047721862793\n",
      "mae =  0.4830510914325714\n",
      "rmse =  15.233651866083559\n",
      "Progress: 79.75%\n",
      "56\n",
      "max difference =  25.478450775146484\n",
      "data at max difference =  3.3817639350891113\n",
      "imputed at max difference =  28.860214233398438\n",
      "mae =  0.5103924870491028\n",
      "rmse =  13.929408861243205\n",
      "Progress: 79.83%\n",
      "57\n",
      "max difference =  18.75011444091797\n",
      "data at max difference =  3.476940155029297\n",
      "imputed at max difference =  22.227054595947266\n",
      "mae =  0.2810509502887726\n",
      "rmse =  8.797528474227242\n",
      "Progress: 79.92%\n",
      "58\n",
      "max difference =  3.9930670261383057\n",
      "data at max difference =  4.55797004699707\n",
      "imputed at max difference =  0.5649029612541199\n",
      "mae =  0.25626739859580994\n",
      "rmse =  3.473302094832711\n",
      "Progress: 80.00%\n",
      "0\n",
      "max difference =  18.270784378051758\n",
      "data at max difference =  1.2311043739318848\n",
      "imputed at max difference =  19.501888275146484\n",
      "mae =  0.5550346374511719\n",
      "rmse =  10.260935244352922\n",
      "Progress: 80.08%\n",
      "1\n",
      "max difference =  20.492536544799805\n",
      "data at max difference =  4.692869663238525\n",
      "imputed at max difference =  25.185405731201172\n",
      "mae =  0.5869856476783752\n",
      "rmse =  12.231250265370244\n",
      "Progress: 80.17%\n",
      "2\n",
      "max difference =  32.62017822265625\n",
      "data at max difference =  6.752999305725098\n",
      "imputed at max difference =  39.37317657470703\n",
      "mae =  1.3295061588287354\n",
      "rmse =  23.606110945991848\n",
      "Progress: 80.25%\n",
      "3\n",
      "max difference =  25.19984245300293\n",
      "data at max difference =  3.0506722927093506\n",
      "imputed at max difference =  28.25051498413086\n",
      "mae =  1.1062132120132446\n",
      "rmse =  18.695086935292117\n",
      "Progress: 80.34%\n",
      "4\n",
      "max difference =  238.16046142578125\n",
      "data at max difference =  -0.545275092124939\n",
      "imputed at max difference =  237.6151885986328\n",
      "mae =  5.852242946624756\n",
      "rmse =  139.52164359714675\n",
      "Progress: 80.42%\n",
      "5\n",
      "max difference =  145.18994140625\n",
      "data at max difference =  13.818947792053223\n",
      "imputed at max difference =  159.00889587402344\n",
      "mae =  5.768470287322998\n",
      "rmse =  104.15153702445652\n",
      "Progress: 80.51%\n",
      "6\n",
      "max difference =  43.56127166748047\n",
      "data at max difference =  4.360837459564209\n",
      "imputed at max difference =  47.9221076965332\n",
      "mae =  1.5062310695648193\n",
      "rmse =  28.785148288892664\n",
      "Progress: 80.59%\n",
      "7\n",
      "max difference =  75.63945007324219\n",
      "data at max difference =  3.7007248401641846\n",
      "imputed at max difference =  79.34017181396484\n",
      "mae =  2.279496908187866\n",
      "rmse =  48.74584430197011\n",
      "Progress: 80.68%\n",
      "8\n",
      "max difference =  91.65094757080078\n",
      "data at max difference =  4.987031936645508\n",
      "imputed at max difference =  96.63797760009766\n",
      "mae =  2.0928151607513428\n",
      "rmse =  47.30849821671196\n",
      "Progress: 80.76%\n",
      "9\n",
      "max difference =  89.66918182373047\n",
      "data at max difference =  3.422072172164917\n",
      "imputed at max difference =  93.09125518798828\n",
      "mae =  1.510358214378357\n",
      "rmse =  43.99761432150136\n",
      "Progress: 80.85%\n",
      "10\n",
      "max difference =  24.769908905029297\n",
      "data at max difference =  3.435976505279541\n",
      "imputed at max difference =  28.20588493347168\n",
      "mae =  0.4298512637615204\n",
      "rmse =  11.572489862856658\n",
      "Progress: 80.93%\n",
      "11\n",
      "max difference =  93.19830322265625\n",
      "data at max difference =  3.75504207611084\n",
      "imputed at max difference =  96.9533462524414\n",
      "mae =  1.5396593809127808\n",
      "rmse =  46.66950789741848\n",
      "Progress: 81.02%\n",
      "12\n",
      "max difference =  44.043025970458984\n",
      "data at max difference =  3.242663860321045\n",
      "imputed at max difference =  47.28569030761719\n",
      "mae =  0.6728673577308655\n",
      "rmse =  20.880899180536687\n",
      "Progress: 81.10%\n",
      "13\n",
      "max difference =  47.56475067138672\n",
      "data at max difference =  3.078768014907837\n",
      "imputed at max difference =  50.64352035522461\n",
      "mae =  0.6883412599563599\n",
      "rmse =  22.200649095618207\n",
      "Progress: 81.19%\n",
      "14\n",
      "max difference =  28.603649139404297\n",
      "data at max difference =  3.136535882949829\n",
      "imputed at max difference =  31.740184783935547\n",
      "mae =  0.6654404997825623\n",
      "rmse =  17.96834663722826\n",
      "Progress: 81.27%\n",
      "15\n",
      "max difference =  34.08599090576172\n",
      "data at max difference =  3.25317645072937\n",
      "imputed at max difference =  37.339168548583984\n",
      "mae =  0.5866380333900452\n",
      "rmse =  16.335780931555707\n",
      "Progress: 81.36%\n",
      "16\n",
      "max difference =  36.1429443359375\n",
      "data at max difference =  3.9510416984558105\n",
      "imputed at max difference =  40.09398651123047\n",
      "mae =  0.7042245268821716\n",
      "rmse =  18.348092784052312\n",
      "Progress: 81.44%\n",
      "17\n",
      "max difference =  155.10763549804688\n",
      "data at max difference =  4.372129440307617\n",
      "imputed at max difference =  159.47976684570312\n",
      "mae =  1.6847556829452515\n",
      "rmse =  70.75473951256794\n",
      "Progress: 81.53%\n",
      "18\n",
      "max difference =  7.657857894897461\n",
      "data at max difference =  3.599268674850464\n",
      "imputed at max difference =  11.257126808166504\n",
      "mae =  0.27231547236442566\n",
      "rmse =  5.321572676948879\n",
      "Progress: 81.61%\n",
      "19\n",
      "max difference =  55.8123664855957\n",
      "data at max difference =  2.7446513175964355\n",
      "imputed at max difference =  58.5570182800293\n",
      "mae =  0.765005886554718\n",
      "rmse =  25.938455332880434\n",
      "Progress: 81.69%\n",
      "20\n",
      "max difference =  23.082799911499023\n",
      "data at max difference =  3.1049461364746094\n",
      "imputed at max difference =  26.187746047973633\n",
      "mae =  0.5957260131835938\n",
      "rmse =  13.715496560801629\n",
      "Progress: 81.78%\n",
      "21\n",
      "max difference =  18.663864135742188\n",
      "data at max difference =  3.0974695682525635\n",
      "imputed at max difference =  21.761333465576172\n",
      "mae =  0.2560054659843445\n",
      "rmse =  8.551337200662363\n",
      "Progress: 81.86%\n",
      "22\n",
      "max difference =  159.065185546875\n",
      "data at max difference =  2.8592002391815186\n",
      "imputed at max difference =  161.9243927001953\n",
      "mae =  1.7312711477279663\n",
      "rmse =  72.5814898947011\n",
      "Progress: 81.95%\n",
      "23\n",
      "max difference =  29.14446258544922\n",
      "data at max difference =  2.2658510208129883\n",
      "imputed at max difference =  31.410314559936523\n",
      "mae =  0.4430288076400757\n",
      "rmse =  13.466297978940217\n",
      "Progress: 82.03%\n",
      "24\n",
      "max difference =  7.831307411193848\n",
      "data at max difference =  2.7563235759735107\n",
      "imputed at max difference =  10.587631225585938\n",
      "mae =  0.202865332365036\n",
      "rmse =  4.0104864369268\n",
      "Progress: 82.12%\n",
      "25\n",
      "max difference =  32.52379608154297\n",
      "data at max difference =  2.893998146057129\n",
      "imputed at max difference =  35.41779327392578\n",
      "mae =  0.6221452355384827\n",
      "rmse =  16.88120701002038\n",
      "Progress: 82.20%\n",
      "26\n",
      "max difference =  32.85367965698242\n",
      "data at max difference =  2.6586732864379883\n",
      "imputed at max difference =  35.512351989746094\n",
      "mae =  0.7330964207649231\n",
      "rmse =  17.89700848123302\n",
      "Progress: 82.29%\n",
      "27\n",
      "max difference =  68.84528350830078\n",
      "data at max difference =  3.4737296104431152\n",
      "imputed at max difference =  72.31901550292969\n",
      "mae =  0.9625015258789062\n",
      "rmse =  31.997842539911687\n",
      "Progress: 82.37%\n",
      "28\n",
      "max difference =  20.196115493774414\n",
      "data at max difference =  3.648150682449341\n",
      "imputed at max difference =  23.844266891479492\n",
      "mae =  0.39409494400024414\n",
      "rmse =  10.331314750339674\n",
      "Progress: 82.46%\n",
      "29\n",
      "max difference =  46.65735626220703\n",
      "data at max difference =  3.1065943241119385\n",
      "imputed at max difference =  49.76395034790039\n",
      "mae =  0.7534573078155518\n",
      "rmse =  22.502998683763586\n",
      "Progress: 82.54%\n",
      "30\n",
      "max difference =  72.73816680908203\n",
      "data at max difference =  3.1269123554229736\n",
      "imputed at max difference =  75.86508178710938\n",
      "mae =  1.1673529148101807\n",
      "rmse =  35.90986168902853\n",
      "Progress: 82.63%\n",
      "31\n",
      "max difference =  89.5836410522461\n",
      "data at max difference =  3.6001527309417725\n",
      "imputed at max difference =  93.18379211425781\n",
      "mae =  1.8408137559890747\n",
      "rmse =  48.637536090353265\n",
      "Progress: 82.71%\n",
      "32\n",
      "max difference =  76.98590087890625\n",
      "data at max difference =  3.0122029781341553\n",
      "imputed at max difference =  79.99810028076172\n",
      "mae =  1.4927984476089478\n",
      "rmse =  39.45830237347147\n",
      "Progress: 82.80%\n",
      "33\n",
      "max difference =  13.489559173583984\n",
      "data at max difference =  2.9661622047424316\n",
      "imputed at max difference =  16.455720901489258\n",
      "mae =  0.4675394296646118\n",
      "rmse =  9.488308450450068\n",
      "Progress: 82.88%\n",
      "34\n",
      "max difference =  29.751022338867188\n",
      "data at max difference =  3.5691335201263428\n",
      "imputed at max difference =  33.32015609741211\n",
      "mae =  1.0642789602279663\n",
      "rmse =  23.15234905740489\n",
      "Progress: 82.97%\n",
      "35\n",
      "max difference =  40.02819061279297\n",
      "data at max difference =  3.577104330062866\n",
      "imputed at max difference =  43.60529327392578\n",
      "mae =  1.4114495515823364\n",
      "rmse =  27.94984767747962\n",
      "Progress: 83.05%\n",
      "36\n",
      "max difference =  36.691490173339844\n",
      "data at max difference =  2.9348385334014893\n",
      "imputed at max difference =  39.62632751464844\n",
      "mae =  1.2176024913787842\n",
      "rmse =  26.693526558254078\n",
      "Progress: 83.14%\n",
      "37\n",
      "max difference =  54.57984161376953\n",
      "data at max difference =  3.152101755142212\n",
      "imputed at max difference =  57.7319450378418\n",
      "mae =  1.6127026081085205\n",
      "rmse =  35.97035814368206\n",
      "Progress: 83.22%\n",
      "38\n",
      "max difference =  9.73032283782959\n",
      "data at max difference =  3.7342121601104736\n",
      "imputed at max difference =  13.464534759521484\n",
      "mae =  0.17747850716114044\n",
      "rmse =  4.625527091648268\n",
      "Progress: 83.31%\n",
      "39\n",
      "max difference =  11.32509708404541\n",
      "data at max difference =  2.502089738845825\n",
      "imputed at max difference =  13.827186584472656\n",
      "mae =  0.350960910320282\n",
      "rmse =  6.99318263841712\n",
      "Progress: 83.39%\n",
      "40\n",
      "max difference =  97.96884155273438\n",
      "data at max difference =  3.11929988861084\n",
      "imputed at max difference =  101.08814239501953\n",
      "mae =  1.4860543012619019\n",
      "rmse =  46.07018512228261\n",
      "Progress: 83.47%\n",
      "41\n",
      "max difference =  15.060152053833008\n",
      "data at max difference =  2.959125518798828\n",
      "imputed at max difference =  18.019277572631836\n",
      "mae =  0.28015217185020447\n",
      "rmse =  7.168153845745584\n",
      "Progress: 83.56%\n",
      "42\n",
      "max difference =  30.4609375\n",
      "data at max difference =  3.852797746658325\n",
      "imputed at max difference =  34.31373596191406\n",
      "mae =  0.571992039680481\n",
      "rmse =  15.107619575832201\n",
      "Progress: 83.64%\n",
      "43\n",
      "max difference =  45.84605407714844\n",
      "data at max difference =  2.022857904434204\n",
      "imputed at max difference =  47.86891174316406\n",
      "mae =  0.6668980121612549\n",
      "rmse =  21.647304369055707\n",
      "Progress: 83.73%\n",
      "44\n",
      "max difference =  1.9552809000015259\n",
      "data at max difference =  1.6781197786331177\n",
      "imputed at max difference =  3.6334006786346436\n",
      "mae =  0.0985952764749527\n",
      "rmse =  1.3813336413839588\n",
      "Progress: 83.81%\n",
      "45\n",
      "max difference =  12.301852226257324\n",
      "data at max difference =  4.227313041687012\n",
      "imputed at max difference =  16.529165267944336\n",
      "mae =  0.2646443545818329\n",
      "rmse =  6.811854486880095\n",
      "Progress: 83.90%\n",
      "46\n",
      "max difference =  23.141813278198242\n",
      "data at max difference =  3.6604838371276855\n",
      "imputed at max difference =  26.802297592163086\n",
      "mae =  0.42905670404434204\n",
      "rmse =  11.433914847995924\n",
      "Progress: 83.98%\n",
      "47\n",
      "max difference =  7.278175354003906\n",
      "data at max difference =  3.482053518295288\n",
      "imputed at max difference =  10.760229110717773\n",
      "mae =  0.18026362359523773\n",
      "rmse =  3.9894206834876016\n",
      "Progress: 84.07%\n",
      "48\n",
      "max difference =  2.403646469116211\n",
      "data at max difference =  4.654101848602295\n",
      "imputed at max difference =  2.250455379486084\n",
      "mae =  0.13445736467838287\n",
      "rmse =  2.0521112524944805\n",
      "Progress: 84.15%\n",
      "49\n",
      "max difference =  28.85832977294922\n",
      "data at max difference =  4.054295539855957\n",
      "imputed at max difference =  32.91262435913086\n",
      "mae =  0.4788666367530823\n",
      "rmse =  14.135448953379756\n",
      "Progress: 84.24%\n",
      "50\n",
      "max difference =  30.723176956176758\n",
      "data at max difference =  4.473196029663086\n",
      "imputed at max difference =  35.196372985839844\n",
      "mae =  0.384475439786911\n",
      "rmse =  14.083610202955162\n",
      "Progress: 84.32%\n",
      "51\n",
      "max difference =  16.29070281982422\n",
      "data at max difference =  4.304757595062256\n",
      "imputed at max difference =  20.595460891723633\n",
      "mae =  0.2576378881931305\n",
      "rmse =  7.663416986880095\n",
      "Progress: 84.41%\n",
      "52\n",
      "max difference =  0.6462888717651367\n",
      "data at max difference =  3.7667183876037598\n",
      "imputed at max difference =  4.4130072593688965\n",
      "mae =  0.04024599492549896\n",
      "rmse =  0.5162898353908373\n",
      "Progress: 84.49%\n",
      "53\n",
      "max difference =  11.463019371032715\n",
      "data at max difference =  3.7796366214752197\n",
      "imputed at max difference =  15.242655754089355\n",
      "mae =  0.21504518389701843\n",
      "rmse =  5.914246268894361\n",
      "Progress: 84.58%\n",
      "54\n",
      "max difference =  3.2003445625305176\n",
      "data at max difference =  3.8035402297973633\n",
      "imputed at max difference =  7.003884792327881\n",
      "mae =  0.08409074693918228\n",
      "rmse =  1.7289456906525984\n",
      "Progress: 84.66%\n",
      "55\n",
      "max difference =  44.971763610839844\n",
      "data at max difference =  3.2829904556274414\n",
      "imputed at max difference =  48.25475311279297\n",
      "mae =  1.0237929821014404\n",
      "rmse =  27.814129373301633\n",
      "Progress: 84.75%\n",
      "56\n",
      "max difference =  23.602550506591797\n",
      "data at max difference =  3.634439468383789\n",
      "imputed at max difference =  27.236989974975586\n",
      "mae =  0.3031143248081207\n",
      "rmse =  10.814557282820992\n",
      "Progress: 84.83%\n",
      "57\n",
      "max difference =  11.236031532287598\n",
      "data at max difference =  3.476940155029297\n",
      "imputed at max difference =  14.712971687316895\n",
      "mae =  0.15791136026382446\n",
      "rmse =  5.164279440174932\n",
      "Progress: 84.92%\n",
      "58\n",
      "max difference =  97.6818618774414\n",
      "data at max difference =  4.55797004699707\n",
      "imputed at max difference =  102.23983001708984\n",
      "mae =  1.2074066400527954\n",
      "rmse =  44.67398203974185\n",
      "Progress: 85.00%\n",
      "0\n",
      "max difference =  57.37282943725586\n",
      "data at max difference =  3.181105136871338\n",
      "imputed at max difference =  60.55393600463867\n",
      "mae =  0.7963879704475403\n",
      "rmse =  26.35032852836277\n",
      "Progress: 85.08%\n",
      "1\n",
      "max difference =  18.115604400634766\n",
      "data at max difference =  5.496946334838867\n",
      "imputed at max difference =  23.612550735473633\n",
      "mae =  0.3590408265590668\n",
      "rmse =  8.470039035962976\n",
      "Progress: 85.17%\n",
      "2\n",
      "max difference =  140.8984375\n",
      "data at max difference =  5.049139499664307\n",
      "imputed at max difference =  145.94757080078125\n",
      "mae =  3.2508535385131836\n",
      "rmse =  81.19499405570653\n",
      "Progress: 85.25%\n",
      "3\n",
      "max difference =  88.9449234008789\n",
      "data at max difference =  3.0506722927093506\n",
      "imputed at max difference =  91.99559783935547\n",
      "mae =  2.792617082595825\n",
      "rmse =  55.72883406929348\n",
      "Progress: 85.34%\n",
      "4\n",
      "max difference =  247.5188446044922\n",
      "data at max difference =  15.242568016052246\n",
      "imputed at max difference =  262.76141357421875\n",
      "mae =  4.76055908203125\n",
      "rmse =  119.23610521399456\n",
      "Progress: 85.42%\n",
      "5\n",
      "max difference =  128.0792236328125\n",
      "data at max difference =  5.54367733001709\n",
      "imputed at max difference =  133.62289428710938\n",
      "mae =  5.7968950271606445\n",
      "rmse =  96.66316024116848\n",
      "Progress: 85.51%\n",
      "6\n",
      "max difference =  84.90058898925781\n",
      "data at max difference =  2.2160632610321045\n",
      "imputed at max difference =  87.11665344238281\n",
      "mae =  3.122565507888794\n",
      "rmse =  51.96088442595108\n",
      "Progress: 85.59%\n",
      "7\n",
      "max difference =  54.68490219116211\n",
      "data at max difference =  4.087564945220947\n",
      "imputed at max difference =  58.77246856689453\n",
      "mae =  1.4534753561019897\n",
      "rmse =  33.895348590353265\n",
      "Progress: 85.68%\n",
      "8\n",
      "max difference =  115.42854309082031\n",
      "data at max difference =  4.2853007316589355\n",
      "imputed at max difference =  119.7138442993164\n",
      "mae =  2.577515125274658\n",
      "rmse =  57.3349609375\n",
      "Progress: 85.76%\n",
      "9\n",
      "max difference =  33.520530700683594\n",
      "data at max difference =  2.8465027809143066\n",
      "imputed at max difference =  36.367034912109375\n",
      "mae =  0.7082395553588867\n",
      "rmse =  17.776462720788043\n",
      "Progress: 85.85%\n",
      "10\n",
      "max difference =  36.664249420166016\n",
      "data at max difference =  3.747382640838623\n",
      "imputed at max difference =  40.4116325378418\n",
      "mae =  1.0541681051254272\n",
      "rmse =  22.6129150390625\n",
      "Progress: 85.93%\n",
      "11\n",
      "max difference =  66.65070343017578\n",
      "data at max difference =  2.8884100914001465\n",
      "imputed at max difference =  69.53911590576172\n",
      "mae =  1.4215970039367676\n",
      "rmse =  35.919369904891305\n",
      "Progress: 86.02%\n",
      "12\n",
      "max difference =  40.481468200683594\n",
      "data at max difference =  3.4866089820861816\n",
      "imputed at max difference =  43.96807861328125\n",
      "mae =  0.983985960483551\n",
      "rmse =  22.998115871263586\n",
      "Progress: 86.10%\n",
      "13\n",
      "max difference =  35.20851135253906\n",
      "data at max difference =  3.6411452293395996\n",
      "imputed at max difference =  38.84965515136719\n",
      "mae =  0.7449963092803955\n",
      "rmse =  19.9013844365659\n",
      "Progress: 86.19%\n",
      "14\n",
      "max difference =  19.29655647277832\n",
      "data at max difference =  3.4648749828338623\n",
      "imputed at max difference =  22.761430740356445\n",
      "mae =  0.3273298442363739\n",
      "rmse =  9.065965735394022\n",
      "Progress: 86.27%\n",
      "15\n",
      "max difference =  26.01799201965332\n",
      "data at max difference =  4.187092304229736\n",
      "imputed at max difference =  30.2050838470459\n",
      "mae =  0.358110636472702\n",
      "rmse =  11.936414635699728\n",
      "Progress: 86.36%\n",
      "16\n",
      "max difference =  13.906984329223633\n",
      "data at max difference =  4.297800540924072\n",
      "imputed at max difference =  18.204784393310547\n",
      "mae =  0.3065601587295532\n",
      "rmse =  6.911520253057065\n",
      "Progress: 86.44%\n",
      "17\n",
      "max difference =  14.131401062011719\n",
      "data at max difference =  3.7386417388916016\n",
      "imputed at max difference =  17.87004280090332\n",
      "mae =  0.3464777171611786\n",
      "rmse =  8.174774169921875\n",
      "Progress: 86.53%\n",
      "18\n",
      "max difference =  16.31726837158203\n",
      "data at max difference =  3.0454649925231934\n",
      "imputed at max difference =  19.362733840942383\n",
      "mae =  0.24014684557914734\n",
      "rmse =  7.5054168701171875\n",
      "Progress: 86.61%\n",
      "19\n",
      "max difference =  10.871044158935547\n",
      "data at max difference =  2.7446513175964355\n",
      "imputed at max difference =  13.61569595336914\n",
      "mae =  0.2575339078903198\n",
      "rmse =  5.800826362941576\n",
      "Progress: 86.69%\n",
      "20\n",
      "max difference =  55.60063552856445\n",
      "data at max difference =  3.635903835296631\n",
      "imputed at max difference =  59.23653793334961\n",
      "mae =  0.7756525874137878\n",
      "rmse =  26.02436098845109\n",
      "Progress: 86.78%\n",
      "21\n",
      "max difference =  23.432220458984375\n",
      "data at max difference =  2.794804811477661\n",
      "imputed at max difference =  26.227025985717773\n",
      "mae =  0.5226634740829468\n",
      "rmse =  13.133594015370246\n",
      "Progress: 86.86%\n",
      "22\n",
      "max difference =  30.078168869018555\n",
      "data at max difference =  3.7011895179748535\n",
      "imputed at max difference =  33.77935791015625\n",
      "mae =  0.6967340707778931\n",
      "rmse =  18.577094036599863\n",
      "Progress: 86.95%\n",
      "23\n",
      "max difference =  20.544864654541016\n",
      "data at max difference =  3.0022151470184326\n",
      "imputed at max difference =  23.54707908630371\n",
      "mae =  0.6285051107406616\n",
      "rmse =  13.239241890285324\n",
      "Progress: 87.03%\n",
      "24\n",
      "max difference =  40.092044830322266\n",
      "data at max difference =  2.5594370365142822\n",
      "imputed at max difference =  42.65148162841797\n",
      "mae =  0.5644705891609192\n",
      "rmse =  18.607731031334918\n",
      "Progress: 87.12%\n",
      "25\n",
      "max difference =  58.02082824707031\n",
      "data at max difference =  2.305284261703491\n",
      "imputed at max difference =  60.32611083984375\n",
      "mae =  1.7748751640319824\n",
      "rmse =  38.6318359375\n",
      "Progress: 87.20%\n",
      "26\n",
      "max difference =  70.50489807128906\n",
      "data at max difference =  2.8632819652557373\n",
      "imputed at max difference =  73.36817932128906\n",
      "mae =  0.795312225818634\n",
      "rmse =  32.16642429517663\n",
      "Progress: 87.29%\n",
      "27\n",
      "max difference =  57.420501708984375\n",
      "data at max difference =  3.5885987281799316\n",
      "imputed at max difference =  61.00910186767578\n",
      "mae =  1.6287966966629028\n",
      "rmse =  36.04339599609375\n",
      "Progress: 87.37%\n",
      "28\n",
      "max difference =  23.956562042236328\n",
      "data at max difference =  3.075853109359741\n",
      "imputed at max difference =  27.03241539001465\n",
      "mae =  1.1712652444839478\n",
      "rmse =  21.002183997112773\n",
      "Progress: 87.46%\n",
      "29\n",
      "max difference =  65.42910766601562\n",
      "data at max difference =  3.1065943241119385\n",
      "imputed at max difference =  68.53570556640625\n",
      "mae =  0.9390682578086853\n",
      "rmse =  30.34080173658288\n",
      "Progress: 87.54%\n",
      "30\n",
      "max difference =  75.24391174316406\n",
      "data at max difference =  3.594463348388672\n",
      "imputed at max difference =  78.83837127685547\n",
      "mae =  2.1607229709625244\n",
      "rmse =  51.64699919327445\n",
      "Progress: 87.63%\n",
      "31\n",
      "max difference =  14.069241523742676\n",
      "data at max difference =  2.297074317932129\n",
      "imputed at max difference =  16.366315841674805\n",
      "mae =  0.4876391887664795\n",
      "rmse =  9.593944383704143\n",
      "Progress: 87.71%\n",
      "32\n",
      "max difference =  27.497539520263672\n",
      "data at max difference =  3.0982155799865723\n",
      "imputed at max difference =  30.595754623413086\n",
      "mae =  0.6729599833488464\n",
      "rmse =  15.262727156929348\n",
      "Progress: 87.80%\n",
      "33\n",
      "max difference =  77.23003387451172\n",
      "data at max difference =  2.9661622047424316\n",
      "imputed at max difference =  80.19619750976562\n",
      "mae =  1.7188059091567993\n",
      "rmse =  42.21405029296875\n",
      "Progress: 87.88%\n",
      "34\n",
      "max difference =  88.33065795898438\n",
      "data at max difference =  3.1056199073791504\n",
      "imputed at max difference =  91.436279296875\n",
      "mae =  1.1093894243240356\n",
      "rmse =  40.516609523607336\n",
      "Progress: 87.97%\n",
      "35\n",
      "max difference =  17.878686904907227\n",
      "data at max difference =  3.109546422958374\n",
      "imputed at max difference =  20.98823356628418\n",
      "mae =  0.3117552399635315\n",
      "rmse =  8.555404663085938\n",
      "Progress: 88.05%\n",
      "36\n",
      "max difference =  23.823898315429688\n",
      "data at max difference =  3.6129720211029053\n",
      "imputed at max difference =  27.436870574951172\n",
      "mae =  0.6778618693351746\n",
      "rmse =  15.522479513417121\n",
      "Progress: 88.14%\n",
      "37\n",
      "max difference =  28.198928833007812\n",
      "data at max difference =  3.746554136276245\n",
      "imputed at max difference =  31.94548225402832\n",
      "mae =  0.6743113398551941\n",
      "rmse =  15.978128184442935\n",
      "Progress: 88.22%\n",
      "38\n",
      "max difference =  55.29155731201172\n",
      "data at max difference =  3.856018304824829\n",
      "imputed at max difference =  59.14757537841797\n",
      "mae =  1.3512721061706543\n",
      "rmse =  33.35281770125679\n",
      "Progress: 88.31%\n",
      "39\n",
      "max difference =  14.403727531433105\n",
      "data at max difference =  3.049424409866333\n",
      "imputed at max difference =  17.45315170288086\n",
      "mae =  0.4409666657447815\n",
      "rmse =  9.531866322393002\n",
      "Progress: 88.39%\n",
      "40\n",
      "max difference =  39.81349182128906\n",
      "data at max difference =  2.844825029373169\n",
      "imputed at max difference =  42.65831756591797\n",
      "mae =  0.6587851047515869\n",
      "rmse =  18.974220607591715\n",
      "Progress: 88.47%\n",
      "41\n",
      "max difference =  1.401780128479004\n",
      "data at max difference =  1.7970588207244873\n",
      "imputed at max difference =  3.198838949203491\n",
      "mae =  0.09281749278306961\n",
      "rmse =  1.2469227003014605\n",
      "Progress: 88.56%\n",
      "42\n",
      "max difference =  9.93733024597168\n",
      "data at max difference =  1.6908007860183716\n",
      "imputed at max difference =  11.628130912780762\n",
      "mae =  0.33559665083885193\n",
      "rmse =  7.286394865616508\n",
      "Progress: 88.64%\n",
      "43\n",
      "max difference =  30.819122314453125\n",
      "data at max difference =  3.081096887588501\n",
      "imputed at max difference =  33.90021896362305\n",
      "mae =  0.4264371395111084\n",
      "rmse =  14.137644892153533\n",
      "Progress: 88.73%\n",
      "44\n",
      "max difference =  40.121360778808594\n",
      "data at max difference =  3.488417148590088\n",
      "imputed at max difference =  43.609779357910156\n",
      "mae =  0.7433385252952576\n",
      "rmse =  22.435926354449727\n",
      "Progress: 88.81%\n",
      "45\n",
      "max difference =  4.030346870422363\n",
      "data at max difference =  4.227313041687012\n",
      "imputed at max difference =  8.257659912109375\n",
      "mae =  0.12656675279140472\n",
      "rmse =  2.1285894642705503\n",
      "Progress: 88.90%\n",
      "46\n",
      "max difference =  8.787745475769043\n",
      "data at max difference =  3.3105075359344482\n",
      "imputed at max difference =  12.09825325012207\n",
      "mae =  0.17926707863807678\n",
      "rmse =  4.243476867675781\n",
      "Progress: 88.98%\n",
      "47\n",
      "max difference =  4.776300430297852\n",
      "data at max difference =  3.482053518295288\n",
      "imputed at max difference =  8.258354187011719\n",
      "mae =  0.14586316049098969\n",
      "rmse =  2.567097871199898\n",
      "Progress: 89.07%\n",
      "48\n",
      "max difference =  2.4894323348999023\n",
      "data at max difference =  3.996349573135376\n",
      "imputed at max difference =  1.506917119026184\n",
      "mae =  0.10249343514442444\n",
      "rmse =  1.5729453045388926\n",
      "Progress: 89.15%\n",
      "49\n",
      "max difference =  32.37038803100586\n",
      "data at max difference =  3.6701767444610596\n",
      "imputed at max difference =  36.040565490722656\n",
      "mae =  0.4835287034511566\n",
      "rmse =  15.291290283203123\n",
      "Progress: 89.24%\n",
      "50\n",
      "max difference =  38.10481643676758\n",
      "data at max difference =  3.7768969535827637\n",
      "imputed at max difference =  41.8817138671875\n",
      "mae =  0.5900668501853943\n",
      "rmse =  18.854898203974184\n",
      "Progress: 89.32%\n",
      "51\n",
      "max difference =  31.069791793823242\n",
      "data at max difference =  4.304757595062256\n",
      "imputed at max difference =  35.374549865722656\n",
      "mae =  0.5526897311210632\n",
      "rmse =  15.395598038383152\n",
      "Progress: 89.41%\n",
      "52\n",
      "max difference =  29.633399963378906\n",
      "data at max difference =  3.488410711288452\n",
      "imputed at max difference =  33.12181091308594\n",
      "mae =  0.42141035199165344\n",
      "rmse =  14.178611423658289\n",
      "Progress: 89.49%\n",
      "53\n",
      "max difference =  51.505226135253906\n",
      "data at max difference =  4.1212592124938965\n",
      "imputed at max difference =  55.62648391723633\n",
      "mae =  0.5577849745750427\n",
      "rmse =  23.49486773947011\n",
      "Progress: 89.58%\n",
      "54\n",
      "max difference =  8.104323387145996\n",
      "data at max difference =  3.8035402297973633\n",
      "imputed at max difference =  11.90786361694336\n",
      "mae =  0.13227519392967224\n",
      "rmse =  3.85674120032269\n",
      "Progress: 89.66%\n",
      "55\n",
      "max difference =  30.215362548828125\n",
      "data at max difference =  3.2829904556274414\n",
      "imputed at max difference =  33.49835205078125\n",
      "mae =  0.6211936473846436\n",
      "rmse =  19.119873046875\n",
      "Progress: 89.75%\n",
      "56\n",
      "max difference =  103.4281997680664\n",
      "data at max difference =  3.957808017730713\n",
      "imputed at max difference =  107.3860092163086\n",
      "mae =  1.562264084815979\n",
      "rmse =  49.704674762228265\n",
      "Progress: 89.83%\n",
      "57\n",
      "max difference =  0.7445416450500488\n",
      "data at max difference =  4.061976432800293\n",
      "imputed at max difference =  4.806518077850342\n",
      "mae =  0.049004800617694855\n",
      "rmse =  0.6203223518703295\n",
      "Progress: 89.92%\n",
      "58\n",
      "max difference =  23.854461669921875\n",
      "data at max difference =  2.351210355758667\n",
      "imputed at max difference =  26.205671310424805\n",
      "mae =  0.67380690574646\n",
      "rmse =  13.432576055112092\n",
      "Progress: 90.00%\n",
      "0\n",
      "max difference =  54.551570892333984\n",
      "data at max difference =  3.181105136871338\n",
      "imputed at max difference =  57.7326774597168\n",
      "mae =  0.8481311798095703\n",
      "rmse =  26.048122240149457\n",
      "Progress: 90.08%\n",
      "1\n",
      "max difference =  96.62039184570312\n",
      "data at max difference =  4.692869663238525\n",
      "imputed at max difference =  101.31326293945312\n",
      "mae =  1.3196629285812378\n",
      "rmse =  44.696326214334235\n",
      "Progress: 90.17%\n",
      "2\n",
      "max difference =  28.408937454223633\n",
      "data at max difference =  5.78329610824585\n",
      "imputed at max difference =  34.19223403930664\n",
      "mae =  1.2188538312911987\n",
      "rmse =  21.20743063221807\n",
      "Progress: 90.25%\n",
      "3\n",
      "max difference =  112.01576232910156\n",
      "data at max difference =  12.65227222442627\n",
      "imputed at max difference =  124.66803741455078\n",
      "mae =  6.61208963394165\n",
      "rmse =  103.19368843410327\n",
      "Progress: 90.34%\n",
      "4\n",
      "max difference =  101.45228576660156\n",
      "data at max difference =  3.644343614578247\n",
      "imputed at max difference =  105.09662628173828\n",
      "mae =  2.745288610458374\n",
      "rmse =  55.853818147078805\n",
      "Progress: 90.42%\n",
      "5\n",
      "max difference =  99.06745910644531\n",
      "data at max difference =  -0.14749836921691895\n",
      "imputed at max difference =  98.91996002197266\n",
      "mae =  3.3946104049682617\n",
      "rmse =  65.95750891644022\n",
      "Progress: 90.51%\n",
      "6\n",
      "max difference =  113.49762725830078\n",
      "data at max difference =  4.688121318817139\n",
      "imputed at max difference =  118.18574523925781\n",
      "mae =  1.85725736618042\n",
      "rmse =  53.69291886039402\n",
      "Progress: 90.59%\n",
      "7\n",
      "max difference =  51.13748550415039\n",
      "data at max difference =  3.7007248401641846\n",
      "imputed at max difference =  54.83821105957031\n",
      "mae =  1.0689102411270142\n",
      "rmse =  25.191947605298914\n",
      "Progress: 90.68%\n",
      "8\n",
      "max difference =  45.45014190673828\n",
      "data at max difference =  2.540346622467041\n",
      "imputed at max difference =  47.9904899597168\n",
      "mae =  1.3937935829162598\n",
      "rmse =  27.903039020040758\n",
      "Progress: 90.76%\n",
      "9\n",
      "max difference =  37.329017639160156\n",
      "data at max difference =  3.7451744079589844\n",
      "imputed at max difference =  41.07419204711914\n",
      "mae =  0.7313106656074524\n",
      "rmse =  18.52410888671875\n",
      "Progress: 90.85%\n",
      "10\n",
      "max difference =  53.90141677856445\n",
      "data at max difference =  3.747382640838623\n",
      "imputed at max difference =  57.648799896240234\n",
      "mae =  1.3793761730194092\n",
      "rmse =  31.88468070652174\n",
      "Progress: 90.93%\n",
      "11\n",
      "max difference =  52.755645751953125\n",
      "data at max difference =  3.75504207611084\n",
      "imputed at max difference =  56.51068878173828\n",
      "mae =  1.1878796815872192\n",
      "rmse =  33.75092083474864\n",
      "Progress: 91.02%\n",
      "12\n",
      "max difference =  31.227642059326172\n",
      "data at max difference =  3.798804521560669\n",
      "imputed at max difference =  35.02644729614258\n",
      "mae =  0.5534251928329468\n",
      "rmse =  15.295901091202445\n",
      "Progress: 91.10%\n",
      "13\n",
      "max difference =  14.309072494506836\n",
      "data at max difference =  3.3944644927978516\n",
      "imputed at max difference =  17.703536987304688\n",
      "mae =  0.3082258701324463\n",
      "rmse =  6.950580762780231\n",
      "Progress: 91.19%\n",
      "14\n",
      "max difference =  92.21220397949219\n",
      "data at max difference =  3.136535882949829\n",
      "imputed at max difference =  95.34873962402344\n",
      "mae =  1.0679162740707397\n",
      "rmse =  42.094734523607336\n",
      "Progress: 91.27%\n",
      "15\n",
      "max difference =  38.535396575927734\n",
      "data at max difference =  3.5889499187469482\n",
      "imputed at max difference =  42.12434768676758\n",
      "mae =  0.7932546734809875\n",
      "rmse =  20.203653086786684\n",
      "Progress: 91.36%\n",
      "16\n",
      "max difference =  101.8280258178711\n",
      "data at max difference =  3.6800894737243652\n",
      "imputed at max difference =  105.50811767578125\n",
      "mae =  1.4584848880767822\n",
      "rmse =  47.67589270550271\n",
      "Progress: 91.44%\n",
      "17\n",
      "max difference =  72.69989013671875\n",
      "data at max difference =  3.7386417388916016\n",
      "imputed at max difference =  76.43852996826172\n",
      "mae =  1.3614169359207153\n",
      "rmse =  36.68404753311821\n",
      "Progress: 91.53%\n",
      "18\n",
      "max difference =  23.05866813659668\n",
      "data at max difference =  2.734581470489502\n",
      "imputed at max difference =  25.793249130249023\n",
      "mae =  0.5495163798332214\n",
      "rmse =  13.240231721297555\n",
      "Progress: 91.61%\n",
      "19\n",
      "max difference =  50.78254318237305\n",
      "data at max difference =  3.578327178955078\n",
      "imputed at max difference =  54.360870361328125\n",
      "mae =  0.9506698250770569\n",
      "rmse =  26.51118800951087\n",
      "Progress: 91.69%\n",
      "20\n",
      "max difference =  34.7201042175293\n",
      "data at max difference =  2.80688738822937\n",
      "imputed at max difference =  37.52699279785156\n",
      "mae =  0.8791685104370117\n",
      "rmse =  20.957268756368887\n",
      "Progress: 91.78%\n",
      "21\n",
      "max difference =  3.8411991596221924\n",
      "data at max difference =  2.794804811477661\n",
      "imputed at max difference =  6.6360039710998535\n",
      "mae =  0.1214900016784668\n",
      "rmse =  2.0899346393087637\n",
      "Progress: 91.86%\n",
      "22\n",
      "max difference =  24.103103637695312\n",
      "data at max difference =  2.8592002391815186\n",
      "imputed at max difference =  26.962303161621094\n",
      "mae =  0.33630892634391785\n",
      "rmse =  11.079076352326766\n",
      "Progress: 91.95%\n",
      "23\n",
      "max difference =  62.16179275512695\n",
      "data at max difference =  3.0022151470184326\n",
      "imputed at max difference =  65.16400909423828\n",
      "mae =  1.187522530555725\n",
      "rmse =  33.547575577445656\n",
      "Progress: 92.03%\n",
      "24\n",
      "max difference =  29.886014938354492\n",
      "data at max difference =  3.0082943439483643\n",
      "imputed at max difference =  32.894309997558594\n",
      "mae =  0.7191053032875061\n",
      "rmse =  17.93809044879416\n",
      "Progress: 92.12%\n",
      "25\n",
      "max difference =  27.810075759887695\n",
      "data at max difference =  3.3274190425872803\n",
      "imputed at max difference =  31.137495040893555\n",
      "mae =  0.9805499315261841\n",
      "rmse =  19.42200237771739\n",
      "Progress: 92.20%\n",
      "26\n",
      "max difference =  26.604068756103516\n",
      "data at max difference =  2.6586732864379883\n",
      "imputed at max difference =  29.262741088867188\n",
      "mae =  1.2078319787979126\n",
      "rmse =  22.188525655995246\n",
      "Progress: 92.29%\n",
      "27\n",
      "max difference =  32.998016357421875\n",
      "data at max difference =  3.0260767936706543\n",
      "imputed at max difference =  36.02409362792969\n",
      "mae =  0.7987812757492065\n",
      "rmse =  19.440469493036687\n",
      "Progress: 92.37%\n",
      "28\n",
      "max difference =  65.23330688476562\n",
      "data at max difference =  3.531285285949707\n",
      "imputed at max difference =  68.76459503173828\n",
      "mae =  0.8946263194084167\n",
      "rmse =  30.072944972826086\n",
      "Progress: 92.46%\n",
      "29\n",
      "max difference =  29.422218322753906\n",
      "data at max difference =  3.688014030456543\n",
      "imputed at max difference =  33.110233306884766\n",
      "mae =  0.9456069469451904\n",
      "rmse =  19.480053445567254\n",
      "Progress: 92.54%\n",
      "30\n",
      "max difference =  95.2098159790039\n",
      "data at max difference =  3.1269123554229736\n",
      "imputed at max difference =  98.33673095703125\n",
      "mae =  1.6312724351882935\n",
      "rmse =  47.417634383491844\n",
      "Progress: 92.63%\n",
      "31\n",
      "max difference =  224.33290100097656\n",
      "data at max difference =  3.720954418182373\n",
      "imputed at max difference =  228.05384826660156\n",
      "mae =  3.6990182399749756\n",
      "rmse =  109.38180409307066\n",
      "Progress: 92.71%\n",
      "32\n",
      "max difference =  55.4001350402832\n",
      "data at max difference =  3.0122029781341553\n",
      "imputed at max difference =  58.41233825683594\n",
      "mae =  1.285791277885437\n",
      "rmse =  30.29003375509511\n",
      "Progress: 92.80%\n",
      "33\n",
      "max difference =  33.3013916015625\n",
      "data at max difference =  2.9661622047424316\n",
      "imputed at max difference =  36.267555236816406\n",
      "mae =  1.0130395889282227\n",
      "rmse =  22.825532332710598\n",
      "Progress: 92.88%\n",
      "34\n",
      "max difference =  150.3287353515625\n",
      "data at max difference =  3.1056199073791504\n",
      "imputed at max difference =  153.43435668945312\n",
      "mae =  1.6404272317886353\n",
      "rmse =  68.6155475118886\n",
      "Progress: 92.97%\n",
      "35\n",
      "max difference =  41.33366394042969\n",
      "data at max difference =  2.8760108947753906\n",
      "imputed at max difference =  44.20967483520508\n",
      "mae =  0.7583086490631104\n",
      "rmse =  20.874494469684105\n",
      "Progress: 93.05%\n",
      "36\n",
      "max difference =  51.26857376098633\n",
      "data at max difference =  3.6129720211029053\n",
      "imputed at max difference =  54.88154602050781\n",
      "mae =  0.6218165159225464\n",
      "rmse =  23.43296482252038\n",
      "Progress: 93.14%\n",
      "37\n",
      "max difference =  84.24689483642578\n",
      "data at max difference =  3.746554136276245\n",
      "imputed at max difference =  87.99344635009766\n",
      "mae =  2.3720767498016357\n",
      "rmse =  58.273978855298914\n",
      "Progress: 93.22%\n",
      "38\n",
      "max difference =  40.579795837402344\n",
      "data at max difference =  3.2595252990722656\n",
      "imputed at max difference =  43.83932113647461\n",
      "mae =  0.5861606001853943\n",
      "rmse =  19.1671898883322\n",
      "Progress: 93.31%\n",
      "39\n",
      "max difference =  84.0336685180664\n",
      "data at max difference =  2.502089738845825\n",
      "imputed at max difference =  86.53575897216797\n",
      "mae =  1.175716757774353\n",
      "rmse =  39.301176651664406\n",
      "Progress: 93.39%\n",
      "40\n",
      "max difference =  65.62295532226562\n",
      "data at max difference =  2.844825029373169\n",
      "imputed at max difference =  68.46778106689453\n",
      "mae =  1.6812540292739868\n",
      "rmse =  43.229733674422555\n",
      "Progress: 93.47%\n",
      "41\n",
      "max difference =  12.479731559753418\n",
      "data at max difference =  1.7181442975997925\n",
      "imputed at max difference =  14.1978759765625\n",
      "mae =  0.21409828960895538\n",
      "rmse =  5.809948465098506\n",
      "Progress: 93.56%\n",
      "42\n",
      "max difference =  23.772457122802734\n",
      "data at max difference =  3.536712169647217\n",
      "imputed at max difference =  27.30916976928711\n",
      "mae =  0.4436556398868561\n",
      "rmse =  12.463952105978262\n",
      "Progress: 93.64%\n",
      "43\n",
      "max difference =  19.232341766357422\n",
      "data at max difference =  2.0938096046447754\n",
      "imputed at max difference =  21.32615089416504\n",
      "mae =  0.36297109723091125\n",
      "rmse =  9.19903962508492\n",
      "Progress: 93.73%\n",
      "44\n",
      "max difference =  9.535633087158203\n",
      "data at max difference =  4.07535982131958\n",
      "imputed at max difference =  13.610992431640625\n",
      "mae =  0.20212513208389282\n",
      "rmse =  4.775153782056726\n",
      "Progress: 93.81%\n",
      "45\n",
      "max difference =  8.649685859680176\n",
      "data at max difference =  1.978124737739563\n",
      "imputed at max difference =  10.62781047821045\n",
      "mae =  0.24482901394367218\n",
      "rmse =  5.130823218304178\n",
      "Progress: 93.90%\n",
      "46\n",
      "max difference =  12.316137313842773\n",
      "data at max difference =  3.933950424194336\n",
      "imputed at max difference =  16.25008773803711\n",
      "mae =  0.3168160617351532\n",
      "rmse =  7.148643161939539\n",
      "Progress: 93.98%\n",
      "47\n",
      "max difference =  1.7588741779327393\n",
      "data at max difference =  4.468069553375244\n",
      "imputed at max difference =  2.709195375442505\n",
      "mae =  0.07935900241136551\n",
      "rmse =  1.139684013698412\n",
      "Progress: 94.07%\n",
      "48\n",
      "max difference =  10.529340744018555\n",
      "data at max difference =  3.6271133422851562\n",
      "imputed at max difference =  14.156454086303711\n",
      "mae =  0.2074027955532074\n",
      "rmse =  5.052747975225034\n",
      "Progress: 94.15%\n",
      "49\n",
      "max difference =  41.687896728515625\n",
      "data at max difference =  4.738558769226074\n",
      "imputed at max difference =  46.426456451416016\n",
      "mae =  0.7340863347053528\n",
      "rmse =  20.365966796875\n",
      "Progress: 94.24%\n",
      "50\n",
      "max difference =  2.9289498329162598\n",
      "data at max difference =  4.864070892333984\n",
      "imputed at max difference =  1.935120940208435\n",
      "mae =  0.0924600213766098\n",
      "rmse =  1.6604813285495925\n",
      "Progress: 94.32%\n",
      "51\n",
      "max difference =  9.41710090637207\n",
      "data at max difference =  5.0189433097839355\n",
      "imputed at max difference =  14.436044692993164\n",
      "mae =  0.15588462352752686\n",
      "rmse =  4.418638809867527\n",
      "Progress: 94.41%\n",
      "52\n",
      "max difference =  6.901800155639648\n",
      "data at max difference =  3.488410711288452\n",
      "imputed at max difference =  10.39021110534668\n",
      "mae =  0.14952902495861053\n",
      "rmse =  4.0344410771908965\n",
      "Progress: 94.49%\n",
      "53\n",
      "max difference =  4.922051429748535\n",
      "data at max difference =  3.171074867248535\n",
      "imputed at max difference =  8.09312629699707\n",
      "mae =  0.11843819171190262\n",
      "rmse =  2.536800550377887\n",
      "Progress: 94.58%\n",
      "54\n",
      "max difference =  9.028972625732422\n",
      "data at max difference =  3.536703109741211\n",
      "imputed at max difference =  12.565675735473633\n",
      "mae =  0.1598282903432846\n",
      "rmse =  4.493726315705673\n",
      "Progress: 94.66%\n",
      "55\n",
      "max difference =  10.810497283935547\n",
      "data at max difference =  3.2829904556274414\n",
      "imputed at max difference =  14.093487739562988\n",
      "mae =  0.1786820888519287\n",
      "rmse =  5.154247449791949\n",
      "Progress: 94.75%\n",
      "56\n",
      "max difference =  24.30933380126953\n",
      "data at max difference =  3.0583953857421875\n",
      "imputed at max difference =  27.36772918701172\n",
      "mae =  0.43635955452919006\n",
      "rmse =  12.308240807574728\n",
      "Progress: 94.83%\n",
      "57\n",
      "max difference =  20.347007751464844\n",
      "data at max difference =  3.1485235691070557\n",
      "imputed at max difference =  23.49553108215332\n",
      "mae =  0.2730277478694916\n",
      "rmse =  9.36445949388587\n",
      "Progress: 94.92%\n",
      "58\n",
      "max difference =  19.474353790283203\n",
      "data at max difference =  3.1417088508605957\n",
      "imputed at max difference =  22.61606216430664\n",
      "mae =  0.531868040561676\n",
      "rmse =  10.97184886103091\n",
      "Progress: 95.00%\n",
      "0\n",
      "max difference =  42.166446685791016\n",
      "data at max difference =  2.3850014209747314\n",
      "imputed at max difference =  44.551448822021484\n",
      "mae =  0.7167324423789978\n",
      "rmse =  19.643614395805027\n",
      "Progress: 95.08%\n",
      "1\n",
      "max difference =  34.359947204589844\n",
      "data at max difference =  5.496946334838867\n",
      "imputed at max difference =  39.856895446777344\n",
      "mae =  1.1299604177474976\n",
      "rmse =  24.46570354959239\n",
      "Progress: 95.17%\n",
      "2\n",
      "max difference =  152.45152282714844\n",
      "data at max difference =  5.049139499664307\n",
      "imputed at max difference =  157.5006561279297\n",
      "mae =  2.5036778450012207\n",
      "rmse =  73.47278362771739\n",
      "Progress: 95.25%\n",
      "3\n",
      "max difference =  53.99641799926758\n",
      "data at max difference =  5.660995960235596\n",
      "imputed at max difference =  59.657413482666016\n",
      "mae =  2.867743492126465\n",
      "rmse =  45.795717985733695\n",
      "Progress: 95.34%\n",
      "4\n",
      "max difference =  140.62881469726562\n",
      "data at max difference =  15.242568016052246\n",
      "imputed at max difference =  155.8713836669922\n",
      "mae =  4.680956840515137\n",
      "rmse =  92.70174507472827\n",
      "Progress: 95.42%\n",
      "5\n",
      "max difference =  99.4677505493164\n",
      "data at max difference =  5.54367733001709\n",
      "imputed at max difference =  105.01142883300781\n",
      "mae =  2.584918260574341\n",
      "rmse =  56.42067021908967\n",
      "Progress: 95.51%\n",
      "6\n",
      "max difference =  157.23345947265625\n",
      "data at max difference =  4.688121318817139\n",
      "imputed at max difference =  161.9215850830078\n",
      "mae =  3.695408582687378\n",
      "rmse =  82.11162003226902\n",
      "Progress: 95.59%\n",
      "7\n",
      "max difference =  25.048128128051758\n",
      "data at max difference =  4.776676654815674\n",
      "imputed at max difference =  29.824804306030273\n",
      "mae =  0.9650541543960571\n",
      "rmse =  17.52190631368886\n",
      "Progress: 95.68%\n",
      "8\n",
      "max difference =  96.06993103027344\n",
      "data at max difference =  4.5931077003479\n",
      "imputed at max difference =  100.66304016113281\n",
      "mae =  1.7493035793304443\n",
      "rmse =  47.38437818444293\n",
      "Progress: 95.76%\n",
      "9\n",
      "max difference =  65.19316864013672\n",
      "data at max difference =  3.422072172164917\n",
      "imputed at max difference =  68.61524200439453\n",
      "mae =  2.1605710983276367\n",
      "rmse =  44.52417522927989\n",
      "Progress: 95.85%\n",
      "10\n",
      "max difference =  18.862762451171875\n",
      "data at max difference =  2.881241798400879\n",
      "imputed at max difference =  21.744003295898438\n",
      "mae =  0.5261510014533997\n",
      "rmse =  11.032153585682744\n",
      "Progress: 95.93%\n",
      "11\n",
      "max difference =  25.463001251220703\n",
      "data at max difference =  3.75504207611084\n",
      "imputed at max difference =  29.21804428100586\n",
      "mae =  0.648569643497467\n",
      "rmse =  14.488114066745924\n",
      "Progress: 96.02%\n",
      "12\n",
      "max difference =  57.50579833984375\n",
      "data at max difference =  3.798804521560669\n",
      "imputed at max difference =  61.304603576660156\n",
      "mae =  0.7809397578239441\n",
      "rmse =  26.47167703379755\n",
      "Progress: 96.10%\n",
      "13\n",
      "max difference =  22.957244873046875\n",
      "data at max difference =  3.078768014907837\n",
      "imputed at max difference =  26.036012649536133\n",
      "mae =  0.3837849795818329\n",
      "rmse =  10.738741667374322\n",
      "Progress: 96.19%\n",
      "14\n",
      "max difference =  84.22786712646484\n",
      "data at max difference =  3.4648749828338623\n",
      "imputed at max difference =  87.69274139404297\n",
      "mae =  1.172818660736084\n",
      "rmse =  39.33372431216033\n",
      "Progress: 96.27%\n",
      "15\n",
      "max difference =  126.2271728515625\n",
      "data at max difference =  3.25317645072937\n",
      "imputed at max difference =  129.4803466796875\n",
      "mae =  1.840014100074768\n",
      "rmse =  59.92505944293478\n",
      "Progress: 96.36%\n",
      "16\n",
      "max difference =  78.46858978271484\n",
      "data at max difference =  3.9510416984558105\n",
      "imputed at max difference =  82.41963195800781\n",
      "mae =  1.355171799659729\n",
      "rmse =  39.59116264011549\n",
      "Progress: 96.44%\n",
      "17\n",
      "max difference =  89.07312774658203\n",
      "data at max difference =  3.7386417388916016\n",
      "imputed at max difference =  92.811767578125\n",
      "mae =  1.2724716663360596\n",
      "rmse =  41.848447053328805\n",
      "Progress: 96.53%\n",
      "18\n",
      "max difference =  46.13793182373047\n",
      "data at max difference =  3.0454649925231934\n",
      "imputed at max difference =  49.18339538574219\n",
      "mae =  0.8725080490112305\n",
      "rmse =  23.47467041015625\n",
      "Progress: 96.61%\n",
      "19\n",
      "max difference =  10.757427215576172\n",
      "data at max difference =  2.7446513175964355\n",
      "imputed at max difference =  13.502079010009766\n",
      "mae =  0.2510216534137726\n",
      "rmse =  5.659474248471468\n",
      "Progress: 96.69%\n",
      "20\n",
      "max difference =  26.474485397338867\n",
      "data at max difference =  3.3378450870513916\n",
      "imputed at max difference =  29.81233024597168\n",
      "mae =  0.5799126029014587\n",
      "rmse =  15.62503715183424\n",
      "Progress: 96.78%\n",
      "21\n",
      "max difference =  27.714832305908203\n",
      "data at max difference =  3.0974695682525635\n",
      "imputed at max difference =  30.812301635742188\n",
      "mae =  0.4986986517906189\n",
      "rmse =  13.527712614639945\n",
      "Progress: 96.86%\n",
      "22\n",
      "max difference =  29.39655113220215\n",
      "data at max difference =  3.7011895179748535\n",
      "imputed at max difference =  33.097740173339844\n",
      "mae =  0.5625381469726562\n",
      "rmse =  14.761485224184783\n",
      "Progress: 96.95%\n",
      "23\n",
      "max difference =  84.79048156738281\n",
      "data at max difference =  2.5305981636047363\n",
      "imputed at max difference =  87.32108306884766\n",
      "mae =  1.01836359500885\n",
      "rmse =  38.75468909222147\n",
      "Progress: 97.03%\n",
      "24\n",
      "max difference =  20.860971450805664\n",
      "data at max difference =  2.5594370365142822\n",
      "imputed at max difference =  23.420408248901367\n",
      "mae =  0.40580353140830994\n",
      "rmse =  10.446052882982338\n",
      "Progress: 97.12%\n",
      "25\n",
      "max difference =  65.25374603271484\n",
      "data at max difference =  2.7827811241149902\n",
      "imputed at max difference =  68.03652954101562\n",
      "mae =  1.9667611122131348\n",
      "rmse =  44.1304055918818\n",
      "Progress: 97.20%\n",
      "26\n",
      "max difference =  99.60784149169922\n",
      "data at max difference =  2.8632819652557373\n",
      "imputed at max difference =  102.47112274169922\n",
      "mae =  2.472280740737915\n",
      "rmse =  55.0064697265625\n",
      "Progress: 97.29%\n",
      "27\n",
      "max difference =  18.253149032592773\n",
      "data at max difference =  3.0260767936706543\n",
      "imputed at max difference =  21.279226303100586\n",
      "mae =  0.5583799481391907\n",
      "rmse =  12.33322408924932\n",
      "Progress: 97.37%\n",
      "28\n",
      "max difference =  53.13617706298828\n",
      "data at max difference =  2.9589877128601074\n",
      "imputed at max difference =  56.09516525268555\n",
      "mae =  1.7905080318450928\n",
      "rmse =  37.05081840183424\n",
      "Progress: 97.46%\n",
      "29\n",
      "max difference =  13.857460021972656\n",
      "data at max difference =  3.5692858695983887\n",
      "imputed at max difference =  17.426746368408203\n",
      "mae =  0.3913842737674713\n",
      "rmse =  8.574742856233017\n",
      "Progress: 97.54%\n",
      "30\n",
      "max difference =  91.5907211303711\n",
      "data at max difference =  3.0069375038146973\n",
      "imputed at max difference =  94.59765625\n",
      "mae =  1.736250400543213\n",
      "rmse =  50.28710406759511\n",
      "Progress: 97.63%\n",
      "31\n",
      "max difference =  46.56710433959961\n",
      "data at max difference =  3.6001527309417725\n",
      "imputed at max difference =  50.16725540161133\n",
      "mae =  1.0805652141571045\n",
      "rmse =  25.181107230808426\n",
      "Progress: 97.71%\n",
      "32\n",
      "max difference =  70.92969512939453\n",
      "data at max difference =  3.129429817199707\n",
      "imputed at max difference =  74.05912780761719\n",
      "mae =  0.8858644962310791\n",
      "rmse =  32.55902630349864\n",
      "Progress: 97.80%\n",
      "33\n",
      "max difference =  17.71767234802246\n",
      "data at max difference =  3.654895544052124\n",
      "imputed at max difference =  21.372568130493164\n",
      "mae =  0.30867499113082886\n",
      "rmse =  8.512647545855978\n",
      "Progress: 97.88%\n",
      "34\n",
      "max difference =  25.050870895385742\n",
      "data at max difference =  3.5691335201263428\n",
      "imputed at max difference =  28.620004653930664\n",
      "mae =  0.6022608280181885\n",
      "rmse =  14.335118832795516\n",
      "Progress: 97.97%\n",
      "35\n",
      "max difference =  53.08935546875\n",
      "data at max difference =  3.6970813274383545\n",
      "imputed at max difference =  56.78643798828125\n",
      "mae =  0.9980151653289795\n",
      "rmse =  27.130166758661684\n",
      "Progress: 98.05%\n",
      "36\n",
      "max difference =  98.92708587646484\n",
      "data at max difference =  3.6129720211029053\n",
      "imputed at max difference =  102.54005432128906\n",
      "mae =  1.8963252305984497\n",
      "rmse =  50.86733079993206\n",
      "Progress: 98.14%\n",
      "37\n",
      "max difference =  49.18037796020508\n",
      "data at max difference =  3.152101755142212\n",
      "imputed at max difference =  52.332481384277344\n",
      "mae =  1.0309851169586182\n",
      "rmse =  26.992665166440215\n",
      "Progress: 98.22%\n",
      "38\n",
      "max difference =  97.91539764404297\n",
      "data at max difference =  3.13771915435791\n",
      "imputed at max difference =  101.05311584472656\n",
      "mae =  1.6855846643447876\n",
      "rmse =  48.10755456012228\n",
      "Progress: 98.31%\n",
      "39\n",
      "max difference =  26.903886795043945\n",
      "data at max difference =  2.3955178260803223\n",
      "imputed at max difference =  29.29940414428711\n",
      "mae =  0.34841978549957275\n",
      "rmse =  12.307844079059103\n",
      "Progress: 98.39%\n",
      "40\n",
      "max difference =  87.6505355834961\n",
      "data at max difference =  2.279470682144165\n",
      "imputed at max difference =  89.93000793457031\n",
      "mae =  1.0322446823120117\n",
      "rmse =  40.1014404296875\n",
      "Progress: 98.47%\n",
      "41\n",
      "max difference =  6.357381820678711\n",
      "data at max difference =  1.7181442975997925\n",
      "imputed at max difference =  8.075526237487793\n",
      "mae =  0.18552598357200623\n",
      "rmse =  3.4804886527683423\n",
      "Progress: 98.56%\n",
      "42\n",
      "max difference =  7.930876731872559\n",
      "data at max difference =  1.7637147903442383\n",
      "imputed at max difference =  9.694591522216797\n",
      "mae =  0.2108628749847412\n",
      "rmse =  4.259452156398607\n",
      "Progress: 98.64%\n",
      "43\n",
      "max difference =  1.0731587409973145\n",
      "data at max difference =  3.971184253692627\n",
      "imputed at max difference =  2.8980255126953125\n",
      "mae =  0.08969463407993317\n",
      "rmse =  1.0075691057288128\n",
      "Progress: 98.73%\n",
      "44\n",
      "max difference =  77.57353973388672\n",
      "data at max difference =  4.07535982131958\n",
      "imputed at max difference =  81.6489028930664\n",
      "mae =  1.2522956132888794\n",
      "rmse =  38.03548265540081\n",
      "Progress: 98.81%\n",
      "45\n",
      "max difference =  4.492189884185791\n",
      "data at max difference =  3.8894925117492676\n",
      "imputed at max difference =  8.381682395935059\n",
      "mae =  0.14344963431358337\n",
      "rmse =  2.4129812821098\n",
      "Progress: 98.90%\n",
      "46\n",
      "max difference =  2.7103171348571777\n",
      "data at max difference =  3.933950424194336\n",
      "imputed at max difference =  6.644267559051514\n",
      "mae =  0.1442214399576187\n",
      "rmse =  2.1463060793669326\n",
      "Progress: 98.98%\n",
      "47\n",
      "max difference =  1.7219011783599854\n",
      "data at max difference =  3.482053518295288\n",
      "imputed at max difference =  5.203954696655273\n",
      "mae =  0.07920200377702713\n",
      "rmse =  1.086263076118801\n",
      "Progress: 99.07%\n",
      "48\n",
      "max difference =  3.024491310119629\n",
      "data at max difference =  3.6271133422851562\n",
      "imputed at max difference =  6.651604652404785\n",
      "mae =  0.12136149406433105\n",
      "rmse =  2.0218535713527515\n",
      "Progress: 99.15%\n",
      "49\n",
      "max difference =  32.98588180541992\n",
      "data at max difference =  4.738558769226074\n",
      "imputed at max difference =  37.72444152832031\n",
      "mae =  0.5884932279586792\n",
      "rmse =  17.624546216881793\n",
      "Progress: 99.24%\n",
      "50\n",
      "max difference =  3.0741114616394043\n",
      "data at max difference =  4.167771816253662\n",
      "imputed at max difference =  1.0936604738235474\n",
      "mae =  0.0873422622680664\n",
      "rmse =  1.604458518650221\n",
      "Progress: 99.32%\n",
      "51\n",
      "max difference =  62.0341796875\n",
      "data at max difference =  4.304757595062256\n",
      "imputed at max difference =  66.33893585205078\n",
      "mae =  1.1379284858703613\n",
      "rmse =  35.249936311141305\n",
      "Progress: 99.41%\n",
      "52\n",
      "max difference =  8.253807067871094\n",
      "data at max difference =  3.488410711288452\n",
      "imputed at max difference =  11.742218017578125\n",
      "mae =  0.21136975288391113\n",
      "rmse =  5.131457453188689\n",
      "Progress: 99.49%\n",
      "53\n",
      "max difference =  10.05897331237793\n",
      "data at max difference =  3.7796366214752197\n",
      "imputed at max difference =  13.83860969543457\n",
      "mae =  0.1486169546842575\n",
      "rmse =  4.648168812627378\n",
      "Progress: 99.58%\n",
      "54\n",
      "max difference =  24.271076202392578\n",
      "data at max difference =  3.8035402297973633\n",
      "imputed at max difference =  28.074615478515625\n",
      "mae =  0.4137156307697296\n",
      "rmse =  12.720607591711957\n",
      "Progress: 99.66%\n",
      "55\n",
      "max difference =  15.312226295471191\n",
      "data at max difference =  3.2829904556274414\n",
      "imputed at max difference =  18.595216751098633\n",
      "mae =  0.46282100677490234\n",
      "rmse =  11.006189097528871\n",
      "Progress: 99.75%\n",
      "56\n",
      "max difference =  28.352542877197266\n",
      "data at max difference =  3.634439468383789\n",
      "imputed at max difference =  31.986982345581055\n",
      "mae =  0.3254067301750183\n",
      "rmse =  12.942365563434102\n",
      "Progress: 99.83%\n",
      "57\n",
      "max difference =  3.7195425033569336\n",
      "data at max difference =  3.476940155029297\n",
      "imputed at max difference =  7.1964826583862305\n",
      "mae =  0.10130017250776291\n",
      "rmse =  2.000696928604789\n",
      "Progress: 99.92%\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "sample_number = 20\n",
    "sample_count = 100\n",
    "# sample_count = test_data_chunks_embedded[0].shape[0]\n",
    "samples = []\n",
    "for i in range(sample_number):\n",
    "    for j in range(len(test_data_chunks_embedded)):#range(58,59):\n",
    "        samples.append(diffusion_imputer.eval(\n",
    "            test_data_chunks_embedded[j][2000:(2000+sample_count)], imputation_masks[j][2000:(2000+sample_count)],\n",
    "            mean = training_mean, std = training_standard_deviation, scale = 1\n",
    "            ),\n",
    "            )\n",
    "        progress = (i * len(test_data_chunks_embedded) + j) / (sample_number * len(test_data_chunks_embedded))      \n",
    "        print(f\"Progress: {progress * 100:.2f}%\")\n",
    "        print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1180"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the samples\n",
    "torch.save(samples, \"samples_cancer_jul8.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples = torch.load(\"samples_cancer_jun3.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation_results = [samples[i][0] for i in range(len(samples))] # = imputation results, input data, mask, mae\n",
    "# imputation_results = torch.stack(imputation_results, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4434e-01, -1.3843e-01, -1.3674e-01, -1.4563e-01, -1.4054e-01,\n",
       "        -1.4305e-01, -1.4281e-01, -1.4529e-01, -1.2997e-01, -1.3473e-01,\n",
       "        -1.3508e-01, -1.3162e-01, -1.4739e-01, -1.4892e-01, -1.4796e-01,\n",
       "        -1.5867e-01,  2.4244e+01,  1.4086e-01,  5.0397e+00,  1.4106e+00,\n",
       "        -1.4407e-01, -1.4659e-01, -1.3905e-01, -1.4908e-01,  2.5593e-01,\n",
       "         5.5878e-01,  3.2165e-01,  5.2567e-01, -1.4153e-01, -1.3596e-01,\n",
       "        -1.3673e-01, -1.4924e-01, -1.4659e-01, -1.4778e-01, -1.4713e-01,\n",
       "        -1.5064e-01, -3.3583e-02,  1.0531e+00,  2.6631e-01,  1.2742e+00,\n",
       "        -1.8855e-02,  1.0403e-01,  3.2683e-02,  1.3174e-01,  5.2804e+00,\n",
       "         1.5490e+00, -1.0785e-01,  6.8113e-01, -9.8129e-02, -8.0722e-02,\n",
       "        -9.2097e-02, -8.3560e-02, -1.1300e-01, -1.3604e-01, -1.3051e-01,\n",
       "        -1.3581e-01, -1.4640e-01, -1.4805e-01, -1.4267e-01, -1.4966e-01,\n",
       "        -1.4139e-01, -1.5513e-01, -1.3492e-01, -1.4873e-01, -1.4748e-01,\n",
       "        -1.5162e-01, -1.5759e-01, -1.5194e-01, -1.4452e-01, -1.4669e-01,\n",
       "        -1.4426e-01, -1.4631e-01, -1.1118e-01, -1.1497e-01, -1.1212e-01,\n",
       "        -1.1827e-01, -1.6520e-01, -1.4758e-01, -1.4836e-01, -1.5038e-01,\n",
       "        -2.6522e-02, -1.7884e-02, -2.0103e-02, -4.2491e-02, -1.2531e-01,\n",
       "        -1.2319e-01, -1.1976e-01, -1.2321e-01,  7.5341e-01,  9.0913e+00,\n",
       "         9.7427e+00,  3.8542e+00, -1.5055e-01, -1.4626e-01, -1.4704e-01,\n",
       "        -1.5358e-01, -1.3834e-01, -1.4134e-01, -1.3954e-01, -1.5094e-01],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor([-1.4814e-01, -1.4660e-01, -1.5451e-01, -1.5383e-01,  4.9978e-01,\n",
       "         3.2893e-02,  4.4637e-01,  3.7186e-01, -1.4314e-01, -1.4616e-01,\n",
       "        -1.4493e-01, -1.4590e-01,  4.9769e-01,  6.8487e-01,  1.9441e-01,\n",
       "         6.0583e-01, -1.3968e-01, -1.3831e-01, -1.3860e-01, -1.4252e-01,\n",
       "        -1.4677e-01, -1.5247e-01, -1.4816e-01, -1.4996e-01, -3.1544e-02,\n",
       "         1.3993e+00,  1.2405e+00,  1.1265e+00,  9.4042e-02,  1.3601e-01,\n",
       "         7.2094e-02,  1.1442e-01,  2.2693e+00,  4.2628e+00,  1.1443e+01,\n",
       "         4.6081e+01, -8.2069e-02, -8.6471e-02, -8.2722e-02, -8.9336e-02,\n",
       "        -1.2926e-01, -1.3095e-01, -1.2998e-01, -1.3296e-01, -1.5233e-01,\n",
       "        -1.4545e-01, -1.3960e-01, -1.4798e-01, -1.4740e-01, -1.4607e-01,\n",
       "        -1.4601e-01, -1.4754e-01, -1.5091e-01, -1.4699e-01, -1.4719e-01,\n",
       "        -1.4987e-01, -1.4476e-01, -1.4403e-01, -1.4736e-01, -1.4749e-01,\n",
       "        -1.1065e-01, -1.1317e-01, -1.1040e-01, -1.1611e-01, -1.4737e-01,\n",
       "        -1.4862e-01, -1.4766e-01, -1.4912e-01, -5.9694e-03, -2.9789e-02,\n",
       "        -1.8956e-02, -2.1115e-02, -1.2224e-01, -1.2373e-01, -1.2213e-01,\n",
       "        -1.2659e-01,  1.2937e+00,  1.5904e+00,  5.8047e+00,  2.6191e+00,\n",
       "        -1.4520e-01, -1.4725e-01, -1.4660e-01, -1.5106e-01, -1.4008e-01,\n",
       "        -1.4216e-01, -1.4121e-01, -1.4298e-01, -6.5143e-02, -6.8682e-02,\n",
       "        -6.8236e-02, -6.6394e-02,  1.7121e-01,  6.7473e-02, -2.8278e-02,\n",
       "         2.0108e-01,  7.5549e-01,  3.2587e-01,  1.1718e+00,  5.9273e-01],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0][0][:, -1, target_column]\n",
    "samples[1][0][:, -1, target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 100, 59])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputation_results = [samples[i][0][:, -1, target_column] for i in range(len(samples))] # = imputation results, input data, mask, mae\n",
    "imputation_results = torch.cat(imputation_results, dim = 0)\n",
    "imputation_results_denormed = imputation_results * training_standard_deviation + training_mean\n",
    "imputation_results_denormed = imputation_results_denormed.reshape(sample_number, sample_count, -1)\n",
    "# imputation_results_denormed\n",
    "imputation_results_denormed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation_results = [samples[i][0] for i in range(len(samples))] # = imputation results, input data, mask, mae\n",
    "# imputation_results = torch.stack(imputation_results, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 59])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "denormed_data = [samples[i][1][:, -1, target_column] for i in range(len(samples))] # = imputation results, input data, mask, mae\n",
    "denormed_data = torch.cat(denormed_data, dim = 0)\n",
    "denormed_data = denormed_data * training_standard_deviation + training_mean\n",
    "denormed_data = denormed_data.reshape(sample_number, sample_count, -1)\n",
    "denormed_data = denormed_data[0]\n",
    "denormed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation_results_denormed[0]\n",
    "# imputation_results_denormed[1]\n",
    "# denormed_data = imputation_results_denormed[1]\n",
    "# imputation_results_denormed = imputation_results_denormed[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation_mask = [samples[i][2][:, -1, 2] for i in range(len(samples))]\n",
    "# imputation_mask = torch.cat(imputation_mask, dim = 0)\n",
    "# imputation_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# denormed_data = test_data_chunks[16] * training_standard_deviation + training_mean\n",
    "# denormed_data = denormed_data.cpu().detach()\n",
    "\n",
    "# given_points = given_points.cpu().detach()\n",
    "# eval_points = eval_points.cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qlist = [0.05, 0.25, 0.50, 0.75, 0.95]\n",
    "# #qlist = [0.5]\n",
    "# quantiles_imp = []\n",
    "# for q in qlist:\n",
    "#     quantiles = torch.quantile(imputation_results_denormed, q, dim=0, interpolation=\"linear\")\n",
    "#     quantiles_imp.append(quantiles)\n",
    "\n",
    "# means = torch.mean(imputation_results_denormed, dim=0)\n",
    "# quantiles_imp.append(means)\n",
    "\n",
    "# quantiles_imp = torch.stack(quantiles_imp, dim=0).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "qlist = [0.05, 0.25, 0.50, 0.75, 0.95]\n",
    "#qlist = [0.5]\n",
    "quantiles_imp = []\n",
    "for q in qlist:\n",
    "    quantiles = torch.quantile(imputation_results_denormed, q, dim=0, interpolation=\"linear\")\n",
    "    quantiles_imp.append(quantiles)\n",
    "\n",
    "means = torch.mean(imputation_results_denormed, dim=0)\n",
    "quantiles_imp.append(means)\n",
    "\n",
    "quantiles_imp = torch.stack(quantiles_imp, dim=0).cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 100, 59])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantiles_imp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mae = torch.mean(torch.abs(denormed_data[imputation_masks[58].cpu() != 0] - torch.Tensor(quantiles_imp[2][imputation_masks[58].cpu() != 0]))).item()\n",
    "# print(mae/1150 * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.281870468803074\n"
     ]
    }
   ],
   "source": [
    "mae = torch.mean(torch.abs(denormed_data.cpu() - torch.Tensor(quantiles_imp[2].cpu()))).item()\n",
    "print(mae/1150 * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse = torch.sqrt(torch.mean((denormed_data[imputation_masks[16].cpu() != 0] - \n",
    "#                               torch.Tensor(quantiles_imp[2][imputation_masks[16].cpu() != 0]))**2)).item()\n",
    "# print(rmse/1150 * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.36651080587636\n"
     ]
    }
   ],
   "source": [
    "rmse = torch.sqrt(torch.mean((denormed_data.cpu() - torch.Tensor(quantiles_imp[2].cpu()))**2)).item()\n",
    "print(rmse/1150 * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_loss(target, forecast, q: float, eval_points) -> float:\n",
    "    return 2 * torch.sum(\n",
    "        torch.abs((forecast - target) * eval_points * ((target <= forecast) * 1.0 - q))\n",
    "    )\n",
    "\n",
    "\n",
    "def calc_denominator(target, eval_points):\n",
    "    return torch.sum(torch.abs(target * eval_points))\n",
    "\n",
    "\n",
    "def calc_quantile_CRPS(target, forecast, eval_points, mean_scaler, scaler):\n",
    "    target = target * scaler + mean_scaler\n",
    "    forecast = forecast * scaler + mean_scaler\n",
    "\n",
    "    quantiles = np.arange(0.05, 1.0, 0.05)\n",
    "    denom = calc_denominator(target, eval_points)\n",
    "    CRPS = 0\n",
    "    for i in range(len(quantiles)):\n",
    "        q_pred = []\n",
    "        for j in range(len(forecast)):\n",
    "            q_pred.append(torch.quantile(forecast[j : j + 1], quantiles[i], dim=1))\n",
    "        q_pred = torch.cat(q_pred, 0)\n",
    "        q_loss = quantile_loss(target, q_pred, quantiles[i], eval_points)\n",
    "        CRPS += q_loss / denom\n",
    "    return CRPS.item() / len(quantiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_number = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m all_generated_samples \u001b[38;5;241m=\u001b[39m imputation_results\u001b[38;5;66;03m#torch.stack([samples[i][0] for i in range(sample_number)]).permute(1,0,2,3)  # (B, sample_num, L, K)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m all_evalpoint \u001b[38;5;241m=\u001b[39m samples[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m2\u001b[39m]  \u001b[38;5;66;03m# mask same for all samples (B, L, K)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m CRPS \u001b[38;5;241m=\u001b[39m \u001b[43mcalc_quantile_CRPS\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_generated_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_evalpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_standard_deviation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(CRPS)\n",
      "Cell \u001b[0;32mIn[92], line 21\u001b[0m, in \u001b[0;36mcalc_quantile_CRPS\u001b[0;34m(target, forecast, eval_points, mean_scaler, scaler)\u001b[0m\n\u001b[1;32m     19\u001b[0m q_pred \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(forecast)):\n\u001b[0;32m---> 21\u001b[0m     q_pred\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforecast\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantiles\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     22\u001b[0m q_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(q_pred, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     23\u001b[0m q_loss \u001b[38;5;241m=\u001b[39m quantile_loss(target, q_pred, quantiles[i], eval_points)\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "all_target = samples[0][1]  # input_data same for all samples (B, L, K)\n",
    "all_generated_samples = torch.stack([samples[i][0] for i in range(sample_number)]).permute(1,0,2,3)  # (B, sample_num, L, K)\n",
    "all_evalpoint = samples[0][2]  # mask same for all samples (B, L, K)\n",
    "CRPS = calc_quantile_CRPS(all_target, all_generated_samples, all_evalpoint, training_mean, training_standard_deviation)\n",
    "print(CRPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"last_expr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1000, 60, 3])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantiles_imp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(dataind):\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_skip, K):  \u001b[38;5;66;03m# Start from n_skip instead of 0\u001b[39;00m\n\u001b[1;32m     13\u001b[0m         df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     14\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marange(start_time, L),\n\u001b[0;32m---> 15\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mdenormed_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m     16\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: eval_points[i, start_time:, k]\n\u001b[1;32m     17\u001b[0m         })\n\u001b[1;32m     18\u001b[0m         df \u001b[38;5;241m=\u001b[39m df[df\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     19\u001b[0m         df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m     20\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marange(start_time, L),\n\u001b[1;32m     21\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m: denormed_data[i, start_time:, k],\n\u001b[1;32m     22\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: given_points[i, start_time:, k]\n\u001b[1;32m     23\u001b[0m         })\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x2b955f7ad990> (for post_execute), with arguments args (),kwargs {}:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/micromamba/envs/pytorch_env/lib/python3.10/site-packages/matplotlib_inline/backend_inline.py:126\u001b[0m, in \u001b[0;36mflush_figures\u001b[0;34m()\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m InlineBackend\u001b[38;5;241m.\u001b[39minstance()\u001b[38;5;241m.\u001b[39mclose_figures:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;66;03m# ignore the tracking, just draw and close all figures\u001b[39;00m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    128\u001b[0m         \u001b[38;5;66;03m# safely show traceback if in IPython, else raise\u001b[39;00m\n\u001b[1;32m    129\u001b[0m         ip \u001b[38;5;241m=\u001b[39m get_ipython()\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_env/lib/python3.10/site-packages/matplotlib_inline/backend_inline.py:90\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m figure_manager \u001b[38;5;129;01min\u001b[39;00m Gcf\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[0;32m---> 90\u001b[0m         \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fetch_figure_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     show\u001b[38;5;241m.\u001b[39m_to_draw \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_env/lib/python3.10/site-packages/IPython/core/display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_env/lib/python3.10/site-packages/IPython/core/formatters.py:179\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    177\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_env/lib/python3.10/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_env/lib/python3.10/site-packages/IPython/core/formatters.py:223\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_env/lib/python3.10/site-packages/IPython/core/formatters.py:340\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    342\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_env/lib/python3.10/site-packages/IPython/core/pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 152\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_env/lib/python3.10/site-packages/matplotlib/backend_bases.py:2164\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2161\u001b[0m     \u001b[38;5;66;03m# we do this instead of `self.figure.draw_without_rendering`\u001b[39;00m\n\u001b[1;32m   2162\u001b[0m     \u001b[38;5;66;03m# so that we can inject the orientation\u001b[39;00m\n\u001b[1;32m   2163\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(renderer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_draw_disabled\u001b[39m\u001b[38;5;124m\"\u001b[39m, nullcontext)():\n\u001b[0;32m-> 2164\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bbox_inches:\n\u001b[1;32m   2166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_env/lib/python3.10/site-packages/matplotlib/artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[1;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_env/lib/python3.10/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_env/lib/python3.10/site-packages/matplotlib/figure.py:3154\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3151\u001b[0m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   3153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 3154\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sfig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubfigs:\n\u001b[1;32m   3158\u001b[0m     sfig\u001b[38;5;241m.\u001b[39mdraw(renderer)\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_env/lib/python3.10/site-packages/matplotlib/image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[0;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_env/lib/python3.10/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_env/lib/python3.10/site-packages/matplotlib/axes/_base.py:3070\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3067\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[1;32m   3068\u001b[0m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, artists_rasterized, renderer)\n\u001b[0;32m-> 3070\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3071\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3073\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   3074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_env/lib/python3.10/site-packages/matplotlib/image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[0;32m--> 132\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_env/lib/python3.10/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_env/lib/python3.10/site-packages/matplotlib/axis.py:1391\u001b[0m, in \u001b[0;36mAxis.draw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1388\u001b[0m tlb1, tlb2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_ticklabel_bboxes(ticks_to_draw, renderer)\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks_to_draw:\n\u001b[0;32m-> 1391\u001b[0m     \u001b[43mtick\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1393\u001b[0m \u001b[38;5;66;03m# Shift label away from axes to avoid overlapping ticklabels.\u001b[39;00m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_label_position(renderer)\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_env/lib/python3.10/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_env/lib/python3.10/site-packages/matplotlib/axis.py:295\u001b[0m, in \u001b[0;36mTick.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    292\u001b[0m renderer\u001b[38;5;241m.\u001b[39mopen_group(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, gid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_gid())\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m artist \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgridline, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtick1line, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtick2line,\n\u001b[1;32m    294\u001b[0m                \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel2]:\n\u001b[0;32m--> 295\u001b[0m     \u001b[43martist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_env/lib/python3.10/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/pytorch_env/lib/python3.10/site-packages/matplotlib/text.py:763\u001b[0m, in \u001b[0;36mText.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    759\u001b[0m canvasw, canvash \u001b[38;5;241m=\u001b[39m renderer\u001b[38;5;241m.\u001b[39mget_canvas_width_height()\n\u001b[1;32m    761\u001b[0m \u001b[38;5;66;03m# Update the location and size of the bbox\u001b[39;00m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;66;03m# (`.patches.FancyBboxPatch`), and draw it.\u001b[39;00m\n\u001b[0;32m--> 763\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bbox_patch:\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_bbox_position_size(renderer)\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bbox_patch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "L = test_data.shape[1]\n",
    "K = test_data.shape[2]\n",
    "\n",
    "dataind = 40  # Number of samples to visualize\n",
    "start_time = 40 \n",
    "n_skip = 0  # Number of columns to skip\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 16\n",
    "fig, axes = plt.subplots(nrows=dataind, ncols=K - n_skip, figsize=(24.0, 6 * dataind))\n",
    "\n",
    "for i in range(dataind):\n",
    "    for k in range(n_skip, K):  # Start from n_skip instead of 0\n",
    "        df = pd.DataFrame({\n",
    "            \"x\": np.arange(start_time, L),\n",
    "            \"val\": denormed_data[i, start_time:, k],\n",
    "            \"y\": eval_points[i, start_time:, k]\n",
    "        })\n",
    "        df = df[df.y != 0]\n",
    "        df2 = pd.DataFrame({\n",
    "            \"x\": np.arange(start_time, L),\n",
    "            \"val\": denormed_data[i, start_time:, k],\n",
    "            \"y\": given_points[i, start_time:, k]\n",
    "        })\n",
    "        df2 = df2[df2.y != 0]\n",
    "        indices = df.x.astype(int).to_numpy()\n",
    "        row = i\n",
    "        col = k - n_skip  # Adjust column index for skipped columns\n",
    "\n",
    "        axes[row][col].plot(range(start_time, L), quantiles_imp[2][i, start_time:, k], color='g', linestyle='solid', label='median')\n",
    "        axes[row][col].fill_between(range(start_time, L), quantiles_imp[0][i, start_time:, k], quantiles_imp[4][i, start_time:, k], color='g', alpha=0.3)\n",
    "        axes[row][col].plot(df.x, df.val, color='b', marker='o', linestyle='None')\n",
    "        axes[row][col].plot(df.x, quantiles_imp[5][i, indices, k], color='r', linestyle='None', label='median', marker='x')\n",
    "        axes[row][col].plot(df.x, quantiles_imp[0][i, indices, k], color='r', linestyle='None', marker=1)\n",
    "        axes[row][col].plot(df.x, quantiles_imp[4][i, indices, k], color='r', linestyle='None', marker=1)\n",
    "\n",
    "        if col == 0:  # Only label the first of the remaining columns\n",
    "            axes[row][col].set_ylabel('Value')\n",
    "        if row == dataind - 1:  # Only label the last row\n",
    "            axes[row][col].set_xlabel('Time')\n",
    "\n",
    "# Optional: Adjust the layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
