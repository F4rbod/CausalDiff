{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, diffusion_imputer, categorical_features_info, num_layers, device=\"cuda\"):\n",
    "        super().__init__()\n",
    "        self.diffusion_imputer = diffusion_imputer\n",
    "        self.categorical_features_info = categorical_features_info\n",
    "        self.device = device\n",
    "\n",
    "        # Flatten indices for categorical features\n",
    "        self.categorical_indices = [idx for info in categorical_features_info for idx in info['indices']]\n",
    "        self.target_categorical_indices = [idx for info in categorical_features_info for idx in info['indices_target']]\n",
    "\n",
    "        # Define layers\n",
    "        self.first_linear_layers = nn.ModuleList([\n",
    "            nn.Linear(info['embedding_dim'], info['hidden_dim'])\n",
    "            for info in categorical_features_info\n",
    "        ])\n",
    "        self.second_linear_layers = nn.ModuleList([\n",
    "            nn.Linear(info['hidden_dim'], info['hidden_dim'])\n",
    "            for info in categorical_features_info\n",
    "        ])\n",
    "        num_total_features_and_hidden_dims = sum(info['hidden_dim'] for info in categorical_features_info)\n",
    "\n",
    "        self.first_layer_ff = nn.Linear(num_total_features_and_hidden_dims, num_total_features_and_hidden_dims)\n",
    "        self.classification_layers = nn.ModuleList([\n",
    "            nn.Linear(num_total_features_and_hidden_dims, num_total_features_and_hidden_dims) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.output_layers = nn.ModuleList([\n",
    "            nn.Linear(num_total_features_and_hidden_dims, info['num_classes']) for info in categorical_features_info\n",
    "        ])\n",
    "\n",
    "    def forward(self, data, target_data):\n",
    "        imputed_samples, _, imputation_mask = self.diffusion_imputer.eval_with_grad(data)\n",
    "        # imputation_results = torch.where(imputation_mask != 0, imputed_samples, data)\n",
    "\n",
    "        # Use precomputed indices to split data\n",
    "        target_data_categorical = target_data[:, :, self.target_categorical_indices]\n",
    "        target_data_numerical = target_data[:, :, [i for i in range(target_data.shape[2]) if i not in self.target_categorical_indices]]\n",
    "        imputation_results_categorical = imputed_samples[:, :, self.categorical_indices]\n",
    "        imputation_results_numerical = imputed_samples[:, :, [i for i in range(data.shape[2]) if i not in self.categorical_indices]]\n",
    "        print(imputation_results_categorical[0])\n",
    "        # Process categorical data\n",
    "        start_idx = 0\n",
    "        class_predictions = []\n",
    "        for first_layer, second_layer, info in zip(self.first_linear_layers, self.second_linear_layers, self.categorical_features_info):\n",
    "            end_idx = start_idx + info['embedding_dim']\n",
    "            feature_data = imputation_results_categorical[:, :, start_idx:end_idx]\n",
    "            feature_data = F.relu(first_layer(feature_data))\n",
    "            feature_data = F.relu(second_layer(feature_data))\n",
    "            class_predictions.append(feature_data)\n",
    "            start_idx = end_idx\n",
    "        \n",
    "        \n",
    "        combined_data_categorical = torch.cat(class_predictions, dim=2)\n",
    "        combined_data_categorical = F.relu(self.first_layer_ff(combined_data_categorical))\n",
    "        for layer in self.classification_layers:\n",
    "            combined_data_categorical = F.relu(layer(combined_data_categorical))\n",
    "\n",
    "        print()\n",
    "\n",
    "        final_outputs_categorical = torch.cat([\n",
    "            output_layer(combined_data_categorical).unsqueeze(2) for output_layer in self.output_layers\n",
    "        ], dim=2)\n",
    "\n",
    "        return imputation_results_numerical, final_outputs_categorical, target_data_numerical, target_data_categorical\n",
    "\n",
    "    def loss_func(self, outputs, targets):\n",
    "        imputation_results_numerical, final_outputs_categorical = outputs\n",
    "        target_numerical, target_categorical = targets\n",
    "        \n",
    "        loss_numerical = F.mse_loss(imputation_results_numerical, target_numerical)\n",
    "        final_outputs_categorical = final_outputs_categorical.view(-1, final_outputs_categorical.shape[2], final_outputs_categorical.shape[3])\n",
    "        target_categorical = target_categorical.view(-1, target_categorical.shape[2])\n",
    "        target_categorical = target_categorical.long().to(self.device)\n",
    "\n",
    "        loss_categorical = sum(F.cross_entropy(final_outputs_categorical[:, i, :], target_categorical[:, i]) for i in range(final_outputs_categorical.shape[1]))\n",
    "        \n",
    "        print(target_categorical[0])\n",
    "        print(final_outputs_categorical[0])\n",
    "        print(loss_numerical)\n",
    "        print(loss_categorical)\n",
    "        # return loss_numerical + loss_categorical\n",
    "        # return loss_categorical \n",
    "        return loss_numerical + loss_categorical\n",
    "\n",
    "    def eval(self, data, imputation_mask):\n",
    "        # self.eval()\n",
    "        with torch.no_grad():\n",
    "            imputed_samples, _, _ = self.diffusion_imputer.eval_with_grad(data, imputation_mask)\n",
    "            imputation_results = torch.where(imputation_mask != 0, imputed_samples, data)\n",
    "\n",
    "            imputation_results_categorical = imputation_results[:, :, self.categorical_indices]\n",
    "            imputation_results_numerical = imputation_results[:, :, [i for i in range(data.shape[2]) if i not in self.categorical_indices]]\n",
    "\n",
    "            start_idx = 0\n",
    "            class_predictions = []\n",
    "            for first_layer, second_layer, info in zip(self.first_linear_layers, self.second_linear_layers, self.categorical_features_info):\n",
    "                end_idx = start_idx + info['embedding_dim']\n",
    "                feature_data = imputation_results_categorical[:, :, start_idx:end_idx]\n",
    "                feature_data = F.relu(first_layer(feature_data))\n",
    "                feature_data = F.relu(second_layer(feature_data))\n",
    "                class_predictions.append(feature_data)\n",
    "                start_idx = end_idx\n",
    "\n",
    "            combined_data_categorical = torch.cat(class_predictions, dim=2)\n",
    "            combined_data_categorical = F.relu(self.first_layer_ff(combined_data_categorical))\n",
    "            for layer in self.classification_layers:\n",
    "                combined_data_categorical = F.relu(layer(combined_data_categorical))\n",
    "\n",
    "            final_outputs_categorical = torch.cat([\n",
    "                output_layer(combined_data_categorical).unsqueeze(2) for output_layer in self.output_layers\n",
    "            ], dim=2)\n",
    "            final_outputs_categorical = torch.argmax(final_outputs_categorical, dim=2)\n",
    "\n",
    "            final_outputs = torch.cat([imputation_results_numerical, final_outputs_categorical], dim=2)\n",
    "            return final_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example initial data setup\n",
    "data = {\n",
    "    'outputs': np.array([\n",
    "        [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12], [13, 14, 15]],  # Patient 1\n",
    "        [[16, 17, 18], [19, 20, 21], [22, 23, 24], [25, 26, 27], [28, 29, 30]]  # Patient 2\n",
    "    ]),\n",
    "    'prev_outputs': np.array([\n",
    "        [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11], [12, 13, 14]],  # Patient 1\n",
    "        [[15, 16, 17], [18, 19, 20], [21, 22, 23], [24, 25, 26], [27, 28, 29]]  # Patient 2\n",
    "    ]),\n",
    "    'sequence_lengths': np.array([5, 5]),  # Both patients have full sequences\n",
    "    'active_entries': np.ones((2, 5, 3)),  # All entries are active\n",
    "    'current_treatments': np.array([\n",
    "        [[0, 0, 0], [1, 1, 1], [2, 2, 2], [3, 3, 3], [4, 4, 4]],  # Patient 1\n",
    "        [[5, 5, 5], [6, 6, 6], [7, 7, 7], [8, 8, 8], [9, 9, 9]]  # Patient 2\n",
    "    ]),\n",
    "    'prev_treatments': np.array([\n",
    "        [[0, 1, 0], [1, 0, 1], [0, 1, 0], [1, 0, 1], [0, 1, 0]],  # Patient 1\n",
    "        [[1, 0, 1], [0, 1, 0], [1, 0, 1], [0, 1, 0], [1, 0, 1]]  # Patient 2\n",
    "    ]),\n",
    "    'static_features': np.array([\n",
    "        [0.1, 0.2, 0.3],  # Patient 1\n",
    "        [0.4, 0.5, 0.6]  # Patient 2\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Assume scaling params for unscaled outputs\n",
    "scaling_params = {\n",
    "    'output_means': np.array([1, 2, 3]),\n",
    "    'output_stds': np.array([0.5, 0.5, 0.5])\n",
    "}\n",
    "\n",
    "# Projection horizon\n",
    "projection_horizon = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def explode_trajectories(data, projection_horizon, scaling_params):\n",
    "    outputs = data['outputs']\n",
    "    prev_outputs = data['prev_outputs']\n",
    "    sequence_lengths = data['sequence_lengths']\n",
    "    active_entries = data['active_entries']\n",
    "    current_treatments = data['current_treatments']\n",
    "    previous_treatments = data['prev_treatments']\n",
    "    static_features = data['static_features']\n",
    "\n",
    "    num_patients, max_seq_length, num_features = outputs.shape\n",
    "    num_seq2seq_rows = num_patients * max_seq_length\n",
    "\n",
    "    seq2seq_previous_treatments = np.zeros((num_seq2seq_rows, max_seq_length, previous_treatments.shape[-1]))\n",
    "    seq2seq_current_treatments = np.zeros((num_seq2seq_rows, max_seq_length, current_treatments.shape[-1]))\n",
    "    seq2seq_static_features = np.zeros((num_seq2seq_rows, static_features.shape[-1]))\n",
    "    seq2seq_outputs = np.zeros((num_seq2seq_rows, max_seq_length, outputs.shape[-1]))\n",
    "    seq2seq_prev_outputs = np.zeros((num_seq2seq_rows, max_seq_length, prev_outputs.shape[-1]))\n",
    "    seq2seq_active_entries = np.zeros((num_seq2seq_rows, max_seq_length, active_entries.shape[-1]))\n",
    "    seq2seq_sequence_lengths = np.zeros(num_seq2seq_rows)\n",
    "\n",
    "    total_seq2seq_rows = 0  # we use this to shorten any trajectories later\n",
    "\n",
    "    for i in range(num_patients):\n",
    "        sequence_length = int(sequence_lengths[i])\n",
    "\n",
    "        for t in range(projection_horizon, sequence_length):  # shift outputs back by 1\n",
    "            seq2seq_active_entries[total_seq2seq_rows, :(t + 1), :] = active_entries[i, :(t + 1), :]\n",
    "            seq2seq_previous_treatments[total_seq2seq_rows, :(t + 1), :] = previous_treatments[i, :(t + 1), :]\n",
    "            seq2seq_current_treatments[total_seq2seq_rows, :(t + 1), :] = current_treatments[i, :(t + 1), :]\n",
    "            seq2seq_outputs[total_seq2seq_rows, :(t + 1), :] = outputs[i, :(t + 1), :]\n",
    "            seq2seq_prev_outputs[total_seq2seq_rows, :(t + 1), :] = prev_outputs[i, :(t + 1), :]\n",
    "            seq2seq_sequence_lengths[total_seq2seq_rows] = t + 1\n",
    "            seq2seq_static_features[total_seq2seq_rows] = static_features[i]\n",
    "\n",
    "            total_seq2seq_rows += 1\n",
    "\n",
    "    # Filter everything shorter\n",
    "    seq2seq_previous_treatments = seq2seq_previous_treatments[:total_seq2seq_rows, :, :]\n",
    "    seq2seq_current_treatments = seq2seq_current_treatments[:total_seq2seq_rows, :, :]\n",
    "    seq2seq_static_features = seq2seq_static_features[:total_seq2seq_rows, :]\n",
    "    seq2seq_outputs = seq2seq_outputs[:total_seq2seq_rows, :, :]\n",
    "    seq2seq_prev_outputs = seq2seq_prev_outputs[:total_seq2seq_rows, :, :]\n",
    "    seq2seq_active_entries = seq2seq_active_entries[:total_seq2seq_rows, :, :]\n",
    "    seq2seq_sequence_lengths = seq2seq_sequence_lengths[:total_seq2seq_rows]\n",
    "\n",
    "    new_data = {\n",
    "        'prev_treatments': seq2seq_previous_treatments,\n",
    "        'current_treatments': seq2seq_current_treatments,\n",
    "        'static_features': seq2seq_static_features,\n",
    "        'prev_outputs': seq2seq_prev_outputs,\n",
    "        'outputs': seq2seq_outputs,\n",
    "        'unscaled_outputs': seq2seq_outputs * scaling_params['output_stds'] + scaling_params['output_means'],\n",
    "        'sequence_lengths': seq2seq_sequence_lengths,\n",
    "        'active_entries': seq2seq_active_entries,\n",
    "    }\n",
    "\n",
    "    return new_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs (2, 5, 3) [[[ 1  2  3]\n",
      "  [ 4  5  6]\n",
      "  [ 7  8  9]\n",
      "  [10 11 12]\n",
      "  [13 14 15]]\n",
      "\n",
      " [[16 17 18]\n",
      "  [19 20 21]\n",
      "  [22 23 24]\n",
      "  [25 26 27]\n",
      "  [28 29 30]]]\n",
      "prev_outputs (2, 5, 3) [[[ 0  1  2]\n",
      "  [ 3  4  5]\n",
      "  [ 6  7  8]\n",
      "  [ 9 10 11]\n",
      "  [12 13 14]]\n",
      "\n",
      " [[15 16 17]\n",
      "  [18 19 20]\n",
      "  [21 22 23]\n",
      "  [24 25 26]\n",
      "  [27 28 29]]]\n",
      "sequence_lengths (2,) [5 5]\n",
      "active_entries (2, 5, 3) [[[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]]\n",
      "current_treatments (2, 5, 3) [[[0 0 0]\n",
      "  [1 1 1]\n",
      "  [2 2 2]\n",
      "  [3 3 3]\n",
      "  [4 4 4]]\n",
      "\n",
      " [[5 5 5]\n",
      "  [6 6 6]\n",
      "  [7 7 7]\n",
      "  [8 8 8]\n",
      "  [9 9 9]]]\n",
      "prev_treatments (2, 5, 3) [[[0 1 0]\n",
      "  [1 0 1]\n",
      "  [0 1 0]\n",
      "  [1 0 1]\n",
      "  [0 1 0]]\n",
      "\n",
      " [[1 0 1]\n",
      "  [0 1 0]\n",
      "  [1 0 1]\n",
      "  [0 1 0]\n",
      "  [1 0 1]]]\n",
      "static_features (2, 3) [[0.1 0.2 0.3]\n",
      " [0.4 0.5 0.6]]\n"
     ]
    }
   ],
   "source": [
    "for key, value in data.items():\n",
    "    print(key, value.shape, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prev_treatments': ((6, 5, 3),\n",
       "  array([[[0., 1., 0.],\n",
       "          [1., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       "  \n",
       "         [[0., 1., 0.],\n",
       "          [1., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [1., 0., 1.],\n",
       "          [0., 0., 0.]],\n",
       "  \n",
       "         [[0., 1., 0.],\n",
       "          [1., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [1., 0., 1.],\n",
       "          [0., 1., 0.]],\n",
       "  \n",
       "         [[1., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [1., 0., 1.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       "  \n",
       "         [[1., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [1., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [0., 0., 0.]],\n",
       "  \n",
       "         [[1., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [1., 0., 1.],\n",
       "          [0., 1., 0.],\n",
       "          [1., 0., 1.]]])),\n",
       " 'current_treatments': ((6, 5, 3),\n",
       "  array([[[0., 0., 0.],\n",
       "          [1., 1., 1.],\n",
       "          [2., 2., 2.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       "  \n",
       "         [[0., 0., 0.],\n",
       "          [1., 1., 1.],\n",
       "          [2., 2., 2.],\n",
       "          [3., 3., 3.],\n",
       "          [0., 0., 0.]],\n",
       "  \n",
       "         [[0., 0., 0.],\n",
       "          [1., 1., 1.],\n",
       "          [2., 2., 2.],\n",
       "          [3., 3., 3.],\n",
       "          [4., 4., 4.]],\n",
       "  \n",
       "         [[5., 5., 5.],\n",
       "          [6., 6., 6.],\n",
       "          [7., 7., 7.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       "  \n",
       "         [[5., 5., 5.],\n",
       "          [6., 6., 6.],\n",
       "          [7., 7., 7.],\n",
       "          [8., 8., 8.],\n",
       "          [0., 0., 0.]],\n",
       "  \n",
       "         [[5., 5., 5.],\n",
       "          [6., 6., 6.],\n",
       "          [7., 7., 7.],\n",
       "          [8., 8., 8.],\n",
       "          [9., 9., 9.]]])),\n",
       " 'static_features': ((6, 3),\n",
       "  array([[0.1, 0.2, 0.3],\n",
       "         [0.1, 0.2, 0.3],\n",
       "         [0.1, 0.2, 0.3],\n",
       "         [0.4, 0.5, 0.6],\n",
       "         [0.4, 0.5, 0.6],\n",
       "         [0.4, 0.5, 0.6]])),\n",
       " 'prev_outputs': ((6, 5, 3),\n",
       "  array([[[ 0.,  1.,  2.],\n",
       "          [ 3.,  4.,  5.],\n",
       "          [ 6.,  7.,  8.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       "  \n",
       "         [[ 0.,  1.,  2.],\n",
       "          [ 3.,  4.,  5.],\n",
       "          [ 6.,  7.,  8.],\n",
       "          [ 9., 10., 11.],\n",
       "          [ 0.,  0.,  0.]],\n",
       "  \n",
       "         [[ 0.,  1.,  2.],\n",
       "          [ 3.,  4.,  5.],\n",
       "          [ 6.,  7.,  8.],\n",
       "          [ 9., 10., 11.],\n",
       "          [12., 13., 14.]],\n",
       "  \n",
       "         [[15., 16., 17.],\n",
       "          [18., 19., 20.],\n",
       "          [21., 22., 23.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       "  \n",
       "         [[15., 16., 17.],\n",
       "          [18., 19., 20.],\n",
       "          [21., 22., 23.],\n",
       "          [24., 25., 26.],\n",
       "          [ 0.,  0.,  0.]],\n",
       "  \n",
       "         [[15., 16., 17.],\n",
       "          [18., 19., 20.],\n",
       "          [21., 22., 23.],\n",
       "          [24., 25., 26.],\n",
       "          [27., 28., 29.]]])),\n",
       " 'outputs': ((6, 5, 3),\n",
       "  array([[[ 1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.],\n",
       "          [ 7.,  8.,  9.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       "  \n",
       "         [[ 1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.],\n",
       "          [ 7.,  8.,  9.],\n",
       "          [10., 11., 12.],\n",
       "          [ 0.,  0.,  0.]],\n",
       "  \n",
       "         [[ 1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.],\n",
       "          [ 7.,  8.,  9.],\n",
       "          [10., 11., 12.],\n",
       "          [13., 14., 15.]],\n",
       "  \n",
       "         [[16., 17., 18.],\n",
       "          [19., 20., 21.],\n",
       "          [22., 23., 24.],\n",
       "          [ 0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.]],\n",
       "  \n",
       "         [[16., 17., 18.],\n",
       "          [19., 20., 21.],\n",
       "          [22., 23., 24.],\n",
       "          [25., 26., 27.],\n",
       "          [ 0.,  0.,  0.]],\n",
       "  \n",
       "         [[16., 17., 18.],\n",
       "          [19., 20., 21.],\n",
       "          [22., 23., 24.],\n",
       "          [25., 26., 27.],\n",
       "          [28., 29., 30.]]])),\n",
       " 'unscaled_outputs': ((6, 5, 3),\n",
       "  array([[[ 1.5,  3. ,  4.5],\n",
       "          [ 3. ,  4.5,  6. ],\n",
       "          [ 4.5,  6. ,  7.5],\n",
       "          [ 1. ,  2. ,  3. ],\n",
       "          [ 1. ,  2. ,  3. ]],\n",
       "  \n",
       "         [[ 1.5,  3. ,  4.5],\n",
       "          [ 3. ,  4.5,  6. ],\n",
       "          [ 4.5,  6. ,  7.5],\n",
       "          [ 6. ,  7.5,  9. ],\n",
       "          [ 1. ,  2. ,  3. ]],\n",
       "  \n",
       "         [[ 1.5,  3. ,  4.5],\n",
       "          [ 3. ,  4.5,  6. ],\n",
       "          [ 4.5,  6. ,  7.5],\n",
       "          [ 6. ,  7.5,  9. ],\n",
       "          [ 7.5,  9. , 10.5]],\n",
       "  \n",
       "         [[ 9. , 10.5, 12. ],\n",
       "          [10.5, 12. , 13.5],\n",
       "          [12. , 13.5, 15. ],\n",
       "          [ 1. ,  2. ,  3. ],\n",
       "          [ 1. ,  2. ,  3. ]],\n",
       "  \n",
       "         [[ 9. , 10.5, 12. ],\n",
       "          [10.5, 12. , 13.5],\n",
       "          [12. , 13.5, 15. ],\n",
       "          [13.5, 15. , 16.5],\n",
       "          [ 1. ,  2. ,  3. ]],\n",
       "  \n",
       "         [[ 9. , 10.5, 12. ],\n",
       "          [10.5, 12. , 13.5],\n",
       "          [12. , 13.5, 15. ],\n",
       "          [13.5, 15. , 16.5],\n",
       "          [15. , 16.5, 18. ]]])),\n",
       " 'sequence_lengths': ((6,), array([3., 4., 5., 3., 4., 5.])),\n",
       " 'active_entries': ((6, 5, 3),\n",
       "  array([[[1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       "  \n",
       "         [[1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [0., 0., 0.]],\n",
       "  \n",
       "         [[1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.]],\n",
       "  \n",
       "         [[1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [0., 0., 0.],\n",
       "          [0., 0., 0.]],\n",
       "  \n",
       "         [[1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [0., 0., 0.]],\n",
       "  \n",
       "         [[1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.]]]))}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the function\n",
    "new_data = explode_trajectories(data, projection_horizon, scaling_params)\n",
    "\n",
    "# Print the results for illustration\n",
    "output_results = {}\n",
    "for key, value in new_data.items():\n",
    "    output_results[key] = value.shape, value\n",
    "\n",
    "output_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'active_encoder_r': (2, 3),\n",
       " 'prev_treatments': (2, 2, 3),\n",
       " 'current_treatments': (2, 2, 3),\n",
       " 'current_covariates': (2, 2, 3),\n",
       " 'prev_outputs': (2, 2, 1),\n",
       " 'static_features': (2, 2),\n",
       " 'outputs': (2, 2, 3),\n",
       " 'sequence_lengths': (2,),\n",
       " 'active_entries': (2, 2, 1),\n",
       " 'unscaled_outputs': (2, 2, 3),\n",
       " 'patient_types': (2,),\n",
       " 'patient_ids_all_trajectories': (2,),\n",
       " 'patient_current_t': (2,)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def process_sequential_test(data, projection_horizon, encoder_r=None, save_encoder_r=False):\n",
    "    \"\"\"\n",
    "    Pre-process test dataset for multiple-step-ahead prediction: takes the last n-steps according to the projection horizon\n",
    "    \"\"\"\n",
    "\n",
    "    sequence_lengths = data['sequence_lengths']\n",
    "    outputs = data['outputs']\n",
    "    current_treatments = data['current_treatments']\n",
    "    previous_treatments = data['prev_treatments'][:, 1:, :]  # Without zero_init_treatment\n",
    "    current_covariates = data['current_covariates']\n",
    "\n",
    "    num_patient_points, max_seq_length, num_features = outputs.shape\n",
    "\n",
    "    if encoder_r is not None:\n",
    "        seq2seq_state_inits = np.zeros((num_patient_points, encoder_r.shape[-1]))\n",
    "    seq2seq_active_encoder_r = np.zeros((num_patient_points, max_seq_length - projection_horizon))\n",
    "    seq2seq_previous_treatments = np.zeros((num_patient_points, projection_horizon, previous_treatments.shape[-1]))\n",
    "    seq2seq_current_treatments = np.zeros((num_patient_points, projection_horizon, current_treatments.shape[-1]))\n",
    "    seq2seq_current_covariates = np.zeros((num_patient_points, projection_horizon, current_covariates.shape[-1]))\n",
    "    seq2seq_outputs = np.zeros((num_patient_points, projection_horizon, outputs.shape[-1]))\n",
    "    seq2seq_active_entries = np.zeros((num_patient_points, projection_horizon, 1))\n",
    "    seq2seq_sequence_lengths = np.zeros(num_patient_points)\n",
    "\n",
    "    for i in range(num_patient_points):\n",
    "        fact_length = int(sequence_lengths[i]) - projection_horizon\n",
    "        if encoder_r is not None:\n",
    "            seq2seq_state_inits[i] = encoder_r[i, fact_length - 1]\n",
    "        seq2seq_active_encoder_r[i, :fact_length] = 1.0\n",
    "\n",
    "        seq2seq_active_entries[i] = np.ones(shape=(projection_horizon, 1))\n",
    "        seq2seq_previous_treatments[i] = previous_treatments[i, fact_length - 1:fact_length + projection_horizon - 1, :]\n",
    "        seq2seq_current_treatments[i] = current_treatments[i, fact_length:fact_length + projection_horizon, :]\n",
    "        seq2seq_outputs[i] = outputs[i, fact_length: fact_length + projection_horizon, :]\n",
    "        seq2seq_sequence_lengths[i] = projection_horizon\n",
    "        seq2seq_current_covariates[i] = np.repeat([current_covariates[i, fact_length - 1]], projection_horizon, axis=0)\n",
    "\n",
    "    # Package outputs\n",
    "    seq2seq_data = {\n",
    "        'active_encoder_r': seq2seq_active_encoder_r,\n",
    "        'prev_treatments': seq2seq_previous_treatments,\n",
    "        'current_treatments': seq2seq_current_treatments,\n",
    "        'current_covariates': seq2seq_current_covariates,\n",
    "        'prev_outputs': seq2seq_current_covariates[:, :, :1],\n",
    "        'static_features': seq2seq_current_covariates[:, 0, 1:],\n",
    "        'outputs': seq2seq_outputs,\n",
    "        'sequence_lengths': seq2seq_sequence_lengths,\n",
    "        'active_entries': seq2seq_active_entries,\n",
    "        'unscaled_outputs': seq2seq_outputs * scaling_params['output_stds'] + scaling_params['output_means'],\n",
    "        'patient_types': data['patient_types'],\n",
    "        'patient_ids_all_trajectories': data['patient_ids_all_trajectories'],\n",
    "        'patient_current_t': data['patient_current_t']\n",
    "    }\n",
    "    if encoder_r is not None:\n",
    "        seq2seq_data['init_state'] = seq2seq_state_inits\n",
    "\n",
    "    data_original = deepcopy(data)\n",
    "    data = seq2seq_data\n",
    "    data_shapes = {k: v.shape for k, v in data.items()}\n",
    "\n",
    "    if save_encoder_r and encoder_r is not None:\n",
    "        encoder_r = encoder_r[:, :max_seq_length - projection_horizon, :]\n",
    "\n",
    "    processed_sequential = True\n",
    "\n",
    "    return data\n",
    "\n",
    "# Example initial data setup for process_sequential_test\n",
    "data['prev_treatments'] = np.array([\n",
    "    [[0, 1, 0], [1, 0, 1], [0, 1, 0], [1, 0, 1], [0, 1, 0]],  # Patient 1\n",
    "    [[1, 0, 1], [0, 1, 0], [1, 0, 1], [0, 1, 0], [1, 0, 1]]  # Patient 2\n",
    "])\n",
    "\n",
    "# Adding dummy current_covariates for the example\n",
    "data['current_covariates'] = np.array([\n",
    "    [[0, 0, 0], [1, 1, 1], [2, 2, 2], [3, 3, 3], [4, 4, 4]],  # Patient 1\n",
    "    [[5, 5, 5], [6, 6, 6], [7, 7, 7], [8, 8, 8], [9, 9, 9]]  # Patient 2\n",
    "])\n",
    "\n",
    "# Adding missing keys for the sake of the example\n",
    "data['patient_types'] = np.array([0, 1])\n",
    "data['patient_ids_all_trajectories'] = np.array([101, 102])\n",
    "data['patient_current_t'] = np.array([0, 0])\n",
    "\n",
    "\n",
    "# Running the function\n",
    "processed_data = process_sequential_test(data, projection_horizon)\n",
    "\n",
    "# Printing the results\n",
    "\n",
    "processed_data_shapes = {k: v.shape for k, v in processed_data.items()}\n",
    "processed_data_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'outputs': array([[[ 1,  2,  3],\n",
       "         [ 4,  5,  6],\n",
       "         [ 7,  8,  9],\n",
       "         [10, 11, 12],\n",
       "         [13, 14, 15]],\n",
       " \n",
       "        [[16, 17, 18],\n",
       "         [19, 20, 21],\n",
       "         [22, 23, 24],\n",
       "         [25, 26, 27],\n",
       "         [28, 29, 30]]]),\n",
       " 'prev_outputs': array([[[ 0,  1,  2],\n",
       "         [ 3,  4,  5],\n",
       "         [ 6,  7,  8],\n",
       "         [ 9, 10, 11],\n",
       "         [12, 13, 14]],\n",
       " \n",
       "        [[15, 16, 17],\n",
       "         [18, 19, 20],\n",
       "         [21, 22, 23],\n",
       "         [24, 25, 26],\n",
       "         [27, 28, 29]]]),\n",
       " 'sequence_lengths': array([5, 5]),\n",
       " 'active_entries': array([[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       " \n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]]),\n",
       " 'current_treatments': array([[[0, 0, 0],\n",
       "         [1, 1, 1],\n",
       "         [2, 2, 2],\n",
       "         [3, 3, 3],\n",
       "         [4, 4, 4]],\n",
       " \n",
       "        [[5, 5, 5],\n",
       "         [6, 6, 6],\n",
       "         [7, 7, 7],\n",
       "         [8, 8, 8],\n",
       "         [9, 9, 9]]]),\n",
       " 'prev_treatments': array([[[0, 1, 0],\n",
       "         [1, 0, 1],\n",
       "         [0, 1, 0],\n",
       "         [1, 0, 1],\n",
       "         [0, 1, 0]],\n",
       " \n",
       "        [[1, 0, 1],\n",
       "         [0, 1, 0],\n",
       "         [1, 0, 1],\n",
       "         [0, 1, 0],\n",
       "         [1, 0, 1]]]),\n",
       " 'static_features': array([[0.1, 0.2, 0.3],\n",
       "        [0.4, 0.5, 0.6]]),\n",
       " 'current_covariates': array([[[0, 0, 0],\n",
       "         [1, 1, 1],\n",
       "         [2, 2, 2],\n",
       "         [3, 3, 3],\n",
       "         [4, 4, 4]],\n",
       " \n",
       "        [[5, 5, 5],\n",
       "         [6, 6, 6],\n",
       "         [7, 7, 7],\n",
       "         [8, 8, 8],\n",
       "         [9, 9, 9]]]),\n",
       " 'patient_types': array([0, 1]),\n",
       " 'patient_ids_all_trajectories': array([101, 102]),\n",
       " 'patient_current_t': array([0, 0])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'active_encoder_r': array([[1., 1., 1.],\n",
       "        [1., 1., 1.]]),\n",
       " 'prev_treatments': array([[[1., 0., 1.],\n",
       "         [0., 1., 0.]],\n",
       " \n",
       "        [[0., 1., 0.],\n",
       "         [1., 0., 1.]]]),\n",
       " 'current_treatments': array([[[3., 3., 3.],\n",
       "         [4., 4., 4.]],\n",
       " \n",
       "        [[8., 8., 8.],\n",
       "         [9., 9., 9.]]]),\n",
       " 'current_covariates': array([[[2., 2., 2.],\n",
       "         [2., 2., 2.]],\n",
       " \n",
       "        [[7., 7., 7.],\n",
       "         [7., 7., 7.]]]),\n",
       " 'prev_outputs': array([[[2.],\n",
       "         [2.]],\n",
       " \n",
       "        [[7.],\n",
       "         [7.]]]),\n",
       " 'static_features': array([[2., 2.],\n",
       "        [7., 7.]]),\n",
       " 'outputs': array([[[10., 11., 12.],\n",
       "         [13., 14., 15.]],\n",
       " \n",
       "        [[25., 26., 27.],\n",
       "         [28., 29., 30.]]]),\n",
       " 'sequence_lengths': array([2., 2.]),\n",
       " 'active_entries': array([[[1.],\n",
       "         [1.]],\n",
       " \n",
       "        [[1.],\n",
       "         [1.]]]),\n",
       " 'unscaled_outputs': array([[[ 6. ,  7.5,  9. ],\n",
       "         [ 7.5,  9. , 10.5]],\n",
       " \n",
       "        [[13.5, 15. , 16.5],\n",
       "         [15. , 16.5, 18. ]]]),\n",
       " 'patient_types': array([0, 1]),\n",
       " 'patient_ids_all_trajectories': array([101, 102]),\n",
       " 'patient_current_t': array([0, 0])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
